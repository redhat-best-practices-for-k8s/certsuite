{
  "data": [
    {
      "_id": "61a57d68bfd4a5234d5960dc",
      "alm_examples": [
        {
          "kind": "StorageCluster",
          "metadata": {
            "annotations": {
              "portworx.io/is-openshift": "true"
            },
            "name": "portworx",
            "namespace": "test-operator"
          },
          "spec": {}
        },
        {
          "kind": "StorageNode",
          "metadata": {
            "name": "example",
            "namespace": "test-operator"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/portworx/portworx-certified-bundle@sha256:45853a8612cc9da123094499ac975eb2bc943346a0092fe9d892c5942170e77f",
      "bundle_path_digest": "sha256:45853a8612cc9da123094499ac975eb2bc943346a0092fe9d892c5942170e77f",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2021-11-30T01:24:56.920000+00:00",
      "csv_description": "Portworx-Enterprise is the most widely-used and reliable cloud-native\nstorage solution for production workloads and provides high-availability,\ndata protection and security for containerized applications.\n\nPortworx Enterprise enables you to migrate entire applications, including\ndata, between clusters in a single data center or cloud, or between clouds,\nwith a single kubectl command.\n\nThe cloud native storage and data management platform that enterprises trust\nto manage data in containers now has an operator which simplifies the install,\nconfiguration, upgrades and manages the Portworx Enterprise cluster lifecycle.\n\nLearn more about the Portworx Enterprise\n[the data platform for Kubernetes](https://portworx.com/products/introduction)\n\nTo learn more about the platform features, please visit our\n[product features page](https://portworx.com/products/features)\n\n### About Portworx\n\nPortworx is the solution for running stateful containers in production,\ndesigned with DevOps in mind. With Portworx, users can manage any database\nor stateful service on any infrastructure using any container scheduler,\nincluding Kubernetes, Mesosphere DC/OS, and Docker Swarm. Portworx solves\nthe five most common problems DevOps teams encounter when running stateful\nservices in production: persistence, high availability, data automation,\nsecurity, and support for multiple data stores and infrastructure.\n\n### How to install StorageCluster\n\nTo customize your cluster's configuration (specification), use the\n[Spec Generator](https://central.portworx.com/) from PX-Central.\n\n### Prerequisite\n\nEnsure ports 17001-17020 on worker nodes are reachable from master and other worker nodes.\n\n### Tutorials\n\n* [Portworx Enterprise on Openshift](https://portworx.com/openshift)\n\n* [Stateful applications on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes/application-install-with-kubernetes)\n\n* [Portworx Enterprise on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes)\n\n* [Kafka on Kubernetes](https://portworx.com/kafka-kubernetes)\n\n* [Elastisearch on Kubernetes](https://portworx.com/elasticsearch-kubernetes)\n\n* [PostgreSQL on Kubernetes](https://portworx.com/postgres-kubernetes/)\n\n* [MongoDB on Kubernetes](https://portworx.com/mongodb-kubernetes/)\n\n* [Cassandra on Kubernetes](https://portworx.com/cassandra-kubernetes/)\n\n* [Kubernetes backup and recovery](https://portworx.com/kubernetes-backup/)\n\n* [Disaster Recovery for Kubernetes](https://portworx.com/kubernetes-disaster-recovery/)\n\n### Uninstall\n\nDeleting the StorageCluster object for Portworx cluster does not stop Portworx\nservice running on the nodes, to avoid application downtime.\n\nTo uninstall Portworx completely without wiping the data, you should add the\nfollowing delete strategy to the StorageCluster spec:\n```\nspec:\n  deleteStrategy:\n    type: Uninstall\n```\n**Caution:** To uninstall Portworx and **wipe all the data**, you should use the following\ndelete strategy:\n```\nspec:\n  deleteStrategy:\n    type: UninstallAndWipe\n```\n",
      "csv_display_name": "Portworx Enterprise",
      "csv_metadata_description": "Cloud native storage solution for production workloads",
      "csv_name": "portworx-operator.v1.6.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:30:54.334000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "portworx-certified",
      "provided_apis": [
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "plural": "storagenodes",
          "version": "v1alpha1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "plural": "storageclusters",
          "version": "v1alpha1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47",
          "name": "openstorage-operator-5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47-annotation"
        },
        {
          "digest": "sha256:5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47",
          "name": "portworx-operator"
        }
      ],
      "skip_range": "<1.6.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.6.1",
      "version_original": "1.6.1"
    },
    {
      "_id": "61a57d72bfd4a5234d5960dd",
      "alm_examples": [
        {
          "kind": "PostgresCluster",
          "metadata": {
            "name": "example"
          },
          "spec": {
            "instances": [
              {
                "dataVolumeClaimSpec": {
                  "accessModes": [
                    "ReadWriteOnce"
                  ],
                  "resources": {
                    "requests": {
                      "storage": "1Gi"
                    }
                  }
                },
                "replicas": 1
              }
            ],
            "postgresVersion": 13
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/crunchydata/postgres-operator-bundle@sha256:98d0ab361f4d3d22de06248949887e6a9eb8b807cd6a709a74a94c5c895fcbb2",
      "bundle_path_digest": "sha256:98d0ab361f4d3d22de06248949887e6a9eb8b807cd6a709a74a94c5c895fcbb2",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "v5",
      "creation_date": "2021-11-30T01:25:06.335000+00:00",
      "csv_description": "[PGO](https://github.com/CrunchyData/postgres-operator), the\n[Postgres Operator](https://github.com/CrunchyData/postgres-operator) from\n[Crunchy Data](https://www.crunchydata.com), gives you a **declarative Postgres** solution that\nautomatically manages your [PostgreSQL](https://www.postgresql.org) clusters.\n\nDesigned for your GitOps workflows, it is [easy to get started](https://access.crunchydata.com/documentation/postgres-operator/v5/quickstart/)\nwith Postgres on Kubernetes with PGO. Within a few moments, you can have a production grade Postgres\ncluster complete with high availability, disaster recovery, and monitoring, all over secure TLS communications.\nEven better, PGO lets you easily customize your Postgres cluster to tailor it to your workload!\n\nWith conveniences like cloning Postgres clusters to using rolling updates to roll out disruptive\nchanges with minimal downtime, PGO is ready to support your Postgres data at every stage of your\nrelease pipeline. Built for resiliency and uptime, PGO will keep your desired Postgres in a desired\nstate so you do not need to worry about it.\n\nPGO is developed with many years of production experience in automating Postgres management on\nKubernetes, providing a seamless cloud native Postgres solution to keep your data always available.\n\n- **PostgreSQL Cluster Provisioning**: [Create, Scale, & Delete PostgreSQL clusters with ease][provisioning],\n  while fully customizing your Pods and PostgreSQL configuration!\n- **High-Availability**: Safe, automated failover backed by a [distributed consensus based high-availability solution][high-availability].\n  Uses [Pod Anti-Affinity][k8s-anti-affinity] to help resiliency; you can configure how aggressive this can be!\n  Failed primaries automatically heal, allowing for faster recovery time. You can even create regularly scheduled\n  backups as well and set your backup retention policy\n- **Disaster Recovery**: [Backups][backups] and [restores][disaster-recovery] leverage the open source [pgBackRest][] utility and\n  [includes support for full, incremental, and differential backups as well as efficient delta restores][backups].\n  Set how long you want your backups retained for. Works great with very large databases!\n- **Monitoring**: [Track the health of your PostgreSQL clusters][monitoring] using the open source [pgMonitor][] library.\n- **Clone**: [Create new clusters from your existing clusters or backups][clone] with efficient data cloning.\n- **TLS**: All connections are over [TLS][tls]. You can also [bring your own TLS infrastructure][tls] if you do not want to use the provided defaults.\n- **Connection Pooling**: Advanced [connection pooling][pool] support using [pgBouncer][].\n- **Affinity and Tolerations**: Have your PostgreSQL clusters deployed to [Kubernetes Nodes][k8s-nodes] of your preference.\n  Set your [pod anti-affinity][k8s-anti-affinity], node affinity, Pod tolerations and more rules to customize your deployment topology!\n- **Full Customizability**: Crunchy PostgreSQL for Kubernetes makes it easy to get your own PostgreSQL-as-a-Service up and running\n  and fully customize your deployments, including:\n    - Choose the resources for your Postgres cluster: [container resources and storage size][resize-cluster]. [Resize at any time][resize-cluster] with minimal disruption.\n    - Use your own container image repository, including support `imagePullSecrets` and private repositories\n    - [Customize your PostgreSQL configuration][customize-cluster]\n\nand much more!\n\n[backups]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/backups/\n[clone]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/disaster-recovery/#clone-a-postgres-cluster\n[customize-cluster]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/customize-cluster/\n[disaster-recovery]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/disaster-recovery/\n[high-availability]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/high-availability/\n[monitoring]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/monitoring/\n[pool]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/connection-pooling/\n[provisioning]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/create-cluster/\n[resize-cluster]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/resize-cluster/\n[tls]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/customize-cluster/#customize-tls\n\n[k8s-anti-affinity]: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n[k8s-nodes]: https://kubernetes.io/docs/concepts/architecture/nodes/\n\n[pgBackRest]: https://www.pgbackrest.org\n[pgBouncer]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/connection-pooling/\n[pgMonitor]: https://github.com/CrunchyData/pgmonitor\n\n\n## Post-Installation\n\n### Tutorial\n\nWant to [learn more about the PostgreSQL Operator][tutorial]? Browse through the [tutorial][] to learn more about what you can do!\n\n[tutorial]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial",
      "csv_display_name": "Crunchy Postgres for Kubernetes",
      "csv_metadata_description": "Production Postgres Made Easy",
      "csv_name": "postgresoperator.v5.0.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:31:00.533000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "crunchy-postgres-operator",
      "provided_apis": [
        {
          "group": "postgres-operator.crunchydata.com",
          "kind": "PostgresCluster",
          "plural": "postgresclusters",
          "version": "v1beta1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:18277dfef37345dd8f08f2e47ceecb99e409efadf926d624a57673ac7491818d",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:18277dfef37345dd8f08f2e47ceecb99e409efadf926d624a57673ac7491818d",
          "name": "postgres-operator-18277dfef37345dd8f08f2e47ceecb99e409efadf926d624a57673ac7491818d-annotation"
        },
        {
          "digest": "sha256:18277dfef37345dd8f08f2e47ceecb99e409efadf926d624a57673ac7491818d",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:18277dfef37345dd8f08f2e47ceecb99e409efadf926d624a57673ac7491818d",
          "name": "operator"
        },
        {
          "digest": "sha256:0fa5f4c6031e690838fe40eb618554f0c1878c14f1ab5d97999cc942177eb5ea",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbackrest@sha256:0fa5f4c6031e690838fe40eb618554f0c1878c14f1ab5d97999cc942177eb5ea",
          "name": "pgbackrest"
        },
        {
          "digest": "sha256:4a3b7bcf6461b4548eb124e7ec834f38e937dad4bd1338de27022bd9a3b13f5d",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbouncer@sha256:4a3b7bcf6461b4548eb124e7ec834f38e937dad4bd1338de27022bd9a3b13f5d",
          "name": "pgbouncer"
        },
        {
          "digest": "sha256:41b4adf29237184cef74380367ac55397d6df55a98866489beb396bdb2107cdf",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-exporter@sha256:41b4adf29237184cef74380367ac55397d6df55a98866489beb396bdb2107cdf",
          "name": "pgexporter"
        },
        {
          "digest": "sha256:155ddaaefb03e4bd3410881da27fcc5fa40dcfe7fc9195e1a563facecaae4356",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-ha@sha256:155ddaaefb03e4bd3410881da27fcc5fa40dcfe7fc9195e1a563facecaae4356",
          "name": "postgres_12"
        },
        {
          "digest": "sha256:fd9a0e9ecd3913210bdcb49d51d7d225fd2920c8235d703f2a2d629634865e1e",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-ha@sha256:fd9a0e9ecd3913210bdcb49d51d7d225fd2920c8235d703f2a2d629634865e1e",
          "name": "postgres_13"
        },
        {
          "digest": "sha256:d049d4cd94d7c810f5ca092e148a880b0c4b2283e55e60689dea49b6de967cf2",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis-ha@sha256:d049d4cd94d7c810f5ca092e148a880b0c4b2283e55e60689dea49b6de967cf2",
          "name": "postgres_12_gis_2.5"
        },
        {
          "digest": "sha256:d2a1f86dfedaf48efe6a9ade9ae15d901bf67792fa17254714cdd2b9002280a6",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis-ha@sha256:d2a1f86dfedaf48efe6a9ade9ae15d901bf67792fa17254714cdd2b9002280a6",
          "name": "postgres_12_gis_3.0"
        },
        {
          "digest": "sha256:d2a2e5cf820cb037c3f167515c9bee80b4d260fc86fe14c18ca794997941246f",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis-ha@sha256:d2a2e5cf820cb037c3f167515c9bee80b4d260fc86fe14c18ca794997941246f",
          "name": "postgres_13_gis_3.0"
        },
        {
          "digest": "sha256:3dc85b5fb89d3481e17ab148c06fb525c5fba0312b79f4707edf308c598ccc61",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis-ha@sha256:3dc85b5fb89d3481e17ab148c06fb525c5fba0312b79f4707edf308c598ccc61",
          "name": "postgres_13_gis_3.1"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "5.0.2",
      "version_original": "5.0.2"
    },
    {
      "_id": "61a57d7ac17162a20c1c68a3",
      "alm_examples": [
        {
          "kind": "PostgresCluster",
          "metadata": {
            "name": "example"
          },
          "spec": {
            "instances": [
              {
                "dataVolumeClaimSpec": {
                  "accessModes": [
                    "ReadWriteOnce"
                  ],
                  "resources": {
                    "requests": {
                      "storage": "1Gi"
                    }
                  }
                },
                "replicas": 1
              }
            ],
            "postgresVersion": 13
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/crunchydata/postgres-operator-bundle@sha256:dc5de09dc39f38932e2490b125b9e22183770ed6d1bd9d62c7bc429b1f50f345",
      "bundle_path_digest": "sha256:dc5de09dc39f38932e2490b125b9e22183770ed6d1bd9d62c7bc429b1f50f345",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "v5",
      "creation_date": "2021-11-30T01:25:14.644000+00:00",
      "csv_description": "[PGO](https://github.com/CrunchyData/postgres-operator), the\n[Postgres Operator](https://github.com/CrunchyData/postgres-operator) from\n[Crunchy Data](https://www.crunchydata.com), gives you a **declarative Postgres** solution that\nautomatically manages your [PostgreSQL](https://www.postgresql.org) clusters.\n\nDesigned for your GitOps workflows, it is [easy to get started](https://access.crunchydata.com/documentation/postgres-operator/v5/quickstart/)\nwith Postgres on Kubernetes with PGO. Within a few moments, you can have a production grade Postgres\ncluster complete with high availability, disaster recovery, and monitoring, all over secure TLS communications.\nEven better, PGO lets you easily customize your Postgres cluster to tailor it to your workload!\n\nWith conveniences like cloning Postgres clusters to using rolling updates to roll out disruptive\nchanges with minimal downtime, PGO is ready to support your Postgres data at every stage of your\nrelease pipeline. Built for resiliency and uptime, PGO will keep your desired Postgres in a desired\nstate so you do not need to worry about it.\n\nPGO is developed with many years of production experience in automating Postgres management on\nKubernetes, providing a seamless cloud native Postgres solution to keep your data always available.\n\n- **PostgreSQL Cluster Provisioning**: [Create, Scale, & Delete PostgreSQL clusters with ease][provisioning],\n  while fully customizing your Pods and PostgreSQL configuration!\n- **High-Availability**: Safe, automated failover backed by a [distributed consensus based high-availability solution][high-availability].\n  Uses [Pod Anti-Affinity][k8s-anti-affinity] to help resiliency; you can configure how aggressive this can be!\n  Failed primaries automatically heal, allowing for faster recovery time. You can even create regularly scheduled\n  backups as well and set your backup retention policy\n- **Disaster Recovery**: [Backups][backups] and [restores][disaster-recovery] leverage the open source [pgBackRest][] utility and\n  [includes support for full, incremental, and differential backups as well as efficient delta restores][backups].\n  Set how long you want your backups retained for. Works great with very large databases!\n- **Monitoring**: [Track the health of your PostgreSQL clusters][monitoring] using the open source [pgMonitor][] library.\n- **Clone**: [Create new clusters from your existing clusters or backups][clone] with efficient data cloning.\n- **TLS**: All connections are over [TLS][tls]. You can also [bring your own TLS infrastructure][tls] if you do not want to use the provided defaults.\n- **Connection Pooling**: Advanced [connection pooling][pool] support using [pgBouncer][].\n- **Affinity and Tolerations**: Have your PostgreSQL clusters deployed to [Kubernetes Nodes][k8s-nodes] of your preference.\n  Set your [pod anti-affinity][k8s-anti-affinity], node affinity, Pod tolerations and more rules to customize your deployment topology!\n- **Full Customizability**: Crunchy PostgreSQL for Kubernetes makes it easy to get your own PostgreSQL-as-a-Service up and running\n  and fully customize your deployments, including:\n    - Choose the resources for your Postgres cluster: [container resources and storage size][resize-cluster]. [Resize at any time][resize-cluster] with minimal disruption.\n    - Use your own container image repository, including support `imagePullSecrets` and private repositories\n    - [Customize your PostgreSQL configuration][customize-cluster]\n\nand much more!\n\n[backups]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/backups/\n[clone]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/disaster-recovery/#clone-a-postgres-cluster\n[customize-cluster]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/customize-cluster/\n[disaster-recovery]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/disaster-recovery/\n[high-availability]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/high-availability/\n[monitoring]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/monitoring/\n[pool]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/connection-pooling/\n[provisioning]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/create-cluster/\n[resize-cluster]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/resize-cluster/\n[tls]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/customize-cluster/#customize-tls\n\n[k8s-anti-affinity]: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n[k8s-nodes]: https://kubernetes.io/docs/concepts/architecture/nodes/\n\n[pgBackRest]: https://www.pgbackrest.org\n[pgBouncer]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/connection-pooling/\n[pgMonitor]: https://github.com/CrunchyData/pgmonitor\n\n\n## Post-Installation\n\n### Tutorial\n\nWant to [learn more about the PostgreSQL Operator][tutorial]? Browse through the [tutorial][] to learn more about what you can do!\n\n[tutorial]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial",
      "csv_display_name": "Crunchy Postgres for Kubernetes",
      "csv_metadata_description": "Production Postgres Made Easy",
      "csv_name": "postgresoperator.v5.0.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:31:02.608000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "crunchy-postgres-operator",
      "provided_apis": [
        {
          "group": "postgres-operator.crunchydata.com",
          "kind": "PostgresCluster",
          "plural": "postgresclusters",
          "version": "v1beta1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:f5ec30082ce775b5a2be9800e389263ecdf4c32a56c6c41874bac6682913559b",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:f5ec30082ce775b5a2be9800e389263ecdf4c32a56c6c41874bac6682913559b",
          "name": "postgres-operator-f5ec30082ce775b5a2be9800e389263ecdf4c32a56c6c41874bac6682913559b-annotation"
        },
        {
          "digest": "sha256:f5ec30082ce775b5a2be9800e389263ecdf4c32a56c6c41874bac6682913559b",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:f5ec30082ce775b5a2be9800e389263ecdf4c32a56c6c41874bac6682913559b",
          "name": "operator"
        },
        {
          "digest": "sha256:eb610233da96ee06f0bec52dec4f50cc7d3bdb191cd6ac11ae8e0d112bf5028e",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbackrest@sha256:eb610233da96ee06f0bec52dec4f50cc7d3bdb191cd6ac11ae8e0d112bf5028e",
          "name": "pgbackrest"
        },
        {
          "digest": "sha256:0b9560dc5df40eb9207c152021536404922e1fced7dcae14aea229b7f4eb0ee0",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbouncer@sha256:0b9560dc5df40eb9207c152021536404922e1fced7dcae14aea229b7f4eb0ee0",
          "name": "pgbouncer"
        },
        {
          "digest": "sha256:e6bff80f2244dd6f469d642bca8117bf758d7529812df0b0a078cc8e0632b929",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-exporter@sha256:e6bff80f2244dd6f469d642bca8117bf758d7529812df0b0a078cc8e0632b929",
          "name": "pgexporter"
        },
        {
          "digest": "sha256:74e35614839ae674ee210e3850dee01e50c5d3d218eeee2d4d33e778db76ffbc",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:74e35614839ae674ee210e3850dee01e50c5d3d218eeee2d4d33e778db76ffbc",
          "name": "postgres_12"
        },
        {
          "digest": "sha256:d74ab0bee968613ab93310c78f7f8b7fc2d4ebc2a2da5835681584d25acbd2fe",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:d74ab0bee968613ab93310c78f7f8b7fc2d4ebc2a2da5835681584d25acbd2fe",
          "name": "postgres_13"
        },
        {
          "digest": "sha256:45778ce94cb7f95751c01eaf084af9d1a5cd2c7c0e359de39ff182dc0c56f909",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:45778ce94cb7f95751c01eaf084af9d1a5cd2c7c0e359de39ff182dc0c56f909",
          "name": "postgres_14"
        },
        {
          "digest": "sha256:c084654b6364288a43a2e07881c91aa86e85db6f3cd0d5721926af137f1b2e17",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:c084654b6364288a43a2e07881c91aa86e85db6f3cd0d5721926af137f1b2e17",
          "name": "postgres_12_gis_2.5"
        },
        {
          "digest": "sha256:2297070eb46e37cc28962354e9da9252eec12050c92f05fab943e1a88336a7d6",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:2297070eb46e37cc28962354e9da9252eec12050c92f05fab943e1a88336a7d6",
          "name": "postgres_12_gis_3.0"
        },
        {
          "digest": "sha256:2228446a660e766bc02443ca1c0b0e4874ec9c986c6b4d3921642dc2d67ec17b",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:2228446a660e766bc02443ca1c0b0e4874ec9c986c6b4d3921642dc2d67ec17b",
          "name": "postgres_13_gis_3.0"
        },
        {
          "digest": "sha256:c40568be23d2ae475e6116b64a1181afc046a55e7b8085354339ac6da20fb7e0",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:c40568be23d2ae475e6116b64a1181afc046a55e7b8085354339ac6da20fb7e0",
          "name": "postgres_13_gis_3.1"
        },
        {
          "digest": "sha256:6c2860dda07fdf12ac9fb24a71b6cd6ebb31d1b83a36f9736832a8e24d29ca78",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:6c2860dda07fdf12ac9fb24a71b6cd6ebb31d1b83a36f9736832a8e24d29ca78",
          "name": "postgres_14_gis_3.1"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "5.0.3",
      "version_original": "5.0.3"
    },
    {
      "_id": "61a57d833e9240fca360f564",
      "alm_examples": [
        {
          "kind": "RuntimeComponent",
          "metadata": {
            "name": "runtimecomponent-sample"
          },
          "spec": {
            "applicationImage": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
            "expose": true,
            "replicas": 1,
            "service": {
              "port": 9080
            }
          }
        },
        {
          "kind": "RuntimeOperation",
          "metadata": {
            "name": "runtimeoperation-sample"
          },
          "spec": {
            "command": [
              "./your_script.sh"
            ],
            "containerName": "app",
            "podName": "Specify_Pod_Name_Here"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/runtime-component-operator-bundle@sha256:65cc8aa40608b76956ff8c19316b63f805d7a28e8d7697b9ea1d427888a2ccdf",
      "bundle_path_digest": "sha256:65cc8aa40608b76956ff8c19316b63f805d7a28e8d7697b9ea1d427888a2ccdf",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "beta2",
      "creation_date": "2021-11-30T01:25:23.246000+00:00",
      "csv_description": "This advanced Operator is capable of deploying any runtime component image with consistent, production-grade QoS. It enables enterprise architects to govern the way their applications get deployed & managed in the cluster, while dramatically reducing the learning curve for developers to deploy into Kubernetes - allowing them to focus on writing the code!\nHere are some key features:\n\n#### Application Lifecyle\nYou can deploy your runtime component container by either pointing to a container image, or an OpenShift ImageStream. When using an ImageStream the Operator will watch for any updates and will re-deploy the modified image.\n\n#### Custom RBAC\nThis Operator is capable of using a custom ServiceAccount from the caller, allowing it to follow RBAC restrictions. By default it creates a ServiceAccount if one is not specified, which can also be bound with specific roles.\n\n#### Environment Configuration\nYou can configure a variety of artifacts with your deployment, such as: labels, annotations, and environment variables from a ConfigMap, a Secret or a value.\n\n#### Routing\nExpose your application to external users via a single toggle to create a Route on OpenShift or an Ingress on other Kubernetes environments. Advanced configuration, such as TLS settings, are also easily enabled.  Expiring Route certificates are re-issued.\n\n#### High Availability via Horizontal Pod Autoscaling\nRun multiple instances of your application for high availability. Either specify a static number of replicas or easily configure horizontal auto scaling to create (and delete) instances based on resource consumption.\n\n#### Persistence and advanced storage\nEnable persistence for your application by specifying simple requirements: just tell us the size of the storage and where you would like it to be mounted and We will create and manage that storage for you.\nThis toggles a StatefulSet resource instead of a Deployment resource, so your container can recover transactions and state upon a pod restart.\nWe offer an advanced mode where the user specifies a built-in PersistentVolumeClaim, allowing them to configure many details of the persistent volume, such as its storage class and access mode.\n\n#### Service Binding\nEasily bind to available services in your cluster.  Your runtime components can expose and consume other services by simply specifying the target endpoinds: we take care of the heavy lifting such as creating k8s Secrets, injecting them into your container and watching for any changes in configuration!  This way your applications can dynamically reconnect to its required services without any intervention or interruption.\n\n#### Exposing metrics to Prometheus\nThe Runtime Component Operator exposes the runtime container's metrics via the [Prometheus Operator](https://operatorhub.io/operator/prometheus).\nUsers can pick between a basic mode, where they simply specify the label that Prometheus is watching to scrape the metrics from the container, or they can specify the full `ServiceMonitor` spec embedded into the RuntimeComponent's `spec.monitoring` key controlling things like the poll internal and security credentials.\n\n#### Easily mount logs and transaction directories\nIf you need to mount the logs and transaction data from your runtime component to an external volume such as NFS (or any storage supported in your cluster), simply add the following (customizing the folder location and size) to your RuntimeComponent CR:\n``` storage: size: 2Gi mountPath: \"/logs\" ```\n\n#### Integration with OpenShift Serverless\nDeploy your serverless runtime component using a single toggle.  The Operator will convert all of its generated resources into [Knative](https://knative.dev) resources, allowing your pod to automatically scale to 0 when it is idle.\n\n#### Integration with OpenShift's Topology UI\nWe set the corresponding labels to support OpenShift's Developer Topology UI, which allows you to visualize your entire set of deployments and how they are connected.\n\nSee our [**documentation**](https://github.com/application-stacks/runtime-component-operator/tree/main/doc/) for more information.\n",
      "csv_display_name": "Runtime Component",
      "csv_metadata_description": "Deploys any runtime component with dynamic and auto-tuning configuration",
      "csv_name": "runtime-component.v0.8.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:31:09.992000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "runtime-component-operator-certified",
      "provided_apis": [
        {
          "group": "rc.app.stacks",
          "kind": "RuntimeComponent",
          "plural": "runtimecomponents",
          "version": "v1beta2"
        },
        {
          "group": "rc.app.stacks",
          "kind": "RuntimeOperation",
          "plural": "runtimeoperations",
          "version": "v1beta2"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:febfbe4a75018bfdb1f3cb13caaa3e5e321bf9f8ac5ca1405dae96f9798bde2b",
          "image": "registry.connect.redhat.com/ibm/runtime-component-operator@sha256:febfbe4a75018bfdb1f3cb13caaa3e5e321bf9f8ac5ca1405dae96f9798bde2b",
          "name": "runtime-component-operator-febfbe4a75018bfdb1f3cb13caaa3e5e321bf9f8ac5ca1405dae96f9798bde2b-annotation"
        },
        {
          "digest": "sha256:febfbe4a75018bfdb1f3cb13caaa3e5e321bf9f8ac5ca1405dae96f9798bde2b",
          "image": "registry.connect.redhat.com/ibm/runtime-component-operator@sha256:febfbe4a75018bfdb1f3cb13caaa3e5e321bf9f8ac5ca1405dae96f9798bde2b",
          "name": "manager"
        },
        {
          "digest": "sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "image": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "name": "open-liberty-samples-8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "0.8.0",
      "version_original": "0.8.0"
    },
    {
      "_id": "61a57d8bbfd4a5234d5960e0",
      "alm_examples": [
        {
          "kind": "SANStorageCSI",
          "metadata": {
            "name": "sanstoragecsi"
          },
          "spec": {
            "driverName": "san.csi.nec.com",
            "images": {
              "csiDriver": "",
              "externalAttacher": "registry.redhat.io/openshift4/ose-csi-external-attacher@sha256:92cb1a244497e71cfc27437f07b95645753f64f7f994db20bf9e5cbfb89ae083",
              "externalProvisioner": "registry.redhat.io/openshift4/ose-csi-external-provisioner@sha256:faefca15575552112c8463ade19ebf5f6ce27a65b9e7286ea74fd6a31a2f2715",
              "livenessProbe": "registry.redhat.io/openshift4/ose-csi-livenessprobe@sha256:241e288cf83443304834af837f9f71a6216c038dd27196748184aa95790b75fe",
              "nodeRegistrar": "registry.redhat.io/openshift4/ose-csi-node-driver-registrar@sha256:dcba3ce367bd546c84d412f57589cd6d2fcde6a882791048ed13f1438b6453c0"
            },
            "parameters": {
              "controller": {
                "logLevel": 5
              },
              "node": {
                "livenessProbePort": 9808,
                "logLevel": 5,
                "maxVolumesPerNode": 1024
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/nec/sanstoragecsi-operator-bundle@sha256:a547f2b1018aebda3dadf2599d082dd7cfebc3e255571634d97b3b3f6161436e",
      "bundle_path_digest": "sha256:a547f2b1018aebda3dadf2599d082dd7cfebc3e255571634d97b3b3f6161436e",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2021-11-30T01:25:31.457000+00:00",
      "csv_description": "This operator deploys the NEC Storage M Series CSI Driver on OpenShift Container Platform.\n\nNEC Storage M Series CSI Driver provides persistent storage for stateful applications using NEC Storage M Series.\nPlease refer to the documentation of the NEC Storage M Series CSI Driver for detail information about supported NEC Storage Platforms and supported CSI features.\n",
      "csv_display_name": "NEC Storage M Series CSI Operator",
      "csv_metadata_description": "An operator for managing the NEC Storage M Series CSI Driver",
      "csv_name": "sanstoragecsi-operator-bundle.v1.0.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:31:14.826000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "sanstoragecsi-operator-bundle",
      "provided_apis": [
        {
          "group": "csi.nec.com",
          "kind": "SANStorageCSI",
          "plural": "sanstoragecsis",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:1e385777c7ce4bfd48902fbbb8023a6eba3f5dff4dc08e200450bc6f0bcb595c",
          "image": "registry.connect.redhat.com/nec/sanstoragecsi-operator@sha256:1e385777c7ce4bfd48902fbbb8023a6eba3f5dff4dc08e200450bc6f0bcb595c",
          "name": "sanstoragecsi-operator-bundle"
        },
        {
          "digest": "sha256:dcba3ce367bd546c84d412f57589cd6d2fcde6a882791048ed13f1438b6453c0",
          "image": "registry.redhat.io/openshift4/ose-csi-node-driver-registrar@sha256:dcba3ce367bd546c84d412f57589cd6d2fcde6a882791048ed13f1438b6453c0",
          "name": "ose-csi-node-driver-registrar-dcba3ce367bd546c84d412f57589cd6d2fcde6a882791048ed13f1438b6453c0-annotation"
        },
        {
          "digest": "sha256:241e288cf83443304834af837f9f71a6216c038dd27196748184aa95790b75fe",
          "image": "registry.redhat.io/openshift4/ose-csi-livenessprobe@sha256:241e288cf83443304834af837f9f71a6216c038dd27196748184aa95790b75fe",
          "name": "ose-csi-livenessprobe-241e288cf83443304834af837f9f71a6216c038dd27196748184aa95790b75fe-annotation"
        },
        {
          "digest": "sha256:faefca15575552112c8463ade19ebf5f6ce27a65b9e7286ea74fd6a31a2f2715",
          "image": "registry.redhat.io/openshift4/ose-csi-external-provisioner@sha256:faefca15575552112c8463ade19ebf5f6ce27a65b9e7286ea74fd6a31a2f2715",
          "name": "ose-csi-external-provisioner-faefca15575552112c8463ade19ebf5f6ce27a65b9e7286ea74fd6a31a2f2715-annotation"
        },
        {
          "digest": "sha256:92cb1a244497e71cfc27437f07b95645753f64f7f994db20bf9e5cbfb89ae083",
          "image": "registry.redhat.io/openshift4/ose-csi-external-attacher@sha256:92cb1a244497e71cfc27437f07b95645753f64f7f994db20bf9e5cbfb89ae083",
          "name": "ose-csi-external-attacher-92cb1a244497e71cfc27437f07b95645753f64f7f994db20bf9e5cbfb89ae083-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.0.0",
      "version_original": "1.0.0"
    },
    {
      "_id": "61a57d93bfd4a5234d5960e2",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:e12119fa5cca31b75f9be94ea70e1980b7fe5da1783475a073ac7ade2fbb360b",
      "bundle_path_digest": "sha256:e12119fa5cca31b75f9be94ea70e1980b7fe5da1783475a073ac7ade2fbb360b",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.20",
      "creation_date": "2021-11-30T01:25:39.409000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.20.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-04T14:31:25.699000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:379efe0c2541e1080aae564eb0ebb697b0995fc447623c037a37b8bcfb3a4e9a",
          "image": "quay.io/tigera/operator@sha256:379efe0c2541e1080aae564eb0ebb697b0995fc447623c037a37b8bcfb3a4e9a",
          "name": "operator-379efe0c2541e1080aae564eb0ebb697b0995fc447623c037a37b8bcfb3a4e9a-annotation"
        },
        {
          "digest": "sha256:379efe0c2541e1080aae564eb0ebb697b0995fc447623c037a37b8bcfb3a4e9a",
          "image": "quay.io/tigera/operator@sha256:379efe0c2541e1080aae564eb0ebb697b0995fc447623c037a37b8bcfb3a4e9a",
          "name": "tigera-operator"
        }
      ],
      "skip_range": "<1.20.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.20.1",
      "version_original": "1.20.1"
    },
    {
      "_id": "61a57d9bc17162a20c1c68a7",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:953d43c1d576ca70a0856d9f0cf8bd2a2e98e7fcb9e2fbff8cf5a214eae220aa",
      "bundle_path_digest": "sha256:953d43c1d576ca70a0856d9f0cf8bd2a2e98e7fcb9e2fbff8cf5a214eae220aa",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.20",
      "creation_date": "2021-11-30T01:25:47.799000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.20.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-04T14:31:27.765000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:078961af067649277ecfb6473a0ab9f098847b73821fd6b7fd87cc31cd733c98",
          "image": "quay.io/tigera/operator@sha256:078961af067649277ecfb6473a0ab9f098847b73821fd6b7fd87cc31cd733c98",
          "name": "operator-078961af067649277ecfb6473a0ab9f098847b73821fd6b7fd87cc31cd733c98-annotation"
        },
        {
          "digest": "sha256:078961af067649277ecfb6473a0ab9f098847b73821fd6b7fd87cc31cd733c98",
          "image": "quay.io/tigera/operator@sha256:078961af067649277ecfb6473a0ab9f098847b73821fd6b7fd87cc31cd733c98",
          "name": "tigera-operator"
        }
      ],
      "skip_range": "<1.20.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.20.2",
      "version_original": "1.20.2"
    },
    {
      "_id": "61a57da33e9240fca360f568",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:af132b6324918a5acfd1523acce674552d62035314bbb55f92ef11ea3081a09d",
      "bundle_path_digest": "sha256:af132b6324918a5acfd1523acce674552d62035314bbb55f92ef11ea3081a09d",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.20",
      "creation_date": "2021-11-30T01:25:55.818000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.20.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-04T14:31:29.964000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:b9c32848a367986af987793cef0ca7b656d235f689d57270027225f8a0dee068",
          "image": "quay.io/tigera/operator@sha256:b9c32848a367986af987793cef0ca7b656d235f689d57270027225f8a0dee068",
          "name": "operator-b9c32848a367986af987793cef0ca7b656d235f689d57270027225f8a0dee068-annotation"
        },
        {
          "digest": "sha256:b9c32848a367986af987793cef0ca7b656d235f689d57270027225f8a0dee068",
          "image": "quay.io/tigera/operator@sha256:b9c32848a367986af987793cef0ca7b656d235f689d57270027225f8a0dee068",
          "name": "tigera-operator"
        }
      ],
      "skip_range": "<1.20.3",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.20.3",
      "version_original": "1.20.3"
    },
    {
      "_id": "61a57dac3e9240fca360f569",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:4d0d814fcfeb628aae8a05cb7a0a416ae85395197950085c907b6cdcf2fb4317",
      "bundle_path_digest": "sha256:4d0d814fcfeb628aae8a05cb7a0a416ae85395197950085c907b6cdcf2fb4317",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.20",
      "creation_date": "2021-11-30T01:26:04.448000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.20.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-04T14:31:32.258000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:bd93e66be5cfbc123fe4e8c3f6e8ddf7654217bf26136f06dcf23f28b53063d2",
          "image": "quay.io/tigera/operator@sha256:bd93e66be5cfbc123fe4e8c3f6e8ddf7654217bf26136f06dcf23f28b53063d2",
          "name": "operator-bd93e66be5cfbc123fe4e8c3f6e8ddf7654217bf26136f06dcf23f28b53063d2-annotation"
        },
        {
          "digest": "sha256:bd93e66be5cfbc123fe4e8c3f6e8ddf7654217bf26136f06dcf23f28b53063d2",
          "image": "quay.io/tigera/operator@sha256:bd93e66be5cfbc123fe4e8c3f6e8ddf7654217bf26136f06dcf23f28b53063d2",
          "name": "tigera-operator"
        }
      ],
      "skip_range": "<1.20.4",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.20.4",
      "version_original": "1.20.4"
    },
    {
      "_id": "61a57db4c17162a20c1c68a8",
      "alm_examples": [
        {
          "kind": "VfunctionServer",
          "metadata": {
            "labels": {
              "app.kubernetes.io/instance": "vfunction-server",
              "app.kubernetes.io/managed-by": "operator",
              "app.kubernetes.io/name": "vfunction",
              "name": "vfunction"
            },
            "name": "example-vfunction-server",
            "namespace": "vfunction"
          },
          "spec": {
            "admin": {
              "email": "admin@mycompany.com",
              "name": "Admin",
              "password": "Password1!"
            },
            "host": "http://my.domain.com",
            "measurements": {
              "auto_scaling": "No",
              "max_number_of_services": "10",
              "min_number_of_services": "2"
            },
            "org_name": "MyCompany",
            "smtp": {
              "identity": "",
              "password": "",
              "url": "",
              "user": ""
            },
            "tls": {
              "crt": "",
              "key": ""
            },
            "upgrade": "Daily"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/vfunction/vfunction-server-operator-bundle@sha256:75cb80116afa46260ad077967679040ee495535933a640f152ed2e2012226d13",
      "bundle_path_digest": "sha256:75cb80116afa46260ad077967679040ee495535933a640f152ed2e2012226d13",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2021-11-30T01:26:12.934000+00:00",
      "csv_description": "\n## Introduction\n\n[vFunction](https://www.vfunction.com/) is a cloud-native modernization platform that combines dynamic and static code analysis, machine learning, and automation to automatically identify and extract services from existing applications. vFunction is the only platform purpose-built for modernization of Java applications.\n\nThe vFunction modernization process starts by learning the running monolithic application, and surfacing the interdependencies within it. Using AI, the platform analyzes and identifies services that can be separated from the application. This decomposition can present a range of micro, mini, or even macro services, depending on your application environment, each being an independently deployable and scalable application component.\n\nvFunction automates the extraction of these services, enabling you to modernize your monolith, quickly and easily.\n\n## The vFunction platform\n\nThe platform consists of 3 basic components; the server, the controller package, and a tools package. The server runs as an operand on an OpenShift environment. The controller package is installed on the machine that runs the monolithic application which can be either a Linux or a Windows machine, and the tools are run on a development machine, with access to the code of the monolithic application.\n\nThe controller package consists of three elements: the vFunction agent, that collects data during the dynamic analysis phase; the vFunction Viper application, that performs static analysis on the binaries of the application; and the vFunction controller that handles all the communication between the agent, Viper, and the vFunction server.\n\nThe vFunction agent is a mix of a Java and native agent, and needs to run on the JVM that is currently running your application. [Refer to the vFunction OOB Support Matrix document](https://drive.google.com/file/d/1ccq8LFab1FrYAimDUxwgjiCOdk4QuVzs/view) for a list of supported application servers and JVMs.\n\nThis operator installs a vFunction server instance to be connected later with one or more vFunction controllers installed on your application machine(s).\n\n## Before You Start\n\nThe vFunction operator requires a Red Hat OpenShift Kubernetes Application Platform 4.x.\n\nThe cluster recommended configuration (which is the same as the minimal one) should consist of:\n\n- *1 master node*\n\n- *1 worker node*\n\n- *Storage capacity enough for dynamically provision 2 PVs of 50G each*\n\n- *A default StorageClass configured*\n\nvFunction doesn\u2019t provide any encryption mechanism for data stored on any attached storage. If required, encryption can be achieved by the client by using its own external means on the storage itself.\n\nvFunction supports backup of all critical data as part of the application. Nevertheless, for complete backup of entire data it is recommended that the client apply its own storage based backup mechanism.\n\n## Install Prerequisites\n\n###Cluster:\nThe operator was certified and tested on OCP 4.6 and 4.7.\nIf you encounter any issue with other OCP versions or cloud providers please contact info@vfunction.com.\n\n###Storage:\nThe operator creates two new PersistentVolumeClaims (PVCs) during installation time. For their creation, it relies on the default StorageClass to dynamically provision two PersistentVolumes (PVs). The system must have a default StorageClass in place.\n\nBoth PersistentVolumes are accessed with ReadWriteOnce mode.\n\n###Project:\nThe operator should be installed in a new and dedicated project (namespace). If you intend to install more than one vFunction operands in the same cluster, please use different projects for each one. Installation of more than one operand on the same cluster will allow scaling by load balancing multiple applications to different vFunction servers.\n\n## Installation instructions\n\n1. Prepare the YAML file to use in the installation:\n\n    a. Copy the following YAML template into a text editor:\n\n    ```yaml\n        apiVersion: vfunction.com/v1\n        kind: VfunctionServer\n        metadata:\n          name: vfunction\n          namespace: vfunction\n          labels:\n            name: vfunction\n            app.kubernetes.io/name: vfunction\n            app.kubernetes.io/instance: vfunction-server\n            app.kubernetes.io/managed-by: operator\n        spec:\n          host: \"http://my.domain.com\"\n          org_name: \"MyCompany\"\n          upgrade: \"Daily\"\n          admin:\n            email: \"admin@mycompany.com\"\n            name: \"Admin\"\n            password: \"Password1!\"\n          smtp:\n            password: \"\"\n            url: \"\"\n            identity: \"\"\n            user: \"\"\n          measurements:\n            auto_scaling: \"No\"\n            min_number_of_services: \"2\"\n            max_number_of_services: \"10\"\n          tls:\n            crt: |\n              -----BEGIN CERTIFICATE-----\n              ...\n              -----END CERTIFICATE-----\n            key: |\n              -----BEGIN PRIVATE KEY-----\n              ...\n              -----END PRIVATE KEY-----\n    ```\n    b. Customize the template fields by replacing with your information:\n\n    - **host**: Enter the FQDN for accessing the vFunction dashboard.\n                Make sure that you use a domain name and not an IP address. Writing \"https://\" will mandate TLS while writing \"http://\" will expose the server through HTTP.\n    - **org_name**: Enter your organization name.\n    - **upgrade**: Choose auto-upgrade mode\n        - **Daily**: The operator will check for a new version every day at 3 AM and will install it automatically (default).\n        - **Always**: The operator will check for a new version every 10 minutes and will install it automatically.\n        - **Never**: The automatic upgrading mechanism is off.\n        - **Maintenance**: Put the operator in a maintenance mode.\n\n    - **admin.email**: Enter the email address of your administrator.\n    - **admin.name**: Enter the name of your administrator.\n    - **admin.password**: Enter the password you want to use for the vFunction administrator.\n                          The password should be at least 8 characters long, and consist of at least one lowercase letter, at least one uppercase letter, at least one number, and at least one special character.\n    - **smtp.user**: Enter the email address for a designated user for the SMTP server (optional).\n    - **smtp.password**: Enter this user\u2019s password (optional).\n    - **smtp.identity**: Enter this user\u2019s password (optional).\n    - **smtp.url**: Enter the SMTP server URL (optional).\n    - **tls.crt**: If your host FQDN starts with \u201chttps\u201d, paste in the certifications you have for using the TLS connection.\n    - **tls.key**: If your host FQDN starts with \u201chttps\u201d, enter the key you have for using the TLS connection.\n    - **measurements.auto_scaling**: Indicates if the measurement services auto scalling is active.\n    - **measurements.min_num_of_services**: Minimum Number of measurement service pods.\n    - **measurements.max_num_of_services**: Maximum Number of measurement service pods.\n    - **measurements.S3**: Save all measurements data to S3, instead of local PV (optional).\n        - **measurements.S3.bucket**: Measurements S3 bucket name.\n        - **measurements.S3.key**: Measurements S3 key.\n        - **measurements.S3.secret**: Measurements S3 secret.\n        - **measurements.S3.region**: Measurements S3 region.\n    - **backup.mysql.S3**: Backup MySQL to S3 (optional).\n        - **backup.mysql.S3.bucket**: MySQL backup S3 bucket name.\n        - **backup.mysql.S3.key**: MySQL backup S3 key.\n        - **backup.mysql.S3.secret**: MySQL backup S3 secret.\n        - **backup.mysql.S3.region**: MySQL backup S3 region.\n\n1. In the Installed Operators window choose and click on vFunction Operator and then Create Instance.\n1. In the Create vFunctionServer window, paste the YAML file that you created in step 1.\n1. Click Create.\n1. You can now click on your new created vFunction operand in order to see its details and installation progress.\n\n## Verifying the installation\n\nCheck that the operand installed successfully:\n\n1. Check that the \"Operand State\" property shows \u201cWorking\u201d.\n1. Check that the \"Successfully Installed\" property shows \"Yes\".\n\nIf \"Operand State\" shows \"Failed\", it indicates the operand wasn\u2019t installed correctly. Check the events and logs for all pods (operator and image containers) for any issues. In the event that you cannot troubleshoot, contact vFunction support.\n\n## After installation\n\nThe vFunction site is now accessible via the newly created vFunction application custom address, for example, my.domain.com. There are two ways you can access the vFunction dashboard.\n\n### Access using the router canonical hostname\n\n1. Update your DNS provider by creating a canonical name (CNAME) record.\nThis record should point to your host address, and to the \u201dvfunction\u201d subdomain of the  OpenShift canonical router hostname as the alias.\nFor example, ***my.domain.com.   CNAME   vfunction.apps.ocp4.my-openshift.com.***\n2. Find your cluster Router Canonical Hostname address in the newly created vfunction-route-xxx under your vFunction OpenShift project -> **Networking** -> **Routes** -> **vfunction-route-xxx** route -> **Router Canonical Hostname** field.\nYou can now access the dashboard using your defined \"host\" spec property (as above).\n\n### Access using the nginx service location\n\nYou may use this access method if your OpenShift is installed on a provider that supports exposing LoadBalancer-type services.\n1. Update your DNS provider by creating a canonical name (CNAME) record.\nThis record should point to your host address and to the vfunction-nginx-xxx service location.\nFor example, ***my.domain.com.   CNAME   a05951ed7cdf-1394239323.us-east-1.elb.amazonaws.com.***\n1. Point your custom domain to the vfunction-nginx-xxx service's external IP location, which you can find in the OpenShift project > **Networking** -> **Services** -> **vfunction-nginx-xxx** service > **Service Address** > **Location** field.\n\n## Upgrade and Rollback\n\nThe vFunction operator includes a built-in auto-upgrade mechanism.\n\nYou can choose one of 4 upgrading modes:\n- **Daily**: The operator will check for a new version every day at 3 AM and will install it automatically (default).\n- **Always**: The operator will check for a new version every 10 minutes and will install it automatically.\n- **Never**: The automatic upgrading mechanism is off.\n- **Maintenance**: Put the operator in a maintenance mode.\n\nFor an on-demand upgrade,  you can change anytime the upgrading mode from \u201cNever\u201d to \u201cAlways\u201d, wait for the operand to be upgraded, and change again to \u201cNever\u201d.\n\nDuring the upgrade, the \"Operand State\" property will change to \u201cUpgrading...\u201d and back again to \u201cWorking\u201d after a successful upgrade.\n\nIn case of a failure upgrading the operand, an automatic rollback to the last working version will occur. The failed version will be marked as defective and the operator will not try to upgrade to it again.\n\nChoosing the \"Maintenance\" option will tell the operator to take down all pods, so you can safely fix storage issues, return volumes from snapshots, etc.\nAfter finishing the maintenance, return the upgrade mode to your original desired policy.",
      "csv_display_name": "vFunction Operator",
      "csv_metadata_description": "vFunction is a cutting-edge code analysis, machine learning, and automation to boost your Java modernization projects.",
      "csv_name": "vfunction-server-operator.v2.2.469",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:31:57.648000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "vfunction-server-operator",
      "provided_apis": [
        {
          "group": "vfunction.com",
          "kind": "VfunctionServer",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:60d1965460101d0fd90ecc9499d0a6d4c9684a54ada61a43a253d30661fab22f",
          "image": "registry.connect.redhat.com/vfunction/vfunction-server-operator@sha256:60d1965460101d0fd90ecc9499d0a6d4c9684a54ada61a43a253d30661fab22f",
          "name": "vfunction-server-operator-60d1965460101d0fd90ecc9499d0a6d4c9684a54ada61a43a253d30661fab22f-annotation"
        },
        {
          "digest": "sha256:60d1965460101d0fd90ecc9499d0a6d4c9684a54ada61a43a253d30661fab22f",
          "image": "registry.connect.redhat.com/vfunction/vfunction-server-operator@sha256:60d1965460101d0fd90ecc9499d0a6d4c9684a54ada61a43a253d30661fab22f",
          "name": "vfunction-server-operator"
        },
        {
          "digest": "sha256:a6e06ea08fffa33b709d4d1240587bb3ab5b4cc6a28f493a227555e88e645798",
          "image": "registry.connect.redhat.com/vfunction/vfunction-mysql@sha256:a6e06ea08fffa33b709d4d1240587bb3ab5b4cc6a28f493a227555e88e645798",
          "name": "vfunction_mysql_original_image"
        },
        {
          "digest": "sha256:435d1489aaf29a811081ddb51f40ae692e5833f42c31dbced6bc189c0ddc40ab",
          "image": "registry.connect.redhat.com/vfunction/vfunction-nginx@sha256:435d1489aaf29a811081ddb51f40ae692e5833f42c31dbced6bc189c0ddc40ab",
          "name": "vfunction_nginx_original_image"
        },
        {
          "digest": "sha256:b778cb9c724a59e51b4cb9088047be471cdf338f1138c31b81f79e50a491203f",
          "image": "registry.connect.redhat.com/vfunction/vfunction-storage@sha256:b778cb9c724a59e51b4cb9088047be471cdf338f1138c31b81f79e50a491203f",
          "name": "vfunction_storage_original_image"
        },
        {
          "digest": "sha256:21ca95a0209f3c557a45658452d154777f928539a93129148470562c79e68d70",
          "image": "registry.connect.redhat.com/vfunction/vfunction-vfapi-idp@sha256:21ca95a0209f3c557a45658452d154777f928539a93129148470562c79e68d70",
          "name": "vfunction_vfapi_idp_original_image"
        },
        {
          "digest": "sha256:35ffbee4b0eead58706b23cf5a702b1d55d2a7913cd0019cefbff94957d4e5d6",
          "image": "registry.connect.redhat.com/vfunction/vfunction-vfapi-measurements@sha256:35ffbee4b0eead58706b23cf5a702b1d55d2a7913cd0019cefbff94957d4e5d6",
          "name": "vfunction_vfapi_measurements_original_image"
        },
        {
          "digest": "sha256:bcc2c3d6222af95e614318daea3108fffc6bc77aa17b23031cce296a3811b79f",
          "image": "registry.connect.redhat.com/vfunction/vfunction-vfapi-organizations@sha256:bcc2c3d6222af95e614318daea3108fffc6bc77aa17b23031cce296a3811b79f",
          "name": "vfunction_vfapi_organizations_original_image"
        },
        {
          "digest": "sha256:e47cc051953976a0e075e8cfb457cd4749e9b9e4394f2fbecab2458c2ade92ca",
          "image": "registry.connect.redhat.com/vfunction/vfunction-vfapi-users@sha256:e47cc051953976a0e075e8cfb457cd4749e9b9e4394f2fbecab2458c2ade92ca",
          "name": "vfunction_vfapi_users_original_image"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "2.2.469",
      "version_original": "2.2.469"
    },
    {
      "_id": "61a57dbc3e9240fca360f56d",
      "alm_examples": [
        {
          "kind": "OpenshiftXray",
          "metadata": {
            "name": "openshiftxray"
          },
          "spec": {
            "xray": {
              "analysis": {
                "image": {
                  "registry": "registry.connect.redhat.com",
                  "repository": "jfrog/xray-analysis"
                },
                "name": "xray-analysis",
                "podManagementPolicy": "Parallel",
                "updateStrategy": "RollingUpdate"
              },
              "common": {
                "xrayGroupId": "1000721035",
                "xrayUserId": "1000721035",
                "xrayVersion": "3.33.3-1"
              },
              "database": {
                "password": "OVERRIDE",
                "url": "OVERRIDE",
                "user": "OVERRIDE"
              },
              "global": {},
              "indexer": {
                "image": {
                  "registry": "registry.connect.redhat.com",
                  "repository": "jfrog/xray-indexer"
                },
                "name": "xray-indexer",
                "podManagementPolicy": "Parallel",
                "updateStrategy": "RollingUpdate"
              },
              "initContainerImage": "registry.connect.redhat.com/jfrog/init@sha256:164b41720a37f75c6129c8a28d05cc56f821022313d44ff918cce4a2146d93e8",
              "persist": {
                "image": {
                  "registry": "registry.connect.redhat.com",
                  "repository": "jfrog/xray-persist"
                },
                "name": "xray-persist",
                "persistence": {
                  "size": "10Gi"
                },
                "podManagementPolicy": "Parallel",
                "updateStrategy": "RollingUpdate"
              },
              "postgresql": {
                "enabled": false
              },
              "rabbitmq": {
                "auth": {
                  "erlangCookie": "XRAYRABBITMQCLUSTER",
                  "password": "xray",
                  "tls": {
                    "caCertificate": "",
                    "enabled": false,
                    "failIfNoPeerCert": true,
                    "serverCertificate": "",
                    "serverKey": "",
                    "sslOptionsVerify": "verify_peer"
                  },
                  "username": "xray"
                },
                "enabled": true,
                "image": {
                  "registry": "registry.connect.redhat.com",
                  "repository": "jfrog/xray-rabbitmq",
                  "tag": "3.33.3-1"
                },
                "podSecurityContext": {
                  "fsGroup": 1000721001,
                  "runAsUser": 1000721001
                },
                "rbac": {
                  "create": true
                },
                "replicaCount": 1
              },
              "rabbitmq-ha": {
                "enabled": false,
                "image": {
                  "repository": "registry.connect.redhat.com/jfrog/xray-rabbitmq",
                  "tag": "3.33.3-1"
                },
                "initContainer": {
                  "enabled": false
                },
                "managementPassword": "guest",
                "managementUsername": "guest",
                "rabbitmqPassword": "guest",
                "rabbitmqUsername": "guest",
                "replicaCount": 1,
                "securityContext": {
                  "fsGroup": 1000721035,
                  "runAsGroup": 1000721035,
                  "runAsUser": 1000721035
                }
              },
              "replicaCount": 1,
              "router": {
                "image": {
                  "imagePullPolicy": "IfNotPresent",
                  "registry": "registry.connect.redhat.com",
                  "repository": "jfrog/xray-router",
                  "tag": "3.33.3-1"
                },
                "name": "router"
              },
              "server": {
                "image": {
                  "registry": "registry.connect.redhat.com",
                  "repository": "jfrog/xray-server"
                },
                "name": "xray-server",
                "podManagementPolicy": "Parallel",
                "replicaCount": 1,
                "updateStrategy": "RollingUpdate"
              },
              "unifiedUpgradeAllowed": "true",
              "xray": {
                "consoleLog": false,
                "jfrogUrl": "OVERRIDE",
                "joinKey": "OVERRIDE",
                "masterKey": "OVERRIDE"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/jfrog/xray-operator-bundle@sha256:57874a477ec87a6f1b54d45c821f42cde38291c7f8a412263a6a8a40832cbb16",
      "bundle_path_digest": "sha256:57874a477ec87a6f1b54d45c821f42cde38291c7f8a412263a6a8a40832cbb16",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2021-11-30T01:26:20.956000+00:00",
      "csv_description": "## Overview\nOpenshift Operator to deploy JFrog Xray Continuous Security scanner into your Openshift cluster.\nNOTE: Artifactory is required for JFrog Xray to connect with and scan artifacts against.\n### Major version v2.0.4 Breaking change notification !!!\nThis release has major bug fix for Rabbitmq Pod.\nPlease update to version 2.0.4 of the operator.\n### Major version v2.0.0 Breaking change notification !!!\nXray is dependent upon Rabbitmq. The version of Rabbitmq that this chart uses has significantly changed from version 1.1.8 of the operator.\nFor full details on how to migrate please visit:\n`https://github.com/jfrog/charts/blob/master/stable/xray/RABBITMQ_MIGRATION_NOTES.md`\n### Security Context Constraints\nTo deploy this helm chart you will need to be a cluster admin w/ access to the anyuid scc and add the operator service account to the anyuid scc.\n\n```\noc adm policy add-scc-to-user anyuid -z xray-operator\n```\n```\noc adm policy add-scc-to-user anyuid -z openshiftxray\n```\n```\noc adm policy add-scc-to-user anyuid -z openshiftxray-rabbitmq-ha\n```\n\n## Usage\n\nAn external DB is required. The operator will not deploy a DB but will require you to specify the configuration values to connect to it.\n\nSearch for JFrog and click JFrog Xray Operator to install.\n\nGo to the Installed Operators.\n\nWait for the JFrog Xray Operator to complete the installation.\n\nOpen the Operator and click on the provided API: Xray\n\nClick Create New Instance and provide the following parameters for your DB configuration:\n\n```\nJFROG_URL\nDATABASE_URL\nDATABASE_USER\nDATABASE_PASSWORD\n```\n\nJFROG_URL is the external ip or DNS of your Artifactory to connect Xray to. Artifactory is required to use this operator.\nYou can set your JFROG_URL to the service name of your Artifactory Nginx:\n``` oc get svc -n my_namespace | grep nginx ```\nDATABASE_URL must be a Postgresql URL in the format:\n``\npostgres://postgres-postgresql:5432/xraydb?sslmode=disable\n``\nDATABASE_USER and DATABASE_PASSWORD must supply a valid user on Postgresql.\n\nClick Create for Xray to deploy into OpenShift.\n\nOpen Artifactory in a web browser to complete the onboarding wizard for Xray!\n\n### Air gap environments\n\nTo use Xray Operator in an air gap environment you will need to download the images as image streams into your Openshift air gap cluster manually.\n\nUse the image overrides to then specify the image stream locations that are local to your cluster.\n\nNext you will need to setup the database of index data for xray to use when scanning artifacts.\n\nFollow the link below for instructions on setup:\n\nhttps://www.jfrog.com/confluence/display/JFROG/Configuring+Xray#ConfiguringXray-SynchronizingtheDatabase\n\n",
      "csv_display_name": "JFrog Xray Continuous Security Operator",
      "csv_metadata_description": "JFrog Xray Enterprise deploys Xray continuous security scanner into Openshift (Requires Jfrog Artifactory)",
      "csv_name": "xray-operator.v2.0.9",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:32:00.361000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "openshiftxray-operator",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "OpenshiftXray",
          "plural": "openshiftxrays",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:79fcd178d5f5f0d69daf714edd9fbf8f1bebb784513cf5d45ccbd7fd8c3a3a2c",
          "image": "registry.connect.redhat.com/jfrog/xray-operator@sha256:79fcd178d5f5f0d69daf714edd9fbf8f1bebb784513cf5d45ccbd7fd8c3a3a2c",
          "name": "xray-operator-79fcd178d5f5f0d69daf714edd9fbf8f1bebb784513cf5d45ccbd7fd8c3a3a2c-annotation"
        },
        {
          "digest": "sha256:79fcd178d5f5f0d69daf714edd9fbf8f1bebb784513cf5d45ccbd7fd8c3a3a2c",
          "image": "registry.connect.redhat.com/jfrog/xray-operator@sha256:79fcd178d5f5f0d69daf714edd9fbf8f1bebb784513cf5d45ccbd7fd8c3a3a2c",
          "name": "xray-operator"
        },
        {
          "digest": "sha256:8321f4971e7f65f8eb39cda6b6fde2e504cbdbce2139849593d8d8431484cba0",
          "image": "registry.connect.redhat.com/jfrog/xray-server@sha256:8321f4971e7f65f8eb39cda6b6fde2e504cbdbce2139849593d8d8431484cba0",
          "name": "xray_server_image_repository"
        },
        {
          "digest": "sha256:c96159770e67caa4004444361549292732d7a080d3ffe44900c148e387ae5f85",
          "image": "registry.connect.redhat.com/jfrog/xray-analysis@sha256:c96159770e67caa4004444361549292732d7a080d3ffe44900c148e387ae5f85",
          "name": "xray_analysis_image_repository"
        },
        {
          "digest": "sha256:ddf1b7980fcc690947c5385141725b20af250cf0e332ededc50babb217840265",
          "image": "registry.connect.redhat.com/jfrog/xray-persist@sha256:ddf1b7980fcc690947c5385141725b20af250cf0e332ededc50babb217840265",
          "name": "xray_persist_image_repository"
        },
        {
          "digest": "sha256:68f5d645dcdfeeb8d3364e176012518faaa995e5a585113fe7904fdf04f9adfc",
          "image": "registry.connect.redhat.com/jfrog/xray-indexer@sha256:68f5d645dcdfeeb8d3364e176012518faaa995e5a585113fe7904fdf04f9adfc",
          "name": "xray_indexer_image_repository"
        },
        {
          "digest": "sha256:1bf671848a06330b350ffeb0c2e90c1591cce5930d1398126377c01c70841319",
          "image": "registry.connect.redhat.com/jfrog/xray-router@sha256:1bf671848a06330b350ffeb0c2e90c1591cce5930d1398126377c01c70841319",
          "name": "xray_router_image_repository"
        },
        {
          "digest": "sha256:65a95da372693c96bdf9b7bcf21e757dc09569cf2eb66afd9bca4c552ad78f01",
          "image": "registry.connect.redhat.com/jfrog/xray-rabbitmq@sha256:65a95da372693c96bdf9b7bcf21e757dc09569cf2eb66afd9bca4c552ad78f01",
          "name": "xray_rabbitmq_image_repository"
        },
        {
          "digest": "sha256:164b41720a37f75c6129c8a28d05cc56f821022313d44ff918cce4a2146d93e8",
          "image": "registry.connect.redhat.com/jfrog/init@sha256:164b41720a37f75c6129c8a28d05cc56f821022313d44ff918cce4a2146d93e8",
          "name": "init-164b41720a37f75c6129c8a28d05cc56f821022313d44ff918cce4a2146d93e8-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "2.0.9",
      "version_original": "2.0.9"
    },
    {
      "_id": "61a57dc4bfd4a5234d5960e5",
      "alm_examples": [
        {
          "kind": "ZabbixAgent",
          "metadata": {
            "labels": {
              "app": "agent",
              "vendor": "zabbix"
            },
            "name": "zabbix-agent"
          },
          "spec": {
            "active_allow": true,
            "activeservers": "",
            "allow_key": "",
            "allow_privileged": true,
            "buffer#": 100,
            "buffer_send": 5,
            "debug_level": 3,
            "deny_key": "system.run[*]",
            "host_interface": "",
            "host_interface_item": "",
            "hostname": "",
            "hostname_item": "system.hostname",
            "load_module": "",
            "log_remote_commands": true,
            "max_lines_per_second": 20,
            "metadata": "",
            "metadata_item": "",
            "passive_allow": true,
            "passive_servers": "",
            "refresh_active_checks": 120,
            "server_host": "zabbix-server",
            "start_agents": 3,
            "timeout": 3,
            "tls_accept": "unencrypted",
            "tls_ca_file_name": "",
            "tls_cert_file_name": "",
            "tls_cipher_all": "",
            "tls_cipher_cert_13": "",
            "tls_cipher_psk": "",
            "tls_cipherall_13": "",
            "tls_connect": "unencrypted",
            "tls_crl_file_name": "",
            "tls_key_file_name": "",
            "tls_psk_file_name": "",
            "tls_psk_identity": "",
            "tls_server_cert_issuer": "",
            "tls_server_cert_subject": "",
            "tlsciphercert": "",
            "tlscipherpsk13": "",
            "unsafe_user_parameters": false
          }
        },
        {
          "kind": "ZabbixAppliance",
          "metadata": {
            "labels": {
              "app": "appliance",
              "vendor": "zabbix"
            },
            "name": "zabbix-appliance"
          },
          "spec": {
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher13": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_double_ieee754": true,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web_enable_route": true,
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "zabbix-mysql-secrets"
          }
        },
        {
          "kind": "ZabbixFull",
          "metadata": {
            "labels": {
              "app": "server",
              "vendor": "zabbix"
            },
            "name": "zabbix-full"
          },
          "spec": {
            "history_storage_url": "",
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlsciphercert": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_cipher_list": "",
              "db_double_ieee754": true,
              "db_encryption": false,
              "db_verify_host": false,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web#": 2,
            "web_enable_route": true,
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "zabbix-mysql-secrets"
          }
        },
        {
          "kind": "ZabbixProxyMysql",
          "metadata": {
            "labels": {
              "app": "proxy",
              "vendor": "zabbix"
            },
            "name": "zabbix-proxy-mysql"
          },
          "spec": {
            "db_server_port": 3306,
            "internal_db": true,
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "mysql_database": "zabbix_proxy",
            "proxy": {
              "cache#": "8M",
              "config_frequency": 3600,
              "data_sender_frequency": 1,
              "db_tls_cipher": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "enable_remote_commands": false,
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "hostname": "",
              "hostname_item": "system.hostname",
              "housekeeping_frequency": 1,
              "log_remote_commands": true,
              "log_slow_queries": 0,
              "proxy_heartbeat_frequency": 60,
              "proxy_local_buffer": 0,
              "proxy_mode": 0,
              "proxy_offline_buffer": 1,
              "server_host": "zabbix-server",
              "server_port": 10051,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "timeout": 4,
              "tls_accept": "unencrypted",
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_connect": "unencrypted",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tls_psk_file_name": "",
              "tls_psk_identity": "",
              "tls_server_cert_issuer": "",
              "tls_server_cert_subject": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "zabbix-mysql-secrets"
          }
        },
        {
          "kind": "ZabbixProxySqlite",
          "metadata": {
            "labels": {
              "app": "proxy",
              "vendor": "zabbix"
            },
            "name": "zabbix-proxy-sqlite"
          },
          "spec": {
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "proxy": {
              "cache#": "8M",
              "config_frequency": 3600,
              "data_sender_frequency": 1,
              "debug_level": 3,
              "enable_remote_commands": false,
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "hostname": "",
              "hostname_item": "system.hostname",
              "housekeeping_frequency": 1,
              "log_remote_commands": true,
              "log_slow_queries": 0,
              "proxy_heartbeat_frequency": 60,
              "proxy_local_buffer": 0,
              "proxy_mode": 0,
              "proxy_offline_buffer": 1,
              "server_host": "zabbix-server",
              "server_port": 10051,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "timeout": 4,
              "tls_accept": "unencrypted",
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_connect": "unencrypted",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tls_psk_file_name": "",
              "tls_psk_identity": "",
              "tls_server_cert_issuer": "",
              "tls_server_cert_subject": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "proxy#": 1
          }
        },
        {
          "kind": "ZabbixServer",
          "metadata": {
            "labels": {
              "app": "server",
              "vendor": "zabbix"
            },
            "name": "zabbix-server"
          },
          "spec": {
            "db_server_host": "mysql-server",
            "db_server_port": 3306,
            "history_storage_url": "",
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "mysql_database": "zabbix",
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher13": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_cipher_list": "",
              "db_double_ieee754": true,
              "db_encryption": false,
              "db_verify_host": false,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web#": 2,
            "web_enable_route": true,
            "zabbix_mysqlsecret": "zabbix-mysql-secrets"
          }
        },
        {
          "kind": "ZabbixAgent",
          "metadata": {
            "labels": {
              "app": "agent",
              "vendor": "zabbix"
            },
            "name": "zabbix-agent"
          },
          "spec": {
            "active_allow": true,
            "activeservers": "",
            "allow_key": "",
            "allow_privileged": true,
            "buffer#": 100,
            "buffer_send": 5,
            "debug_level": 3,
            "deny_key": "system.run[*]",
            "host_interface": "",
            "host_interface_item": "",
            "hostname": "",
            "hostname_item": "system.hostname",
            "load_module": "",
            "log_remote_commands": true,
            "max_lines_per_second": 20,
            "metadata": "",
            "metadata_item": "",
            "passive_allow": true,
            "passive_servers": "",
            "refresh_active_checks": 120,
            "server_host": "zabbix-server",
            "start_agents": 3,
            "timeout": 3,
            "tls_accept": "unencrypted",
            "tls_ca_file_name": "",
            "tls_cert_file_name": "",
            "tls_cipher_all": "",
            "tls_cipher_cert_13": "",
            "tls_cipher_psk": "",
            "tls_cipherall_13": "",
            "tls_connect": "unencrypted",
            "tls_crl_file_name": "",
            "tls_key_file_name": "",
            "tls_psk_file_name": "",
            "tls_psk_identity": "",
            "tls_server_cert_issuer": "",
            "tls_server_cert_subject": "",
            "tlsciphercert": "",
            "tlscipherpsk13": "",
            "unsafe_user_parameters": false
          }
        },
        {
          "kind": "ZabbixServer",
          "metadata": {
            "labels": {
              "app": "server",
              "vendor": "zabbix"
            },
            "name": "zabbix-server"
          },
          "spec": {
            "db_server_host": "mysql-server",
            "db_server_port": 3306,
            "history_storage_url": "",
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "mysql_database": "zabbix",
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher13": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_cipher_list": "",
              "db_double_ieee754": true,
              "db_encryption": false,
              "db_verify_host": false,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web#": 2,
            "web_enable_route": true,
            "zabbix_mysqlsecret": "mysql-secrets"
          }
        },
        {
          "kind": "ZabbixProxySqlite",
          "metadata": {
            "labels": {
              "app": "proxy",
              "vendor": "zabbix"
            },
            "name": "zabbix-proxy-sqlite"
          },
          "spec": {
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "proxy": {
              "cache#": "8M",
              "config_frequency": 3600,
              "data_sender_frequency": 1,
              "debug_level": 3,
              "enable_remote_commands": false,
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "hostname": "",
              "hostname_item": "system.hostname",
              "housekeeping_frequency": 1,
              "log_remote_commands": true,
              "log_slow_queries": 0,
              "proxy_heartbeat_frequency": 60,
              "proxy_local_buffer": 0,
              "proxy_mode": 0,
              "proxy_offline_buffer": 1,
              "server_host": "zabbix-server",
              "server_port": 10051,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "timeout": 4,
              "tls_accept": "unencrypted",
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_connect": "unencrypted",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tls_psk_file_name": "",
              "tls_psk_identity": "",
              "tls_server_cert_issuer": "",
              "tls_server_cert_subject": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "proxy#": 1
          }
        },
        {
          "kind": "ZabbixProxyMysql",
          "metadata": {
            "labels": {
              "app": "proxy",
              "vendor": "zabbix"
            },
            "name": "zabbix-proxy-mysql"
          },
          "spec": {
            "db_server_port": 3306,
            "internal_db": true,
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "mysql_database": "zabbix_proxy",
            "proxy": {
              "cache#": "8M",
              "config_frequency": 3600,
              "data_sender_frequency": 1,
              "db_tls_cipher": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "enable_remote_commands": false,
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "hostname": "",
              "hostname_item": "system.hostname",
              "housekeeping_frequency": 1,
              "log_remote_commands": true,
              "log_slow_queries": 0,
              "proxy_heartbeat_frequency": 60,
              "proxy_local_buffer": 0,
              "proxy_mode": 0,
              "proxy_offline_buffer": 1,
              "server_host": "zabbix-server",
              "server_port": 10051,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "timeout": 4,
              "tls_accept": "unencrypted",
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_connect": "unencrypted",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tls_psk_file_name": "",
              "tls_psk_identity": "",
              "tls_server_cert_issuer": "",
              "tls_server_cert_subject": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "zabbix-mysql-secrets"
          }
        },
        {
          "kind": "ZabbixFull",
          "metadata": {
            "labels": {
              "app": "server",
              "vendor": "zabbix"
            },
            "name": "zabbix-full"
          },
          "spec": {
            "history_storage_url": "",
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlsciphercert": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_cipher_list": "",
              "db_double_ieee754": true,
              "db_encryption": false,
              "db_verify_host": false,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web#": 2,
            "web_enable_route": true,
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "mysql-secrets"
          }
        },
        {
          "kind": "ZabbixAppliance",
          "metadata": {
            "labels": {
              "app": "appliance",
              "vendor": "zabbix"
            },
            "name": "zabbix-appliance"
          },
          "spec": {
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher13": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_double_ieee754": true,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web_enable_route": true,
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "mysql-secrets"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/zabbix/zabbixoperator-certified-bundle@sha256:236d7cc772634f20540dc153f9a7fc66357d7d4852962c5c7b5daff61c99e5c8",
      "bundle_path_digest": "sha256:236d7cc772634f20540dc153f9a7fc66357d7d4852962c5c7b5daff61c99e5c8",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "lts",
      "creation_date": "2021-11-30T01:26:28.907000+00:00",
      "csv_description": "## About this Operator\n\nZabbix helps you to real-time monitoring of millions of metrics collected from tens of thousands of servers, virtual machines and network devices.\nThe Zabbix Operator allows users to easily deploy, manage, and maintain Zabbix deployments on OpenShift. By installing this integration you will be able to deploy Zabbix server / proxies and other components with a single command.\n## Supported Features\n* **Zabbix Server** - Simple Zabbix installation with included Zabbix server, Zabbix web-interface and Zabbix Java Gateway with MySQL database support. The feature does not provide MySQL service and requires an external MySQL database. \n* **Zabbix Server (Full)** - Zabbix installation with included Zabbix server, Zabbix web-interface, Zabbix Java Gateway and MySQL server instance.\n* **Zabbix proxy (SQLite3)** - Very simple way to gain power of Zabbix proxy. The feature has  SQLite3 support for Zabbix proxies and allow to specify amount of proxies. \n* **Zabbix proxy (MySQL)** - Another option of Zabbix proxy. The option support and deliver MySQL database.\n* **Zabbix agent** - Zabbix agent can be deployed on each available node for stability and performance monitoring on remote nodes. It allows to gather metrics with full automation!\n* **Zabbix Appliance** - Zabbix appliance very simple way to test and check Zabbix features. The option provides all core components in one solution. It includes Zabbix server, Zabbix Java Gateway, Zabbix web-interface and MySQL server in deployment. It is very useful for testing Zabbix features!\n## Prerequisites\nAll deployment options are require additional information during deployment. Please, check the following instructions and provide required configuration:\n* **Zabbix Server** - MySQL database host information and MySQL database credentials in specially formatted *Secret*. Additionally it is possible to specify SSL certificates for HTTPS support in *Secret*.\n* **Zabbix Server (Full)** - MySQL database credentials in specially formatted *Secret*. MySQL database volume name information. Additionally it is possible to specify SSL certificates for HTTPS support in *Secret*.\n* **Zabbix proxy (SQLite3)** - Zabbix server host information only.\n* **Zabbix proxy (MySQL)** - MySQL database credentials in specially formatted *Secrets* and Zabbix server host information.\n* **Zabbix agent** - Zabbix server host information only for outgoing and incoming connections. Zabbix agent uses \"privileged\" mode to monitor node resources! For example, running processes.\n* **Zabbix Appliance** - MySQL database credentials in specially formatted *Secret*. MySQL database volume name information. Additionally it is possible to specify SSL certificates for HTTPS support in *Secret*.\n### MySQL credentials\n```\nkind: Secret\napiVersion: v1\nmetadata:\n  name: zabbix-full-secrets\ndata:\n  mysql_root_password: emFiYml4X3N1cGVyX3Jvb3Q= [1]\n  mysql_zabbix_password: emFiYml4X3VzZXJfcGFzc3dvcmQ= [2]\n  mysql_zabbix_username: emFiYml4 [3]\ntype: Opaque\n```\nUsing MySQL root password (*mysqlrootpassword* [1]) Zabbix server / proxy will try to create MySQL database schema with grant permissions to *mysqlzabbixusername* [2] and *mysqlzabbixpassword* [3].\n### SSL certificates for HTTPS\n```\nkind: Secret\napiVersion: v1\nmetadata:\n  name: zabbix-web-sslsecret\ndata:\n  ssl.crt: >-\n   < ssl.crt data>\n  ssl.key: >-\n\t < ssl.key data >\n  dhparam.pem: >-\n   <  dhparam.pem data >\n```\nFiles *ssl.crt*, *ssl.key* and *dhparam.perm* are required for Zabbix web-interface for SSL support.\n",
      "csv_display_name": "Zabbix Operator",
      "csv_metadata_description": "Zabbix operator with multiple deployment variants and different components",
      "csv_name": "zabbix-operator-certified.v0.0.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:32:03.489000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "zabbix-operator-certified",
      "provided_apis": [
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixProxyMysql",
          "version": "v1alpha1"
        },
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixProxySqlite",
          "version": "v1alpha1"
        },
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixServer",
          "version": "v1alpha1"
        },
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixAgent",
          "version": "v1alpha1"
        },
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixAppliance",
          "version": "v1alpha1"
        },
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixFull",
          "version": "v1alpha1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:c2dee633a667191d3272bf1652412ac1077455f18b90168ddcaa2ac8882f0c66",
          "image": "registry.connect.redhat.com/zabbix/zabbixoperator-certified@sha256:c2dee633a667191d3272bf1652412ac1077455f18b90168ddcaa2ac8882f0c66",
          "name": "zabbixoperator-certified-c2dee633a667191d3272bf1652412ac1077455f18b90168ddcaa2ac8882f0c66-annotation"
        },
        {
          "digest": "sha256:c2dee633a667191d3272bf1652412ac1077455f18b90168ddcaa2ac8882f0c66",
          "image": "registry.connect.redhat.com/zabbix/zabbixoperator-certified@sha256:c2dee633a667191d3272bf1652412ac1077455f18b90168ddcaa2ac8882f0c66",
          "name": "ansible"
        },
        {
          "digest": "sha256:c2dee633a667191d3272bf1652412ac1077455f18b90168ddcaa2ac8882f0c66",
          "image": "registry.connect.redhat.com/zabbix/zabbixoperator-certified@sha256:c2dee633a667191d3272bf1652412ac1077455f18b90168ddcaa2ac8882f0c66",
          "name": "operator"
        },
        {
          "digest": "sha256:2f76e7cbece9d9366b613bcb1079b030ddbcc5e97b2f133b73bd0131f0869725",
          "image": "registry.connect.redhat.com/zabbix/zabbix-server-mysql-50@sha256:2f76e7cbece9d9366b613bcb1079b030ddbcc5e97b2f133b73bd0131f0869725",
          "name": "zbx_server_mysql"
        },
        {
          "digest": "sha256:9f3ba82445ea3d9754f016e21b2ea1c99c1958da928f49aee1b18377af78d365",
          "image": "registry.connect.redhat.com/zabbix/zabbix-web-mysql-50@sha256:9f3ba82445ea3d9754f016e21b2ea1c99c1958da928f49aee1b18377af78d365",
          "name": "zbx_web_mysql"
        },
        {
          "digest": "sha256:a216de448dc10b2797a70f4fc6664c2bd611840b7b6c26f066635d48c606bf06",
          "image": "registry.connect.redhat.com/zabbix/zabbix-java-gateway-50@sha256:a216de448dc10b2797a70f4fc6664c2bd611840b7b6c26f066635d48c606bf06",
          "name": "zbx_java_gateway"
        },
        {
          "digest": "sha256:054ad28ade616642fb50fd38a48df2d00a9c0c6a57df1e367caeceb6469f6c42",
          "image": "registry.connect.redhat.com/zabbix/zabbix-proxy-mysql-50@sha256:054ad28ade616642fb50fd38a48df2d00a9c0c6a57df1e367caeceb6469f6c42",
          "name": "zbx_proxy_mysql"
        },
        {
          "digest": "sha256:713a6223a01ee57efb719d6f491ef779d74104a1bc1b8599eade8b3f4a3318ed",
          "image": "registry.connect.redhat.com/zabbix/zabbix-proxy-sqlite-50@sha256:713a6223a01ee57efb719d6f491ef779d74104a1bc1b8599eade8b3f4a3318ed",
          "name": "zbx_proxy_sqlite"
        },
        {
          "digest": "sha256:229562a27ed45319ef17397fe81cac81129c84eccd2c14f6085531a86ef9b87d",
          "image": "registry.connect.redhat.com/zabbix/zabbix-agent-50@sha256:229562a27ed45319ef17397fe81cac81129c84eccd2c14f6085531a86ef9b87d",
          "name": "zbx_agent"
        },
        {
          "digest": "sha256:7236c68c494f572edf64ced85c3a083b7eafff1c6562e95bdc50e50c37e3e3bf",
          "image": "registry.connect.redhat.com/zabbix/zabbix-appliance-50@sha256:7236c68c494f572edf64ced85c3a083b7eafff1c6562e95bdc50e50c37e3e3bf",
          "name": "zbx_appliance"
        },
        {
          "digest": "sha256:e7541d9fbcb7a71ac8a68cc4efc1806bab74023961c7d3fb562ded320df90c43",
          "image": "registry.redhat.io/rhel8/mysql-80@sha256:e7541d9fbcb7a71ac8a68cc4efc1806bab74023961c7d3fb562ded320df90c43",
          "name": "db_mysql"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "0.0.2",
      "version_original": "0.0.2"
    },
    {
      "_id": "61a57dccbfd4a5234d5960e6",
      "alm_examples": [
        {
          "kind": "ZabbixAgent",
          "metadata": {
            "labels": {
              "app": "agent",
              "vendor": "zabbix"
            },
            "name": "zabbix-agent"
          },
          "spec": {
            "active_allow": true,
            "activeservers": "",
            "allow_key": "",
            "allow_privileged": true,
            "buffer#": 100,
            "buffer_send": 5,
            "debug_level": 3,
            "deny_key": "system.run[*]",
            "host_interface": "",
            "host_interface_item": "",
            "hostname": "",
            "hostname_item": "system.hostname",
            "load_module": "",
            "log_remote_commands": true,
            "max_lines_per_second": 20,
            "metadata": "",
            "metadata_item": "",
            "passive_allow": true,
            "passive_servers": "",
            "refresh_active_checks": 120,
            "server_host": "zabbix-server",
            "start_agents": 3,
            "timeout": 3,
            "tls_accept": "unencrypted",
            "tls_ca_file_name": "",
            "tls_cert_file_name": "",
            "tls_cipher_all": "",
            "tls_cipher_cert_13": "",
            "tls_cipher_psk": "",
            "tls_cipherall_13": "",
            "tls_connect": "unencrypted",
            "tls_crl_file_name": "",
            "tls_key_file_name": "",
            "tls_psk_file_name": "",
            "tls_psk_identity": "",
            "tls_server_cert_issuer": "",
            "tls_server_cert_subject": "",
            "tlsciphercert": "",
            "tlscipherpsk13": "",
            "unsafe_user_parameters": false
          }
        },
        {
          "kind": "ZabbixAppliance",
          "metadata": {
            "labels": {
              "app": "appliance",
              "vendor": "zabbix"
            },
            "name": "zabbix-appliance"
          },
          "spec": {
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher13": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_double_ieee754": true,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web_enable_route": true,
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "zabbix-mysql-secrets"
          }
        },
        {
          "kind": "ZabbixFull",
          "metadata": {
            "labels": {
              "app": "server",
              "vendor": "zabbix"
            },
            "name": "zabbix-full"
          },
          "spec": {
            "history_storage_url": "",
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlsciphercert": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_cipher_list": "",
              "db_double_ieee754": true,
              "db_encryption": false,
              "db_verify_host": false,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web#": 2,
            "web_enable_route": true,
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "zabbix-mysql-secrets"
          }
        },
        {
          "kind": "ZabbixProxyMysql",
          "metadata": {
            "labels": {
              "app": "proxy",
              "vendor": "zabbix"
            },
            "name": "zabbix-proxy-mysql"
          },
          "spec": {
            "db_server_port": 3306,
            "internal_db": true,
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "mysql_database": "zabbix_proxy",
            "proxy": {
              "cache#": "8M",
              "config_frequency": 3600,
              "data_sender_frequency": 1,
              "db_tls_cipher": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "enable_remote_commands": false,
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "hostname": "",
              "hostname_item": "system.hostname",
              "housekeeping_frequency": 1,
              "log_remote_commands": true,
              "log_slow_queries": 0,
              "proxy_heartbeat_frequency": 60,
              "proxy_local_buffer": 0,
              "proxy_mode": 0,
              "proxy_offline_buffer": 1,
              "server_host": "zabbix-server",
              "server_port": 10051,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "timeout": 4,
              "tls_accept": "unencrypted",
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_connect": "unencrypted",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tls_psk_file_name": "",
              "tls_psk_identity": "",
              "tls_server_cert_issuer": "",
              "tls_server_cert_subject": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "zabbix-mysql-secrets"
          }
        },
        {
          "kind": "ZabbixProxySqlite",
          "metadata": {
            "labels": {
              "app": "proxy",
              "vendor": "zabbix"
            },
            "name": "zabbix-proxy-sqlite"
          },
          "spec": {
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "proxy": {
              "cache#": "8M",
              "config_frequency": 3600,
              "data_sender_frequency": 1,
              "debug_level": 3,
              "enable_remote_commands": false,
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "hostname": "",
              "hostname_item": "system.hostname",
              "housekeeping_frequency": 1,
              "log_remote_commands": true,
              "log_slow_queries": 0,
              "proxy_heartbeat_frequency": 60,
              "proxy_local_buffer": 0,
              "proxy_mode": 0,
              "proxy_offline_buffer": 1,
              "server_host": "zabbix-server",
              "server_port": 10051,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "timeout": 4,
              "tls_accept": "unencrypted",
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_connect": "unencrypted",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tls_psk_file_name": "",
              "tls_psk_identity": "",
              "tls_server_cert_issuer": "",
              "tls_server_cert_subject": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "proxy#": 1
          }
        },
        {
          "kind": "ZabbixServer",
          "metadata": {
            "labels": {
              "app": "server",
              "vendor": "zabbix"
            },
            "name": "zabbix-server"
          },
          "spec": {
            "db_server_host": "mysql-server",
            "db_server_port": 3306,
            "history_storage_url": "",
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "mysql_database": "zabbix",
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher13": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_cipher_list": "",
              "db_double_ieee754": true,
              "db_encryption": false,
              "db_verify_host": false,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web#": 2,
            "web_enable_route": true,
            "zabbix_mysqlsecret": "zabbix-mysql-secrets"
          }
        },
        {
          "kind": "ZabbixAgent",
          "metadata": {
            "labels": {
              "app": "agent",
              "vendor": "zabbix"
            },
            "name": "zabbix-agent"
          },
          "spec": {
            "active_allow": true,
            "activeservers": "",
            "allow_key": "",
            "allow_privileged": true,
            "buffer#": 100,
            "buffer_send": 5,
            "debug_level": 3,
            "deny_key": "system.run[*]",
            "host_interface": "",
            "host_interface_item": "",
            "hostname": "",
            "hostname_item": "system.hostname",
            "load_module": "",
            "log_remote_commands": true,
            "max_lines_per_second": 20,
            "metadata": "",
            "metadata_item": "",
            "passive_allow": true,
            "passive_servers": "",
            "refresh_active_checks": 120,
            "server_host": "zabbix-server",
            "start_agents": 3,
            "timeout": 3,
            "tls_accept": "unencrypted",
            "tls_ca_file_name": "",
            "tls_cert_file_name": "",
            "tls_cipher_all": "",
            "tls_cipher_cert_13": "",
            "tls_cipher_psk": "",
            "tls_cipherall_13": "",
            "tls_connect": "unencrypted",
            "tls_crl_file_name": "",
            "tls_key_file_name": "",
            "tls_psk_file_name": "",
            "tls_psk_identity": "",
            "tls_server_cert_issuer": "",
            "tls_server_cert_subject": "",
            "tlsciphercert": "",
            "tlscipherpsk13": "",
            "unsafe_user_parameters": false
          }
        },
        {
          "kind": "ZabbixServer",
          "metadata": {
            "labels": {
              "app": "server",
              "vendor": "zabbix"
            },
            "name": "zabbix-server"
          },
          "spec": {
            "db_server_host": "mysql-server",
            "db_server_port": 3306,
            "history_storage_url": "",
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "mysql_database": "zabbix",
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher13": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_cipher_list": "",
              "db_double_ieee754": true,
              "db_encryption": false,
              "db_verify_host": false,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web#": 2,
            "web_enable_route": true,
            "zabbix_mysqlsecret": "mysql-secrets"
          }
        },
        {
          "kind": "ZabbixProxySqlite",
          "metadata": {
            "labels": {
              "app": "proxy",
              "vendor": "zabbix"
            },
            "name": "zabbix-proxy-sqlite"
          },
          "spec": {
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "proxy": {
              "cache#": "8M",
              "config_frequency": 3600,
              "data_sender_frequency": 1,
              "debug_level": 3,
              "enable_remote_commands": false,
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "hostname": "",
              "hostname_item": "system.hostname",
              "housekeeping_frequency": 1,
              "log_remote_commands": true,
              "log_slow_queries": 0,
              "proxy_heartbeat_frequency": 60,
              "proxy_local_buffer": 0,
              "proxy_mode": 0,
              "proxy_offline_buffer": 1,
              "server_host": "zabbix-server",
              "server_port": 10051,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "timeout": 4,
              "tls_accept": "unencrypted",
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_connect": "unencrypted",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tls_psk_file_name": "",
              "tls_psk_identity": "",
              "tls_server_cert_issuer": "",
              "tls_server_cert_subject": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "proxy#": 1
          }
        },
        {
          "kind": "ZabbixProxyMysql",
          "metadata": {
            "labels": {
              "app": "proxy",
              "vendor": "zabbix"
            },
            "name": "zabbix-proxy-mysql"
          },
          "spec": {
            "db_server_port": 3306,
            "internal_db": true,
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "mysql_database": "zabbix_proxy",
            "proxy": {
              "cache#": "8M",
              "config_frequency": 3600,
              "data_sender_frequency": 1,
              "db_tls_cipher": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "enable_remote_commands": false,
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "hostname": "",
              "hostname_item": "system.hostname",
              "housekeeping_frequency": 1,
              "log_remote_commands": true,
              "log_slow_queries": 0,
              "proxy_heartbeat_frequency": 60,
              "proxy_local_buffer": 0,
              "proxy_mode": 0,
              "proxy_offline_buffer": 1,
              "server_host": "zabbix-server",
              "server_port": 10051,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "timeout": 4,
              "tls_accept": "unencrypted",
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_connect": "unencrypted",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tls_psk_file_name": "",
              "tls_psk_identity": "",
              "tls_server_cert_issuer": "",
              "tls_server_cert_subject": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "zabbix-mysql-secrets"
          }
        },
        {
          "kind": "ZabbixFull",
          "metadata": {
            "labels": {
              "app": "server",
              "vendor": "zabbix"
            },
            "name": "zabbix-full"
          },
          "spec": {
            "history_storage_url": "",
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlsciphercert": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_cipher_list": "",
              "db_double_ieee754": true,
              "db_encryption": false,
              "db_verify_host": false,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web#": 2,
            "web_enable_route": true,
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "mysql-secrets"
          }
        },
        {
          "kind": "ZabbixAppliance",
          "metadata": {
            "labels": {
              "app": "appliance",
              "vendor": "zabbix"
            },
            "name": "zabbix-appliance"
          },
          "spec": {
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher13": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_double_ieee754": true,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web_enable_route": true,
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "mysql-secrets"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/zabbix/zabbixoperator-certified-bundle@sha256:3351d4e9f8ddf2b4498852335ebd7197188ff3f167919c603c5dc77b08774091",
      "bundle_path_digest": "sha256:3351d4e9f8ddf2b4498852335ebd7197188ff3f167919c603c5dc77b08774091",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "lts",
      "creation_date": "2021-11-30T01:26:36.803000+00:00",
      "csv_description": "## About this Operator\n\nZabbix helps you to real-time monitoring of millions of metrics collected from tens of thousands of servers, virtual machines and network devices.\nThe Zabbix Operator allows users to easily deploy, manage, and maintain Zabbix deployments on OpenShift. By installing this integration you will be able to deploy Zabbix server / proxies and other components with a single command.\n## Supported Features\n* **Zabbix Server** - Simple Zabbix installation with included Zabbix server, Zabbix web-interface and Zabbix Java Gateway with MySQL database support. The feature does not provide MySQL service and requires an external MySQL database. \n* **Zabbix Server (Full)** - Zabbix installation with included Zabbix server, Zabbix web-interface, Zabbix Java Gateway and MySQL server instance.\n* **Zabbix proxy (SQLite3)** - Very simple way to gain power of Zabbix proxy. The feature has  SQLite3 support for Zabbix proxies and allow to specify amount of proxies. \n* **Zabbix proxy (MySQL)** - Another option of Zabbix proxy. The option support and deliver MySQL database.\n* **Zabbix agent** - Zabbix agent can be deployed on each available node for stability and performance monitoring on remote nodes. It allows to gather metrics with full automation!\n* **Zabbix Appliance** - Zabbix appliance very simple way to test and check Zabbix features. The option provides all core components in one solution. It includes Zabbix server, Zabbix Java Gateway, Zabbix web-interface and MySQL server in deployment. It is very useful for testing Zabbix features!\n## Prerequisites\nAll deployment options are require additional information during deployment. Please, check the following instructions and provide required configuration:\n* **Zabbix Server** - MySQL database host information and MySQL database credentials in specially formatted *Secret*. Additionally it is possible to specify SSL certificates for HTTPS support in *Secret*.\n* **Zabbix Server (Full)** - MySQL database credentials in specially formatted *Secret*. MySQL database volume name information. Additionally it is possible to specify SSL certificates for HTTPS support in *Secret*.\n* **Zabbix proxy (SQLite3)** - Zabbix server host information only.\n* **Zabbix proxy (MySQL)** - MySQL database credentials in specially formatted *Secrets* and Zabbix server host information.\n* **Zabbix agent** - Zabbix server host information only for outgoing and incoming connections. Zabbix agent uses \"privileged\" mode to monitor node resources! For example, running processes.\n* **Zabbix Appliance** - MySQL database credentials in specially formatted *Secret*. MySQL database volume name information. Additionally it is possible to specify SSL certificates for HTTPS support in *Secret*.\n### MySQL credentials\n```\nkind: Secret\napiVersion: v1\nmetadata:\n  name: zabbix-full-secrets\ndata:\n  mysql_root_password: emFiYml4X3N1cGVyX3Jvb3Q= [1]\n  mysql_zabbix_password: emFiYml4X3VzZXJfcGFzc3dvcmQ= [2]\n  mysql_zabbix_username: emFiYml4 [3]\ntype: Opaque\n```\nUsing MySQL root password (*mysqlrootpassword* [1]) Zabbix server / proxy will try to create MySQL database schema with grant permissions to *mysqlzabbixusername* [2] and *mysqlzabbixpassword* [3].\n### SSL certificates for HTTPS\n```\nkind: Secret\napiVersion: v1\nmetadata:\n  name: zabbix-web-sslsecret\ndata:\n  ssl.crt: >-\n   < ssl.crt data>\n  ssl.key: >-\n\t < ssl.key data >\n  dhparam.pem: >-\n   <  dhparam.pem data >\n```\nFiles *ssl.crt*, *ssl.key* and *dhparam.perm* are required for Zabbix web-interface for SSL support.\n",
      "csv_display_name": "Zabbix Operator",
      "csv_metadata_description": "Zabbix operator with multiple deployment variants and different components",
      "csv_name": "zabbix-operator-certified.v0.0.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:32:06.882000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "zabbix-operator-certified",
      "provided_apis": [
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixAgent",
          "version": "v1alpha1"
        },
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixAppliance",
          "version": "v1alpha1"
        },
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixFull",
          "version": "v1alpha1"
        },
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixProxyMysql",
          "version": "v1alpha1"
        },
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixProxySqlite",
          "version": "v1alpha1"
        },
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixServer",
          "version": "v1alpha1"
        }
      ],
      "related_images": [],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "0.0.3",
      "version_original": "0.0.3"
    },
    {
      "_id": "61a57dd4c17162a20c1c68aa",
      "alm_examples": [
        {
          "kind": "XCrypt",
          "metadata": {
            "name": "zts-masterset"
          },
          "spec": {
            "status": {
              "podNames": "zts-ca",
              "replicas": "1,"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/zts/xcrypt-operator-1-bundle@sha256:c3913778f986ae4f3a7d94da2a9d0157233dbb676e3c1eecacbdbc02a864685a",
      "bundle_path_digest": "sha256:c3913778f986ae4f3a7d94da2a9d0157233dbb676e3c1eecacbdbc02a864685a",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2021-11-30T01:26:44.838000+00:00",
      "csv_description": "Zettaset\u2019s RedHat Certified XCrypt Operator allows users to deploy multiple XCrypt components on OpenShift with just a few simple commands. The XCrypt Operator deployment provides software-defined encryption that transparently protects container data throughout your OpenShift environment.\n\n## Core Features\n* **Automated XCrypt provisioning** - Deploying a Zettaset XCrypt has never been easier. Adjust cluster specific configuration and let the Zettaset Operator take care of provisioning XCrypt services and setting up the XCrypt encryption to your exact specification. \n* **CSI Driver deployment**: Zettaset XCrypt Operator automatically deploys Zettaset XCrypt CSI Driver in order to provide automated and transparent data-at-rest  encryption functionality compatible with Openshift and any other container orchestrator. Once the Operator is provisioned, the driver runs fine tuned and ready to work with other XCrypt components.\n* **Multi-node topology**: Encrypt as many nodes and volumes as you need to. XCrypt components can be installed on multiple nodes across the cluster. This is defined by two labels: zts-master and zts-worker. Normally zts-master node is a single node that runs Zettaset XCrypt major services required for the product operation. Multiple nodes can be marked as zts-worker and those are the nodes that can have encrypted volumes.\n* **Seamless Encrypted Volume mount**: Volumes are not only being encrypted, but also are mounted/unmounted to containers with Persistent Volume Claims. This happens as seamlessly as regular volumes provision and mount/unmount.\n* **Robust failover**: A node failure doesn\u2019t affect XCrypt operations on other nodes of the cluster. Encryption on a restarted/recovered node gets back to normal functioning if the node stays healthy and data hasn\u2019t been corrupted during the restart\n\n## About Zettaset XCrypt Kubernetes Encryption for OpenShift\nXCrypt Kubernetes Encryption for OpenShift is a software-only solution that enables encryption of data at rest stored in Red Hat OpenShift container environments without slowing down the DevSecOps process. In addition to providing a transparent and high-performance layer of security that flexibly protects container data across on-premise, in hybrid, and multi-cloud environments, it also helps your organization efficiently transition from DevOps to DevSecOps.  \n\nMore information about Zettaset XCrypt Kubernetes Encryption for OpenShift can be found in the [Deployment and Administration Guide](https://1f2aca073706bb52f501-133f3466c38fdb0417539cdf095d8336.ssl.cf1.rackcdn.com/ZettasetXCryptContainerEncryption.8.5.0.Final.pdf)\n\n## RedHat OpenShift + Zettaset: The next generation of secure enterprise infrastructure for DevSecOps  \nBy combining RedHat\u2019s Container Platform with Zettaset\u2019s certified software-defined encryption, you can create the next generation of secure enterprise infrastructure that DevSecOps requires. Together they create the stable, consistent, and supported base that your organization needs to develop applications faster, simplify updates, drive innovation, and reduce the risk of potential security breaches and data theft.\n### Core Features\n* Software-only for simple and scalable deployments \n* Negligible performance impact\n* Transparent to developers and administrators \n* Works with AWS, Google, and Azure \n* Unique encryption key per container volume \n* Encrypted volumes are only available when in use\n* Direct integration with OpenShift \n* Automated encryption policy management Secure erase of volumes\n* Ability to securely decommission a node\n\n## How does XCrypt Kubernetes Encryption fit into OpenShift? \nXCrypt XCrypt Kubernetes Encryption for OpenShift Encryption makes it incredibly easy to protect container data in your OpenShift environment. \n### Use cases include:\n* Transitioning from DevOps to DevSecOps \n* Ensuring data protection in OpenShift container environments with negligible performance impact \n* Achieving compliance in regulated industries like healthcare and finance\n\n## Other Information\nRole-based access control needs to be configured prior to the Operator installation. Please find details in the [Deployment and Administration Guide](https://1f2aca073706bb52f501-133f3466c38fdb0417539cdf095d8336.ssl.cf1.rackcdn.com/ZettasetXCryptContainerEncryption.8.5.0.Final.pdf)    ",
      "csv_display_name": "Zettaset XCrypt Operator",
      "csv_metadata_description": "XCrypt Operator deploys Zettaset XCrypt Container Encryption  - the only software-defined solution that offers transparent high performance data-at-rest encryption of critical data in container environments.",
      "csv_name": "zts-xcrypt-operator.v0.0.17",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:32:09.967000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "xcrypt-operator",
      "provided_apis": [
        {
          "group": "xcrypt.zettaset.com",
          "kind": "XCrypt",
          "plural": "xcrypts",
          "version": "v1alpha1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:7e6316a6c41dd71c4d9025bd958a475929369284eee1a02d9e870e883acfd9ac",
          "image": "registry.connect.redhat.com/zts/xcrypt-operator-1@sha256:7e6316a6c41dd71c4d9025bd958a475929369284eee1a02d9e870e883acfd9ac",
          "name": "xcrypt-operator-1-7e6316a6c41dd71c4d9025bd958a475929369284eee1a02d9e870e883acfd9ac-annotation"
        },
        {
          "digest": "sha256:7e6316a6c41dd71c4d9025bd958a475929369284eee1a02d9e870e883acfd9ac",
          "image": "registry.connect.redhat.com/zts/xcrypt-operator-1@sha256:7e6316a6c41dd71c4d9025bd958a475929369284eee1a02d9e870e883acfd9ac",
          "name": "zts-xcrypt-operator"
        },
        {
          "digest": "sha256:9f1015dfb459b69f5dbf449efa0517452095a6cf4f20826ebae278f9f800ffe7",
          "image": "registry.connect.redhat.com/zts/xcrypt-ca-1@sha256:9f1015dfb459b69f5dbf449efa0517452095a6cf4f20826ebae278f9f800ffe7",
          "name": "ca"
        },
        {
          "digest": "sha256:9af5d21dd748dfbf4e107f27a5f10fa3c0ba928ade9b989a744b620ce34ec757",
          "image": "registry.connect.redhat.com/zts/xcrypt-kmip-server-1@sha256:9af5d21dd748dfbf4e107f27a5f10fa3c0ba928ade9b989a744b620ce34ec757",
          "name": "kmip"
        },
        {
          "digest": "sha256:bc5486892a41e70f5dc4c4e1d82fca8db2149598fb8b5950ba5da1ee2d9d245d",
          "image": "registry.connect.redhat.com/zts/xcrypt-license-server-1@sha256:bc5486892a41e70f5dc4c4e1d82fca8db2149598fb8b5950ba5da1ee2d9d245d",
          "name": "ls"
        },
        {
          "digest": "sha256:9faa4b597eb74df412761dffa057b64fb69dbf9fa016414962eb2099a343e734",
          "image": "registry.connect.redhat.com/zts/xcrypt-host-manager-1@sha256:9faa4b597eb74df412761dffa057b64fb69dbf9fa016414962eb2099a343e734",
          "name": "hm"
        },
        {
          "digest": "sha256:c15fa9a7cc40891103f426206663dcebe1210c8ee3ab6037cbf64e1f86b9c7e5",
          "image": "registry.connect.redhat.com/zts/zts-csi-driver-1@sha256:c15fa9a7cc40891103f426206663dcebe1210c8ee3ab6037cbf64e1f86b9c7e5",
          "name": "csi_driver"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "0.0.17",
      "version_original": "0.0.17"
    },
    {
      "_id": "61a5e1283e9240fca360f696",
      "alm_examples": [
        {
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:c771db6ff2400a5a78b66b4345e50f0346aa64f6cc66a3de34913d4f3dc57ea6",
      "bundle_path_digest": "sha256:c771db6ff2400a5a78b66b4345e50f0346aa64f6cc66a3de34913d4f3dc57ea6",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2021-11-30T08:30:32.060000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.4.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:17:35.816000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "name": "kubeturbo-operator-879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d-annotation"
        },
        {
          "digest": "sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:4828ed949374c8191da9d54c0d3ea95d7c3c1f1d9548db55eed7ebf09a1ba076",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:4828ed949374c8191da9d54c0d3ea95d7c3c1f1d9548db55eed7ebf09a1ba076",
          "name": "kubeturbo"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "8.4.0",
      "version_original": "8.4.0"
    },
    {
      "_id": "61a6b905bfd4a5234d5963a9",
      "alm_examples": [
        {
          "kind": "System",
          "metadata": {
            "name": "ionir"
          },
          "spec": {
            "imageRegistry": "quay.io/ionir",
            "profile": "minimal",
            "tag": "v2.5"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ionir/ionir-operator-bundle@sha256:79319e01b6f760d6a494bae31e8dfad3adfddc5d63f4c4d03424618b742b0279",
      "bundle_path_digest": "sha256:79319e01b6f760d6a494bae31e8dfad3adfddc5d63f4c4d03424618b742b0279",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2021-11-30T23:51:33.094000+00:00",
      "csv_description": "Ionir is a container-native data platform for Kubernetes.\nIonir virtualizes all available storage in a Kubernetes cluster to create a single pool of highly scalable storage.\nHaving a Container Storage Interface (CSI) plugin, Ionir storage can be provisioned and managed by Kubernetes,\nthe common control plane in the environment. In addition to providing resilient, high-performance storage, Ionir\nalso provides end-to-end data management capabilities. The Ionir architecture separates the metadata from the data,\nwhich enables unique data management capabilities such as instant clones. The microservices architecture provides\na unified data platform that is elastic, scalable, and agile, which is critical for containerized deployments.\n### Instant Data Mobility\nIonir gives K8s application data wings. Persistent volumes move at the speed of applications, in any direction, to and from anywhere - on-prem, cloud, public, private - in seconds!\nWhat\u2019s more, ionir transparently delivers everything you\u2019ve come to expect from enterprise storage \u2013 performance and scalability, data protection, replication, deduplication and more - built to run natively on Kubernetes clusters.\n### Enterprise-Class Data Protection\nOffering instant point-in-time restore with one second granularity, ionir\u2019s highly efficient data protection capabilities exceed even traditional monolithic arrays, and are unrivaled in K8s native storage.\n### Simple. Converged. Native.\nOne comprehensive platform \u2015 orchestrated by Kubernetes \u2015 serves, stores and manages all your K8s application data. All based on RESTful APIs for easy automation.\n### Aligned to Applications\nAdvanced machine learning ensures data is mapped to the optimal storage resource based on performance, density, cost, location, and other key factors.\n### How to install Ionir\n### Prerequisites\n* See details in [Ionir Deployment Requirements - OCP](https://github.com/ionir-cloud/deployments/blob/main/documents/Ionir%20Deployment%20Requirements%20-%20OCP.pdf)\n* Review Ionir [EULA] (https://ionir.com/legal/eula/)\n\n### Uninstall\nFirst remove all applications consuming Ionir storage prior to deleting Ionir system custom resource.<br>\nNote: Storage classes with Ionir provisioner should be deleted manually\n> :warning: This action uninstalls Ionir completely and wipes the entire data. This action can not be reversed.\n",
      "csv_display_name": "Ionir",
      "csv_metadata_description": "Ionir is a container-native data platform built in Kubernetes",
      "csv_name": "ionir-operator.v1.0.7",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:18:41.073000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "ionir-operator",
      "provided_apis": [
        {
          "group": "operator.ionir.com",
          "kind": "System",
          "plural": "systems",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:5b28c9559e65d15fdeb13c62e893e05e8090de7658c10e06feb18c69fd8a5525",
          "image": "registry.connect.redhat.com/ionir/ionir-operator@sha256:5b28c9559e65d15fdeb13c62e893e05e8090de7658c10e06feb18c69fd8a5525",
          "name": "ionir-operator-5b28c9559e65d15fdeb13c62e893e05e8090de7658c10e06feb18c69fd8a5525-annotation"
        },
        {
          "digest": "sha256:5b28c9559e65d15fdeb13c62e893e05e8090de7658c10e06feb18c69fd8a5525",
          "image": "registry.connect.redhat.com/ionir/ionir-operator@sha256:5b28c9559e65d15fdeb13c62e893e05e8090de7658c10e06feb18c69fd8a5525",
          "name": "manager"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "1.0.7",
      "version_original": "1.0.7"
    },
    {
      "_id": "61a6ba07c17162a20c1c6baf",
      "alm_examples": [
        {
          "kind": "PostgresCluster",
          "metadata": {
            "name": "example"
          },
          "spec": {
            "instances": [
              {
                "dataVolumeClaimSpec": {
                  "accessModes": [
                    "ReadWriteOnce"
                  ],
                  "resources": {
                    "requests": {
                      "storage": "1Gi"
                    }
                  }
                },
                "replicas": 1
              }
            ],
            "postgresVersion": 13
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/crunchydata/postgres-operator-bundle@sha256:6166f3ee3ea06cd8c3d4e78ee2b9298cb203002521db6de5ec97131d2ef3d97d",
      "bundle_path_digest": "sha256:6166f3ee3ea06cd8c3d4e78ee2b9298cb203002521db6de5ec97131d2ef3d97d",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "v5",
      "creation_date": "2021-11-30T23:55:51.410000+00:00",
      "csv_description": "[PGO](https://github.com/CrunchyData/postgres-operator), the\n[Postgres Operator](https://github.com/CrunchyData/postgres-operator) from\n[Crunchy Data](https://www.crunchydata.com), gives you a **declarative Postgres** solution that\nautomatically manages your [PostgreSQL](https://www.postgresql.org) clusters.\n\nDesigned for your GitOps workflows, it is [easy to get started](https://access.crunchydata.com/documentation/postgres-operator/v5/quickstart/)\nwith Postgres on Kubernetes with PGO. Within a few moments, you can have a production grade Postgres\ncluster complete with high availability, disaster recovery, and monitoring, all over secure TLS communications.\nEven better, PGO lets you easily customize your Postgres cluster to tailor it to your workload!\n\nWith conveniences like cloning Postgres clusters to using rolling updates to roll out disruptive\nchanges with minimal downtime, PGO is ready to support your Postgres data at every stage of your\nrelease pipeline. Built for resiliency and uptime, PGO will keep your desired Postgres in a desired\nstate so you do not need to worry about it.\n\nPGO is developed with many years of production experience in automating Postgres management on\nKubernetes, providing a seamless cloud native Postgres solution to keep your data always available.\n\n- **PostgreSQL Cluster Provisioning**: [Create, Scale, & Delete PostgreSQL clusters with ease][provisioning],\n  while fully customizing your Pods and PostgreSQL configuration!\n- **High-Availability**: Safe, automated failover backed by a [distributed consensus based high-availability solution][high-availability].\n  Uses [Pod Anti-Affinity][k8s-anti-affinity] to help resiliency; you can configure how aggressive this can be!\n  Failed primaries automatically heal, allowing for faster recovery time. You can even create regularly scheduled\n  backups as well and set your backup retention policy\n- **Disaster Recovery**: [Backups][backups] and [restores][disaster-recovery] leverage the open source [pgBackRest][] utility and\n  [includes support for full, incremental, and differential backups as well as efficient delta restores][backups].\n  Set how long you want your backups retained for. Works great with very large databases!\n- **Monitoring**: [Track the health of your PostgreSQL clusters][monitoring] using the open source [pgMonitor][] library.\n- **Clone**: [Create new clusters from your existing clusters or backups][clone] with efficient data cloning.\n- **TLS**: All connections are over [TLS][tls]. You can also [bring your own TLS infrastructure][tls] if you do not want to use the provided defaults.\n- **Connection Pooling**: Advanced [connection pooling][pool] support using [pgBouncer][].\n- **Affinity and Tolerations**: Have your PostgreSQL clusters deployed to [Kubernetes Nodes][k8s-nodes] of your preference.\n  Set your [pod anti-affinity][k8s-anti-affinity], node affinity, Pod tolerations and more rules to customize your deployment topology!\n- **Full Customizability**: Crunchy PostgreSQL for Kubernetes makes it easy to get your own PostgreSQL-as-a-Service up and running\n  and fully customize your deployments, including:\n    - Choose the resources for your Postgres cluster: [container resources and storage size][resize-cluster]. [Resize at any time][resize-cluster] with minimal disruption.\n    - Use your own container image repository, including support `imagePullSecrets` and private repositories\n    - [Customize your PostgreSQL configuration][customize-cluster]\n\nand much more!\n\n[backups]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/backups/\n[clone]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/disaster-recovery/#clone-a-postgres-cluster\n[customize-cluster]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/customize-cluster/\n[disaster-recovery]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/disaster-recovery/\n[high-availability]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/high-availability/\n[monitoring]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/monitoring/\n[pool]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/connection-pooling/\n[provisioning]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/create-cluster/\n[resize-cluster]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/resize-cluster/\n[tls]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/customize-cluster/#customize-tls\n\n[k8s-anti-affinity]: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n[k8s-nodes]: https://kubernetes.io/docs/concepts/architecture/nodes/\n\n[pgBackRest]: https://www.pgbackrest.org\n[pgBouncer]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/connection-pooling/\n[pgMonitor]: https://github.com/CrunchyData/pgmonitor\n\n\n## Post-Installation\n\n### Tutorial\n\nWant to [learn more about the PostgreSQL Operator][tutorial]? Browse through the [tutorial][] to learn more about what you can do!\n\n[tutorial]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial",
      "csv_display_name": "Crunchy Postgres for Kubernetes",
      "csv_metadata_description": "Production Postgres Made Easy",
      "csv_name": "postgresoperator.v5.0.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:14:04.903000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "crunchy-postgres-operator",
      "provided_apis": [
        {
          "group": "postgres-operator.crunchydata.com",
          "kind": "PostgresCluster",
          "plural": "postgresclusters",
          "version": "v1beta1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:35bd6e284d71881524766662657e60c654a9bc77cd79c43a667cd76b1984dc34",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:35bd6e284d71881524766662657e60c654a9bc77cd79c43a667cd76b1984dc34",
          "name": "postgres-operator-35bd6e284d71881524766662657e60c654a9bc77cd79c43a667cd76b1984dc34-annotation"
        },
        {
          "digest": "sha256:35bd6e284d71881524766662657e60c654a9bc77cd79c43a667cd76b1984dc34",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:35bd6e284d71881524766662657e60c654a9bc77cd79c43a667cd76b1984dc34",
          "name": "operator"
        },
        {
          "digest": "sha256:4256829ed455475e45ef210bea800c42d6eb53497a734428cb753c2af3d46ced",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbackrest@sha256:4256829ed455475e45ef210bea800c42d6eb53497a734428cb753c2af3d46ced",
          "name": "pgbackrest"
        },
        {
          "digest": "sha256:dd8c2aff733a4c064ce5a89bcd2b1e984099c72807e790def526d90dbc7f46dd",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbouncer@sha256:dd8c2aff733a4c064ce5a89bcd2b1e984099c72807e790def526d90dbc7f46dd",
          "name": "pgbouncer"
        },
        {
          "digest": "sha256:a6f88150ddd3e01d32d1c573ee3022072f98031341d1bed2ae440d772482ce65",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-exporter@sha256:a6f88150ddd3e01d32d1c573ee3022072f98031341d1bed2ae440d772482ce65",
          "name": "pgexporter"
        },
        {
          "digest": "sha256:74e35614839ae674ee210e3850dee01e50c5d3d218eeee2d4d33e778db76ffbc",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:74e35614839ae674ee210e3850dee01e50c5d3d218eeee2d4d33e778db76ffbc",
          "name": "postgres_12"
        },
        {
          "digest": "sha256:b9a152771c489673a51dfe815c290af5666e68e614ac0dfd1d3ba54a371f47be",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:b9a152771c489673a51dfe815c290af5666e68e614ac0dfd1d3ba54a371f47be",
          "name": "postgres_13"
        },
        {
          "digest": "sha256:a2b34428eb1e23cd2a39e85d3da95a35a19715543b13d3d7ab0183ba8083ec33",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:a2b34428eb1e23cd2a39e85d3da95a35a19715543b13d3d7ab0183ba8083ec33",
          "name": "postgres_14"
        },
        {
          "digest": "sha256:ec92544d41f771e69ce84009ef145e1e59cd31521e4a948c5ecb8f0ddfb8fe9b",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:ec92544d41f771e69ce84009ef145e1e59cd31521e4a948c5ecb8f0ddfb8fe9b",
          "name": "postgres_12_gis_2.5"
        },
        {
          "digest": "sha256:a1ec04b12610e2cb1094b85ed8fdd97106c07c048a3480d2baa25d7171284921",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:a1ec04b12610e2cb1094b85ed8fdd97106c07c048a3480d2baa25d7171284921",
          "name": "postgres_12_gis_3.0"
        },
        {
          "digest": "sha256:23b8deca0a30982f14b433937c1c133e6f257b8599d52be60de9d85571a7f2a3",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:23b8deca0a30982f14b433937c1c133e6f257b8599d52be60de9d85571a7f2a3",
          "name": "postgres_13_gis_3.0"
        },
        {
          "digest": "sha256:4e6bfa1def778e9f20506ba980a2bd2cfd392142c1cd072b6892b41a68d56db1",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:4e6bfa1def778e9f20506ba980a2bd2cfd392142c1cd072b6892b41a68d56db1",
          "name": "postgres_13_gis_3.1"
        },
        {
          "digest": "sha256:550426086d4647d3c49ec17ffc1fde265ac3026ab042113b64111177eb898fb6",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:550426086d4647d3c49ec17ffc1fde265ac3026ab042113b64111177eb898fb6",
          "name": "postgres_14_gis_3.1"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "5.0.4",
      "version_original": "5.0.4"
    },
    {
      "_id": "61a6bc42bfd4a5234d5963ab",
      "alm_examples": [
        {
          "kind": "System",
          "metadata": {
            "name": "ionir"
          },
          "spec": {
            "imageRegistry": "quay.io/ionir",
            "profile": "minimal",
            "tag": "ilan-certification-test"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ionir/ionir-operator-bundle@sha256:f54f915f843f9372f447cec692d4076a963668cecacf11f66fd85439b069558e",
      "bundle_path_digest": "sha256:f54f915f843f9372f447cec692d4076a963668cecacf11f66fd85439b069558e",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2021-12-01T00:05:22.643000+00:00",
      "csv_description": "Ionir is a container-native data platform for Kubernetes.\nIonir virtualizes all available storage in a Kubernetes cluster to create a single pool of highly scalable storage.\nHaving a Container Storage Interface (CSI) plugin, Ionir storage can be provisioned and managed by Kubernetes,\nthe common control plane in the environment. In addition to providing resilient, high-performance storage, Ionir\nalso provides end-to-end data management capabilities. The Ionir architecture separates the metadata from the data,\nwhich enables unique data management capabilities such as instant clones. The microservices architecture provides\na unified data platform that is elastic, scalable, and agile, which is critical for containerized deployments.\n### Instant Data Mobility\nIonir gives K8s application data wings. Persistent volumes move at the speed of applications, in any direction, to and from anywhere - on-prem, cloud, public, private - in seconds!\nWhat\u2019s more, ionir transparently delivers everything you\u2019ve come to expect from enterprise storage \u2013 performance and scalability, data protection, replication, deduplication and more - built to run natively on Kubernetes clusters.\n### Enterprise-Class Data Protection\nOffering instant point-in-time restore with one second granularity, ionir\u2019s highly efficient data protection capabilities exceed even traditional monolithic arrays, and are unrivaled in K8s native storage.\n### Simple. Converged. Native.\nOne comprehensive platform \u2015 orchestrated by Kubernetes \u2015 serves, stores and manages all your K8s application data. All based on RESTful APIs for easy automation.\n### Aligned to Applications\nAdvanced machine learning ensures data is mapped to the optimal storage resource based on performance, density, cost, location, and other key factors.\n### How to install Ionir\n### Prerequisites\n* See details in [Ionir Deployment Requirements - OCP](https://github.com/ionir-cloud/deployments/blob/main/documents/Ionir%20Deployment%20Requirements%20-%20OCP.pdf)\n* Review Ionir [EULA] (https://ionir.com/legal/eula/)\n\n### Uninstall\nFirst remove all applications consuming Ionir storage prior to deleting Ionir system custom resource.<br>\nNote: Storage classes with Ionir provisioner should be deleted manually\n> :warning: This action uninstalls Ionir completely and wipes the entire data. This action can not be reversed.\n",
      "csv_display_name": "Ionir",
      "csv_metadata_description": "Ionir is a container-native data platform built in Kubernetes",
      "csv_name": "ionir-operator.v1.0.6",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:14:49.100000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "ionir-operator",
      "provided_apis": [
        {
          "group": "operator.ionir.com",
          "kind": "System",
          "plural": "systems",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:3c6c05ea8feb356bb9f90c652bd05a94edeb33248be09eedf4f9f21e80de6ef1",
          "image": "registry.connect.redhat.com/ionir/ionir-operator@sha256:3c6c05ea8feb356bb9f90c652bd05a94edeb33248be09eedf4f9f21e80de6ef1",
          "name": "ionir-operator-3c6c05ea8feb356bb9f90c652bd05a94edeb33248be09eedf4f9f21e80de6ef1-annotation"
        },
        {
          "digest": "sha256:3c6c05ea8feb356bb9f90c652bd05a94edeb33248be09eedf4f9f21e80de6ef1",
          "image": "registry.connect.redhat.com/ionir/ionir-operator@sha256:3c6c05ea8feb356bb9f90c652bd05a94edeb33248be09eedf4f9f21e80de6ef1",
          "name": "manager"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "1.0.6",
      "version_original": "1.0.6"
    },
    {
      "_id": "61a756bcbfd4a5234d59648b",
      "alm_examples": [
        {
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:c771db6ff2400a5a78b66b4345e50f0346aa64f6cc66a3de34913d4f3dc57ea6",
      "bundle_path_digest": "sha256:c771db6ff2400a5a78b66b4345e50f0346aa64f6cc66a3de34913d4f3dc57ea6",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2021-12-01T11:04:28.797000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.4.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T10:58:52.525000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "name": "kubeturbo-operator-879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d-annotation"
        },
        {
          "digest": "sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:4828ed949374c8191da9d54c0d3ea95d7c3c1f1d9548db55eed7ebf09a1ba076",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:4828ed949374c8191da9d54c0d3ea95d7c3c1f1d9548db55eed7ebf09a1ba076",
          "name": "kubeturbo"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "8.4.0",
      "version_original": "8.4.0"
    },
    {
      "_id": "61a75702bfd4a5234d59648c",
      "alm_examples": [
        {
          "kind": "PostgresCluster",
          "metadata": {
            "name": "example"
          },
          "spec": {
            "instances": [
              {
                "dataVolumeClaimSpec": {
                  "accessModes": [
                    "ReadWriteOnce"
                  ],
                  "resources": {
                    "requests": {
                      "storage": "1Gi"
                    }
                  }
                },
                "replicas": 1
              }
            ],
            "postgresVersion": 13
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/crunchydata/postgres-operator-bundle@sha256:6166f3ee3ea06cd8c3d4e78ee2b9298cb203002521db6de5ec97131d2ef3d97d",
      "bundle_path_digest": "sha256:6166f3ee3ea06cd8c3d4e78ee2b9298cb203002521db6de5ec97131d2ef3d97d",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "v5",
      "creation_date": "2021-12-01T11:05:38.286000+00:00",
      "csv_description": "[PGO](https://github.com/CrunchyData/postgres-operator), the\n[Postgres Operator](https://github.com/CrunchyData/postgres-operator) from\n[Crunchy Data](https://www.crunchydata.com), gives you a **declarative Postgres** solution that\nautomatically manages your [PostgreSQL](https://www.postgresql.org) clusters.\n\nDesigned for your GitOps workflows, it is [easy to get started](https://access.crunchydata.com/documentation/postgres-operator/v5/quickstart/)\nwith Postgres on Kubernetes with PGO. Within a few moments, you can have a production grade Postgres\ncluster complete with high availability, disaster recovery, and monitoring, all over secure TLS communications.\nEven better, PGO lets you easily customize your Postgres cluster to tailor it to your workload!\n\nWith conveniences like cloning Postgres clusters to using rolling updates to roll out disruptive\nchanges with minimal downtime, PGO is ready to support your Postgres data at every stage of your\nrelease pipeline. Built for resiliency and uptime, PGO will keep your desired Postgres in a desired\nstate so you do not need to worry about it.\n\nPGO is developed with many years of production experience in automating Postgres management on\nKubernetes, providing a seamless cloud native Postgres solution to keep your data always available.\n\n- **PostgreSQL Cluster Provisioning**: [Create, Scale, & Delete PostgreSQL clusters with ease][provisioning],\n  while fully customizing your Pods and PostgreSQL configuration!\n- **High-Availability**: Safe, automated failover backed by a [distributed consensus based high-availability solution][high-availability].\n  Uses [Pod Anti-Affinity][k8s-anti-affinity] to help resiliency; you can configure how aggressive this can be!\n  Failed primaries automatically heal, allowing for faster recovery time. You can even create regularly scheduled\n  backups as well and set your backup retention policy\n- **Disaster Recovery**: [Backups][backups] and [restores][disaster-recovery] leverage the open source [pgBackRest][] utility and\n  [includes support for full, incremental, and differential backups as well as efficient delta restores][backups].\n  Set how long you want your backups retained for. Works great with very large databases!\n- **Monitoring**: [Track the health of your PostgreSQL clusters][monitoring] using the open source [pgMonitor][] library.\n- **Clone**: [Create new clusters from your existing clusters or backups][clone] with efficient data cloning.\n- **TLS**: All connections are over [TLS][tls]. You can also [bring your own TLS infrastructure][tls] if you do not want to use the provided defaults.\n- **Connection Pooling**: Advanced [connection pooling][pool] support using [pgBouncer][].\n- **Affinity and Tolerations**: Have your PostgreSQL clusters deployed to [Kubernetes Nodes][k8s-nodes] of your preference.\n  Set your [pod anti-affinity][k8s-anti-affinity], node affinity, Pod tolerations and more rules to customize your deployment topology!\n- **Full Customizability**: Crunchy PostgreSQL for Kubernetes makes it easy to get your own PostgreSQL-as-a-Service up and running\n  and fully customize your deployments, including:\n    - Choose the resources for your Postgres cluster: [container resources and storage size][resize-cluster]. [Resize at any time][resize-cluster] with minimal disruption.\n    - Use your own container image repository, including support `imagePullSecrets` and private repositories\n    - [Customize your PostgreSQL configuration][customize-cluster]\n\nand much more!\n\n[backups]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/backups/\n[clone]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/disaster-recovery/#clone-a-postgres-cluster\n[customize-cluster]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/customize-cluster/\n[disaster-recovery]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/disaster-recovery/\n[high-availability]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/high-availability/\n[monitoring]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/monitoring/\n[pool]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/connection-pooling/\n[provisioning]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/create-cluster/\n[resize-cluster]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/resize-cluster/\n[tls]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/customize-cluster/#customize-tls\n\n[k8s-anti-affinity]: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n[k8s-nodes]: https://kubernetes.io/docs/concepts/architecture/nodes/\n\n[pgBackRest]: https://www.pgbackrest.org\n[pgBouncer]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/connection-pooling/\n[pgMonitor]: https://github.com/CrunchyData/pgmonitor\n\n\n## Post-Installation\n\n### Tutorial\n\nWant to [learn more about the PostgreSQL Operator][tutorial]? Browse through the [tutorial][] to learn more about what you can do!\n\n[tutorial]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial",
      "csv_display_name": "Crunchy Postgres for Kubernetes",
      "csv_metadata_description": "Production Postgres Made Easy",
      "csv_name": "postgresoperator.v5.0.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:00:44.236000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "crunchy-postgres-operator",
      "provided_apis": [
        {
          "group": "postgres-operator.crunchydata.com",
          "kind": "PostgresCluster",
          "plural": "postgresclusters",
          "version": "v1beta1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:35bd6e284d71881524766662657e60c654a9bc77cd79c43a667cd76b1984dc34",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:35bd6e284d71881524766662657e60c654a9bc77cd79c43a667cd76b1984dc34",
          "name": "postgres-operator-35bd6e284d71881524766662657e60c654a9bc77cd79c43a667cd76b1984dc34-annotation"
        },
        {
          "digest": "sha256:35bd6e284d71881524766662657e60c654a9bc77cd79c43a667cd76b1984dc34",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:35bd6e284d71881524766662657e60c654a9bc77cd79c43a667cd76b1984dc34",
          "name": "operator"
        },
        {
          "digest": "sha256:4256829ed455475e45ef210bea800c42d6eb53497a734428cb753c2af3d46ced",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbackrest@sha256:4256829ed455475e45ef210bea800c42d6eb53497a734428cb753c2af3d46ced",
          "name": "pgbackrest"
        },
        {
          "digest": "sha256:dd8c2aff733a4c064ce5a89bcd2b1e984099c72807e790def526d90dbc7f46dd",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbouncer@sha256:dd8c2aff733a4c064ce5a89bcd2b1e984099c72807e790def526d90dbc7f46dd",
          "name": "pgbouncer"
        },
        {
          "digest": "sha256:a6f88150ddd3e01d32d1c573ee3022072f98031341d1bed2ae440d772482ce65",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-exporter@sha256:a6f88150ddd3e01d32d1c573ee3022072f98031341d1bed2ae440d772482ce65",
          "name": "pgexporter"
        },
        {
          "digest": "sha256:74e35614839ae674ee210e3850dee01e50c5d3d218eeee2d4d33e778db76ffbc",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:74e35614839ae674ee210e3850dee01e50c5d3d218eeee2d4d33e778db76ffbc",
          "name": "postgres_12"
        },
        {
          "digest": "sha256:b9a152771c489673a51dfe815c290af5666e68e614ac0dfd1d3ba54a371f47be",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:b9a152771c489673a51dfe815c290af5666e68e614ac0dfd1d3ba54a371f47be",
          "name": "postgres_13"
        },
        {
          "digest": "sha256:a2b34428eb1e23cd2a39e85d3da95a35a19715543b13d3d7ab0183ba8083ec33",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:a2b34428eb1e23cd2a39e85d3da95a35a19715543b13d3d7ab0183ba8083ec33",
          "name": "postgres_14"
        },
        {
          "digest": "sha256:ec92544d41f771e69ce84009ef145e1e59cd31521e4a948c5ecb8f0ddfb8fe9b",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:ec92544d41f771e69ce84009ef145e1e59cd31521e4a948c5ecb8f0ddfb8fe9b",
          "name": "postgres_12_gis_2.5"
        },
        {
          "digest": "sha256:a1ec04b12610e2cb1094b85ed8fdd97106c07c048a3480d2baa25d7171284921",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:a1ec04b12610e2cb1094b85ed8fdd97106c07c048a3480d2baa25d7171284921",
          "name": "postgres_12_gis_3.0"
        },
        {
          "digest": "sha256:23b8deca0a30982f14b433937c1c133e6f257b8599d52be60de9d85571a7f2a3",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:23b8deca0a30982f14b433937c1c133e6f257b8599d52be60de9d85571a7f2a3",
          "name": "postgres_13_gis_3.0"
        },
        {
          "digest": "sha256:4e6bfa1def778e9f20506ba980a2bd2cfd392142c1cd072b6892b41a68d56db1",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:4e6bfa1def778e9f20506ba980a2bd2cfd392142c1cd072b6892b41a68d56db1",
          "name": "postgres_13_gis_3.1"
        },
        {
          "digest": "sha256:550426086d4647d3c49ec17ffc1fde265ac3026ab042113b64111177eb898fb6",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:550426086d4647d3c49ec17ffc1fde265ac3026ab042113b64111177eb898fb6",
          "name": "postgres_14_gis_3.1"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "5.0.4",
      "version_original": "5.0.4"
    },
    {
      "_id": "61a75cca3e9240fca360f969",
      "alm_examples": [
        {
          "kind": "PostgresCluster",
          "metadata": {
            "name": "example"
          },
          "spec": {
            "instances": [
              {
                "dataVolumeClaimSpec": {
                  "accessModes": [
                    "ReadWriteOnce"
                  ],
                  "resources": {
                    "requests": {
                      "storage": "1Gi"
                    }
                  }
                },
                "replicas": 1
              }
            ],
            "postgresVersion": 13
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/crunchydata/postgres-operator-bundle@sha256:6166f3ee3ea06cd8c3d4e78ee2b9298cb203002521db6de5ec97131d2ef3d97d",
      "bundle_path_digest": "sha256:6166f3ee3ea06cd8c3d4e78ee2b9298cb203002521db6de5ec97131d2ef3d97d",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "v5",
      "creation_date": "2021-12-01T11:30:18.651000+00:00",
      "csv_description": "[PGO](https://github.com/CrunchyData/postgres-operator), the\n[Postgres Operator](https://github.com/CrunchyData/postgres-operator) from\n[Crunchy Data](https://www.crunchydata.com), gives you a **declarative Postgres** solution that\nautomatically manages your [PostgreSQL](https://www.postgresql.org) clusters.\n\nDesigned for your GitOps workflows, it is [easy to get started](https://access.crunchydata.com/documentation/postgres-operator/v5/quickstart/)\nwith Postgres on Kubernetes with PGO. Within a few moments, you can have a production grade Postgres\ncluster complete with high availability, disaster recovery, and monitoring, all over secure TLS communications.\nEven better, PGO lets you easily customize your Postgres cluster to tailor it to your workload!\n\nWith conveniences like cloning Postgres clusters to using rolling updates to roll out disruptive\nchanges with minimal downtime, PGO is ready to support your Postgres data at every stage of your\nrelease pipeline. Built for resiliency and uptime, PGO will keep your desired Postgres in a desired\nstate so you do not need to worry about it.\n\nPGO is developed with many years of production experience in automating Postgres management on\nKubernetes, providing a seamless cloud native Postgres solution to keep your data always available.\n\n- **PostgreSQL Cluster Provisioning**: [Create, Scale, & Delete PostgreSQL clusters with ease][provisioning],\n  while fully customizing your Pods and PostgreSQL configuration!\n- **High-Availability**: Safe, automated failover backed by a [distributed consensus based high-availability solution][high-availability].\n  Uses [Pod Anti-Affinity][k8s-anti-affinity] to help resiliency; you can configure how aggressive this can be!\n  Failed primaries automatically heal, allowing for faster recovery time. You can even create regularly scheduled\n  backups as well and set your backup retention policy\n- **Disaster Recovery**: [Backups][backups] and [restores][disaster-recovery] leverage the open source [pgBackRest][] utility and\n  [includes support for full, incremental, and differential backups as well as efficient delta restores][backups].\n  Set how long you want your backups retained for. Works great with very large databases!\n- **Monitoring**: [Track the health of your PostgreSQL clusters][monitoring] using the open source [pgMonitor][] library.\n- **Clone**: [Create new clusters from your existing clusters or backups][clone] with efficient data cloning.\n- **TLS**: All connections are over [TLS][tls]. You can also [bring your own TLS infrastructure][tls] if you do not want to use the provided defaults.\n- **Connection Pooling**: Advanced [connection pooling][pool] support using [pgBouncer][].\n- **Affinity and Tolerations**: Have your PostgreSQL clusters deployed to [Kubernetes Nodes][k8s-nodes] of your preference.\n  Set your [pod anti-affinity][k8s-anti-affinity], node affinity, Pod tolerations and more rules to customize your deployment topology!\n- **Full Customizability**: Crunchy PostgreSQL for Kubernetes makes it easy to get your own PostgreSQL-as-a-Service up and running\n  and fully customize your deployments, including:\n    - Choose the resources for your Postgres cluster: [container resources and storage size][resize-cluster]. [Resize at any time][resize-cluster] with minimal disruption.\n    - Use your own container image repository, including support `imagePullSecrets` and private repositories\n    - [Customize your PostgreSQL configuration][customize-cluster]\n\nand much more!\n\n[backups]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/backups/\n[clone]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/disaster-recovery/#clone-a-postgres-cluster\n[customize-cluster]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/customize-cluster/\n[disaster-recovery]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/disaster-recovery/\n[high-availability]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/high-availability/\n[monitoring]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/monitoring/\n[pool]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/connection-pooling/\n[provisioning]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/create-cluster/\n[resize-cluster]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/resize-cluster/\n[tls]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/customize-cluster/#customize-tls\n\n[k8s-anti-affinity]: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n[k8s-nodes]: https://kubernetes.io/docs/concepts/architecture/nodes/\n\n[pgBackRest]: https://www.pgbackrest.org\n[pgBouncer]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/connection-pooling/\n[pgMonitor]: https://github.com/CrunchyData/pgmonitor\n\n\n## Post-Installation\n\n### Tutorial\n\nWant to [learn more about the PostgreSQL Operator][tutorial]? Browse through the [tutorial][] to learn more about what you can do!\n\n[tutorial]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial",
      "csv_display_name": "Crunchy Postgres for Kubernetes",
      "csv_metadata_description": "Production Postgres Made Easy",
      "csv_name": "postgresoperator.v5.0.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:11:56.971000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "crunchy-postgres-operator",
      "provided_apis": [
        {
          "group": "postgres-operator.crunchydata.com",
          "kind": "PostgresCluster",
          "plural": "postgresclusters",
          "version": "v1beta1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:35bd6e284d71881524766662657e60c654a9bc77cd79c43a667cd76b1984dc34",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:35bd6e284d71881524766662657e60c654a9bc77cd79c43a667cd76b1984dc34",
          "name": "postgres-operator-35bd6e284d71881524766662657e60c654a9bc77cd79c43a667cd76b1984dc34-annotation"
        },
        {
          "digest": "sha256:35bd6e284d71881524766662657e60c654a9bc77cd79c43a667cd76b1984dc34",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:35bd6e284d71881524766662657e60c654a9bc77cd79c43a667cd76b1984dc34",
          "name": "operator"
        },
        {
          "digest": "sha256:4256829ed455475e45ef210bea800c42d6eb53497a734428cb753c2af3d46ced",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbackrest@sha256:4256829ed455475e45ef210bea800c42d6eb53497a734428cb753c2af3d46ced",
          "name": "pgbackrest"
        },
        {
          "digest": "sha256:dd8c2aff733a4c064ce5a89bcd2b1e984099c72807e790def526d90dbc7f46dd",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbouncer@sha256:dd8c2aff733a4c064ce5a89bcd2b1e984099c72807e790def526d90dbc7f46dd",
          "name": "pgbouncer"
        },
        {
          "digest": "sha256:a6f88150ddd3e01d32d1c573ee3022072f98031341d1bed2ae440d772482ce65",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-exporter@sha256:a6f88150ddd3e01d32d1c573ee3022072f98031341d1bed2ae440d772482ce65",
          "name": "pgexporter"
        },
        {
          "digest": "sha256:74e35614839ae674ee210e3850dee01e50c5d3d218eeee2d4d33e778db76ffbc",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:74e35614839ae674ee210e3850dee01e50c5d3d218eeee2d4d33e778db76ffbc",
          "name": "postgres_12"
        },
        {
          "digest": "sha256:b9a152771c489673a51dfe815c290af5666e68e614ac0dfd1d3ba54a371f47be",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:b9a152771c489673a51dfe815c290af5666e68e614ac0dfd1d3ba54a371f47be",
          "name": "postgres_13"
        },
        {
          "digest": "sha256:a2b34428eb1e23cd2a39e85d3da95a35a19715543b13d3d7ab0183ba8083ec33",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:a2b34428eb1e23cd2a39e85d3da95a35a19715543b13d3d7ab0183ba8083ec33",
          "name": "postgres_14"
        },
        {
          "digest": "sha256:ec92544d41f771e69ce84009ef145e1e59cd31521e4a948c5ecb8f0ddfb8fe9b",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:ec92544d41f771e69ce84009ef145e1e59cd31521e4a948c5ecb8f0ddfb8fe9b",
          "name": "postgres_12_gis_2.5"
        },
        {
          "digest": "sha256:a1ec04b12610e2cb1094b85ed8fdd97106c07c048a3480d2baa25d7171284921",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:a1ec04b12610e2cb1094b85ed8fdd97106c07c048a3480d2baa25d7171284921",
          "name": "postgres_12_gis_3.0"
        },
        {
          "digest": "sha256:23b8deca0a30982f14b433937c1c133e6f257b8599d52be60de9d85571a7f2a3",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:23b8deca0a30982f14b433937c1c133e6f257b8599d52be60de9d85571a7f2a3",
          "name": "postgres_13_gis_3.0"
        },
        {
          "digest": "sha256:4e6bfa1def778e9f20506ba980a2bd2cfd392142c1cd072b6892b41a68d56db1",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:4e6bfa1def778e9f20506ba980a2bd2cfd392142c1cd072b6892b41a68d56db1",
          "name": "postgres_13_gis_3.1"
        },
        {
          "digest": "sha256:550426086d4647d3c49ec17ffc1fde265ac3026ab042113b64111177eb898fb6",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:550426086d4647d3c49ec17ffc1fde265ac3026ab042113b64111177eb898fb6",
          "name": "postgres_14_gis_3.1"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "5.0.4",
      "version_original": "5.0.4"
    },
    {
      "_id": "61a75d3f27e166330707dc6f",
      "alm_examples": [
        {
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:c771db6ff2400a5a78b66b4345e50f0346aa64f6cc66a3de34913d4f3dc57ea6",
      "bundle_path_digest": "sha256:c771db6ff2400a5a78b66b4345e50f0346aa64f6cc66a3de34913d4f3dc57ea6",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2021-12-01T11:32:15.969000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.4.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:20:10.653000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "name": "kubeturbo-operator-879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d-annotation"
        },
        {
          "digest": "sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:4828ed949374c8191da9d54c0d3ea95d7c3c1f1d9548db55eed7ebf09a1ba076",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:4828ed949374c8191da9d54c0d3ea95d7c3c1f1d9548db55eed7ebf09a1ba076",
          "name": "kubeturbo"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "8.4.0",
      "version_original": "8.4.0"
    },
    {
      "_id": "61a762cc27e166330707dc78",
      "alm_examples": [
        {
          "kind": "System",
          "metadata": {
            "name": "ionir"
          },
          "spec": {
            "imageRegistry": "quay.io/ionir",
            "profile": "minimal",
            "tag": "v2.5"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ionir/ionir-operator-bundle@sha256:79319e01b6f760d6a494bae31e8dfad3adfddc5d63f4c4d03424618b742b0279",
      "bundle_path_digest": "sha256:79319e01b6f760d6a494bae31e8dfad3adfddc5d63f4c4d03424618b742b0279",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2021-12-01T11:55:56.591000+00:00",
      "csv_description": "Ionir is a container-native data platform for Kubernetes.\nIonir virtualizes all available storage in a Kubernetes cluster to create a single pool of highly scalable storage.\nHaving a Container Storage Interface (CSI) plugin, Ionir storage can be provisioned and managed by Kubernetes,\nthe common control plane in the environment. In addition to providing resilient, high-performance storage, Ionir\nalso provides end-to-end data management capabilities. The Ionir architecture separates the metadata from the data,\nwhich enables unique data management capabilities such as instant clones. The microservices architecture provides\na unified data platform that is elastic, scalable, and agile, which is critical for containerized deployments.\n### Instant Data Mobility\nIonir gives K8s application data wings. Persistent volumes move at the speed of applications, in any direction, to and from anywhere - on-prem, cloud, public, private - in seconds!\nWhat\u2019s more, ionir transparently delivers everything you\u2019ve come to expect from enterprise storage \u2013 performance and scalability, data protection, replication, deduplication and more - built to run natively on Kubernetes clusters.\n### Enterprise-Class Data Protection\nOffering instant point-in-time restore with one second granularity, ionir\u2019s highly efficient data protection capabilities exceed even traditional monolithic arrays, and are unrivaled in K8s native storage.\n### Simple. Converged. Native.\nOne comprehensive platform \u2015 orchestrated by Kubernetes \u2015 serves, stores and manages all your K8s application data. All based on RESTful APIs for easy automation.\n### Aligned to Applications\nAdvanced machine learning ensures data is mapped to the optimal storage resource based on performance, density, cost, location, and other key factors.\n### How to install Ionir\n### Prerequisites\n* See details in [Ionir Deployment Requirements - OCP](https://github.com/ionir-cloud/deployments/blob/main/documents/Ionir%20Deployment%20Requirements%20-%20OCP.pdf)\n* Review Ionir [EULA] (https://ionir.com/legal/eula/)\n\n### Uninstall\nFirst remove all applications consuming Ionir storage prior to deleting Ionir system custom resource.<br>\nNote: Storage classes with Ionir provisioner should be deleted manually\n> :warning: This action uninstalls Ionir completely and wipes the entire data. This action can not be reversed.\n",
      "csv_display_name": "Ionir",
      "csv_metadata_description": "Ionir is a container-native data platform built in Kubernetes",
      "csv_name": "ionir-operator.v1.0.7",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T15:01:00.332000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "ionir-operator",
      "provided_apis": [
        {
          "group": "operator.ionir.com",
          "kind": "System",
          "plural": "systems",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:5b28c9559e65d15fdeb13c62e893e05e8090de7658c10e06feb18c69fd8a5525",
          "image": "registry.connect.redhat.com/ionir/ionir-operator@sha256:5b28c9559e65d15fdeb13c62e893e05e8090de7658c10e06feb18c69fd8a5525",
          "name": "ionir-operator-5b28c9559e65d15fdeb13c62e893e05e8090de7658c10e06feb18c69fd8a5525-annotation"
        },
        {
          "digest": "sha256:5b28c9559e65d15fdeb13c62e893e05e8090de7658c10e06feb18c69fd8a5525",
          "image": "registry.connect.redhat.com/ionir/ionir-operator@sha256:5b28c9559e65d15fdeb13c62e893e05e8090de7658c10e06feb18c69fd8a5525",
          "name": "manager"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "1.0.7",
      "version_original": "1.0.7"
    },
    {
      "_id": "61a762f53e9240fca360f976",
      "alm_examples": [
        {
          "kind": "System",
          "metadata": {
            "name": "ionir"
          },
          "spec": {
            "imageRegistry": "quay.io/ionir",
            "profile": "minimal",
            "tag": "ilan-certification-test"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ionir/ionir-operator-bundle@sha256:f54f915f843f9372f447cec692d4076a963668cecacf11f66fd85439b069558e",
      "bundle_path_digest": "sha256:f54f915f843f9372f447cec692d4076a963668cecacf11f66fd85439b069558e",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2021-12-01T11:56:37.123000+00:00",
      "csv_description": "Ionir is a container-native data platform for Kubernetes.\nIonir virtualizes all available storage in a Kubernetes cluster to create a single pool of highly scalable storage.\nHaving a Container Storage Interface (CSI) plugin, Ionir storage can be provisioned and managed by Kubernetes,\nthe common control plane in the environment. In addition to providing resilient, high-performance storage, Ionir\nalso provides end-to-end data management capabilities. The Ionir architecture separates the metadata from the data,\nwhich enables unique data management capabilities such as instant clones. The microservices architecture provides\na unified data platform that is elastic, scalable, and agile, which is critical for containerized deployments.\n### Instant Data Mobility\nIonir gives K8s application data wings. Persistent volumes move at the speed of applications, in any direction, to and from anywhere - on-prem, cloud, public, private - in seconds!\nWhat\u2019s more, ionir transparently delivers everything you\u2019ve come to expect from enterprise storage \u2013 performance and scalability, data protection, replication, deduplication and more - built to run natively on Kubernetes clusters.\n### Enterprise-Class Data Protection\nOffering instant point-in-time restore with one second granularity, ionir\u2019s highly efficient data protection capabilities exceed even traditional monolithic arrays, and are unrivaled in K8s native storage.\n### Simple. Converged. Native.\nOne comprehensive platform \u2015 orchestrated by Kubernetes \u2015 serves, stores and manages all your K8s application data. All based on RESTful APIs for easy automation.\n### Aligned to Applications\nAdvanced machine learning ensures data is mapped to the optimal storage resource based on performance, density, cost, location, and other key factors.\n### How to install Ionir\n### Prerequisites\n* See details in [Ionir Deployment Requirements - OCP](https://github.com/ionir-cloud/deployments/blob/main/documents/Ionir%20Deployment%20Requirements%20-%20OCP.pdf)\n* Review Ionir [EULA] (https://ionir.com/legal/eula/)\n\n### Uninstall\nFirst remove all applications consuming Ionir storage prior to deleting Ionir system custom resource.<br>\nNote: Storage classes with Ionir provisioner should be deleted manually\n> :warning: This action uninstalls Ionir completely and wipes the entire data. This action can not be reversed.\n",
      "csv_display_name": "Ionir",
      "csv_metadata_description": "Ionir is a container-native data platform built in Kubernetes",
      "csv_name": "ionir-operator.v1.0.6",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:45:38.850000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "ionir-operator",
      "provided_apis": [
        {
          "group": "operator.ionir.com",
          "kind": "System",
          "plural": "systems",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:3c6c05ea8feb356bb9f90c652bd05a94edeb33248be09eedf4f9f21e80de6ef1",
          "image": "registry.connect.redhat.com/ionir/ionir-operator@sha256:3c6c05ea8feb356bb9f90c652bd05a94edeb33248be09eedf4f9f21e80de6ef1",
          "name": "ionir-operator-3c6c05ea8feb356bb9f90c652bd05a94edeb33248be09eedf4f9f21e80de6ef1-annotation"
        },
        {
          "digest": "sha256:3c6c05ea8feb356bb9f90c652bd05a94edeb33248be09eedf4f9f21e80de6ef1",
          "image": "registry.connect.redhat.com/ionir/ionir-operator@sha256:3c6c05ea8feb356bb9f90c652bd05a94edeb33248be09eedf4f9f21e80de6ef1",
          "name": "manager"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "1.0.6",
      "version_original": "1.0.6"
    },
    {
      "_id": "61a765413e9240fca360f978",
      "alm_examples": [
        {
          "kind": "PostgresCluster",
          "metadata": {
            "name": "example"
          },
          "spec": {
            "instances": [
              {
                "dataVolumeClaimSpec": {
                  "accessModes": [
                    "ReadWriteOnce"
                  ],
                  "resources": {
                    "requests": {
                      "storage": "1Gi"
                    }
                  }
                },
                "replicas": 1
              }
            ],
            "postgresVersion": 13
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/crunchydata/postgres-operator-bundle@sha256:6166f3ee3ea06cd8c3d4e78ee2b9298cb203002521db6de5ec97131d2ef3d97d",
      "bundle_path_digest": "sha256:6166f3ee3ea06cd8c3d4e78ee2b9298cb203002521db6de5ec97131d2ef3d97d",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "v5",
      "creation_date": "2021-12-01T12:06:25.750000+00:00",
      "csv_description": "[PGO](https://github.com/CrunchyData/postgres-operator), the\n[Postgres Operator](https://github.com/CrunchyData/postgres-operator) from\n[Crunchy Data](https://www.crunchydata.com), gives you a **declarative Postgres** solution that\nautomatically manages your [PostgreSQL](https://www.postgresql.org) clusters.\n\nDesigned for your GitOps workflows, it is [easy to get started](https://access.crunchydata.com/documentation/postgres-operator/v5/quickstart/)\nwith Postgres on Kubernetes with PGO. Within a few moments, you can have a production grade Postgres\ncluster complete with high availability, disaster recovery, and monitoring, all over secure TLS communications.\nEven better, PGO lets you easily customize your Postgres cluster to tailor it to your workload!\n\nWith conveniences like cloning Postgres clusters to using rolling updates to roll out disruptive\nchanges with minimal downtime, PGO is ready to support your Postgres data at every stage of your\nrelease pipeline. Built for resiliency and uptime, PGO will keep your desired Postgres in a desired\nstate so you do not need to worry about it.\n\nPGO is developed with many years of production experience in automating Postgres management on\nKubernetes, providing a seamless cloud native Postgres solution to keep your data always available.\n\n- **PostgreSQL Cluster Provisioning**: [Create, Scale, & Delete PostgreSQL clusters with ease][provisioning],\n  while fully customizing your Pods and PostgreSQL configuration!\n- **High-Availability**: Safe, automated failover backed by a [distributed consensus based high-availability solution][high-availability].\n  Uses [Pod Anti-Affinity][k8s-anti-affinity] to help resiliency; you can configure how aggressive this can be!\n  Failed primaries automatically heal, allowing for faster recovery time. You can even create regularly scheduled\n  backups as well and set your backup retention policy\n- **Disaster Recovery**: [Backups][backups] and [restores][disaster-recovery] leverage the open source [pgBackRest][] utility and\n  [includes support for full, incremental, and differential backups as well as efficient delta restores][backups].\n  Set how long you want your backups retained for. Works great with very large databases!\n- **Monitoring**: [Track the health of your PostgreSQL clusters][monitoring] using the open source [pgMonitor][] library.\n- **Clone**: [Create new clusters from your existing clusters or backups][clone] with efficient data cloning.\n- **TLS**: All connections are over [TLS][tls]. You can also [bring your own TLS infrastructure][tls] if you do not want to use the provided defaults.\n- **Connection Pooling**: Advanced [connection pooling][pool] support using [pgBouncer][].\n- **Affinity and Tolerations**: Have your PostgreSQL clusters deployed to [Kubernetes Nodes][k8s-nodes] of your preference.\n  Set your [pod anti-affinity][k8s-anti-affinity], node affinity, Pod tolerations and more rules to customize your deployment topology!\n- **Full Customizability**: Crunchy PostgreSQL for Kubernetes makes it easy to get your own PostgreSQL-as-a-Service up and running\n  and fully customize your deployments, including:\n    - Choose the resources for your Postgres cluster: [container resources and storage size][resize-cluster]. [Resize at any time][resize-cluster] with minimal disruption.\n    - Use your own container image repository, including support `imagePullSecrets` and private repositories\n    - [Customize your PostgreSQL configuration][customize-cluster]\n\nand much more!\n\n[backups]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/backups/\n[clone]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/disaster-recovery/#clone-a-postgres-cluster\n[customize-cluster]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/customize-cluster/\n[disaster-recovery]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/disaster-recovery/\n[high-availability]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/high-availability/\n[monitoring]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/monitoring/\n[pool]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/connection-pooling/\n[provisioning]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/create-cluster/\n[resize-cluster]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/resize-cluster/\n[tls]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/customize-cluster/#customize-tls\n\n[k8s-anti-affinity]: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n[k8s-nodes]: https://kubernetes.io/docs/concepts/architecture/nodes/\n\n[pgBackRest]: https://www.pgbackrest.org\n[pgBouncer]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/connection-pooling/\n[pgMonitor]: https://github.com/CrunchyData/pgmonitor\n\n\n## Post-Installation\n\n### Tutorial\n\nWant to [learn more about the PostgreSQL Operator][tutorial]? Browse through the [tutorial][] to learn more about what you can do!\n\n[tutorial]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial",
      "csv_display_name": "Crunchy Postgres for Kubernetes",
      "csv_metadata_description": "Production Postgres Made Easy",
      "csv_name": "postgresoperator.v5.0.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:56:47.742000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "crunchy-postgres-operator",
      "provided_apis": [
        {
          "group": "postgres-operator.crunchydata.com",
          "kind": "PostgresCluster",
          "plural": "postgresclusters",
          "version": "v1beta1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:35bd6e284d71881524766662657e60c654a9bc77cd79c43a667cd76b1984dc34",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:35bd6e284d71881524766662657e60c654a9bc77cd79c43a667cd76b1984dc34",
          "name": "postgres-operator-35bd6e284d71881524766662657e60c654a9bc77cd79c43a667cd76b1984dc34-annotation"
        },
        {
          "digest": "sha256:35bd6e284d71881524766662657e60c654a9bc77cd79c43a667cd76b1984dc34",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:35bd6e284d71881524766662657e60c654a9bc77cd79c43a667cd76b1984dc34",
          "name": "operator"
        },
        {
          "digest": "sha256:4256829ed455475e45ef210bea800c42d6eb53497a734428cb753c2af3d46ced",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbackrest@sha256:4256829ed455475e45ef210bea800c42d6eb53497a734428cb753c2af3d46ced",
          "name": "pgbackrest"
        },
        {
          "digest": "sha256:dd8c2aff733a4c064ce5a89bcd2b1e984099c72807e790def526d90dbc7f46dd",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbouncer@sha256:dd8c2aff733a4c064ce5a89bcd2b1e984099c72807e790def526d90dbc7f46dd",
          "name": "pgbouncer"
        },
        {
          "digest": "sha256:a6f88150ddd3e01d32d1c573ee3022072f98031341d1bed2ae440d772482ce65",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-exporter@sha256:a6f88150ddd3e01d32d1c573ee3022072f98031341d1bed2ae440d772482ce65",
          "name": "pgexporter"
        },
        {
          "digest": "sha256:74e35614839ae674ee210e3850dee01e50c5d3d218eeee2d4d33e778db76ffbc",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:74e35614839ae674ee210e3850dee01e50c5d3d218eeee2d4d33e778db76ffbc",
          "name": "postgres_12"
        },
        {
          "digest": "sha256:b9a152771c489673a51dfe815c290af5666e68e614ac0dfd1d3ba54a371f47be",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:b9a152771c489673a51dfe815c290af5666e68e614ac0dfd1d3ba54a371f47be",
          "name": "postgres_13"
        },
        {
          "digest": "sha256:a2b34428eb1e23cd2a39e85d3da95a35a19715543b13d3d7ab0183ba8083ec33",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:a2b34428eb1e23cd2a39e85d3da95a35a19715543b13d3d7ab0183ba8083ec33",
          "name": "postgres_14"
        },
        {
          "digest": "sha256:ec92544d41f771e69ce84009ef145e1e59cd31521e4a948c5ecb8f0ddfb8fe9b",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:ec92544d41f771e69ce84009ef145e1e59cd31521e4a948c5ecb8f0ddfb8fe9b",
          "name": "postgres_12_gis_2.5"
        },
        {
          "digest": "sha256:a1ec04b12610e2cb1094b85ed8fdd97106c07c048a3480d2baa25d7171284921",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:a1ec04b12610e2cb1094b85ed8fdd97106c07c048a3480d2baa25d7171284921",
          "name": "postgres_12_gis_3.0"
        },
        {
          "digest": "sha256:23b8deca0a30982f14b433937c1c133e6f257b8599d52be60de9d85571a7f2a3",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:23b8deca0a30982f14b433937c1c133e6f257b8599d52be60de9d85571a7f2a3",
          "name": "postgres_13_gis_3.0"
        },
        {
          "digest": "sha256:4e6bfa1def778e9f20506ba980a2bd2cfd392142c1cd072b6892b41a68d56db1",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:4e6bfa1def778e9f20506ba980a2bd2cfd392142c1cd072b6892b41a68d56db1",
          "name": "postgres_13_gis_3.1"
        },
        {
          "digest": "sha256:550426086d4647d3c49ec17ffc1fde265ac3026ab042113b64111177eb898fb6",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:550426086d4647d3c49ec17ffc1fde265ac3026ab042113b64111177eb898fb6",
          "name": "postgres_14_gis_3.1"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "5.0.4",
      "version_original": "5.0.4"
    },
    {
      "_id": "61a765963e9240fca360f979",
      "alm_examples": [
        {
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:c771db6ff2400a5a78b66b4345e50f0346aa64f6cc66a3de34913d4f3dc57ea6",
      "bundle_path_digest": "sha256:c771db6ff2400a5a78b66b4345e50f0346aa64f6cc66a3de34913d4f3dc57ea6",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2021-12-01T12:07:50.823000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.4.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T15:13:38.810000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "name": "kubeturbo-operator-879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d-annotation"
        },
        {
          "digest": "sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:4828ed949374c8191da9d54c0d3ea95d7c3c1f1d9548db55eed7ebf09a1ba076",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:4828ed949374c8191da9d54c0d3ea95d7c3c1f1d9548db55eed7ebf09a1ba076",
          "name": "kubeturbo"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "8.4.0",
      "version_original": "8.4.0"
    },
    {
      "_id": "61a877703e9240fca360fa84",
      "alm_examples": [
        {
          "kind": "Installer",
          "metadata": {
            "name": "installer-sample"
          },
          "spec": {
            "foo": "bar"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/aarna/amcop-k8s-operator-bundle@sha256:8cb7a9b39361707719f0dfc5589bbb55432e65941136d6034551003bd37c7f39",
      "bundle_path_digest": "sha256:8cb7a9b39361707719f0dfc5589bbb55432e65941136d6034551003bd37c7f39",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2021-12-02T07:36:16.951000+00:00",
      "csv_description": "LifeCycle Manager for Aarna Networks Multi Cluster Orchestration Platform (AMCOP)",
      "csv_display_name": "amcop-k8s-operator",
      "csv_metadata_description": "",
      "csv_name": "amcop-operator.v0.0.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:18:04.274000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "amcop-operator",
      "provided_apis": [
        {
          "group": "amcop.aarnanetworks.com",
          "kind": "Installer",
          "plural": "installers",
          "version": "v1alpha1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:bb3b5ba76e7ce94441d0395dc5a66f7bb6fff59bd37d5328e418072b3bb174ab",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:bb3b5ba76e7ce94441d0395dc5a66f7bb6fff59bd37d5328e418072b3bb174ab",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:2cf47405d836adb9ec50ac39cbf3ee5550a41033865a77cec3ecece1c37d840c",
          "image": "registry.connect.redhat.com/aarna/amcop-k8s-operator@sha256:2cf47405d836adb9ec50ac39cbf3ee5550a41033865a77cec3ecece1c37d840c",
          "name": "manager"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "0.0.1",
      "version_original": "0.0.1"
    },
    {
      "_id": "61a8795c27e166330707dd67",
      "alm_examples": [
        {
          "kind": "Installer",
          "metadata": {
            "name": "installer-sample"
          },
          "spec": {
            "foo": "bar"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/aarna/amcop-k8s-operator-bundle@sha256:8cb7a9b39361707719f0dfc5589bbb55432e65941136d6034551003bd37c7f39",
      "bundle_path_digest": "sha256:8cb7a9b39361707719f0dfc5589bbb55432e65941136d6034551003bd37c7f39",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2021-12-02T07:44:28.599000+00:00",
      "csv_description": "LifeCycle Manager for Aarna Networks Multi Cluster Orchestration Platform (AMCOP)",
      "csv_display_name": "amcop-k8s-operator",
      "csv_metadata_description": "",
      "csv_name": "amcop-operator.v0.0.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:49:44.825000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "amcop-operator",
      "provided_apis": [
        {
          "group": "amcop.aarnanetworks.com",
          "kind": "Installer",
          "plural": "installers",
          "version": "v1alpha1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:bb3b5ba76e7ce94441d0395dc5a66f7bb6fff59bd37d5328e418072b3bb174ab",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:bb3b5ba76e7ce94441d0395dc5a66f7bb6fff59bd37d5328e418072b3bb174ab",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:2cf47405d836adb9ec50ac39cbf3ee5550a41033865a77cec3ecece1c37d840c",
          "image": "registry.connect.redhat.com/aarna/amcop-k8s-operator@sha256:2cf47405d836adb9ec50ac39cbf3ee5550a41033865a77cec3ecece1c37d840c",
          "name": "manager"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "0.0.1",
      "version_original": "0.0.1"
    },
    {
      "_id": "61a89ab9c17162a20c1c6e33",
      "alm_examples": [
        {
          "kind": "Installer",
          "metadata": {
            "name": "installer-sample"
          },
          "spec": {
            "foo": "bar"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/aarna/amcop-k8s-operator-bundle@sha256:8cb7a9b39361707719f0dfc5589bbb55432e65941136d6034551003bd37c7f39",
      "bundle_path_digest": "sha256:8cb7a9b39361707719f0dfc5589bbb55432e65941136d6034551003bd37c7f39",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2021-12-02T10:06:49.093000+00:00",
      "csv_description": "LifeCycle Manager for Aarna Networks Multi Cluster Orchestration Platform (AMCOP)",
      "csv_display_name": "amcop-k8s-operator",
      "csv_metadata_description": "",
      "csv_name": "amcop-operator.v0.0.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:22:40.298000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "amcop-operator",
      "provided_apis": [
        {
          "group": "amcop.aarnanetworks.com",
          "kind": "Installer",
          "plural": "installers",
          "version": "v1alpha1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:bb3b5ba76e7ce94441d0395dc5a66f7bb6fff59bd37d5328e418072b3bb174ab",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:bb3b5ba76e7ce94441d0395dc5a66f7bb6fff59bd37d5328e418072b3bb174ab",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:2cf47405d836adb9ec50ac39cbf3ee5550a41033865a77cec3ecece1c37d840c",
          "image": "registry.connect.redhat.com/aarna/amcop-k8s-operator@sha256:2cf47405d836adb9ec50ac39cbf3ee5550a41033865a77cec3ecece1c37d840c",
          "name": "manager"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "0.0.1",
      "version_original": "0.0.1"
    },
    {
      "_id": "61a8c596bfd4a5234d596591",
      "alm_examples": [
        {
          "kind": "FlashSystemCluster",
          "metadata": {
            "name": "flashsystemcluster-sample",
            "namespace": "openshift-storage"
          },
          "spec": {
            "defaultPool": {
              "fsType": "ext4",
              "poolName": "Pool0",
              "spaceEfficiency": "thick",
              "storageclassName": "odf-flashsystemcluster-sample",
              "volumeNamePrefix": "odf"
            },
            "insecureSkipVerify": true,
            "name": "flashsystem-xxx",
            "secret": {
              "name": "fs-secrets-example",
              "namespace": "openshift-storage"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/ibm-storage-odf-operator-bundle@sha256:905efe96fa1145c90b540289d9582ed789082c9b269a9beccb72f00a343eb22b",
      "bundle_path_digest": "sha256:905efe96fa1145c90b540289d9582ed789082c9b269a9beccb72f00a343eb22b",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable-v1",
      "creation_date": "2021-12-02T13:09:42.981000+00:00",
      "csv_description": "IBM Storage ODF operator provides basic storage capabilities and extended management functions through OpenShift data foundation framework for applications.",
      "csv_display_name": "IBM Storage ODF operator",
      "csv_metadata_description": "",
      "csv_name": "ibm-storage-odf-operator.v1.0.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T10:57:53.086000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "ibm-storage-odf-operator",
      "provided_apis": [
        {
          "group": "odf.ibm.com",
          "kind": "FlashSystemCluster",
          "plural": "flashsystemclusters",
          "version": "v1alpha1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:c34e32465c0f2c6aea4381de958d753433b4da454795fddb5048809ed67f654f",
          "image": "docker.io/ibmcom/ibm-storage-odf-operator@sha256:c34e32465c0f2c6aea4381de958d753433b4da454795fddb5048809ed67f654f",
          "name": "manager"
        },
        {
          "digest": "sha256:d49baf989ad004408b7fcaf3f421c90777fa78c8029ecd203d495e17e99f832d",
          "image": "docker.io/ibmcom/ibm-storage-odf-plugin@sha256:d49baf989ad004408b7fcaf3f421c90777fa78c8029ecd203d495e17e99f832d",
          "name": "ibm-odf-console"
        }
      ],
      "skip_range": ">=0.0.1 <1.0.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.0.0",
      "version_original": "1.0.0"
    },
    {
      "_id": "61a920383e9240fca360fd38",
      "alm_examples": [
        {
          "kind": "ClusterPolicy",
          "metadata": {
            "name": "gpu-cluster-policy"
          },
          "spec": {
            "daemonsets": {},
            "dcgm": {
              "enabled": true
            },
            "dcgmExporter": {
              "config": {
                "name": ""
              }
            },
            "devicePlugin": {},
            "driver": {
              "certConfig": {
                "name": ""
              },
              "enabled": true,
              "licensingConfig": {
                "configMapName": "",
                "nlsEnabled": false
              },
              "repoConfig": {
                "configMapName": ""
              },
              "use_ocp_driver_toolkit": true,
              "virtualTopology": {
                "config": ""
              }
            },
            "gfd": {},
            "mig": {
              "strategy": "single"
            },
            "migManager": {
              "enabled": true
            },
            "nodeStatusExporter": {
              "enabled": true
            },
            "operator": {
              "defaultRuntime": "crio",
              "deployGFD": true,
              "initContainer": {}
            },
            "toolkit": {
              "enabled": true
            },
            "validator": {
              "plugin": {
                "env": [
                  {
                    "name": "WITH_WORKLOAD",
                    "value": "true"
                  }
                ]
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/nvidia/gpu-operator-bundle@sha256:311c0af18755aa941fca8e319f2bcf183f107897742ea4c4c85a08c75b31111d",
      "bundle_path_digest": "sha256:311c0af18755aa941fca8e319f2bcf183f107897742ea4c4c85a08c75b31111d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "v1.9.0",
      "creation_date": "2021-12-02T19:36:24.232000+00:00",
      "csv_description": "Kubernetes provides access to special hardware resources such as NVIDIA GPUs, NICs, Infiniband adapters and other devices through the [device plugin framework](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/). However, configuring and managing nodes with these hardware resources requires configuration of multiple software components such as drivers, container runtimes or other libraries which are difficult and prone to errors.\nThe NVIDIA GPU Operator uses the [operator framework](https://coreos.com/blog/introducing-operator-framework) within Kubernetes to automate the management of all NVIDIA software components needed to provision and monitor GPUs. These components include the NVIDIA drivers (to enable CUDA), Kubernetes device plugin for GPUs, the NVIDIA Container Runtime, automatic node labelling and NVIDIA DCGM exporter.\nVisit the official site of the [GPU Operator](https://github.com/NVIDIA/gpu-operator) for more information. For getting started with using the GPU Operator with OpenShift, see the instructions [here](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/contents.html).\n",
      "csv_display_name": "NVIDIA GPU Operator",
      "csv_metadata_description": "Automate the management and monitoring of NVIDIA GPUs.",
      "csv_name": "gpu-operator-certified.v1.9.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-05T10:57:16.598000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "gpu-operator-certified",
      "provided_apis": [
        {
          "group": "nvidia.com",
          "kind": "ClusterPolicy",
          "plural": "clusterpolicies",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395",
          "name": "gpu-operator-image"
        },
        {
          "digest": "sha256:5f0d3af074c92dfe0ce36899a1545bb5a408f2ad59878d43045e9ca302b82a41",
          "image": "nvcr.io/nvidia/k8s/dcgm-exporter@sha256:5f0d3af074c92dfe0ce36899a1545bb5a408f2ad59878d43045e9ca302b82a41",
          "name": "dcgm-exporter-image"
        },
        {
          "digest": "sha256:f4c4de8d66b2fef8cebaee6fec2fb2d15d01e835de2654df6dfd4a0ce0baec6b",
          "image": "nvcr.io/nvidia/cloud-native/dcgm@sha256:f4c4de8d66b2fef8cebaee6fec2fb2d15d01e835de2654df6dfd4a0ce0baec6b",
          "name": "dcgm-image"
        },
        {
          "digest": "sha256:5f826e306d093332a86afa7d1e96218b5bdda8d33067931cff7914f6bb2994ee",
          "image": "nvcr.io/nvidia/k8s/container-toolkit@sha256:5f826e306d093332a86afa7d1e96218b5bdda8d33067931cff7914f6bb2994ee",
          "name": "container-toolkit-image"
        },
        {
          "digest": "sha256:35c8231e28e572b148699d52a5f5c9745556fd32ab4160da68d0fc84234c1309",
          "image": "nvcr.io/nvidia/driver@sha256:35c8231e28e572b148699d52a5f5c9745556fd32ab4160da68d0fc84234c1309",
          "name": "driver-image"
        },
        {
          "digest": "sha256:69171f906efe4bbabe31688343e59feea08a7e0ef8b0d9efb466abfa153aec16",
          "image": "nvcr.io/nvidia/k8s-device-plugin@sha256:69171f906efe4bbabe31688343e59feea08a7e0ef8b0d9efb466abfa153aec16",
          "name": "device-plugin-image"
        },
        {
          "digest": "sha256:bfc39d23568458dfd50c0c5323b6d42bdcd038c420fb2a2becd513a3ed3be27f",
          "image": "nvcr.io/nvidia/gpu-feature-discovery@sha256:bfc39d23568458dfd50c0c5323b6d42bdcd038c420fb2a2becd513a3ed3be27f",
          "name": "gpu-feature-discovery-image"
        },
        {
          "digest": "sha256:d718dda2f9c9f0a465240772ed1ca6db44789d37255172e00637a092bdd1ba31",
          "image": "nvcr.io/nvidia/cloud-native/k8s-mig-manager@sha256:d718dda2f9c9f0a465240772ed1ca6db44789d37255172e00637a092bdd1ba31",
          "name": "mig-manager-image"
        },
        {
          "digest": "sha256:e137c897256501537e0986963889a91ec90cac029b5263fc4b229b278f5b1a02",
          "image": "nvcr.io/nvidia/cuda@sha256:e137c897256501537e0986963889a91ec90cac029b5263fc4b229b278f5b1a02",
          "name": "init-container-image"
        },
        {
          "digest": "sha256:7b3509daf52c333c28da40d90586efa514ed9c14473f5ca495de7b65567ce4c2",
          "image": "nvcr.io/nvidia/cloud-native/gpu-operator-validator@sha256:7b3509daf52c333c28da40d90586efa514ed9c14473f5ca495de7b65567ce4c2",
          "name": "gpu-operator-validator-image"
        },
        {
          "digest": "sha256:54233ebccbc3d2b388b237031907d58c3719d0e6f3ecb874349c91e8145225d2",
          "image": "nvcr.io/nvidia/cloud-native/k8s-driver-manager@sha256:54233ebccbc3d2b388b237031907d58c3719d0e6f3ecb874349c91e8145225d2",
          "name": "k8s-driver-manager-image"
        },
        {
          "digest": "sha256:57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395",
          "name": "gpu-operator-57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395-annotation"
        },
        {
          "digest": "sha256:57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395",
          "name": "gpu-operator"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.9.0",
      "version_original": "1.9.0"
    },
    {
      "_id": "61a9229e3e9240fca360fd40",
      "alm_examples": [
        {
          "kind": "ClusterPolicy",
          "metadata": {
            "name": "gpu-cluster-policy"
          },
          "spec": {
            "daemonsets": {},
            "dcgm": {
              "enabled": true
            },
            "dcgmExporter": {
              "config": {
                "name": ""
              }
            },
            "devicePlugin": {},
            "driver": {
              "certConfig": {
                "name": ""
              },
              "enabled": true,
              "licensingConfig": {
                "configMapName": "",
                "nlsEnabled": false
              },
              "repoConfig": {
                "configMapName": ""
              },
              "use_ocp_driver_toolkit": true,
              "virtualTopology": {
                "config": ""
              }
            },
            "gfd": {},
            "mig": {
              "strategy": "single"
            },
            "migManager": {
              "enabled": true
            },
            "nodeStatusExporter": {
              "enabled": true
            },
            "operator": {
              "defaultRuntime": "crio",
              "deployGFD": true,
              "initContainer": {}
            },
            "toolkit": {
              "enabled": true
            },
            "validator": {
              "plugin": {
                "env": [
                  {
                    "name": "WITH_WORKLOAD",
                    "value": "true"
                  }
                ]
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/nvidia/gpu-operator-bundle@sha256:311c0af18755aa941fca8e319f2bcf183f107897742ea4c4c85a08c75b31111d",
      "bundle_path_digest": "sha256:311c0af18755aa941fca8e319f2bcf183f107897742ea4c4c85a08c75b31111d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2021-12-02T19:46:38.993000+00:00",
      "csv_description": "Kubernetes provides access to special hardware resources such as NVIDIA GPUs, NICs, Infiniband adapters and other devices through the [device plugin framework](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/). However, configuring and managing nodes with these hardware resources requires configuration of multiple software components such as drivers, container runtimes or other libraries which are difficult and prone to errors.\nThe NVIDIA GPU Operator uses the [operator framework](https://coreos.com/blog/introducing-operator-framework) within Kubernetes to automate the management of all NVIDIA software components needed to provision and monitor GPUs. These components include the NVIDIA drivers (to enable CUDA), Kubernetes device plugin for GPUs, the NVIDIA Container Runtime, automatic node labelling and NVIDIA DCGM exporter.\nVisit the official site of the [GPU Operator](https://github.com/NVIDIA/gpu-operator) for more information. For getting started with using the GPU Operator with OpenShift, see the instructions [here](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/contents.html).\n",
      "csv_display_name": "NVIDIA GPU Operator",
      "csv_metadata_description": "Automate the management and monitoring of NVIDIA GPUs.",
      "csv_name": "gpu-operator-certified.v1.9.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-05T11:18:31.109000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "gpu-operator-certified",
      "provided_apis": [
        {
          "group": "nvidia.com",
          "kind": "ClusterPolicy",
          "plural": "clusterpolicies",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395",
          "name": "gpu-operator-image"
        },
        {
          "digest": "sha256:5f0d3af074c92dfe0ce36899a1545bb5a408f2ad59878d43045e9ca302b82a41",
          "image": "nvcr.io/nvidia/k8s/dcgm-exporter@sha256:5f0d3af074c92dfe0ce36899a1545bb5a408f2ad59878d43045e9ca302b82a41",
          "name": "dcgm-exporter-image"
        },
        {
          "digest": "sha256:f4c4de8d66b2fef8cebaee6fec2fb2d15d01e835de2654df6dfd4a0ce0baec6b",
          "image": "nvcr.io/nvidia/cloud-native/dcgm@sha256:f4c4de8d66b2fef8cebaee6fec2fb2d15d01e835de2654df6dfd4a0ce0baec6b",
          "name": "dcgm-image"
        },
        {
          "digest": "sha256:5f826e306d093332a86afa7d1e96218b5bdda8d33067931cff7914f6bb2994ee",
          "image": "nvcr.io/nvidia/k8s/container-toolkit@sha256:5f826e306d093332a86afa7d1e96218b5bdda8d33067931cff7914f6bb2994ee",
          "name": "container-toolkit-image"
        },
        {
          "digest": "sha256:35c8231e28e572b148699d52a5f5c9745556fd32ab4160da68d0fc84234c1309",
          "image": "nvcr.io/nvidia/driver@sha256:35c8231e28e572b148699d52a5f5c9745556fd32ab4160da68d0fc84234c1309",
          "name": "driver-image"
        },
        {
          "digest": "sha256:69171f906efe4bbabe31688343e59feea08a7e0ef8b0d9efb466abfa153aec16",
          "image": "nvcr.io/nvidia/k8s-device-plugin@sha256:69171f906efe4bbabe31688343e59feea08a7e0ef8b0d9efb466abfa153aec16",
          "name": "device-plugin-image"
        },
        {
          "digest": "sha256:bfc39d23568458dfd50c0c5323b6d42bdcd038c420fb2a2becd513a3ed3be27f",
          "image": "nvcr.io/nvidia/gpu-feature-discovery@sha256:bfc39d23568458dfd50c0c5323b6d42bdcd038c420fb2a2becd513a3ed3be27f",
          "name": "gpu-feature-discovery-image"
        },
        {
          "digest": "sha256:d718dda2f9c9f0a465240772ed1ca6db44789d37255172e00637a092bdd1ba31",
          "image": "nvcr.io/nvidia/cloud-native/k8s-mig-manager@sha256:d718dda2f9c9f0a465240772ed1ca6db44789d37255172e00637a092bdd1ba31",
          "name": "mig-manager-image"
        },
        {
          "digest": "sha256:e137c897256501537e0986963889a91ec90cac029b5263fc4b229b278f5b1a02",
          "image": "nvcr.io/nvidia/cuda@sha256:e137c897256501537e0986963889a91ec90cac029b5263fc4b229b278f5b1a02",
          "name": "init-container-image"
        },
        {
          "digest": "sha256:7b3509daf52c333c28da40d90586efa514ed9c14473f5ca495de7b65567ce4c2",
          "image": "nvcr.io/nvidia/cloud-native/gpu-operator-validator@sha256:7b3509daf52c333c28da40d90586efa514ed9c14473f5ca495de7b65567ce4c2",
          "name": "gpu-operator-validator-image"
        },
        {
          "digest": "sha256:54233ebccbc3d2b388b237031907d58c3719d0e6f3ecb874349c91e8145225d2",
          "image": "nvcr.io/nvidia/cloud-native/k8s-driver-manager@sha256:54233ebccbc3d2b388b237031907d58c3719d0e6f3ecb874349c91e8145225d2",
          "name": "k8s-driver-manager-image"
        },
        {
          "digest": "sha256:57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395",
          "name": "gpu-operator-57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395-annotation"
        },
        {
          "digest": "sha256:57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395",
          "name": "gpu-operator"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.9.0",
      "version_original": "1.9.0"
    },
    {
      "_id": "61a922a1c17162a20c1c71ad",
      "alm_examples": [
        {
          "kind": "ClusterPolicy",
          "metadata": {
            "name": "gpu-cluster-policy"
          },
          "spec": {
            "daemonsets": {},
            "dcgm": {
              "enabled": true
            },
            "dcgmExporter": {
              "config": {
                "name": ""
              }
            },
            "devicePlugin": {},
            "driver": {
              "certConfig": {
                "name": ""
              },
              "enabled": true,
              "licensingConfig": {
                "configMapName": "",
                "nlsEnabled": false
              },
              "repoConfig": {
                "configMapName": ""
              },
              "use_ocp_driver_toolkit": true,
              "virtualTopology": {
                "config": ""
              }
            },
            "gfd": {},
            "mig": {
              "strategy": "single"
            },
            "migManager": {
              "enabled": true
            },
            "nodeStatusExporter": {
              "enabled": true
            },
            "operator": {
              "defaultRuntime": "crio",
              "deployGFD": true,
              "initContainer": {}
            },
            "toolkit": {
              "enabled": true
            },
            "validator": {
              "plugin": {
                "env": [
                  {
                    "name": "WITH_WORKLOAD",
                    "value": "true"
                  }
                ]
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/nvidia/gpu-operator-bundle@sha256:311c0af18755aa941fca8e319f2bcf183f107897742ea4c4c85a08c75b31111d",
      "bundle_path_digest": "sha256:311c0af18755aa941fca8e319f2bcf183f107897742ea4c4c85a08c75b31111d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "v1.9.0",
      "creation_date": "2021-12-02T19:46:41.494000+00:00",
      "csv_description": "Kubernetes provides access to special hardware resources such as NVIDIA GPUs, NICs, Infiniband adapters and other devices through the [device plugin framework](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/). However, configuring and managing nodes with these hardware resources requires configuration of multiple software components such as drivers, container runtimes or other libraries which are difficult and prone to errors.\nThe NVIDIA GPU Operator uses the [operator framework](https://coreos.com/blog/introducing-operator-framework) within Kubernetes to automate the management of all NVIDIA software components needed to provision and monitor GPUs. These components include the NVIDIA drivers (to enable CUDA), Kubernetes device plugin for GPUs, the NVIDIA Container Runtime, automatic node labelling and NVIDIA DCGM exporter.\nVisit the official site of the [GPU Operator](https://github.com/NVIDIA/gpu-operator) for more information. For getting started with using the GPU Operator with OpenShift, see the instructions [here](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/contents.html).\n",
      "csv_display_name": "NVIDIA GPU Operator",
      "csv_metadata_description": "Automate the management and monitoring of NVIDIA GPUs.",
      "csv_name": "gpu-operator-certified.v1.9.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:17:12.811000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "gpu-operator-certified",
      "provided_apis": [
        {
          "group": "nvidia.com",
          "kind": "ClusterPolicy",
          "plural": "clusterpolicies",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395",
          "name": "gpu-operator-image"
        },
        {
          "digest": "sha256:5f0d3af074c92dfe0ce36899a1545bb5a408f2ad59878d43045e9ca302b82a41",
          "image": "nvcr.io/nvidia/k8s/dcgm-exporter@sha256:5f0d3af074c92dfe0ce36899a1545bb5a408f2ad59878d43045e9ca302b82a41",
          "name": "dcgm-exporter-image"
        },
        {
          "digest": "sha256:f4c4de8d66b2fef8cebaee6fec2fb2d15d01e835de2654df6dfd4a0ce0baec6b",
          "image": "nvcr.io/nvidia/cloud-native/dcgm@sha256:f4c4de8d66b2fef8cebaee6fec2fb2d15d01e835de2654df6dfd4a0ce0baec6b",
          "name": "dcgm-image"
        },
        {
          "digest": "sha256:5f826e306d093332a86afa7d1e96218b5bdda8d33067931cff7914f6bb2994ee",
          "image": "nvcr.io/nvidia/k8s/container-toolkit@sha256:5f826e306d093332a86afa7d1e96218b5bdda8d33067931cff7914f6bb2994ee",
          "name": "container-toolkit-image"
        },
        {
          "digest": "sha256:35c8231e28e572b148699d52a5f5c9745556fd32ab4160da68d0fc84234c1309",
          "image": "nvcr.io/nvidia/driver@sha256:35c8231e28e572b148699d52a5f5c9745556fd32ab4160da68d0fc84234c1309",
          "name": "driver-image"
        },
        {
          "digest": "sha256:69171f906efe4bbabe31688343e59feea08a7e0ef8b0d9efb466abfa153aec16",
          "image": "nvcr.io/nvidia/k8s-device-plugin@sha256:69171f906efe4bbabe31688343e59feea08a7e0ef8b0d9efb466abfa153aec16",
          "name": "device-plugin-image"
        },
        {
          "digest": "sha256:bfc39d23568458dfd50c0c5323b6d42bdcd038c420fb2a2becd513a3ed3be27f",
          "image": "nvcr.io/nvidia/gpu-feature-discovery@sha256:bfc39d23568458dfd50c0c5323b6d42bdcd038c420fb2a2becd513a3ed3be27f",
          "name": "gpu-feature-discovery-image"
        },
        {
          "digest": "sha256:d718dda2f9c9f0a465240772ed1ca6db44789d37255172e00637a092bdd1ba31",
          "image": "nvcr.io/nvidia/cloud-native/k8s-mig-manager@sha256:d718dda2f9c9f0a465240772ed1ca6db44789d37255172e00637a092bdd1ba31",
          "name": "mig-manager-image"
        },
        {
          "digest": "sha256:e137c897256501537e0986963889a91ec90cac029b5263fc4b229b278f5b1a02",
          "image": "nvcr.io/nvidia/cuda@sha256:e137c897256501537e0986963889a91ec90cac029b5263fc4b229b278f5b1a02",
          "name": "init-container-image"
        },
        {
          "digest": "sha256:7b3509daf52c333c28da40d90586efa514ed9c14473f5ca495de7b65567ce4c2",
          "image": "nvcr.io/nvidia/cloud-native/gpu-operator-validator@sha256:7b3509daf52c333c28da40d90586efa514ed9c14473f5ca495de7b65567ce4c2",
          "name": "gpu-operator-validator-image"
        },
        {
          "digest": "sha256:54233ebccbc3d2b388b237031907d58c3719d0e6f3ecb874349c91e8145225d2",
          "image": "nvcr.io/nvidia/cloud-native/k8s-driver-manager@sha256:54233ebccbc3d2b388b237031907d58c3719d0e6f3ecb874349c91e8145225d2",
          "name": "k8s-driver-manager-image"
        },
        {
          "digest": "sha256:57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395",
          "name": "gpu-operator-57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395-annotation"
        },
        {
          "digest": "sha256:57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:57e7be259af342ccdf281d23d79e15d474e2e6f506f84c0cdae3db2a199b3395",
          "name": "gpu-operator"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.9.0",
      "version_original": "1.9.0"
    },
    {
      "_id": "61a947e0c17162a20c1c71ff",
      "alm_examples": [
        {
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent": {
              "configuration_yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n",
              "endpointHost": "ingress-red-saas.instana.io",
              "endpointPort": "443",
              "env": {},
              "key": "replace-key"
            },
            "cluster": {
              "name": "my-cluster"
            },
            "zone": {
              "name": "edited-zone"
            }
          }
        },
        {
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent.endpoint.host": "ingress-red-saas.instana.io",
            "agent.endpoint.port": 443,
            "agent.env": {
              "INSTANA_AGENT_TAGS": "example"
            },
            "agent.key": "replace-me",
            "agent.zone.name": "my-zone",
            "cluster.name": "replace-me",
            "config.files": {
              "configuration.yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/instana/instana-agent-operator-bundle@sha256:70821638936b353d5f06e3ed030d1d58b1eb14196e9b4238531cd67868df6570",
      "bundle_path_digest": "sha256:70821638936b353d5f06e3ed030d1d58b1eb14196e9b4238531cd67868df6570",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2021-12-02T22:25:36.110000+00:00",
      "csv_description": "# Instana\n\nInstana is an [APM solution](https://www.instana.com/product-overview/) built for microservices that enables IT Ops to build applications faster and deliver higher quality services by automating monitoring, tracing and root cause analysis. The solution is optimized for [Kubernetes](https://www.instana.com/automatic-kubernetes-monitoring/) and [OpenShift](https://www.instana.com/blog/automatic-root-cause-analysis-for-openshift-applications/).\n\n## Instana Agent Operator\n\nThis is the Kubernetes Operator for installing the Instana Agent on Kubernetes or OpenShift.\n\n## Prerequisites for OpenShift\n\nBefore the agent will be able to run in OpenShift, you need to perform a couple of extra configuration steps.\n\nYou need to set up a project for the Instana Agent and configure it's permissions.\n\nThe project you create here needs to be the namespace where you create the Instana Agent custom resource that the operator will use to deploy the agent.\n\nFor example, create the `instana-agent` project:\n\n    oc new-project instana-agent\n\nThen, ensure the `instana-agent` service account is in the privileged security context:\n\n    oc adm policy add-scc-to-user privileged -z instana-agent\n\nThis service account will be created by the operator.\n\nNow you can proceed with installing the operator for the Instana agent.\n\n## Installation and Configuration\n\nFirst, install this operator from [OperatorHub.io](https://operatorhub.io/), [OpenShift Container Platform](https://www.openshift.com/), or [OKD](https://www.okd.io/).\n\nSecond, create the target namespace where the Instana agent should be installed. The agent does not need to run in the same namespace as the operator. Most users create a new namespace `instana-agent` for running the agents.\n\nThird, create a custom resource with the agent configuration in the target namespace. The operator will pick up the custom resource and install the Instana agent accordingly.\n\nThe following is a minimal template of the custom resource:\n\n```yaml\napiVersion: instana.io/v1beta1\nkind: InstanaAgent\nmetadata:\n  name: instana-agent\n  namespace: instana-agent\nspec:\n  agent.zone.name: my-zone # (optional) name of the zone of the host\n  agent.key: replace-me # replace with your Instana agent key\n  agent.endpoint.host: ingress-red-saas.instana.io # the monitoring ingress endpoint\n  agent.endpoint.port: 443 # the monitoring ingress endpoint port, wrapped in quotes\n  agent.env:\n    INSTANA_AGENT_TAGS: example\n  cluster.name: replace-me # replace with the name of your Kubernetes cluster\n  config.files:\n    configuration.yaml: |\n      # You can leave this empty, or use this to configure your instana agent.\n      # See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n```\n\nSave the template in a file `instana-agent.yaml` and edit the following values:\n\n* If your target namespace is not `instana-agent`, replace the `namespace:` accordingly.\n* `agent.key` must be set with your Instana agent key.\n* `agent.endpoint` must be set with the monitoring ingress endpoint, generally either `saas-us-west-2.instana.io` or `saas-eu-west-1.instana.io`.\n* `agent.endpoint.port` must be set with the monitoring ingress port, generally \"443\" (wrapped in quotes).\n* `agent.zone.name` should be set with the name of the Kubernetes cluster that is be displayed in Instana.\n\nFor advanced configuration, you can edit the contents of the `configuration.yaml` file. View documentation [here](https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/).\n\nApply the custom resource with `kubectl apply -f instana-agent.yaml`. After some time, you should see `instana-agent` Pods being created on each node of your cluster, and your cluster should show on the infrastructure map on your Instana Web interface.\n\n## Uninstalling\n\nIn order to uninstall the Instana agent, simply remove the custom resource with `kubectl delete -f instana-agent.yaml`.\n\n## Source Code\n\nThe Instana agent operator is an open source project hosted on [https://github.com/instana/instana-agent-operator](https://github.com/instana/instana-agent-operator/).\n",
      "csv_display_name": "Instana Agent Operator",
      "csv_metadata_description": "Fully automated Application Performance Monitoring (APM) for microservices.",
      "csv_name": "instana-agent-operator.v2.0.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:43:12.871000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.5",
      "organization": "certified-operators",
      "package": "instana-agent-operator",
      "provided_apis": [
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1"
        },
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1beta1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:73cf53ca24ffe758a1c37db088a16be0da46c261436e9fef2ac0ccd6ed19e423",
          "image": "instana/instana-agent-operator@sha256:73cf53ca24ffe758a1c37db088a16be0da46c261436e9fef2ac0ccd6ed19e423",
          "name": "instana-agent-operator"
        },
        {
          "digest": "sha256:de42da5d3a955bfccfdcde86e8159ab4e0a20b8fe799c7e8a82878e971f3ec95",
          "image": "instana/agent@sha256:de42da5d3a955bfccfdcde86e8159ab4e0a20b8fe799c7e8a82878e971f3ec95",
          "name": "instana-agent"
        },
        {
          "digest": "sha256:73cf53ca24ffe758a1c37db088a16be0da46c261436e9fef2ac0ccd6ed19e423",
          "image": "instana/instana-agent-operator@sha256:73cf53ca24ffe758a1c37db088a16be0da46c261436e9fef2ac0ccd6ed19e423",
          "name": "instana-agent-operator-73cf53ca24ffe758a1c37db088a16be0da46c261436e9fef2ac0ccd6ed19e423-annotation"
        },
        {
          "digest": "sha256:73cf53ca24ffe758a1c37db088a16be0da46c261436e9fef2ac0ccd6ed19e423",
          "image": "instana/instana-agent-operator@sha256:73cf53ca24ffe758a1c37db088a16be0da46c261436e9fef2ac0ccd6ed19e423",
          "name": "manager"
        }
      ],
      "skip_range": "<2.0.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.5",
      "version": "2.0.0",
      "version_original": "2.0.0"
    },
    {
      "_id": "61ad9681bfd4a5234d596a09",
      "alm_examples": [
        {
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.4.1"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:a14d47bb4fd884917a50b8f9be82409272c50b1c30f879452d66305268ffd40e",
      "bundle_path_digest": "sha256:a14d47bb4fd884917a50b8f9be82409272c50b1c30f879452d66305268ffd40e",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2021-12-06T04:50:09.003000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.4.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:01:36.305000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:65c7bca4c2323581867463317f6d9c519411d0770b73d7c68ef90ec1c34b7bf7",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:65c7bca4c2323581867463317f6d9c519411d0770b73d7c68ef90ec1c34b7bf7",
          "name": "t8c-operator-65c7bca4c2323581867463317f6d9c519411d0770b73d7c68ef90ec1c34b7bf7-annotation"
        },
        {
          "digest": "sha256:65c7bca4c2323581867463317f6d9c519411d0770b73d7c68ef90ec1c34b7bf7",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:65c7bca4c2323581867463317f6d9c519411d0770b73d7c68ef90ec1c34b7bf7",
          "name": "t8c-operator"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "42.4.0",
      "version_original": "42.4.0"
    },
    {
      "_id": "61ad9b30bfd4a5234d596a0a",
      "alm_examples": [
        {
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.4.1"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:a14d47bb4fd884917a50b8f9be82409272c50b1c30f879452d66305268ffd40e",
      "bundle_path_digest": "sha256:a14d47bb4fd884917a50b8f9be82409272c50b1c30f879452d66305268ffd40e",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2021-12-06T05:10:08.267000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.4.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:19:43.492000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:65c7bca4c2323581867463317f6d9c519411d0770b73d7c68ef90ec1c34b7bf7",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:65c7bca4c2323581867463317f6d9c519411d0770b73d7c68ef90ec1c34b7bf7",
          "name": "t8c-operator-65c7bca4c2323581867463317f6d9c519411d0770b73d7c68ef90ec1c34b7bf7-annotation"
        },
        {
          "digest": "sha256:65c7bca4c2323581867463317f6d9c519411d0770b73d7c68ef90ec1c34b7bf7",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:65c7bca4c2323581867463317f6d9c519411d0770b73d7c68ef90ec1c34b7bf7",
          "name": "t8c-operator"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "42.4.0",
      "version_original": "42.4.0"
    },
    {
      "_id": "61add9bfbfd4a5234d596a4e",
      "alm_examples": [
        {
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.4.1"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:a14d47bb4fd884917a50b8f9be82409272c50b1c30f879452d66305268ffd40e",
      "bundle_path_digest": "sha256:a14d47bb4fd884917a50b8f9be82409272c50b1c30f879452d66305268ffd40e",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2021-12-06T09:37:03.742000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.4.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:14:26.594000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:65c7bca4c2323581867463317f6d9c519411d0770b73d7c68ef90ec1c34b7bf7",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:65c7bca4c2323581867463317f6d9c519411d0770b73d7c68ef90ec1c34b7bf7",
          "name": "t8c-operator-65c7bca4c2323581867463317f6d9c519411d0770b73d7c68ef90ec1c34b7bf7-annotation"
        },
        {
          "digest": "sha256:65c7bca4c2323581867463317f6d9c519411d0770b73d7c68ef90ec1c34b7bf7",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:65c7bca4c2323581867463317f6d9c519411d0770b73d7c68ef90ec1c34b7bf7",
          "name": "t8c-operator"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "42.4.0",
      "version_original": "42.4.0"
    },
    {
      "_id": "61af62c13e9240fca361089c",
      "alm_examples": [
        {
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent": {
              "configuration_yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n",
              "endpointHost": "ingress-red-saas.instana.io",
              "endpointPort": "443",
              "env": {},
              "key": "replace-key"
            },
            "cluster": {
              "name": "my-cluster"
            },
            "zone": {
              "name": "edited-zone"
            }
          }
        },
        {
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent.endpoint.host": "ingress-red-saas.instana.io",
            "agent.endpoint.port": 443,
            "agent.env": {
              "INSTANA_AGENT_TAGS": "example"
            },
            "agent.key": "replace-me",
            "agent.zone.name": "my-zone",
            "cluster.name": "replace-me",
            "config.files": {
              "configuration.yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/instana/instana-agent-operator-bundle@sha256:d72b299e1344da4c81ad10f853facba47fd60a4554a79b0137da6646318428c0",
      "bundle_path_digest": "sha256:d72b299e1344da4c81ad10f853facba47fd60a4554a79b0137da6646318428c0",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2021-12-07T13:33:53.535000+00:00",
      "csv_description": "# Instana\n\nInstana is an [APM solution](https://www.instana.com/product-overview/) built for microservices that enables IT Ops to build applications faster and deliver higher quality services by automating monitoring, tracing and root cause analysis. The solution is optimized for [Kubernetes](https://www.instana.com/automatic-kubernetes-monitoring/) and [OpenShift](https://www.instana.com/blog/automatic-root-cause-analysis-for-openshift-applications/).\n\n## Instana Agent Operator\n\nThis is the Kubernetes Operator for installing the Instana Agent on Kubernetes or OpenShift.\n\n## Prerequisites for OpenShift\n\nBefore the agent will be able to run in OpenShift, you need to perform a couple of extra configuration steps.\n\nYou need to set up a project for the Instana Agent and configure it's permissions.\n\nThe project you create here needs to be the namespace where you create the Instana Agent custom resource that the operator will use to deploy the agent.\n\nFor example, create the `instana-agent` project:\n\n    oc new-project instana-agent\n\nThen, ensure the `instana-agent` service account is in the privileged security context:\n\n    oc adm policy add-scc-to-user privileged -z instana-agent\n\nThis service account will be created by the operator.\n\nNow you can proceed with installing the operator for the Instana agent.\n\n## Installation and Configuration\n\nFirst, install this operator from [OperatorHub.io](https://operatorhub.io/), [OpenShift Container Platform](https://www.openshift.com/), or [OKD](https://www.okd.io/).\n\nSecond, create a custom resource with the agent configuration in the target namespace (for now, this MUST always be the `instana-agent` namespace). The operator will pick up the custom resource and install the Instana agent accordingly.\n\nThe following is a minimal template of the custom resource:\n\n```yaml\napiVersion: instana.io/v1\nkind: InstanaAgent\nmetadata:\n  name: instana-agent\n  namespace: instana-agent\nspec:\n  zone:\n    name: my-zone # (optional) name of the zone of the host\n  cluster:\n    name: replace-me # replace with the name of your Kubernetes cluster\n  agent:\n    key: replace-me # replace with your Instana agent key\n    endpointHost: ingress-red-saas.instana.io # the monitoring ingress endpoint\n    endpointPort: \"443\" # the monitoring ingress endpoint port, wrapped in quotes\n    env:\n      INSTANA_AGENT_TAGS: example\n    configuration_yaml: |\n      # You can leave this empty, or use this to configure your instana agent.\n      # See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n```\n\nSave the template in a file `instana-agent.yaml` and edit the following values:\n\n* If your target namespace is not `instana-agent`, replace the `namespace:` accordingly.\n* `agent.key` must be set with your Instana agent key.\n* `agent.endpointHost` must be set with the monitoring ingress endpoint, generally either `saas-us-west-2.instana.io` or `saas-eu-west-1.instana.io`.\n* `agent.endpointPort` must be set with the monitoring ingress port, generally \"443\" (wrapped in quotes).\n* `zone.name` should be set with the name of the Kubernetes cluster that is be displayed in Instana.\n\nFor advanced configuration, you can edit the contents of the `configuration.yaml` file. View documentation [here](https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/).\n\nApply the custom resource with `kubectl apply -f instana-agent.yaml`. After some time, you should see `instana-agent` Pods being created on each node of your cluster, and your cluster should show on the infrastructure map on your Instana Web interface.\n\n## Uninstalling\n\nIn order to uninstall the Instana agent, simply remove the custom resource with `kubectl delete -f instana-agent.yaml`.\n\n## Source Code\n\nThe Instana agent operator is an open source project hosted on [https://github.com/instana/instana-agent-operator](https://github.com/instana/instana-agent-operator/).\n",
      "csv_display_name": "Instana Agent Operator",
      "csv_metadata_description": "Fully automated Application Performance Monitoring (APM) for microservices.",
      "csv_name": "instana-agent-operator.v2.0.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:30:57.421000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.5",
      "organization": "certified-operators",
      "package": "instana-agent-operator",
      "provided_apis": [
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1"
        },
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1beta1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:dad92f35c638d37b3f13ae2c2bc814411ff358d92c4cad9d325f5e191d36ff09",
          "image": "instana/instana-agent-operator@sha256:dad92f35c638d37b3f13ae2c2bc814411ff358d92c4cad9d325f5e191d36ff09",
          "name": "instana-agent-operator"
        },
        {
          "digest": "sha256:de42da5d3a955bfccfdcde86e8159ab4e0a20b8fe799c7e8a82878e971f3ec95",
          "image": "instana/agent@sha256:de42da5d3a955bfccfdcde86e8159ab4e0a20b8fe799c7e8a82878e971f3ec95",
          "name": "instana-agent"
        },
        {
          "digest": "sha256:dad92f35c638d37b3f13ae2c2bc814411ff358d92c4cad9d325f5e191d36ff09",
          "image": "instana/instana-agent-operator@sha256:dad92f35c638d37b3f13ae2c2bc814411ff358d92c4cad9d325f5e191d36ff09",
          "name": "instana-agent-operator-dad92f35c638d37b3f13ae2c2bc814411ff358d92c4cad9d325f5e191d36ff09-annotation"
        },
        {
          "digest": "sha256:dad92f35c638d37b3f13ae2c2bc814411ff358d92c4cad9d325f5e191d36ff09",
          "image": "instana/instana-agent-operator@sha256:dad92f35c638d37b3f13ae2c2bc814411ff358d92c4cad9d325f5e191d36ff09",
          "name": "manager"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.5",
      "version": "2.0.1",
      "version_original": "2.0.1"
    },
    {
      "_id": "61af670d3e9240fca36108c0",
      "alm_examples": [
        {
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent": {
              "configuration_yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n",
              "endpointHost": "ingress-red-saas.instana.io",
              "endpointPort": "443",
              "env": {},
              "key": "replace-key"
            },
            "cluster": {
              "name": "my-cluster"
            },
            "zone": {
              "name": "edited-zone"
            }
          }
        },
        {
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent.endpoint.host": "ingress-red-saas.instana.io",
            "agent.endpoint.port": 443,
            "agent.env": {
              "INSTANA_AGENT_TAGS": "example"
            },
            "agent.key": "replace-me",
            "agent.zone.name": "my-zone",
            "cluster.name": "replace-me",
            "config.files": {
              "configuration.yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/instana/instana-agent-operator-bundle@sha256:1d8e2148413f5284dcedfe722bbf481ebbd64c6f4e78a5015081e3b4af826f81",
      "bundle_path_digest": "sha256:1d8e2148413f5284dcedfe722bbf481ebbd64c6f4e78a5015081e3b4af826f81",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2021-12-07T13:52:13.128000+00:00",
      "csv_description": "# Instana\n\nInstana is an [APM solution](https://www.instana.com/product-overview/) built for microservices that enables IT Ops to build applications faster and deliver higher quality services by automating monitoring, tracing and root cause analysis. The solution is optimized for [Kubernetes](https://www.instana.com/automatic-kubernetes-monitoring/) and [OpenShift](https://www.instana.com/blog/automatic-root-cause-analysis-for-openshift-applications/).\n\n## Instana Agent Operator\n\nThis is the Kubernetes Operator for installing the Instana Agent on Kubernetes or OpenShift.\n\n## Prerequisites for OpenShift\n\nBefore the agent will be able to run in OpenShift, you need to perform a couple of extra configuration steps.\n\nYou need to set up a project for the Instana Agent and configure it's permissions.\n\nThe project you create here needs to be the namespace where you create the Instana Agent custom resource that the operator will use to deploy the agent.\n\nFor example, create the `instana-agent` project:\n\n    oc new-project instana-agent\n\nThen, ensure the `instana-agent` service account is in the privileged security context:\n\n    oc adm policy add-scc-to-user privileged -z instana-agent\n\nThis service account will be created by the operator.\n\nNow you can proceed with installing the operator for the Instana agent.\n\n## Installation and Configuration\n\nFirst, install this operator from [OperatorHub.io](https://operatorhub.io/), [OpenShift Container Platform](https://www.openshift.com/), or [OKD](https://www.okd.io/).\n\nSecond, create a custom resource with the agent configuration in the target namespace (for now, this MUST always be the `instana-agent` namespace). The operator will pick up the custom resource and install the Instana agent accordingly.\n\nThe following is a minimal template of the custom resource:\n\n```yaml\napiVersion: instana.io/v1\nkind: InstanaAgent\nmetadata:\n  name: instana-agent\n  namespace: instana-agent\nspec:\n  zone:\n    name: my-zone # (optional) name of the zone of the host\n  cluster:\n    name: replace-me # replace with the name of your Kubernetes cluster\n  agent:\n    key: replace-me # replace with your Instana agent key\n    endpointHost: ingress-red-saas.instana.io # the monitoring ingress endpoint\n    endpointPort: \"443\" # the monitoring ingress endpoint port, wrapped in quotes\n    env:\n      INSTANA_AGENT_TAGS: example\n    configuration_yaml: |\n      # You can leave this empty, or use this to configure your instana agent.\n      # See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n```\n\nSave the template in a file `instana-agent.yaml` and edit the following values:\n\n* If your target namespace is not `instana-agent`, replace the `namespace:` accordingly.\n* `agent.key` must be set with your Instana agent key.\n* `agent.endpointHost` must be set with the monitoring ingress endpoint, generally either `saas-us-west-2.instana.io` or `saas-eu-west-1.instana.io`.\n* `agent.endpointPort` must be set with the monitoring ingress port, generally \"443\" (wrapped in quotes).\n* `zone.name` should be set with the name of the Kubernetes cluster that is be displayed in Instana.\n\nFor advanced configuration, you can edit the contents of the `configuration.yaml` file. View documentation [here](https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/).\n\nApply the custom resource with `kubectl apply -f instana-agent.yaml`. After some time, you should see `instana-agent` Pods being created on each node of your cluster, and your cluster should show on the infrastructure map on your Instana Web interface.\n\n## Uninstalling\n\nIn order to uninstall the Instana agent, simply remove the custom resource with `kubectl delete -f instana-agent.yaml`.\n\n## Source Code\n\nThe Instana agent operator is an open source project hosted on [https://github.com/instana/instana-agent-operator](https://github.com/instana/instana-agent-operator/).\n",
      "csv_display_name": "Instana Agent Operator",
      "csv_metadata_description": "Fully automated Application Performance Monitoring (APM) for microservices.",
      "csv_name": "instana-agent-operator.v2.0.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:31:45.174000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.5",
      "organization": "certified-operators",
      "package": "instana-agent-operator",
      "provided_apis": [
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1"
        },
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1beta1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:6e44ea0498f98f82383dd47e988eaca1aabd5c65a3e61e6b2241be1ea12c6aa0",
          "image": "instana/instana-agent-operator@sha256:6e44ea0498f98f82383dd47e988eaca1aabd5c65a3e61e6b2241be1ea12c6aa0",
          "name": "instana-agent-operator"
        },
        {
          "digest": "sha256:aaa9a53850cbb1a876cd1b85286380ea970973ec21d1532dffd3efbcf7320bb8",
          "image": "instana/agent@sha256:aaa9a53850cbb1a876cd1b85286380ea970973ec21d1532dffd3efbcf7320bb8",
          "name": "instana-agent"
        },
        {
          "digest": "sha256:6e44ea0498f98f82383dd47e988eaca1aabd5c65a3e61e6b2241be1ea12c6aa0",
          "image": "instana/instana-agent-operator@sha256:6e44ea0498f98f82383dd47e988eaca1aabd5c65a3e61e6b2241be1ea12c6aa0",
          "name": "instana-agent-operator-6e44ea0498f98f82383dd47e988eaca1aabd5c65a3e61e6b2241be1ea12c6aa0-annotation"
        },
        {
          "digest": "sha256:6e44ea0498f98f82383dd47e988eaca1aabd5c65a3e61e6b2241be1ea12c6aa0",
          "image": "instana/instana-agent-operator@sha256:6e44ea0498f98f82383dd47e988eaca1aabd5c65a3e61e6b2241be1ea12c6aa0",
          "name": "manager"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.5",
      "version": "2.0.2",
      "version_original": "2.0.2"
    },
    {
      "_id": "61af8503bfd4a5234d5974ab",
      "alm_examples": [
        {
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.4.1"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:a14d47bb4fd884917a50b8f9be82409272c50b1c30f879452d66305268ffd40e",
      "bundle_path_digest": "sha256:a14d47bb4fd884917a50b8f9be82409272c50b1c30f879452d66305268ffd40e",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2021-12-07T16:00:03.847000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.4.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:49:04.048000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1alpha1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:65c7bca4c2323581867463317f6d9c519411d0770b73d7c68ef90ec1c34b7bf7",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:65c7bca4c2323581867463317f6d9c519411d0770b73d7c68ef90ec1c34b7bf7",
          "name": "t8c-operator-65c7bca4c2323581867463317f6d9c519411d0770b73d7c68ef90ec1c34b7bf7-annotation"
        },
        {
          "digest": "sha256:65c7bca4c2323581867463317f6d9c519411d0770b73d7c68ef90ec1c34b7bf7",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:65c7bca4c2323581867463317f6d9c519411d0770b73d7c68ef90ec1c34b7bf7",
          "name": "t8c-operator"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "42.4.0",
      "version_original": "42.4.0"
    },
    {
      "_id": "61b04425f405208b380d9691",
      "alm_examples": [
        {
          "kind": "WorkloadManager",
          "metadata": {
            "name": "workload-manager",
            "namespace": "nec-workload-manager"
          },
          "spec": {
            "api_timeout": 3,
            "cluster_collection#": 10737418240,
            "cluster_platform": "OpenShift",
            "common_config_log_level": "INFO",
            "db_startup_recheck_time": 5,
            "db_startup_wait_time": 60,
            "default_monitor_count": 10,
            "default_monitor_interval": 60,
            "default_repeat_interval": 1800,
            "detail_collection#": 10737418240,
            "detect_count": 1,
            "detect_interval": 60,
            "event_collection#": 10737418240,
            "expire_after_seconds": 31536000,
            "get_info_interval": 60,
            "get_info_ssc": "off",
            "grafana_cooperation": "off",
            "grafana_datasource": "prometheus",
            "grafana_node_additional_varlist": "",
            "grafana_node_dashboard_endpoint": "https://changeit.nec.co.jp:443/d/wmnode/wm-node-dashboard",
            "grafana_node_varname_datasource": "datasource",
            "grafana_node_varname_node": "node",
            "grafana_pod_additional_varlist": "",
            "grafana_pod_dashboard_endpoint": "https://changeit.nec.co.jp:443/d/wmpod/wm-pod-dashboard",
            "grafana_pod_varname_datasource": "datasource",
            "grafana_pod_varname_pod": "pod",
            "grafana_time_range_minutes": 60,
            "hidden_namespace": "",
            "image": "registry.connect.redhat.com/nec/nec-workload-manager@sha256:1d99212cf18d83886a7b487151af00ef3abae8e2662aadfca38108b5eff9649d",
            "jaeger_endpoint": "https://changeit.nec.co.jp:443/search",
            "jaeger_service_mapping": "{}",
            "jaeger_time_range_sec": 60,
            "max_policy_fired_histories": 512,
            "mode": "trial",
            "node_cpu_usage_threshold": 80,
            "node_disk_usage_threshold": 100,
            "node_memory_usage_threshold": 80,
            "node_network_usage_threshold": 55,
            "openshift": {
              "use_ebs": "n",
              "web_console_host": "REPLACE_WEB_CONSOLE_HOST"
            },
            "policy_fired_histories_collection_max#": 1073741824,
            "policy_fired_histories_expire_after_seconds": 31536000,
            "skip_action_interval": 600,
            "ssc_auth_by_secret": "false",
            "ssc_event_collection#": 1073741824,
            "use_auth": "false",
            "use_pv": "false",
            "user_authority_config_json": "[\n  {\n    \"username\": \"cluster-admin-user\",\n    \"is_cluster_admin\": true,\n    \"namespaces\": []\n  },\n  {\n    \"username\": \"tenant-user\",\n    \"is_cluster_admin\": false,\n    \"namespaces\": [\n      \"tenant-namespace\"\n    ]\n  }\n]\n"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/nec/nec-workload-manager-operator-bundle@sha256:5a47a3ac2e5c777cd226a410bba29bca08701416cfcd342215e579e24c8a738d",
      "bundle_path_digest": "sha256:5a47a3ac2e5c777cd226a410bba29bca08701416cfcd342215e579e24c8a738d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2021-12-08T05:35:33.828000+00:00",
      "csv_description": "This operator deploys the NEC Workload Manager for Container Platform on OpenShift Container Platform.",
      "csv_display_name": "NEC Workload Manager for Container Platform Operator",
      "csv_metadata_description": "",
      "csv_name": "workload-manager-operator.v1.3.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:22:44.018000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "workload-manager-operator",
      "provided_apis": [
        {
          "group": "workloadmanager.nec.com",
          "kind": "WorkloadManager",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:1d99212cf18d83886a7b487151af00ef3abae8e2662aadfca38108b5eff9649d",
          "image": "registry.connect.redhat.com/nec/nec-workload-manager@sha256:1d99212cf18d83886a7b487151af00ef3abae8e2662aadfca38108b5eff9649d",
          "name": "nec-workload-manager"
        },
        {
          "digest": "sha256:5805850512de4c4868d0dcc7da6d2cc557196285b8c0e3c67c32065115e9ae87",
          "image": "registry.connect.redhat.com/nec/nec-workload-manager-operator@sha256:5805850512de4c4868d0dcc7da6d2cc557196285b8c0e3c67c32065115e9ae87",
          "name": "nec-workload-manager-operator"
        },
        {
          "digest": "sha256:5805850512de4c4868d0dcc7da6d2cc557196285b8c0e3c67c32065115e9ae87",
          "image": "registry.connect.redhat.com/nec/nec-workload-manager-operator@sha256:5805850512de4c4868d0dcc7da6d2cc557196285b8c0e3c67c32065115e9ae87",
          "name": "workload-manager-operator"
        },
        {
          "digest": "sha256:1d99212cf18d83886a7b487151af00ef3abae8e2662aadfca38108b5eff9649d",
          "image": "registry.connect.redhat.com/nec/nec-workload-manager@sha256:1d99212cf18d83886a7b487151af00ef3abae8e2662aadfca38108b5eff9649d",
          "name": "nec-workload-manager-1d99212cf18d83886a7b487151af00ef3abae8e2662aadfca38108b5eff9649d-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "1.3.1",
      "version_original": "1.3.1"
    },
    {
      "_id": "61b044b97f84cb9883a2f2d9",
      "alm_examples": [
        {
          "kind": "WorkloadManager",
          "metadata": {
            "name": "workload-manager",
            "namespace": "nec-workload-manager"
          },
          "spec": {
            "api_timeout": 3,
            "cluster_collection#": 10737418240,
            "cluster_platform": "OpenShift",
            "common_config_log_level": "INFO",
            "db_startup_recheck_time": 5,
            "db_startup_wait_time": 60,
            "default_monitor_count": 10,
            "default_monitor_interval": 60,
            "default_repeat_interval": 1800,
            "detail_collection#": 10737418240,
            "detect_count": 1,
            "detect_interval": 60,
            "event_collection#": 10737418240,
            "expire_after_seconds": 31536000,
            "get_info_interval": 60,
            "get_info_ssc": "off",
            "grafana_cooperation": "off",
            "grafana_datasource": "prometheus",
            "grafana_node_additional_varlist": "",
            "grafana_node_dashboard_endpoint": "https://changeit.nec.co.jp:443/d/wmnode/wm-node-dashboard",
            "grafana_node_varname_datasource": "datasource",
            "grafana_node_varname_node": "node",
            "grafana_pod_additional_varlist": "",
            "grafana_pod_dashboard_endpoint": "https://changeit.nec.co.jp:443/d/wmpod/wm-pod-dashboard",
            "grafana_pod_varname_datasource": "datasource",
            "grafana_pod_varname_pod": "pod",
            "grafana_time_range_minutes": 60,
            "hidden_namespace": "",
            "image": "registry.connect.redhat.com/nec/nec-workload-manager@sha256:1d99212cf18d83886a7b487151af00ef3abae8e2662aadfca38108b5eff9649d",
            "jaeger_endpoint": "https://changeit.nec.co.jp:443/search",
            "jaeger_service_mapping": "{}",
            "jaeger_time_range_sec": 60,
            "max_policy_fired_histories": 512,
            "mode": "trial",
            "node_cpu_usage_threshold": 80,
            "node_disk_usage_threshold": 100,
            "node_memory_usage_threshold": 80,
            "node_network_usage_threshold": 55,
            "openshift": {
              "use_ebs": "n",
              "web_console_host": "REPLACE_WEB_CONSOLE_HOST"
            },
            "policy_fired_histories_collection_max#": 1073741824,
            "policy_fired_histories_expire_after_seconds": 31536000,
            "skip_action_interval": 600,
            "ssc_auth_by_secret": "false",
            "ssc_event_collection#": 1073741824,
            "use_auth": "false",
            "use_pv": "false",
            "user_authority_config_json": "[\n  {\n    \"username\": \"cluster-admin-user\",\n    \"is_cluster_admin\": true,\n    \"namespaces\": []\n  },\n  {\n    \"username\": \"tenant-user\",\n    \"is_cluster_admin\": false,\n    \"namespaces\": [\n      \"tenant-namespace\"\n    ]\n  }\n]\n"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/nec/nec-workload-manager-operator-bundle@sha256:5a47a3ac2e5c777cd226a410bba29bca08701416cfcd342215e579e24c8a738d",
      "bundle_path_digest": "sha256:5a47a3ac2e5c777cd226a410bba29bca08701416cfcd342215e579e24c8a738d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2021-12-08T05:38:01.227000+00:00",
      "csv_description": "This operator deploys the NEC Workload Manager for Container Platform on OpenShift Container Platform.",
      "csv_display_name": "NEC Workload Manager for Container Platform Operator",
      "csv_metadata_description": "",
      "csv_name": "workload-manager-operator.v1.3.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:49:22.334000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "workload-manager-operator",
      "provided_apis": [
        {
          "group": "workloadmanager.nec.com",
          "kind": "WorkloadManager",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:1d99212cf18d83886a7b487151af00ef3abae8e2662aadfca38108b5eff9649d",
          "image": "registry.connect.redhat.com/nec/nec-workload-manager@sha256:1d99212cf18d83886a7b487151af00ef3abae8e2662aadfca38108b5eff9649d",
          "name": "nec-workload-manager"
        },
        {
          "digest": "sha256:5805850512de4c4868d0dcc7da6d2cc557196285b8c0e3c67c32065115e9ae87",
          "image": "registry.connect.redhat.com/nec/nec-workload-manager-operator@sha256:5805850512de4c4868d0dcc7da6d2cc557196285b8c0e3c67c32065115e9ae87",
          "name": "nec-workload-manager-operator"
        },
        {
          "digest": "sha256:5805850512de4c4868d0dcc7da6d2cc557196285b8c0e3c67c32065115e9ae87",
          "image": "registry.connect.redhat.com/nec/nec-workload-manager-operator@sha256:5805850512de4c4868d0dcc7da6d2cc557196285b8c0e3c67c32065115e9ae87",
          "name": "workload-manager-operator"
        },
        {
          "digest": "sha256:1d99212cf18d83886a7b487151af00ef3abae8e2662aadfca38108b5eff9649d",
          "image": "registry.connect.redhat.com/nec/nec-workload-manager@sha256:1d99212cf18d83886a7b487151af00ef3abae8e2662aadfca38108b5eff9649d",
          "name": "nec-workload-manager-1d99212cf18d83886a7b487151af00ef3abae8e2662aadfca38108b5eff9649d-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "1.3.1",
      "version_original": "1.3.1"
    },
    {
      "_id": "61b079e409fbfe27c991b077",
      "alm_examples": [
        {
          "kind": "WorkloadManager",
          "metadata": {
            "name": "workload-manager",
            "namespace": "nec-workload-manager"
          },
          "spec": {
            "api_timeout": 3,
            "cluster_collection#": 10737418240,
            "cluster_platform": "OpenShift",
            "common_config_log_level": "INFO",
            "db_startup_recheck_time": 5,
            "db_startup_wait_time": 60,
            "default_monitor_count": 10,
            "default_monitor_interval": 60,
            "default_repeat_interval": 1800,
            "detail_collection#": 10737418240,
            "detect_count": 1,
            "detect_interval": 60,
            "event_collection#": 10737418240,
            "expire_after_seconds": 31536000,
            "get_info_interval": 60,
            "get_info_ssc": "off",
            "grafana_cooperation": "off",
            "grafana_datasource": "prometheus",
            "grafana_node_additional_varlist": "",
            "grafana_node_dashboard_endpoint": "https://changeit.nec.co.jp:443/d/wmnode/wm-node-dashboard",
            "grafana_node_varname_datasource": "datasource",
            "grafana_node_varname_node": "node",
            "grafana_pod_additional_varlist": "",
            "grafana_pod_dashboard_endpoint": "https://changeit.nec.co.jp:443/d/wmpod/wm-pod-dashboard",
            "grafana_pod_varname_datasource": "datasource",
            "grafana_pod_varname_pod": "pod",
            "grafana_time_range_minutes": 60,
            "hidden_namespace": "",
            "image": "registry.connect.redhat.com/nec/nec-workload-manager@sha256:1d99212cf18d83886a7b487151af00ef3abae8e2662aadfca38108b5eff9649d",
            "jaeger_endpoint": "https://changeit.nec.co.jp:443/search",
            "jaeger_service_mapping": "{}",
            "jaeger_time_range_sec": 60,
            "max_policy_fired_histories": 512,
            "mode": "trial",
            "node_cpu_usage_threshold": 80,
            "node_disk_usage_threshold": 100,
            "node_memory_usage_threshold": 80,
            "node_network_usage_threshold": 55,
            "openshift": {
              "use_ebs": "n",
              "web_console_host": "REPLACE_WEB_CONSOLE_HOST"
            },
            "policy_fired_histories_collection_max#": 1073741824,
            "policy_fired_histories_expire_after_seconds": 31536000,
            "skip_action_interval": 600,
            "ssc_auth_by_secret": "false",
            "ssc_event_collection#": 1073741824,
            "use_auth": "false",
            "use_pv": "false",
            "user_authority_config_json": "[\n  {\n    \"username\": \"cluster-admin-user\",\n    \"is_cluster_admin\": true,\n    \"namespaces\": []\n  },\n  {\n    \"username\": \"tenant-user\",\n    \"is_cluster_admin\": false,\n    \"namespaces\": [\n      \"tenant-namespace\"\n    ]\n  }\n]\n"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/nec/nec-workload-manager-operator-bundle@sha256:5a47a3ac2e5c777cd226a410bba29bca08701416cfcd342215e579e24c8a738d",
      "bundle_path_digest": "sha256:5a47a3ac2e5c777cd226a410bba29bca08701416cfcd342215e579e24c8a738d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2021-12-08T09:24:52.586000+00:00",
      "csv_description": "This operator deploys the NEC Workload Manager for Container Platform on OpenShift Container Platform.",
      "csv_display_name": "NEC Workload Manager for Container Platform Operator",
      "csv_metadata_description": "",
      "csv_name": "workload-manager-operator.v1.3.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:17:42.448000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "workload-manager-operator",
      "provided_apis": [
        {
          "group": "workloadmanager.nec.com",
          "kind": "WorkloadManager",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:1d99212cf18d83886a7b487151af00ef3abae8e2662aadfca38108b5eff9649d",
          "image": "registry.connect.redhat.com/nec/nec-workload-manager@sha256:1d99212cf18d83886a7b487151af00ef3abae8e2662aadfca38108b5eff9649d",
          "name": "nec-workload-manager"
        },
        {
          "digest": "sha256:5805850512de4c4868d0dcc7da6d2cc557196285b8c0e3c67c32065115e9ae87",
          "image": "registry.connect.redhat.com/nec/nec-workload-manager-operator@sha256:5805850512de4c4868d0dcc7da6d2cc557196285b8c0e3c67c32065115e9ae87",
          "name": "nec-workload-manager-operator"
        },
        {
          "digest": "sha256:5805850512de4c4868d0dcc7da6d2cc557196285b8c0e3c67c32065115e9ae87",
          "image": "registry.connect.redhat.com/nec/nec-workload-manager-operator@sha256:5805850512de4c4868d0dcc7da6d2cc557196285b8c0e3c67c32065115e9ae87",
          "name": "workload-manager-operator"
        },
        {
          "digest": "sha256:1d99212cf18d83886a7b487151af00ef3abae8e2662aadfca38108b5eff9649d",
          "image": "registry.connect.redhat.com/nec/nec-workload-manager@sha256:1d99212cf18d83886a7b487151af00ef3abae8e2662aadfca38108b5eff9649d",
          "name": "nec-workload-manager-1d99212cf18d83886a7b487151af00ef3abae8e2662aadfca38108b5eff9649d-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.3.1",
      "version_original": "1.3.1"
    },
    {
      "_id": "61b16ee5f90e846f0ebdb0f2",
      "alm_examples": [
        {
          "kind": "HSPC",
          "metadata": {
            "name": "hspc",
            "namespace": "kube-system"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/hitachi/hspc-operator-bundle@sha256:91cd03f337743bb14df9fe49a0439dd6acc16a55c20bff7f7f7bf84b367676d4",
      "bundle_path_digest": "sha256:91cd03f337743bb14df9fe49a0439dd6acc16a55c20bff7f7f7bf84b367676d4",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2021-12-09T02:50:13.484000+00:00",
      "csv_description": "## About\nHitachi Storage Plug-in for Containers (HSPC) is a plugin that integrates Hitachi VSP storage into Kubernetes based clusters.\nHSPC provides dynamic persistent volume provisioning capabilities from Hitachi's block storage arrays.\n\nFor full documentation, go to our [Knowledge Base](https://knowledge.hitachivantara.com/Documents/Adapters_and_Drivers/Storage_Adapters_and_Drivers/Containers) and refer to the reference guide for HSPC v3.8.0.\n\n## Requirements\n\n### Supported Driver Version\n\n* HSPC v3.8.0\n\n### Supported Platforms\n\n* OpenShift v4.6, v4.7, v4.8\n\n### Supported Operating Systems\n\n* RHEL 7.x\n* RHEL 8.x",
      "csv_display_name": "Hitachi Storage Plug-in for Containers",
      "csv_metadata_description": "An operator for managing Hitachi Storage Plug-in for Containers CSI driver",
      "csv_name": "hspc-operator.v1.8.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:18:25.169000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "hspc-operator",
      "provided_apis": [
        {
          "group": "csi.hitachi.com",
          "kind": "HSPC",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:f82f352feadf07a971ab6a276cfb01e20310dfd611cc712958695a7b637f70bf",
          "image": "registry.connect.redhat.com/hitachi/hspc-operator@sha256:f82f352feadf07a971ab6a276cfb01e20310dfd611cc712958695a7b637f70bf",
          "name": "hspc-operator"
        },
        {
          "digest": "sha256:f82f352feadf07a971ab6a276cfb01e20310dfd611cc712958695a7b637f70bf",
          "image": "registry.connect.redhat.com/hitachi/hspc-operator@sha256:f82f352feadf07a971ab6a276cfb01e20310dfd611cc712958695a7b637f70bf",
          "name": "hspc-operator-f82f352feadf07a971ab6a276cfb01e20310dfd611cc712958695a7b637f70bf-annotation"
        },
        {
          "digest": "sha256:f82f352feadf07a971ab6a276cfb01e20310dfd611cc712958695a7b637f70bf",
          "image": "registry.connect.redhat.com/hitachi/hspc-operator@sha256:f82f352feadf07a971ab6a276cfb01e20310dfd611cc712958695a7b637f70bf",
          "name": "manager"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "1.8.0",
      "version_original": "1.8.0"
    },
    {
      "_id": "61b391c2f5a71c2d7c841e4e",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:69638694cb924d90c1c741bb90be3fee24efc6a3072774e875b30d5c55877108",
      "bundle_path_digest": "sha256:69638694cb924d90c1c741bb90be3fee24efc6a3072774e875b30d5c55877108",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.23",
      "creation_date": "2021-12-10T17:43:30.067000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.23.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-04T14:31:34.279000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "CalicoNodeStatus",
          "plural": "caliconodestatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "APIServer",
          "plural": "apiservers",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPReservation",
          "plural": "ipreservations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272",
          "image": "quay.io/tigera/operator@sha256:3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272",
          "name": "tigera-operator"
        },
        {
          "digest": "sha256:3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272",
          "image": "quay.io/tigera/operator@sha256:3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272",
          "name": "operator-3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272-annotation"
        }
      ],
      "skip_range": "<1.23.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.23.0",
      "version_original": "1.23.0"
    },
    {
      "_id": "61b394ef39aedd4833bb11ad",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:69638694cb924d90c1c741bb90be3fee24efc6a3072774e875b30d5c55877108",
      "bundle_path_digest": "sha256:69638694cb924d90c1c741bb90be3fee24efc6a3072774e875b30d5c55877108",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.23",
      "creation_date": "2021-12-10T17:57:03.788000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.23.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-05T11:20:10.715000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "operator.tigera.io",
          "kind": "APIServer",
          "plural": "apiservers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPReservation",
          "plural": "ipreservations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "CalicoNodeStatus",
          "plural": "caliconodestatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272",
          "image": "quay.io/tigera/operator@sha256:3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272",
          "name": "tigera-operator"
        },
        {
          "digest": "sha256:3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272",
          "image": "quay.io/tigera/operator@sha256:3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272",
          "name": "operator-3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272-annotation"
        }
      ],
      "skip_range": "<1.23.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.23.0",
      "version_original": "1.23.0"
    },
    {
      "_id": "61b3950d9e4335b6d1b1d8bd",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:69638694cb924d90c1c741bb90be3fee24efc6a3072774e875b30d5c55877108",
      "bundle_path_digest": "sha256:69638694cb924d90c1c741bb90be3fee24efc6a3072774e875b30d5c55877108",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.23",
      "creation_date": "2021-12-10T17:57:33.938000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.23.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-05T11:01:57.586000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "crd.projectcalico.org",
          "kind": "CalicoNodeStatus",
          "plural": "caliconodestatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "APIServer",
          "plural": "apiservers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPReservation",
          "plural": "ipreservations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272",
          "image": "quay.io/tigera/operator@sha256:3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272",
          "name": "tigera-operator"
        },
        {
          "digest": "sha256:3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272",
          "image": "quay.io/tigera/operator@sha256:3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272",
          "name": "operator-3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272-annotation"
        }
      ],
      "skip_range": "<1.23.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.23.0",
      "version_original": "1.23.0"
    },
    {
      "_id": "61b3956860a98527f7695a58",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:69638694cb924d90c1c741bb90be3fee24efc6a3072774e875b30d5c55877108",
      "bundle_path_digest": "sha256:69638694cb924d90c1c741bb90be3fee24efc6a3072774e875b30d5c55877108",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.23",
      "creation_date": "2021-12-10T17:59:04.690000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.23.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-04T14:49:16.642000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "APIServer",
          "plural": "apiservers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPReservation",
          "plural": "ipreservations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "CalicoNodeStatus",
          "plural": "caliconodestatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272",
          "image": "quay.io/tigera/operator@sha256:3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272",
          "name": "tigera-operator"
        },
        {
          "digest": "sha256:3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272",
          "image": "quay.io/tigera/operator@sha256:3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272",
          "name": "operator-3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272-annotation"
        }
      ],
      "skip_range": "<1.23.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "1.23.0",
      "version_original": "1.23.0"
    },
    {
      "_id": "61b395c3f5a71c2d7c841e50",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:69638694cb924d90c1c741bb90be3fee24efc6a3072774e875b30d5c55877108",
      "bundle_path_digest": "sha256:69638694cb924d90c1c741bb90be3fee24efc6a3072774e875b30d5c55877108",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.23",
      "creation_date": "2021-12-10T18:00:35.385000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.23.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-05T11:20:07.737000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPReservation",
          "plural": "ipreservations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "CalicoNodeStatus",
          "plural": "caliconodestatuses",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "APIServer",
          "plural": "apiservers",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272",
          "image": "quay.io/tigera/operator@sha256:3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272",
          "name": "tigera-operator"
        },
        {
          "digest": "sha256:3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272",
          "image": "quay.io/tigera/operator@sha256:3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272",
          "name": "operator-3685ddcc878ab11b91b9ea8b0adc94570dc398c8d79bb6ca87b1ea78e16ca272-annotation"
        }
      ],
      "skip_range": "<1.23.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "1.23.0",
      "version_original": "1.23.0"
    },
    {
      "_id": "61b3b88e9e4335b6d1b1d8c0",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:55c18554ceac30fc13b0bd91b2374e2f95045605f80d94c861cd185adfa0e1b4",
      "bundle_path_digest": "sha256:55c18554ceac30fc13b0bd91b2374e2f95045605f80d94c861cd185adfa0e1b4",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.23",
      "creation_date": "2021-12-10T20:29:02.910000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.23.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-04T14:31:36.334000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPReservation",
          "plural": "ipreservations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "CalicoNodeStatus",
          "plural": "caliconodestatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "APIServer",
          "plural": "apiservers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65",
          "image": "quay.io/tigera/operator@sha256:df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65",
          "name": "tigera-operator"
        },
        {
          "digest": "sha256:df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65",
          "image": "quay.io/tigera/operator@sha256:df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65",
          "name": "operator-df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65-annotation"
        }
      ],
      "skip_range": "<1.23.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.23.1",
      "version_original": "1.23.1"
    },
    {
      "_id": "61b3b8aaf5a71c2d7c841e55",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:55c18554ceac30fc13b0bd91b2374e2f95045605f80d94c861cd185adfa0e1b4",
      "bundle_path_digest": "sha256:55c18554ceac30fc13b0bd91b2374e2f95045605f80d94c861cd185adfa0e1b4",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.23",
      "creation_date": "2021-12-10T20:29:30.990000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.23.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-05T11:01:59.508000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "CalicoNodeStatus",
          "plural": "caliconodestatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPReservation",
          "plural": "ipreservations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "APIServer",
          "plural": "apiservers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65",
          "image": "quay.io/tigera/operator@sha256:df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65",
          "name": "tigera-operator"
        },
        {
          "digest": "sha256:df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65",
          "image": "quay.io/tigera/operator@sha256:df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65",
          "name": "operator-df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65-annotation"
        }
      ],
      "skip_range": "<1.23.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.23.1",
      "version_original": "1.23.1"
    },
    {
      "_id": "61b3baddf5a71c2d7c841e56",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:55c18554ceac30fc13b0bd91b2374e2f95045605f80d94c861cd185adfa0e1b4",
      "bundle_path_digest": "sha256:55c18554ceac30fc13b0bd91b2374e2f95045605f80d94c861cd185adfa0e1b4",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.23",
      "creation_date": "2021-12-10T20:38:53.293000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.23.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-05T11:13:53.300000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPReservation",
          "plural": "ipreservations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "CalicoNodeStatus",
          "plural": "caliconodestatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "APIServer",
          "plural": "apiservers",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65",
          "image": "quay.io/tigera/operator@sha256:df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65",
          "name": "tigera-operator"
        },
        {
          "digest": "sha256:df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65",
          "image": "quay.io/tigera/operator@sha256:df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65",
          "name": "operator-df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65-annotation"
        }
      ],
      "skip_range": "<1.23.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "1.23.1",
      "version_original": "1.23.1"
    },
    {
      "_id": "61b3bb3039aedd4833bb11b4",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:55c18554ceac30fc13b0bd91b2374e2f95045605f80d94c861cd185adfa0e1b4",
      "bundle_path_digest": "sha256:55c18554ceac30fc13b0bd91b2374e2f95045605f80d94c861cd185adfa0e1b4",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.23",
      "creation_date": "2021-12-10T20:40:16.981000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.23.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-05T11:14:13.565000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPReservation",
          "plural": "ipreservations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "CalicoNodeStatus",
          "plural": "caliconodestatuses",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "APIServer",
          "plural": "apiservers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65",
          "image": "quay.io/tigera/operator@sha256:df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65",
          "name": "tigera-operator"
        },
        {
          "digest": "sha256:df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65",
          "image": "quay.io/tigera/operator@sha256:df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65",
          "name": "operator-df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65-annotation"
        }
      ],
      "skip_range": "<1.23.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.23.1",
      "version_original": "1.23.1"
    },
    {
      "_id": "61b3bb8960a98527f7695a5f",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:55c18554ceac30fc13b0bd91b2374e2f95045605f80d94c861cd185adfa0e1b4",
      "bundle_path_digest": "sha256:55c18554ceac30fc13b0bd91b2374e2f95045605f80d94c861cd185adfa0e1b4",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.23",
      "creation_date": "2021-12-10T20:41:45.677000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.23.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-04T14:55:19.540000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "crd.projectcalico.org",
          "kind": "IPReservation",
          "plural": "ipreservations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "APIServer",
          "plural": "apiservers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "CalicoNodeStatus",
          "plural": "caliconodestatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65",
          "image": "quay.io/tigera/operator@sha256:df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65",
          "name": "tigera-operator"
        },
        {
          "digest": "sha256:df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65",
          "image": "quay.io/tigera/operator@sha256:df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65",
          "name": "operator-df959774a8c3b2a870b42772d11dc0844c5bc4430a973c92a592be0b1012df65-annotation"
        }
      ],
      "skip_range": "<1.23.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "1.23.1",
      "version_original": "1.23.1"
    },
    {
      "_id": "61b40a549e4335b6d1b1d8c5",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:85bb416b033fdeee5af37e48ac5ef16ae8d586c6a4305946e2f335713b021193",
      "bundle_path_digest": "sha256:85bb416b033fdeee5af37e48ac5ef16ae8d586c6a4305946e2f335713b021193",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.23",
      "creation_date": "2021-12-11T02:17:56.638000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.23.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-05T11:12:45.214000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPReservation",
          "plural": "ipreservations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "APIServer",
          "plural": "apiservers",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "CalicoNodeStatus",
          "plural": "caliconodestatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a",
          "image": "quay.io/tigera/operator@sha256:a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a",
          "name": "tigera-operator"
        },
        {
          "digest": "sha256:a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a",
          "image": "quay.io/tigera/operator@sha256:a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a",
          "name": "operator-a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a-annotation"
        }
      ],
      "skip_range": "<1.23.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "1.23.2",
      "version_original": "1.23.2"
    },
    {
      "_id": "61b40aa59e4335b6d1b1d8c6",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:85bb416b033fdeee5af37e48ac5ef16ae8d586c6a4305946e2f335713b021193",
      "bundle_path_digest": "sha256:85bb416b033fdeee5af37e48ac5ef16ae8d586c6a4305946e2f335713b021193",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.23",
      "creation_date": "2021-12-11T02:19:17.392000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.23.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-05T11:13:25.212000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "crd.projectcalico.org",
          "kind": "IPReservation",
          "plural": "ipreservations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "CalicoNodeStatus",
          "plural": "caliconodestatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "APIServer",
          "plural": "apiservers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a",
          "image": "quay.io/tigera/operator@sha256:a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a",
          "name": "tigera-operator"
        },
        {
          "digest": "sha256:a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a",
          "image": "quay.io/tigera/operator@sha256:a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a",
          "name": "operator-a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a-annotation"
        }
      ],
      "skip_range": "<1.23.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.23.2",
      "version_original": "1.23.2"
    },
    {
      "_id": "61b40b4639aedd4833bb11b7",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:85bb416b033fdeee5af37e48ac5ef16ae8d586c6a4305946e2f335713b021193",
      "bundle_path_digest": "sha256:85bb416b033fdeee5af37e48ac5ef16ae8d586c6a4305946e2f335713b021193",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.23",
      "creation_date": "2021-12-11T02:21:58.451000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.23.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-04T15:01:20.087000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "crd.projectcalico.org",
          "kind": "IPReservation",
          "plural": "ipreservations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "APIServer",
          "plural": "apiservers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "CalicoNodeStatus",
          "plural": "caliconodestatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a",
          "image": "quay.io/tigera/operator@sha256:a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a",
          "name": "tigera-operator"
        },
        {
          "digest": "sha256:a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a",
          "image": "quay.io/tigera/operator@sha256:a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a",
          "name": "operator-a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a-annotation"
        }
      ],
      "skip_range": "<1.23.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "1.23.2",
      "version_original": "1.23.2"
    },
    {
      "_id": "61b44c6360a98527f7695a6c",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:85bb416b033fdeee5af37e48ac5ef16ae8d586c6a4305946e2f335713b021193",
      "bundle_path_digest": "sha256:85bb416b033fdeee5af37e48ac5ef16ae8d586c6a4305946e2f335713b021193",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.23",
      "creation_date": "2021-12-11T06:59:47.553000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.23.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-05T11:02:01.491000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPReservation",
          "plural": "ipreservations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "CalicoNodeStatus",
          "plural": "caliconodestatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "APIServer",
          "plural": "apiservers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a",
          "image": "quay.io/tigera/operator@sha256:a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a",
          "name": "tigera-operator"
        },
        {
          "digest": "sha256:a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a",
          "image": "quay.io/tigera/operator@sha256:a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a",
          "name": "operator-a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a-annotation"
        }
      ],
      "skip_range": "<1.23.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.23.2",
      "version_original": "1.23.2"
    },
    {
      "_id": "61b471f59e4335b6d1b1d8d4",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:85bb416b033fdeee5af37e48ac5ef16ae8d586c6a4305946e2f335713b021193",
      "bundle_path_digest": "sha256:85bb416b033fdeee5af37e48ac5ef16ae8d586c6a4305946e2f335713b021193",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.23",
      "creation_date": "2021-12-11T09:40:05.110000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.23.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-04T14:31:38.356000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "CalicoNodeStatus",
          "plural": "caliconodestatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "APIServer",
          "plural": "apiservers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPReservation",
          "plural": "ipreservations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a",
          "image": "quay.io/tigera/operator@sha256:a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a",
          "name": "tigera-operator"
        },
        {
          "digest": "sha256:a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a",
          "image": "quay.io/tigera/operator@sha256:a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a",
          "name": "operator-a370072cbe39ee8afe03d843e803d91e41e8573a7385654138e31207a9b44d9a-annotation"
        }
      ],
      "skip_range": "<1.23.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.23.2",
      "version_original": "1.23.2"
    },
    {
      "_id": "61b471f69e4335b6d1b1d8d5",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:af2675c5b6917536944375fabb8cb53667c19fd5a24c498350ef4f66750f095e",
      "bundle_path_digest": "sha256:af2675c5b6917536944375fabb8cb53667c19fd5a24c498350ef4f66750f095e",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.23",
      "creation_date": "2021-12-11T09:40:06.514000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.23.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-04T14:31:40.592000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "CalicoNodeStatus",
          "plural": "caliconodestatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "APIServer",
          "plural": "apiservers",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPReservation",
          "plural": "ipreservations",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69",
          "image": "quay.io/tigera/operator@sha256:b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69",
          "name": "tigera-operator"
        },
        {
          "digest": "sha256:b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69",
          "image": "quay.io/tigera/operator@sha256:b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69",
          "name": "operator-b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69-annotation"
        }
      ],
      "skip_range": "<1.23.3",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.23.3",
      "version_original": "1.23.3"
    },
    {
      "_id": "61b472439e4335b6d1b1d8d6",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:af2675c5b6917536944375fabb8cb53667c19fd5a24c498350ef4f66750f095e",
      "bundle_path_digest": "sha256:af2675c5b6917536944375fabb8cb53667c19fd5a24c498350ef4f66750f095e",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.23",
      "creation_date": "2021-12-11T09:41:23.482000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.23.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-05T11:21:46.153000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "CalicoNodeStatus",
          "plural": "caliconodestatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPReservation",
          "plural": "ipreservations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "APIServer",
          "plural": "apiservers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69",
          "image": "quay.io/tigera/operator@sha256:b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69",
          "name": "tigera-operator"
        },
        {
          "digest": "sha256:b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69",
          "image": "quay.io/tigera/operator@sha256:b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69",
          "name": "operator-b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69-annotation"
        }
      ],
      "skip_range": "<1.23.3",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.23.3",
      "version_original": "1.23.3"
    },
    {
      "_id": "61b4729c9e4335b6d1b1d8d7",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:af2675c5b6917536944375fabb8cb53667c19fd5a24c498350ef4f66750f095e",
      "bundle_path_digest": "sha256:af2675c5b6917536944375fabb8cb53667c19fd5a24c498350ef4f66750f095e",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.23",
      "creation_date": "2021-12-11T09:42:52.128000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.23.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-04T14:49:06.892000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "CalicoNodeStatus",
          "plural": "caliconodestatuses",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPReservation",
          "plural": "ipreservations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "APIServer",
          "plural": "apiservers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69",
          "image": "quay.io/tigera/operator@sha256:b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69",
          "name": "tigera-operator"
        },
        {
          "digest": "sha256:b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69",
          "image": "quay.io/tigera/operator@sha256:b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69",
          "name": "operator-b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69-annotation"
        }
      ],
      "skip_range": "<1.23.3",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "1.23.3",
      "version_original": "1.23.3"
    },
    {
      "_id": "61b473039e4335b6d1b1d8d9",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:af2675c5b6917536944375fabb8cb53667c19fd5a24c498350ef4f66750f095e",
      "bundle_path_digest": "sha256:af2675c5b6917536944375fabb8cb53667c19fd5a24c498350ef4f66750f095e",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.23",
      "creation_date": "2021-12-11T09:44:35.900000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.23.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-05T11:02:03.427000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "CalicoNodeStatus",
          "plural": "caliconodestatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "APIServer",
          "plural": "apiservers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPReservation",
          "plural": "ipreservations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69",
          "image": "quay.io/tigera/operator@sha256:b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69",
          "name": "tigera-operator"
        },
        {
          "digest": "sha256:b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69",
          "image": "quay.io/tigera/operator@sha256:b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69",
          "name": "operator-b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69-annotation"
        }
      ],
      "skip_range": "<1.23.3",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.23.3",
      "version_original": "1.23.3"
    },
    {
      "_id": "61b4742b60a98527f7695a6e",
      "alm_examples": [
        {
          "kind": "Installation",
          "metadata": {
            "name": "default"
          },
          "spec": {
            "variant": "Calico"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/tigera/operator@sha256:af2675c5b6917536944375fabb8cb53667c19fd5a24c498350ef4f66750f095e",
      "bundle_path_digest": "sha256:af2675c5b6917536944375fabb8cb53667c19fd5a24c498350ef4f66750f095e",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "release-v1.23",
      "creation_date": "2021-12-11T09:49:31.817000+00:00",
      "csv_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift. Its goal is to make installation, upgrades, and ongoing lifecycle management of Calico and Calico Enterprise as simple and reliable as possible. **Important**: this operator should only be installed if the cluster was already provisioned with Calico.",
      "csv_display_name": "Tigera Operator",
      "csv_metadata_description": "An operator which manages the lifecycle of a Calico or Calico Enterprise installation on Kubernetes or OpenShift.",
      "csv_name": "tigera-operator.v1.23.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-05T11:12:43.187000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "tigera-operator",
      "provided_apis": [
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkPolicy",
          "plural": "networkpolicies",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkPolicy",
          "plural": "globalnetworkpolicies",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "APIServer",
          "plural": "apiservers",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "Installation",
          "plural": "installations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "FelixConfiguration",
          "plural": "felixconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "NetworkSet",
          "plural": "networksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPReservation",
          "plural": "ipreservations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMConfig",
          "plural": "ipamconfigs",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "CalicoNodeStatus",
          "plural": "caliconodestatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "ClusterInformation",
          "plural": "clusterinformations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPConfiguration",
          "plural": "bgpconfigurations",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMBlock",
          "plural": "ipamblocks",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "TigeraStatus",
          "plural": "tigerastatuses",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BGPPeer",
          "plural": "bgppeers",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "BlockAffinity",
          "plural": "blockaffinities",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPPool",
          "plural": "ippools",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "IPAMHandle",
          "plural": "ipamhandles",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "GlobalNetworkSet",
          "plural": "globalnetworksets",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "HostEndpoint",
          "plural": "hostendpoints",
          "version": "v1"
        },
        {
          "group": "crd.projectcalico.org",
          "kind": "KubeControllersConfiguration",
          "plural": "kubecontrollersconfigurations",
          "version": "v1"
        },
        {
          "group": "operator.tigera.io",
          "kind": "ImageSet",
          "plural": "imagesets",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69",
          "image": "quay.io/tigera/operator@sha256:b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69",
          "name": "tigera-operator"
        },
        {
          "digest": "sha256:b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69",
          "image": "quay.io/tigera/operator@sha256:b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69",
          "name": "operator-b4e3eeccfd3d5a931c07f31c244b272e058ccabd2d8155ccc3ff52ed78855e69-annotation"
        }
      ],
      "skip_range": "<1.23.3",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "1.23.3",
      "version_original": "1.23.3"
    },
    {
      "_id": "61b7b936365e714ccb637aeb",
      "alm_examples": [
        {
          "kind": "ConjurFollower",
          "metadata": {
            "labels": {
              "app": "conjur-follower"
            },
            "name": "conjur-follower-operator-my-conjur-follower",
            "namespace": "conjur-follower-operator-system"
          },
          "spec": {
            "images": {
              "configurator": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
              "conjur": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
              "info": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
              "nginx": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
              "postgres": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
              "syslogNg": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c"
            },
            "master": {
              "account": "my-company",
              "authenticatorID": "conjur-openshift-follower",
              "authnLogin": "host/conjur-openshift-follower",
              "caCertificateFrom": {
                "configMapKeyRef": {
                  "key": "conjur.master-cert",
                  "name": "follower"
                }
              },
              "hostname": "conjur.my-company.net"
            },
            "replicas": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator-bundle@sha256:e3bc395543de733defc75270df2828fa8ba4cdf5c5cf79848a4640ee99a9fef7",
      "bundle_path_digest": "sha256:e3bc395543de733defc75270df2828fa8ba4cdf5c5cf79848a4640ee99a9fef7",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "preview",
      "creation_date": "2021-12-13T21:20:54.693000+00:00",
      "csv_description": "Use this Operator for managing Conjur Followers in an OpenShift cluster.\n\nCyberArk products secure your most sensitive and high-value assets\u2014and supporting your Identity Security goals is our top priority. We offer 24/7 service for high priority issues to all customers with resources across ten countries and in all continents.\n\nCyberArk Conjur makes secrets management simple. Conjur provides a seamless open source interface to securely authenticate, control, and audit non-human access across tools, applications, containers, and cloud environments via robust secrets management.",
      "csv_display_name": "Conjur Enterprise Follower Operator",
      "csv_metadata_description": "",
      "csv_name": "conjur-follower-operator.v2.0.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-05T20:17:45.884000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "conjur-follower-operator",
      "provided_apis": [
        {
          "group": "conjur.cyberark.com",
          "kind": "ConjurFollower",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator@sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "name": "conjur-openshift-follower-operator"
        },
        {
          "digest": "sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "name": "conjur-openshift-follower-configurator"
        },
        {
          "digest": "sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "name": "conjur-openshift-follower-conjur"
        },
        {
          "digest": "sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "name": "conjur-openshift-follower-info"
        },
        {
          "digest": "sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "name": "conjur-openshift-follower-nginx"
        },
        {
          "digest": "sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "name": "conjur-openshift-follower-postgres"
        },
        {
          "digest": "sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "name": "conjur-openshift-follower-syslog-ng"
        },
        {
          "digest": "sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator@sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "name": "conjur-follower-operator"
        },
        {
          "digest": "sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "name": "conjur-openshift-follower-syslog-ng-7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c-annotation"
        },
        {
          "digest": "sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "name": "conjur-openshift-follower-postgres-96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5-annotation"
        },
        {
          "digest": "sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "name": "conjur-openshift-follower-nginx-d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981-annotation"
        },
        {
          "digest": "sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "name": "conjur-openshift-follower-info-27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05-annotation"
        },
        {
          "digest": "sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "name": "conjur-openshift-follower-conjur-ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c-annotation"
        },
        {
          "digest": "sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "name": "conjur-openshift-follower-configurator-b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2.0.2",
      "version_original": "2.0.2"
    },
    {
      "_id": "61b7b939dda6c5fe6ba361dd",
      "alm_examples": [
        {
          "kind": "ConjurFollower",
          "metadata": {
            "labels": {
              "app": "conjur-follower"
            },
            "name": "conjur-follower-operator-my-conjur-follower",
            "namespace": "conjur-follower-operator-system"
          },
          "spec": {
            "images": {
              "configurator": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
              "conjur": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
              "info": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
              "nginx": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
              "postgres": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
              "syslogNg": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c"
            },
            "master": {
              "account": "my-company",
              "authenticatorID": "conjur-openshift-follower",
              "authnLogin": "host/conjur-openshift-follower",
              "caCertificateFrom": {
                "configMapKeyRef": {
                  "key": "conjur.master-cert",
                  "name": "follower"
                }
              },
              "hostname": "conjur.my-company.net"
            },
            "replicas": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator-bundle@sha256:e3bc395543de733defc75270df2828fa8ba4cdf5c5cf79848a4640ee99a9fef7",
      "bundle_path_digest": "sha256:e3bc395543de733defc75270df2828fa8ba4cdf5c5cf79848a4640ee99a9fef7",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2021-12-13T21:20:57.202000+00:00",
      "csv_description": "Use this Operator for managing Conjur Followers in an OpenShift cluster.\n\nCyberArk products secure your most sensitive and high-value assets\u2014and supporting your Identity Security goals is our top priority. We offer 24/7 service for high priority issues to all customers with resources across ten countries and in all continents.\n\nCyberArk Conjur makes secrets management simple. Conjur provides a seamless open source interface to securely authenticate, control, and audit non-human access across tools, applications, containers, and cloud environments via robust secrets management.",
      "csv_display_name": "Conjur Enterprise Follower Operator",
      "csv_metadata_description": "",
      "csv_name": "conjur-follower-operator.v2.0.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T20:17:46.657000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "conjur-follower-operator",
      "provided_apis": [
        {
          "group": "conjur.cyberark.com",
          "kind": "ConjurFollower",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator@sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "name": "conjur-openshift-follower-operator"
        },
        {
          "digest": "sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "name": "conjur-openshift-follower-configurator"
        },
        {
          "digest": "sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "name": "conjur-openshift-follower-conjur"
        },
        {
          "digest": "sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "name": "conjur-openshift-follower-info"
        },
        {
          "digest": "sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "name": "conjur-openshift-follower-nginx"
        },
        {
          "digest": "sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "name": "conjur-openshift-follower-postgres"
        },
        {
          "digest": "sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "name": "conjur-openshift-follower-syslog-ng"
        },
        {
          "digest": "sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator@sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "name": "conjur-follower-operator"
        },
        {
          "digest": "sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "name": "conjur-openshift-follower-syslog-ng-7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c-annotation"
        },
        {
          "digest": "sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "name": "conjur-openshift-follower-postgres-96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5-annotation"
        },
        {
          "digest": "sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "name": "conjur-openshift-follower-nginx-d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981-annotation"
        },
        {
          "digest": "sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "name": "conjur-openshift-follower-info-27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05-annotation"
        },
        {
          "digest": "sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "name": "conjur-openshift-follower-conjur-ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c-annotation"
        },
        {
          "digest": "sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "name": "conjur-openshift-follower-configurator-b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2.0.2",
      "version_original": "2.0.2"
    },
    {
      "_id": "61b7ba1b365e714ccb637aec",
      "alm_examples": [
        {
          "kind": "ConjurFollower",
          "metadata": {
            "labels": {
              "app": "conjur-follower"
            },
            "name": "conjur-follower-operator-my-conjur-follower",
            "namespace": "conjur-follower-operator-system"
          },
          "spec": {
            "images": {
              "configurator": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
              "conjur": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
              "info": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
              "nginx": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
              "postgres": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
              "syslogNg": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c"
            },
            "master": {
              "account": "my-company",
              "authenticatorID": "conjur-openshift-follower",
              "authnLogin": "host/conjur-openshift-follower",
              "caCertificateFrom": {
                "configMapKeyRef": {
                  "key": "conjur.master-cert",
                  "name": "follower"
                }
              },
              "hostname": "conjur.my-company.net"
            },
            "replicas": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator-bundle@sha256:e3bc395543de733defc75270df2828fa8ba4cdf5c5cf79848a4640ee99a9fef7",
      "bundle_path_digest": "sha256:e3bc395543de733defc75270df2828fa8ba4cdf5c5cf79848a4640ee99a9fef7",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2021-12-13T21:24:43.594000+00:00",
      "csv_description": "Use this Operator for managing Conjur Followers in an OpenShift cluster.\n\nCyberArk products secure your most sensitive and high-value assets\u2014and supporting your Identity Security goals is our top priority. We offer 24/7 service for high priority issues to all customers with resources across ten countries and in all continents.\n\nCyberArk Conjur makes secrets management simple. Conjur provides a seamless open source interface to securely authenticate, control, and audit non-human access across tools, applications, containers, and cloud environments via robust secrets management.",
      "csv_display_name": "Conjur Enterprise Follower Operator",
      "csv_metadata_description": "",
      "csv_name": "conjur-follower-operator.v2.0.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T20:42:29.506000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "conjur-follower-operator",
      "provided_apis": [
        {
          "group": "conjur.cyberark.com",
          "kind": "ConjurFollower",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator@sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "name": "conjur-openshift-follower-operator"
        },
        {
          "digest": "sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "name": "conjur-openshift-follower-configurator"
        },
        {
          "digest": "sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "name": "conjur-openshift-follower-conjur"
        },
        {
          "digest": "sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "name": "conjur-openshift-follower-info"
        },
        {
          "digest": "sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "name": "conjur-openshift-follower-nginx"
        },
        {
          "digest": "sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "name": "conjur-openshift-follower-postgres"
        },
        {
          "digest": "sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "name": "conjur-openshift-follower-syslog-ng"
        },
        {
          "digest": "sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator@sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "name": "conjur-follower-operator"
        },
        {
          "digest": "sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "name": "conjur-openshift-follower-syslog-ng-7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c-annotation"
        },
        {
          "digest": "sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "name": "conjur-openshift-follower-postgres-96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5-annotation"
        },
        {
          "digest": "sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "name": "conjur-openshift-follower-nginx-d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981-annotation"
        },
        {
          "digest": "sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "name": "conjur-openshift-follower-info-27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05-annotation"
        },
        {
          "digest": "sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "name": "conjur-openshift-follower-conjur-ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c-annotation"
        },
        {
          "digest": "sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "name": "conjur-openshift-follower-configurator-b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "2.0.2",
      "version_original": "2.0.2"
    },
    {
      "_id": "61b7ba1edda6c5fe6ba361df",
      "alm_examples": [
        {
          "kind": "ConjurFollower",
          "metadata": {
            "labels": {
              "app": "conjur-follower"
            },
            "name": "conjur-follower-operator-my-conjur-follower",
            "namespace": "conjur-follower-operator-system"
          },
          "spec": {
            "images": {
              "configurator": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
              "conjur": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
              "info": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
              "nginx": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
              "postgres": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
              "syslogNg": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c"
            },
            "master": {
              "account": "my-company",
              "authenticatorID": "conjur-openshift-follower",
              "authnLogin": "host/conjur-openshift-follower",
              "caCertificateFrom": {
                "configMapKeyRef": {
                  "key": "conjur.master-cert",
                  "name": "follower"
                }
              },
              "hostname": "conjur.my-company.net"
            },
            "replicas": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator-bundle@sha256:e3bc395543de733defc75270df2828fa8ba4cdf5c5cf79848a4640ee99a9fef7",
      "bundle_path_digest": "sha256:e3bc395543de733defc75270df2828fa8ba4cdf5c5cf79848a4640ee99a9fef7",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "preview",
      "creation_date": "2021-12-13T21:24:46.108000+00:00",
      "csv_description": "Use this Operator for managing Conjur Followers in an OpenShift cluster.\n\nCyberArk products secure your most sensitive and high-value assets\u2014and supporting your Identity Security goals is our top priority. We offer 24/7 service for high priority issues to all customers with resources across ten countries and in all continents.\n\nCyberArk Conjur makes secrets management simple. Conjur provides a seamless open source interface to securely authenticate, control, and audit non-human access across tools, applications, containers, and cloud environments via robust secrets management.",
      "csv_display_name": "Conjur Enterprise Follower Operator",
      "csv_metadata_description": "",
      "csv_name": "conjur-follower-operator.v2.0.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-05T20:42:30.240000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "conjur-follower-operator",
      "provided_apis": [
        {
          "group": "conjur.cyberark.com",
          "kind": "ConjurFollower",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator@sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "name": "conjur-openshift-follower-operator"
        },
        {
          "digest": "sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "name": "conjur-openshift-follower-configurator"
        },
        {
          "digest": "sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "name": "conjur-openshift-follower-conjur"
        },
        {
          "digest": "sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "name": "conjur-openshift-follower-info"
        },
        {
          "digest": "sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "name": "conjur-openshift-follower-nginx"
        },
        {
          "digest": "sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "name": "conjur-openshift-follower-postgres"
        },
        {
          "digest": "sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "name": "conjur-openshift-follower-syslog-ng"
        },
        {
          "digest": "sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator@sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "name": "conjur-follower-operator"
        },
        {
          "digest": "sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "name": "conjur-openshift-follower-syslog-ng-7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c-annotation"
        },
        {
          "digest": "sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "name": "conjur-openshift-follower-postgres-96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5-annotation"
        },
        {
          "digest": "sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "name": "conjur-openshift-follower-nginx-d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981-annotation"
        },
        {
          "digest": "sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "name": "conjur-openshift-follower-info-27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05-annotation"
        },
        {
          "digest": "sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "name": "conjur-openshift-follower-conjur-ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c-annotation"
        },
        {
          "digest": "sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "name": "conjur-openshift-follower-configurator-b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "2.0.2",
      "version_original": "2.0.2"
    },
    {
      "_id": "61b7bbe9dda6c5fe6ba361e1",
      "alm_examples": [
        {
          "kind": "ConjurFollower",
          "metadata": {
            "labels": {
              "app": "conjur-follower"
            },
            "name": "conjur-follower-operator-my-conjur-follower",
            "namespace": "conjur-follower-operator-system"
          },
          "spec": {
            "images": {
              "configurator": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
              "conjur": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
              "info": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
              "nginx": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
              "postgres": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
              "syslogNg": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c"
            },
            "master": {
              "account": "my-company",
              "authenticatorID": "conjur-openshift-follower",
              "authnLogin": "host/conjur-openshift-follower",
              "caCertificateFrom": {
                "configMapKeyRef": {
                  "key": "conjur.master-cert",
                  "name": "follower"
                }
              },
              "hostname": "conjur.my-company.net"
            },
            "replicas": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator-bundle@sha256:e3bc395543de733defc75270df2828fa8ba4cdf5c5cf79848a4640ee99a9fef7",
      "bundle_path_digest": "sha256:e3bc395543de733defc75270df2828fa8ba4cdf5c5cf79848a4640ee99a9fef7",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "preview",
      "creation_date": "2021-12-13T21:32:25.632000+00:00",
      "csv_description": "Use this Operator for managing Conjur Followers in an OpenShift cluster.\n\nCyberArk products secure your most sensitive and high-value assets\u2014and supporting your Identity Security goals is our top priority. We offer 24/7 service for high priority issues to all customers with resources across ten countries and in all continents.\n\nCyberArk Conjur makes secrets management simple. Conjur provides a seamless open source interface to securely authenticate, control, and audit non-human access across tools, applications, containers, and cloud environments via robust secrets management.",
      "csv_display_name": "Conjur Enterprise Follower Operator",
      "csv_metadata_description": "",
      "csv_name": "conjur-follower-operator.v2.0.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-05T20:43:38.527000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "conjur-follower-operator",
      "provided_apis": [
        {
          "group": "conjur.cyberark.com",
          "kind": "ConjurFollower",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator@sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "name": "conjur-openshift-follower-operator"
        },
        {
          "digest": "sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "name": "conjur-openshift-follower-configurator"
        },
        {
          "digest": "sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "name": "conjur-openshift-follower-conjur"
        },
        {
          "digest": "sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "name": "conjur-openshift-follower-info"
        },
        {
          "digest": "sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "name": "conjur-openshift-follower-nginx"
        },
        {
          "digest": "sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "name": "conjur-openshift-follower-postgres"
        },
        {
          "digest": "sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "name": "conjur-openshift-follower-syslog-ng"
        },
        {
          "digest": "sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator@sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "name": "conjur-follower-operator"
        },
        {
          "digest": "sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "name": "conjur-openshift-follower-syslog-ng-7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c-annotation"
        },
        {
          "digest": "sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "name": "conjur-openshift-follower-postgres-96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5-annotation"
        },
        {
          "digest": "sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "name": "conjur-openshift-follower-nginx-d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981-annotation"
        },
        {
          "digest": "sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "name": "conjur-openshift-follower-info-27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05-annotation"
        },
        {
          "digest": "sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "name": "conjur-openshift-follower-conjur-ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c-annotation"
        },
        {
          "digest": "sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "name": "conjur-openshift-follower-configurator-b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "2.0.2",
      "version_original": "2.0.2"
    },
    {
      "_id": "61b7bbec2e8aeda4b340e5cf",
      "alm_examples": [
        {
          "kind": "ConjurFollower",
          "metadata": {
            "labels": {
              "app": "conjur-follower"
            },
            "name": "conjur-follower-operator-my-conjur-follower",
            "namespace": "conjur-follower-operator-system"
          },
          "spec": {
            "images": {
              "configurator": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
              "conjur": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
              "info": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
              "nginx": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
              "postgres": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
              "syslogNg": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c"
            },
            "master": {
              "account": "my-company",
              "authenticatorID": "conjur-openshift-follower",
              "authnLogin": "host/conjur-openshift-follower",
              "caCertificateFrom": {
                "configMapKeyRef": {
                  "key": "conjur.master-cert",
                  "name": "follower"
                }
              },
              "hostname": "conjur.my-company.net"
            },
            "replicas": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator-bundle@sha256:e3bc395543de733defc75270df2828fa8ba4cdf5c5cf79848a4640ee99a9fef7",
      "bundle_path_digest": "sha256:e3bc395543de733defc75270df2828fa8ba4cdf5c5cf79848a4640ee99a9fef7",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2021-12-13T21:32:28.183000+00:00",
      "csv_description": "Use this Operator for managing Conjur Followers in an OpenShift cluster.\n\nCyberArk products secure your most sensitive and high-value assets\u2014and supporting your Identity Security goals is our top priority. We offer 24/7 service for high priority issues to all customers with resources across ten countries and in all continents.\n\nCyberArk Conjur makes secrets management simple. Conjur provides a seamless open source interface to securely authenticate, control, and audit non-human access across tools, applications, containers, and cloud environments via robust secrets management.",
      "csv_display_name": "Conjur Enterprise Follower Operator",
      "csv_metadata_description": "",
      "csv_name": "conjur-follower-operator.v2.0.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T20:43:39.179000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "conjur-follower-operator",
      "provided_apis": [
        {
          "group": "conjur.cyberark.com",
          "kind": "ConjurFollower",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator@sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "name": "conjur-openshift-follower-operator"
        },
        {
          "digest": "sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "name": "conjur-openshift-follower-configurator"
        },
        {
          "digest": "sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "name": "conjur-openshift-follower-conjur"
        },
        {
          "digest": "sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "name": "conjur-openshift-follower-info"
        },
        {
          "digest": "sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "name": "conjur-openshift-follower-nginx"
        },
        {
          "digest": "sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "name": "conjur-openshift-follower-postgres"
        },
        {
          "digest": "sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "name": "conjur-openshift-follower-syslog-ng"
        },
        {
          "digest": "sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator@sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "name": "conjur-follower-operator"
        },
        {
          "digest": "sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "name": "conjur-openshift-follower-syslog-ng-7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c-annotation"
        },
        {
          "digest": "sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "name": "conjur-openshift-follower-postgres-96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5-annotation"
        },
        {
          "digest": "sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "name": "conjur-openshift-follower-nginx-d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981-annotation"
        },
        {
          "digest": "sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "name": "conjur-openshift-follower-info-27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05-annotation"
        },
        {
          "digest": "sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "name": "conjur-openshift-follower-conjur-ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c-annotation"
        },
        {
          "digest": "sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "name": "conjur-openshift-follower-configurator-b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "2.0.2",
      "version_original": "2.0.2"
    },
    {
      "_id": "61b7bc4856779435db589dd4",
      "alm_examples": [
        {
          "kind": "ConjurFollower",
          "metadata": {
            "labels": {
              "app": "conjur-follower"
            },
            "name": "conjur-follower-operator-my-conjur-follower",
            "namespace": "conjur-follower-operator-system"
          },
          "spec": {
            "images": {
              "configurator": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
              "conjur": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
              "info": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
              "nginx": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
              "postgres": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
              "syslogNg": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c"
            },
            "master": {
              "account": "my-company",
              "authenticatorID": "conjur-openshift-follower",
              "authnLogin": "host/conjur-openshift-follower",
              "caCertificateFrom": {
                "configMapKeyRef": {
                  "key": "conjur.master-cert",
                  "name": "follower"
                }
              },
              "hostname": "conjur.my-company.net"
            },
            "replicas": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator-bundle@sha256:e3bc395543de733defc75270df2828fa8ba4cdf5c5cf79848a4640ee99a9fef7",
      "bundle_path_digest": "sha256:e3bc395543de733defc75270df2828fa8ba4cdf5c5cf79848a4640ee99a9fef7",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2021-12-13T21:34:00.170000+00:00",
      "csv_description": "Use this Operator for managing Conjur Followers in an OpenShift cluster.\n\nCyberArk products secure your most sensitive and high-value assets\u2014and supporting your Identity Security goals is our top priority. We offer 24/7 service for high priority issues to all customers with resources across ten countries and in all continents.\n\nCyberArk Conjur makes secrets management simple. Conjur provides a seamless open source interface to securely authenticate, control, and audit non-human access across tools, applications, containers, and cloud environments via robust secrets management.",
      "csv_display_name": "Conjur Enterprise Follower Operator",
      "csv_metadata_description": "",
      "csv_name": "conjur-follower-operator.v2.0.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T20:41:05.323000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "conjur-follower-operator",
      "provided_apis": [
        {
          "group": "conjur.cyberark.com",
          "kind": "ConjurFollower",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator@sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "name": "conjur-openshift-follower-operator"
        },
        {
          "digest": "sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "name": "conjur-openshift-follower-configurator"
        },
        {
          "digest": "sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "name": "conjur-openshift-follower-conjur"
        },
        {
          "digest": "sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "name": "conjur-openshift-follower-info"
        },
        {
          "digest": "sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "name": "conjur-openshift-follower-nginx"
        },
        {
          "digest": "sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "name": "conjur-openshift-follower-postgres"
        },
        {
          "digest": "sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "name": "conjur-openshift-follower-syslog-ng"
        },
        {
          "digest": "sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator@sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "name": "conjur-follower-operator"
        },
        {
          "digest": "sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "name": "conjur-openshift-follower-syslog-ng-7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c-annotation"
        },
        {
          "digest": "sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "name": "conjur-openshift-follower-postgres-96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5-annotation"
        },
        {
          "digest": "sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "name": "conjur-openshift-follower-nginx-d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981-annotation"
        },
        {
          "digest": "sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "name": "conjur-openshift-follower-info-27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05-annotation"
        },
        {
          "digest": "sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "name": "conjur-openshift-follower-conjur-ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c-annotation"
        },
        {
          "digest": "sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "name": "conjur-openshift-follower-configurator-b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2.0.2",
      "version_original": "2.0.2"
    },
    {
      "_id": "61b7bc4adda6c5fe6ba361e2",
      "alm_examples": [
        {
          "kind": "ConjurFollower",
          "metadata": {
            "labels": {
              "app": "conjur-follower"
            },
            "name": "conjur-follower-operator-my-conjur-follower",
            "namespace": "conjur-follower-operator-system"
          },
          "spec": {
            "images": {
              "configurator": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
              "conjur": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
              "info": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
              "nginx": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
              "postgres": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
              "syslogNg": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c"
            },
            "master": {
              "account": "my-company",
              "authenticatorID": "conjur-openshift-follower",
              "authnLogin": "host/conjur-openshift-follower",
              "caCertificateFrom": {
                "configMapKeyRef": {
                  "key": "conjur.master-cert",
                  "name": "follower"
                }
              },
              "hostname": "conjur.my-company.net"
            },
            "replicas": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator-bundle@sha256:e3bc395543de733defc75270df2828fa8ba4cdf5c5cf79848a4640ee99a9fef7",
      "bundle_path_digest": "sha256:e3bc395543de733defc75270df2828fa8ba4cdf5c5cf79848a4640ee99a9fef7",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "preview",
      "creation_date": "2021-12-13T21:34:02.821000+00:00",
      "csv_description": "Use this Operator for managing Conjur Followers in an OpenShift cluster.\n\nCyberArk products secure your most sensitive and high-value assets\u2014and supporting your Identity Security goals is our top priority. We offer 24/7 service for high priority issues to all customers with resources across ten countries and in all continents.\n\nCyberArk Conjur makes secrets management simple. Conjur provides a seamless open source interface to securely authenticate, control, and audit non-human access across tools, applications, containers, and cloud environments via robust secrets management.",
      "csv_display_name": "Conjur Enterprise Follower Operator",
      "csv_metadata_description": "",
      "csv_name": "conjur-follower-operator.v2.0.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-05T20:41:06.078000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "conjur-follower-operator",
      "provided_apis": [
        {
          "group": "conjur.cyberark.com",
          "kind": "ConjurFollower",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator@sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "name": "conjur-openshift-follower-operator"
        },
        {
          "digest": "sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "name": "conjur-openshift-follower-configurator"
        },
        {
          "digest": "sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "name": "conjur-openshift-follower-conjur"
        },
        {
          "digest": "sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "name": "conjur-openshift-follower-info"
        },
        {
          "digest": "sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "name": "conjur-openshift-follower-nginx"
        },
        {
          "digest": "sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "name": "conjur-openshift-follower-postgres"
        },
        {
          "digest": "sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "name": "conjur-openshift-follower-syslog-ng"
        },
        {
          "digest": "sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-operator@sha256:ba6d5751c8428a8749c7f0cda46aff3ac4f871c5127a1499b22dbd1988c7f63d",
          "name": "conjur-follower-operator"
        },
        {
          "digest": "sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-syslog-ng@sha256:7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c",
          "name": "conjur-openshift-follower-syslog-ng-7a51775bbea3185f5660c340e27813f97ac1a364d85dcc3fe62702926155840c-annotation"
        },
        {
          "digest": "sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-postgres@sha256:96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5",
          "name": "conjur-openshift-follower-postgres-96a96a3ee41a08105c37a6ad44efe0a245dae51f2112529fb5c1fda31a0897f5-annotation"
        },
        {
          "digest": "sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-nginx@sha256:d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981",
          "name": "conjur-openshift-follower-nginx-d2d23fffb9a867633622560fe99cfb0152607e7af46806bc1c0c636229914981-annotation"
        },
        {
          "digest": "sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-info@sha256:27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05",
          "name": "conjur-openshift-follower-info-27b5d09d78b87a032104f6b4e79f9dae8069607202f0e7af327f6d2ef958aa05-annotation"
        },
        {
          "digest": "sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-conjur@sha256:ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c",
          "name": "conjur-openshift-follower-conjur-ba4a079664b1ed1bae7f1cfb00145af150a23bd046c1606503382cb171131e6c-annotation"
        },
        {
          "digest": "sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "image": "registry.connect.redhat.com/cyberark/conjur-openshift-follower-configurator@sha256:b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21",
          "name": "conjur-openshift-follower-configurator-b4074231697be6e87b2cb0cb18dd89aa45fed314619ad102b261182eadb74c21-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2.0.2",
      "version_original": "2.0.2"
    },
    {
      "_id": "61b908222d8e211ba9baba39",
      "alm_examples": [
        {
          "kind": "AirgappedDeployment",
          "metadata": {
            "name": "airgappeddeployment"
          },
          "spec": {
            "airgapped": {
              "backup_deletion_frequency": "@daily",
              "backup_retention_period": 7
            },
            "allowed_domains": "*",
            "db_archive": {
              "frequency": "@monthly",
              "persistent_storage": {
                "storage#": "10G",
                "storage_class": "ibmc-file-bronze-gid"
              },
              "retention_age": 6
            },
            "env_type": "lite",
            "event_scheduler_frequency": "@hourly",
            "image_pull_secret": "bas-images-pull-secret",
            "kafka": {
              "storage#": "5G",
              "storage_class": "ibmc-block-bronze",
              "zookeeper_storage#": "5G",
              "zookeeper_storage_class": "ibmc-block-bronze"
            },
            "postgres": {
              "storage#": "10G",
              "storage_class": "ibmc-block-bronze"
            }
          }
        },
        {
          "kind": "AnalyticsProxy",
          "metadata": {
            "name": "analyticsproxy"
          },
          "spec": {
            "airgapped": {
              "backup_deletion_frequency": "@daily",
              "backup_retention_period": 7,
              "enabled": false
            },
            "allowed_domains": "*",
            "db_archive": {
              "frequency": "@monthly",
              "persistent_storage": {
                "storage#": "10G",
                "storage_class": "ibmc-file-bronze-gid"
              },
              "retention_age": 6
            },
            "env_type": "lite",
            "event_scheduler_frequency": "@hourly",
            "ibmproxyurl": "https://iaps.ibm.com",
            "image_pull_secret": "bas-images-pull-secret",
            "kafka": {
              "storage#": "5G",
              "storage_class": "ibmc-block-bronze",
              "zookeeper_storage#": "5G",
              "zookeeper_storage_class": "ibmc-block-bronze"
            },
            "postgres": {
              "storage#": "10G",
              "storage_class": "ibmc-block-bronze"
            }
          }
        },
        {
          "kind": "DeleteCluster",
          "metadata": {
            "name": "deletecluster"
          },
          "spec": {
            "image_pull_secret": "bas-images-pull-secret"
          }
        },
        {
          "kind": "FullDeployment",
          "metadata": {
            "name": "fulldeployment"
          },
          "spec": {
            "airgapped": {
              "backup_deletion_frequency": "@daily",
              "backup_retention_period": 7,
              "enabled": false
            },
            "allowed_domains": "*",
            "db_archive": {
              "frequency": "@monthly",
              "persistent_storage": {
                "storage#": "10G",
                "storage_class": "ibmc-file-bronze-gid"
              },
              "retention_age": 6
            },
            "env_type": "lite",
            "event_scheduler_frequency": "@hourly",
            "ibmproxyurl": "https://iaps.ibm.com",
            "image_pull_secret": "bas-images-pull-secret",
            "kafka": {
              "storage#": "5G",
              "storage_class": "ibmc-block-bronze",
              "zookeeper_storage#": "5G",
              "zookeeper_storage_class": "ibmc-block-bronze"
            },
            "postgres": {
              "storage#": "10G",
              "storage_class": "ibmc-block-bronze"
            },
            "prometheus_metrics": [],
            "prometheus_scheduler_frequency": "@daily"
          }
        },
        {
          "kind": "GenerateKey",
          "metadata": {
            "name": "bas-api-key"
          },
          "spec": {
            "image_pull_secret": "bas-images-pull-secret"
          }
        },
        {
          "kind": "StoreForwardMetric",
          "metadata": {
            "name": "storeforwardmetric"
          },
          "spec": {
            "db_archive": {
              "frequency": "@monthly",
              "persistent_storage": {
                "storage#": "10G",
                "storage_class": "ibmc-file-bronze-gid"
              },
              "retention_age": 6
            },
            "env_type": "lite",
            "event_scheduler_frequency": "@hourly",
            "ibmproxyurl": "https://iaps.ibm.com",
            "image_pull_secret": "bas-images-pull-secret",
            "postgres": {
              "storage#": "10G",
              "storage_class": "ibmc-block-bronze"
            },
            "prometheus_metrics": [],
            "prometheus_scheduler_frequency": "@daily"
          }
        },
        {
          "kind": "Dashboard",
          "metadata": {
            "name": "dashboard"
          },
          "spec": {
            "enable_test_api": true,
            "image_pull_secret": "bas-images-pull-secret"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm-edge/behavior-analytics-services-operator-bundle@sha256:1113bb05d4dae37249cbdea23dc0b72eac99bd33e7a6ad1d723e74d423c14be9",
      "bundle_path_digest": "sha256:1113bb05d4dae37249cbdea23dc0b72eac99bd33e7a6ad1d723e74d423c14be9",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2021-12-14T21:09:54.487000+00:00",
      "csv_description": "Behavior Analytics Services Operator is a service that collects, transforms and transmits product usage data.\nThe Operator supports deployments using-\nA. Dashboard\nB. Openshift portal or CLI\n\n**A. Dashboard**\n----\nWhen the Operator is installed, the Dashboard is installed too. Goto the Dashboard Custom Resource to get the URL to the Dashboard.\n\n\n**B. Openshift portal or CLI**\n----\n----\nFor manual installation using Openshift portal or CLI, follow the steps below\n\n\n**Pre-requisites**\n----\nStep 1: Create a new Project\n```sh\noc new-project <project-name>\n```\n\nStep 2: Create a secret named \"database-credentials\" for PostgreSQL DB\n```sh\n oc create secret generic database-credentials --from-literal=db_username=<DB Username> --from-literal=db_password=<DB Password> -n <project-name>\n```\n\nStep 3: [Optional] If the images require a secret to pull the container images, create a secret of type dockerconfigjson. Pass this secret name in the CR spec image\\_pull\\_secret\n```sh\noc create secret generic bas-images-pull-secret --from-file=.dockerconfigjson=<path/to/.docker/config.json>  --type=kubernetes.io/dockerconfigjson\n```\n\nStep 4: Create a secret named \"mtls-proxy-secret\" which has the client key and certificate to connect to IBM Proxy service. If you don't have certificates then refer link https://developers.cloudflare.com/access/service-auth/mtls-testing#generating-the-root-ca to create root and client certificates. Please ensure to share root certificate with edge@us.ibm.com to allow access to IBM proxy service using client certificate.\n```sh\noc create secret tls mtls-proxy-secret --key client-key.pem --cert client.pem\n```\n\n**Installing the Behavior Analytics Services**\n----\n\nSelect any one of the deployments to setup the Behavior Analytics Services\n1. Full Deployment\n2. Analytics Proxy Deployment\n3. Store and Forward metrics Deployment\n4. Airgapped Analytics Proxy Deployment\n\n| Spec                                                      | Description                                                      | Default Value          |\n| --------------------------------------------------------- | ------------------------------------------------------------ | ---------------------- |\n| `ibmproxyurl`                                               | URL of IBM Proxy Service                                     | `https://iaps.ibm.com`   |\n| `postgres.storage_class`                                    | Storage class of type ReadWriteOnce                          | Required user input        |\n| `postgres.size`                                             | Size (in G) of the storage to be attached to Database        | `10G`                    |\n| `kafka.storage_class`                                       | Storage class of type ReadWriteOnce                          | Required user input        |\n| `kafka.storage_size`                                        | Size (in G) of the storage to be attached to Kafka  | `5G`                     |\n| `kafka.zookeeper_storage_class`                                 | Storage class of type ReadWriteOnce                          | Required user input        |\n| `kafka.zookeeper_storage_size`                                 | Size (in G) of the storage to be attached to Zookeeper | `5G`                     |\n| `airgapped.enabled`                                         | Set value to \"true\" if airgapped setup is to be enabled otherwise keep the default value \"false\" | `false`                  |\n| `airgapped.backup_retention_period`   | Number of days to keep the backup files in the storage       | `7`                     |\n| `airgapped.backup_deletion_frequency` | Frequency of job to delete files from the storage. It accepts values in Cron format (https://en.wikipedia.org/wiki/Cron) | `@daily`                 |\n| `event_scheduler_frequency`                               | Frequency at which events will be forwarded to proxy in Cron format. In case if internet connection available on the cluster only during a certain time frame, specify time in UTC equivalent Cron format. | `@hourly`                |\n| `prometheus_scheduler_frequency`                          | Frequency in Cronjob format to pull metrics from Prometheus  | `@daily`                |\n| `image_pull_secret`                                       | Secret to pull container images from registry                | `bas-images-pull-secret` |\n| `db_archive.frequency`                                    | Frequency in Cronjob format to run archive job                                                           | `@monthly`             |\n| `db_archive.retention_age`                                | Number of months to retain the data in Database              | `6`                    |\n| `db_archive.persistent_storage.storage_class`             |Storage class of type ReadWriteMany         | Required user input    |\n| `db_archive.persistent_storage.storage_size`              | Size (in G) of the storage to be attached for saving airgapped files | `10G`                  |\n| `prometheus_metrics`                                      | Array of metrics information to be send to destination at desired frequency | []\n| `env_type`              | Type of environment. Can be **prod** (HA) or **lite** (non HA)   | `lite`                  |\n| `allowed_domains`                                         | Comma separated values of domains allowed by BAS. By default all domains are allowed | '*'\n\n\n**Generating the API Key**\n----\nOnce the deployment is complete, to use the Behavior Analytics Services Endpoints, generate an API key using the CR GenerateKey. This API key to be used to authenticate Behavior Analytics Services Endpoints.\n\nNote- Key can be retrieved from the secret with same name used while creating Generate Key CR's instance.\nOnce you get key from the secret, decode it using below command:\n```sh\necho -n <secret key> | base64 -d\n```\n\n**Deleting the API Key**\n----\nTo revoke the Key, delete the corresponding GenerateKey instance.\n\n**Using Behavior Analytics Services Endpoints**\n---\nFor all BAS APIs, use the Generated API Key for Authentication. Pass it as the Header- X-API-KEY and the key while using the APIs.\n",
      "csv_display_name": "Behavior Analytics Services",
      "csv_metadata_description": "Behavior Analytics Services is a service that collects, transforms and transmits product usage data.",
      "csv_name": "behavior-analytics-services-operator-certified.v1.1.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:16:42.814000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "behavior-analytics-services-operator-certified",
      "provided_apis": [
        {
          "group": "bas.ibm.com",
          "kind": "StoreForwardMetric",
          "plural": "storeforwardmetrics",
          "version": "v1"
        },
        {
          "group": "bas.ibm.com",
          "kind": "AirgappedDeployment",
          "plural": "airgappeddeployments",
          "version": "v1"
        },
        {
          "group": "bas.ibm.com",
          "kind": "AnalyticsProxy",
          "plural": "analyticsproxies",
          "version": "v1"
        },
        {
          "group": "bas.ibm.com",
          "kind": "Dashboard",
          "plural": "dashboards",
          "version": "v1"
        },
        {
          "group": "bas.ibm.com",
          "kind": "DeleteCluster",
          "plural": "deleteclusters",
          "version": "v1"
        },
        {
          "group": "bas.ibm.com",
          "kind": "FullDeployment",
          "plural": "fulldeployments",
          "version": "v1"
        },
        {
          "group": "bas.ibm.com",
          "kind": "GenerateKey",
          "plural": "generatekeys",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:609c19d1718947ee814b829334c37e1d720acf5fb642b0712b8ab1b14d57f53f",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:609c19d1718947ee814b829334c37e1d720acf5fb642b0712b8ab1b14d57f53f",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:c30a58a4f7a6457bf7da404ccde64f58f26162eeee0be9cc01ad517542027e2a",
          "image": "registry.connect.redhat.com/ibm-edge/behavior-analytics-services-operator@sha256:c30a58a4f7a6457bf7da404ccde64f58f26162eeee0be9cc01ad517542027e2a",
          "name": "behavior-analytics-services-operator"
        },
        {
          "digest": "sha256:8e0f1d33edf005eb2dfafed9b8367435b0f33ef4adf006bc75338f2a88e8942c",
          "image": "registry.redhat.io/openshift4/ose-cli@sha256:8e0f1d33edf005eb2dfafed9b8367435b0f33ef4adf006bc75338f2a88e8942c",
          "name": "dashboardinstaller"
        },
        {
          "digest": "sha256:b35f209bb491f88da6a9e6ca2b55675a4d0eeb69c4a369a07704cd9a9443a058",
          "image": "registry.connect.redhat.com/ibm-edge/event-api@sha256:b35f209bb491f88da6a9e6ca2b55675a4d0eeb69c4a369a07704cd9a9443a058",
          "name": "event_api"
        },
        {
          "digest": "sha256:a606caf41cb689bb3496d1e76312ebbbe531ab5df52d4d0813bd7763cc170da1",
          "image": "registry.connect.redhat.com/ibm-edge/store-api@sha256:a606caf41cb689bb3496d1e76312ebbbe531ab5df52d4d0813bd7763cc170da1",
          "name": "store_api"
        },
        {
          "digest": "sha256:0b5a7b02e4cb4baf0e08171fdd1d7d35a16bb82254ff2e245e051e483f6cd08c",
          "image": "registry.connect.redhat.com/ibm-edge/event-reader@sha256:0b5a7b02e4cb4baf0e08171fdd1d7d35a16bb82254ff2e245e051e483f6cd08c",
          "name": "reader"
        },
        {
          "digest": "sha256:caf7464165c82783ec83f0cffd1163cbfdffc4bad1f81def00dd3a25ae8a806c",
          "image": "registry.connect.redhat.com/ibm-edge/event-scheduler@sha256:caf7464165c82783ec83f0cffd1163cbfdffc4bad1f81def00dd3a25ae8a806c",
          "name": "event_scheduler"
        },
        {
          "digest": "sha256:08ba04c0c3a0966568538ac709f7bb243f7768c1f200c1a7c99e2761144a9a6b",
          "image": "registry.connect.redhat.com/ibm-edge/prometheus-scheduler@sha256:08ba04c0c3a0966568538ac709f7bb243f7768c1f200c1a7c99e2761144a9a6b",
          "name": "prometheus_scheduler"
        },
        {
          "digest": "sha256:90ddecb54abe2880b86016a407507cecf77a113b4c7724235ab0abd21ad1d9aa",
          "image": "registry.connect.redhat.com/ibm-edge/pgo-client@sha256:90ddecb54abe2880b86016a407507cecf77a113b4c7724235ab0abd21ad1d9aa",
          "name": "pgo_client"
        },
        {
          "digest": "sha256:815630d23e8d88664907fbf8096952adfd22593a4989063e9dd55549e674ee15",
          "image": "registry.connect.redhat.com/ibm-edge/reverse-proxy@sha256:815630d23e8d88664907fbf8096952adfd22593a4989063e9dd55549e674ee15",
          "name": "nginx"
        },
        {
          "digest": "sha256:a2e20cac50352c1ad13cd03185f326484ee20202c8a60313ba116920d6d6da88",
          "image": "registry.redhat.io/openshift4/ose-grafana@sha256:a2e20cac50352c1ad13cd03185f326484ee20202c8a60313ba116920d6d6da88",
          "name": "grafana"
        },
        {
          "digest": "sha256:c305e8a59ed5a6f100dd263c34743ad688c999c82cfdef76806d9e01b93834b6",
          "image": "registry.redhat.io/openshift3/ose-kube-rbac-proxy@sha256:c305e8a59ed5a6f100dd263c34743ad688c999c82cfdef76806d9e01b93834b6",
          "name": "ksm"
        },
        {
          "digest": "sha256:0c53b2cd52735491f15c39898c7d1347de6518a7cbff2c1bfc20623e29351361",
          "image": "registry.connect.redhat.com/ibm-edge/growth-stack-base@sha256:0c53b2cd52735491f15c39898c7d1347de6518a7cbff2c1bfc20623e29351361",
          "name": "init_container"
        },
        {
          "digest": "sha256:d748c21a55796827da82c61f162b505c59451cba24f1874e5185f21275b6bddc",
          "image": "registry.access.redhat.com/ubi8/ubi@sha256:d748c21a55796827da82c61f162b505c59451cba24f1874e5185f21275b6bddc",
          "name": "ubi"
        },
        {
          "digest": "sha256:19a8b33e2f4c2beee5266d5243abb7f43d85322fc62800899759cdf6ec568fee",
          "image": "registry.connect.redhat.com/ibm-edge/airgap-download-ui@sha256:19a8b33e2f4c2beee5266d5243abb7f43d85322fc62800899759cdf6ec568fee",
          "name": "download_ui"
        },
        {
          "digest": "sha256:d9034bf774c1cdf7933706eb76f274c57d1aeded7f59db747bfd9f0f2ac7581a",
          "image": "registry.connect.redhat.com/ibm-edge/bas-operator-dashboard@sha256:d9034bf774c1cdf7933706eb76f274c57d1aeded7f59db747bfd9f0f2ac7581a",
          "name": "dashboard_ui"
        },
        {
          "digest": "sha256:5e31ce8745926e0116827b1b658800dd3e8b91cd1800be4f9943a84a1c023f78",
          "image": "registry.redhat.io/openshift4/ose-oauth-proxy@sha256:5e31ce8745926e0116827b1b658800dd3e8b91cd1800be4f9943a84a1c023f78",
          "name": "oauth_proxy"
        },
        {
          "digest": "sha256:4c5f605669edc2125a6aea31c66c89cef524b57284eac302f35bbfa4680d1467",
          "image": "registry.connect.redhat.com/crunchydata/pgo-deployer@sha256:4c5f605669edc2125a6aea31c66c89cef524b57284eac302f35bbfa4680d1467",
          "name": "pgo_deployer"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "1.1.1",
      "version_original": "1.1.1"
    },
    {
      "_id": "61b914d02d8e211ba9babaa4",
      "alm_examples": [
        {
          "kind": "AirgappedDeployment",
          "metadata": {
            "name": "airgappeddeployment"
          },
          "spec": {
            "airgapped": {
              "backup_deletion_frequency": "@daily",
              "backup_retention_period": 7
            },
            "allowed_domains": "*",
            "db_archive": {
              "frequency": "@monthly",
              "persistent_storage": {
                "storage#": "10G",
                "storage_class": "ibmc-file-bronze-gid"
              },
              "retention_age": 6
            },
            "env_type": "lite",
            "event_scheduler_frequency": "@hourly",
            "image_pull_secret": "bas-images-pull-secret",
            "kafka": {
              "storage#": "5G",
              "storage_class": "ibmc-block-bronze",
              "zookeeper_storage#": "5G",
              "zookeeper_storage_class": "ibmc-block-bronze"
            },
            "postgres": {
              "storage#": "10G",
              "storage_class": "ibmc-block-bronze"
            }
          }
        },
        {
          "kind": "AnalyticsProxy",
          "metadata": {
            "name": "analyticsproxy"
          },
          "spec": {
            "airgapped": {
              "backup_deletion_frequency": "@daily",
              "backup_retention_period": 7,
              "enabled": false
            },
            "allowed_domains": "*",
            "db_archive": {
              "frequency": "@monthly",
              "persistent_storage": {
                "storage#": "10G",
                "storage_class": "ibmc-file-bronze-gid"
              },
              "retention_age": 6
            },
            "env_type": "lite",
            "event_scheduler_frequency": "@hourly",
            "ibmproxyurl": "https://iaps.ibm.com",
            "image_pull_secret": "bas-images-pull-secret",
            "kafka": {
              "storage#": "5G",
              "storage_class": "ibmc-block-bronze",
              "zookeeper_storage#": "5G",
              "zookeeper_storage_class": "ibmc-block-bronze"
            },
            "postgres": {
              "storage#": "10G",
              "storage_class": "ibmc-block-bronze"
            }
          }
        },
        {
          "kind": "DeleteCluster",
          "metadata": {
            "name": "deletecluster"
          },
          "spec": {
            "image_pull_secret": "bas-images-pull-secret"
          }
        },
        {
          "kind": "FullDeployment",
          "metadata": {
            "name": "fulldeployment"
          },
          "spec": {
            "airgapped": {
              "backup_deletion_frequency": "@daily",
              "backup_retention_period": 7,
              "enabled": false
            },
            "allowed_domains": "*",
            "db_archive": {
              "frequency": "@monthly",
              "persistent_storage": {
                "storage#": "10G",
                "storage_class": "ibmc-file-bronze-gid"
              },
              "retention_age": 6
            },
            "env_type": "lite",
            "event_scheduler_frequency": "@hourly",
            "ibmproxyurl": "https://iaps.ibm.com",
            "image_pull_secret": "bas-images-pull-secret",
            "kafka": {
              "storage#": "5G",
              "storage_class": "ibmc-block-bronze",
              "zookeeper_storage#": "5G",
              "zookeeper_storage_class": "ibmc-block-bronze"
            },
            "postgres": {
              "storage#": "10G",
              "storage_class": "ibmc-block-bronze"
            },
            "prometheus_metrics": [],
            "prometheus_scheduler_frequency": "@daily"
          }
        },
        {
          "kind": "GenerateKey",
          "metadata": {
            "name": "bas-api-key"
          },
          "spec": {
            "image_pull_secret": "bas-images-pull-secret"
          }
        },
        {
          "kind": "StoreForwardMetric",
          "metadata": {
            "name": "storeforwardmetric"
          },
          "spec": {
            "db_archive": {
              "frequency": "@monthly",
              "persistent_storage": {
                "storage#": "10G",
                "storage_class": "ibmc-file-bronze-gid"
              },
              "retention_age": 6
            },
            "env_type": "lite",
            "event_scheduler_frequency": "@hourly",
            "ibmproxyurl": "https://iaps.ibm.com",
            "image_pull_secret": "bas-images-pull-secret",
            "postgres": {
              "storage#": "10G",
              "storage_class": "ibmc-block-bronze"
            },
            "prometheus_metrics": [],
            "prometheus_scheduler_frequency": "@daily"
          }
        },
        {
          "kind": "Dashboard",
          "metadata": {
            "name": "dashboard"
          },
          "spec": {
            "enable_test_api": true,
            "image_pull_secret": "bas-images-pull-secret"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm-edge/behavior-analytics-services-operator-bundle@sha256:1113bb05d4dae37249cbdea23dc0b72eac99bd33e7a6ad1d723e74d423c14be9",
      "bundle_path_digest": "sha256:1113bb05d4dae37249cbdea23dc0b72eac99bd33e7a6ad1d723e74d423c14be9",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2021-12-14T22:04:00.510000+00:00",
      "csv_description": "Behavior Analytics Services Operator is a service that collects, transforms and transmits product usage data.\nThe Operator supports deployments using-\nA. Dashboard\nB. Openshift portal or CLI\n\n**A. Dashboard**\n----\nWhen the Operator is installed, the Dashboard is installed too. Goto the Dashboard Custom Resource to get the URL to the Dashboard.\n\n\n**B. Openshift portal or CLI**\n----\n----\nFor manual installation using Openshift portal or CLI, follow the steps below\n\n\n**Pre-requisites**\n----\nStep 1: Create a new Project\n```sh\noc new-project <project-name>\n```\n\nStep 2: Create a secret named \"database-credentials\" for PostgreSQL DB\n```sh\n oc create secret generic database-credentials --from-literal=db_username=<DB Username> --from-literal=db_password=<DB Password> -n <project-name>\n```\n\nStep 3: [Optional] If the images require a secret to pull the container images, create a secret of type dockerconfigjson. Pass this secret name in the CR spec image\\_pull\\_secret\n```sh\noc create secret generic bas-images-pull-secret --from-file=.dockerconfigjson=<path/to/.docker/config.json>  --type=kubernetes.io/dockerconfigjson\n```\n\nStep 4: Create a secret named \"mtls-proxy-secret\" which has the client key and certificate to connect to IBM Proxy service. If you don't have certificates then refer link https://developers.cloudflare.com/access/service-auth/mtls-testing#generating-the-root-ca to create root and client certificates. Please ensure to share root certificate with edge@us.ibm.com to allow access to IBM proxy service using client certificate.\n```sh\noc create secret tls mtls-proxy-secret --key client-key.pem --cert client.pem\n```\n\n**Installing the Behavior Analytics Services**\n----\n\nSelect any one of the deployments to setup the Behavior Analytics Services\n1. Full Deployment\n2. Analytics Proxy Deployment\n3. Store and Forward metrics Deployment\n4. Airgapped Analytics Proxy Deployment\n\n| Spec                                                      | Description                                                      | Default Value          |\n| --------------------------------------------------------- | ------------------------------------------------------------ | ---------------------- |\n| `ibmproxyurl`                                               | URL of IBM Proxy Service                                     | `https://iaps.ibm.com`   |\n| `postgres.storage_class`                                    | Storage class of type ReadWriteOnce                          | Required user input        |\n| `postgres.size`                                             | Size (in G) of the storage to be attached to Database        | `10G`                    |\n| `kafka.storage_class`                                       | Storage class of type ReadWriteOnce                          | Required user input        |\n| `kafka.storage_size`                                        | Size (in G) of the storage to be attached to Kafka  | `5G`                     |\n| `kafka.zookeeper_storage_class`                                 | Storage class of type ReadWriteOnce                          | Required user input        |\n| `kafka.zookeeper_storage_size`                                 | Size (in G) of the storage to be attached to Zookeeper | `5G`                     |\n| `airgapped.enabled`                                         | Set value to \"true\" if airgapped setup is to be enabled otherwise keep the default value \"false\" | `false`                  |\n| `airgapped.backup_retention_period`   | Number of days to keep the backup files in the storage       | `7`                     |\n| `airgapped.backup_deletion_frequency` | Frequency of job to delete files from the storage. It accepts values in Cron format (https://en.wikipedia.org/wiki/Cron) | `@daily`                 |\n| `event_scheduler_frequency`                               | Frequency at which events will be forwarded to proxy in Cron format. In case if internet connection available on the cluster only during a certain time frame, specify time in UTC equivalent Cron format. | `@hourly`                |\n| `prometheus_scheduler_frequency`                          | Frequency in Cronjob format to pull metrics from Prometheus  | `@daily`                |\n| `image_pull_secret`                                       | Secret to pull container images from registry                | `bas-images-pull-secret` |\n| `db_archive.frequency`                                    | Frequency in Cronjob format to run archive job                                                           | `@monthly`             |\n| `db_archive.retention_age`                                | Number of months to retain the data in Database              | `6`                    |\n| `db_archive.persistent_storage.storage_class`             |Storage class of type ReadWriteMany         | Required user input    |\n| `db_archive.persistent_storage.storage_size`              | Size (in G) of the storage to be attached for saving airgapped files | `10G`                  |\n| `prometheus_metrics`                                      | Array of metrics information to be send to destination at desired frequency | []\n| `env_type`              | Type of environment. Can be **prod** (HA) or **lite** (non HA)   | `lite`                  |\n| `allowed_domains`                                         | Comma separated values of domains allowed by BAS. By default all domains are allowed | '*'\n\n\n**Generating the API Key**\n----\nOnce the deployment is complete, to use the Behavior Analytics Services Endpoints, generate an API key using the CR GenerateKey. This API key to be used to authenticate Behavior Analytics Services Endpoints.\n\nNote- Key can be retrieved from the secret with same name used while creating Generate Key CR's instance.\nOnce you get key from the secret, decode it using below command:\n```sh\necho -n <secret key> | base64 -d\n```\n\n**Deleting the API Key**\n----\nTo revoke the Key, delete the corresponding GenerateKey instance.\n\n**Using Behavior Analytics Services Endpoints**\n---\nFor all BAS APIs, use the Generated API Key for Authentication. Pass it as the Header- X-API-KEY and the key while using the APIs.\n",
      "csv_display_name": "Behavior Analytics Services",
      "csv_metadata_description": "Behavior Analytics Services is a service that collects, transforms and transmits product usage data.",
      "csv_name": "behavior-analytics-services-operator-certified.v1.1.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T15:10:04.537000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "behavior-analytics-services-operator-certified",
      "provided_apis": [
        {
          "group": "bas.ibm.com",
          "kind": "AnalyticsProxy",
          "plural": "analyticsproxies",
          "version": "v1"
        },
        {
          "group": "bas.ibm.com",
          "kind": "Dashboard",
          "plural": "dashboards",
          "version": "v1"
        },
        {
          "group": "bas.ibm.com",
          "kind": "DeleteCluster",
          "plural": "deleteclusters",
          "version": "v1"
        },
        {
          "group": "bas.ibm.com",
          "kind": "FullDeployment",
          "plural": "fulldeployments",
          "version": "v1"
        },
        {
          "group": "bas.ibm.com",
          "kind": "GenerateKey",
          "plural": "generatekeys",
          "version": "v1"
        },
        {
          "group": "bas.ibm.com",
          "kind": "StoreForwardMetric",
          "plural": "storeforwardmetrics",
          "version": "v1"
        },
        {
          "group": "bas.ibm.com",
          "kind": "AirgappedDeployment",
          "plural": "airgappeddeployments",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:609c19d1718947ee814b829334c37e1d720acf5fb642b0712b8ab1b14d57f53f",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:609c19d1718947ee814b829334c37e1d720acf5fb642b0712b8ab1b14d57f53f",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:c30a58a4f7a6457bf7da404ccde64f58f26162eeee0be9cc01ad517542027e2a",
          "image": "registry.connect.redhat.com/ibm-edge/behavior-analytics-services-operator@sha256:c30a58a4f7a6457bf7da404ccde64f58f26162eeee0be9cc01ad517542027e2a",
          "name": "behavior-analytics-services-operator"
        },
        {
          "digest": "sha256:8e0f1d33edf005eb2dfafed9b8367435b0f33ef4adf006bc75338f2a88e8942c",
          "image": "registry.redhat.io/openshift4/ose-cli@sha256:8e0f1d33edf005eb2dfafed9b8367435b0f33ef4adf006bc75338f2a88e8942c",
          "name": "dashboardinstaller"
        },
        {
          "digest": "sha256:b35f209bb491f88da6a9e6ca2b55675a4d0eeb69c4a369a07704cd9a9443a058",
          "image": "registry.connect.redhat.com/ibm-edge/event-api@sha256:b35f209bb491f88da6a9e6ca2b55675a4d0eeb69c4a369a07704cd9a9443a058",
          "name": "event_api"
        },
        {
          "digest": "sha256:a606caf41cb689bb3496d1e76312ebbbe531ab5df52d4d0813bd7763cc170da1",
          "image": "registry.connect.redhat.com/ibm-edge/store-api@sha256:a606caf41cb689bb3496d1e76312ebbbe531ab5df52d4d0813bd7763cc170da1",
          "name": "store_api"
        },
        {
          "digest": "sha256:0b5a7b02e4cb4baf0e08171fdd1d7d35a16bb82254ff2e245e051e483f6cd08c",
          "image": "registry.connect.redhat.com/ibm-edge/event-reader@sha256:0b5a7b02e4cb4baf0e08171fdd1d7d35a16bb82254ff2e245e051e483f6cd08c",
          "name": "reader"
        },
        {
          "digest": "sha256:caf7464165c82783ec83f0cffd1163cbfdffc4bad1f81def00dd3a25ae8a806c",
          "image": "registry.connect.redhat.com/ibm-edge/event-scheduler@sha256:caf7464165c82783ec83f0cffd1163cbfdffc4bad1f81def00dd3a25ae8a806c",
          "name": "event_scheduler"
        },
        {
          "digest": "sha256:08ba04c0c3a0966568538ac709f7bb243f7768c1f200c1a7c99e2761144a9a6b",
          "image": "registry.connect.redhat.com/ibm-edge/prometheus-scheduler@sha256:08ba04c0c3a0966568538ac709f7bb243f7768c1f200c1a7c99e2761144a9a6b",
          "name": "prometheus_scheduler"
        },
        {
          "digest": "sha256:90ddecb54abe2880b86016a407507cecf77a113b4c7724235ab0abd21ad1d9aa",
          "image": "registry.connect.redhat.com/ibm-edge/pgo-client@sha256:90ddecb54abe2880b86016a407507cecf77a113b4c7724235ab0abd21ad1d9aa",
          "name": "pgo_client"
        },
        {
          "digest": "sha256:815630d23e8d88664907fbf8096952adfd22593a4989063e9dd55549e674ee15",
          "image": "registry.connect.redhat.com/ibm-edge/reverse-proxy@sha256:815630d23e8d88664907fbf8096952adfd22593a4989063e9dd55549e674ee15",
          "name": "nginx"
        },
        {
          "digest": "sha256:a2e20cac50352c1ad13cd03185f326484ee20202c8a60313ba116920d6d6da88",
          "image": "registry.redhat.io/openshift4/ose-grafana@sha256:a2e20cac50352c1ad13cd03185f326484ee20202c8a60313ba116920d6d6da88",
          "name": "grafana"
        },
        {
          "digest": "sha256:c305e8a59ed5a6f100dd263c34743ad688c999c82cfdef76806d9e01b93834b6",
          "image": "registry.redhat.io/openshift3/ose-kube-rbac-proxy@sha256:c305e8a59ed5a6f100dd263c34743ad688c999c82cfdef76806d9e01b93834b6",
          "name": "ksm"
        },
        {
          "digest": "sha256:0c53b2cd52735491f15c39898c7d1347de6518a7cbff2c1bfc20623e29351361",
          "image": "registry.connect.redhat.com/ibm-edge/growth-stack-base@sha256:0c53b2cd52735491f15c39898c7d1347de6518a7cbff2c1bfc20623e29351361",
          "name": "init_container"
        },
        {
          "digest": "sha256:d748c21a55796827da82c61f162b505c59451cba24f1874e5185f21275b6bddc",
          "image": "registry.access.redhat.com/ubi8/ubi@sha256:d748c21a55796827da82c61f162b505c59451cba24f1874e5185f21275b6bddc",
          "name": "ubi"
        },
        {
          "digest": "sha256:19a8b33e2f4c2beee5266d5243abb7f43d85322fc62800899759cdf6ec568fee",
          "image": "registry.connect.redhat.com/ibm-edge/airgap-download-ui@sha256:19a8b33e2f4c2beee5266d5243abb7f43d85322fc62800899759cdf6ec568fee",
          "name": "download_ui"
        },
        {
          "digest": "sha256:d9034bf774c1cdf7933706eb76f274c57d1aeded7f59db747bfd9f0f2ac7581a",
          "image": "registry.connect.redhat.com/ibm-edge/bas-operator-dashboard@sha256:d9034bf774c1cdf7933706eb76f274c57d1aeded7f59db747bfd9f0f2ac7581a",
          "name": "dashboard_ui"
        },
        {
          "digest": "sha256:5e31ce8745926e0116827b1b658800dd3e8b91cd1800be4f9943a84a1c023f78",
          "image": "registry.redhat.io/openshift4/ose-oauth-proxy@sha256:5e31ce8745926e0116827b1b658800dd3e8b91cd1800be4f9943a84a1c023f78",
          "name": "oauth_proxy"
        },
        {
          "digest": "sha256:4c5f605669edc2125a6aea31c66c89cef524b57284eac302f35bbfa4680d1467",
          "image": "registry.connect.redhat.com/crunchydata/pgo-deployer@sha256:4c5f605669edc2125a6aea31c66c89cef524b57284eac302f35bbfa4680d1467",
          "name": "pgo_deployer"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "1.1.1",
      "version_original": "1.1.1"
    },
    {
      "_id": "61d324ce8093b97ef52e1b3c",
      "alm_examples": [
        {
          "kind": "Neuvector",
          "metadata": {
            "name": "neuvector"
          },
          "spec": {
            "admissionwebhook": {
              "type": "ClusterIP"
            },
            "bottlerocket": {
              "enabled": false,
              "runtimePath": "/run/dockershim.sock"
            },
            "containerd": {
              "enabled": false,
              "path": "/var/run/containerd/containerd.sock"
            },
            "controller": {
              "affinity": {
                "podAntiAffinity": {
                  "preferredDuringSchedulingIgnoredDuringExecution": [
                    {
                      "podAffinityTerm": {
                        "labelSelector": {
                          "matchExpressions": [
                            {
                              "key": "app",
                              "operator": "In",
                              "values": [
                                "neuvector-controller-pod"
                              ]
                            }
                          ]
                        },
                        "topologyKey": "kubernetes.io/hostname"
                      },
                      "weight": 100
                    }
                  ]
                }
              },
              "apisvc": {
                "annotations": {},
                "route": {
                  "enabled": false,
                  "host": "",
                  "termination": "passthrough"
                },
                "type": ""
              },
              "azureFileShare": {
                "enabled": false,
                "secretName": "",
                "shareName": ""
              },
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "configmap": {
                "data": "",
                "enabled": false
              },
              "disruptionbudget": 0,
              "enabled": true,
              "env": [],
              "federation": {
                "managedsvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                },
                "mastersvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                }
              },
              "image": "registry.connect.redhat.com/neuvector/controller",
              "ingress": {
                "annotations": {
                  "ingress.kubernetes.io/protocol": "https"
                },
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "pvc": {
                "accessModes": [
                  "ReadWriteMany"
                ],
                "capacity": "",
                "enabled": false,
                "storageClass": ""
              },
              "replicas": 3,
              "resources": {},
              "schedulerName": "",
              "secret": {
                "data": {},
                "enabled": false
              },
              "strategy": {
                "rollingUpdate": {
                  "maxSurge": 1,
                  "maxUnavailable": 0
                },
                "type": "RollingUpdate"
              },
              "tolerations": []
            },
            "crdwebhook": {
              "enabled": true,
              "type": "ClusterIP"
            },
            "crio": {
              "enabled": true,
              "path": "/var/run/crio/crio.sock"
            },
            "cve": {
              "scanner": {
                "affinity": {},
                "dockerPath": "",
                "enabled": true,
                "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
                "nodeSelector": {},
                "priorityClassName": "",
                "replicas": 3,
                "resources": {},
                "strategy": {
                  "rollingUpdate": {
                    "maxSurge": 1,
                    "maxUnavailable": 0
                  },
                  "type": "RollingUpdate"
                },
                "tolerations": []
              },
              "updater": {
                "enabled": true,
                "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
                "priorityClassName": "",
                "schedule": "0 0 * * *",
                "secure": false
              }
            },
            "docker": {
              "enabled": false,
              "path": "/var/run/docker.sock"
            },
            "enforcer": {
              "enabled": true,
              "image": "registry.connect.redhat.com/neuvector/enforcer",
              "priorityClassName": "",
              "resources": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                }
              ]
            },
            "k3s": {
              "enabled": false,
              "runtimePath": "/run/k3s/containerd/containerd.sock"
            },
            "manager": {
              "affinity": {},
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "enabled": true,
              "env": {
                "ssl": true
              },
              "image": "registry.connect.redhat.com/neuvector/manager",
              "ingress": {
                "annotations": {},
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "resources": {},
              "route": {
                "enabled": true,
                "host": "",
                "termination": "passthrough"
              },
              "svc": {
                "annotations": {},
                "loadBalancerIP": "",
                "type": "NodePort"
              },
              "tolerations": []
            },
            "openshift": true,
            "psp": false,
            "resources": {},
            "serviceAccount": "default"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/neuvector/neuvector-operator-bundle@sha256:bb9a141e7420196baf0bfc456ae28d7d150f6b40de987b214d0833207fcc1a3e",
      "bundle_path_digest": "sha256:bb9a141e7420196baf0bfc456ae28d7d150f6b40de987b214d0833207fcc1a3e",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-01-03T16:31:10.004000+00:00",
      "csv_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.\n\nThe NeuVector Operator runs  in the openshift container platform to deploy and manage the NeuVector Security cluster components. The NeuVector operator contains all necessary information to deploy NeuVector using helm charts. You simply need to install the NeuVector operator from the OpenShift embeded operator hub and create NeuVector instance. You can modify the NeuVector installation configuration by modifying yaml while creating the NeuVector instance such as imagePullSecrets, tag version, etc. Please refer to [github link](https://github.com/neuvector/neuvector-helm/tree/master/charts/core) for the values that can be modifed during installation. To upgrade to a newer version of NeuVector, just reapply the NeuVector instance with desired tag , which in turn pulls the specified NeuVector image tags and upgrades as per upgrade plan configured on the helm chart.  NeuVector Operator versions are tied to NeuVector product versions. Version 1.3.2 of the NeuVector Certified Operator deploys version 4.4.2 of NeuVector.\n\n**Complete below steps to Grant Service Account Access to the Privileged SCC before installation.**\n\nCreate the NeuVector namespace\n\n         oc new-project  neuvector\nLogin as system:admin account\n\n         oc login -u system:admin\n\nGrant Service Account Access to the Privileged SCC\n\n         oc -n neuvector adm policy add-scc-to-user privileged -z default\n\nThe following info will be added in the Privileged SCC users:\n\n         - system:serviceaccount:neuvector:default\n\nIn OpenShift 4.6+ use the following to check:\n\n         oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide\n         system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/default\n\n\n**Add NeuVector license from NeuVector WebUI->setting**\n\n\n#Deploying the NeuVector Operator#\n\n\nPlease refer to the instructions [here](https://github.com/neuvector/neuvector-operator/blob/master/README.md)\n\n\n",
      "csv_display_name": "NeuVector Operator",
      "csv_metadata_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.",
      "csv_name": "neuvector-operator.v1.3.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:14:53.034000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "neuvector-certified-operator",
      "provided_apis": [
        {
          "group": "apm.neuvector.com",
          "kind": "Neuvector",
          "plural": "neuvectors",
          "version": "v1alpha1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "name": "neuvector-operator-a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0-annotation"
        },
        {
          "digest": "sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "name": "neuvector-operator"
        },
        {
          "digest": "sha256:ecc4814bf9e38d41898ae2354bbafd2f1ed7c6e5602bb30cb40486e67725395c",
          "image": "registry.connect.redhat.com/neuvector/controller@sha256:ecc4814bf9e38d41898ae2354bbafd2f1ed7c6e5602bb30cb40486e67725395c",
          "name": "controller"
        },
        {
          "digest": "sha256:4621d69ca47929eedcab2c9163fc9d73ede09e0cd14f2a14db495e610590f5c2",
          "image": "registry.connect.redhat.com/neuvector/enforcer@sha256:4621d69ca47929eedcab2c9163fc9d73ede09e0cd14f2a14db495e610590f5c2",
          "name": "enforcer"
        },
        {
          "digest": "sha256:b49ba8bba9aaf292603896d5d3b9e5328b23260dfd977c70e7f3e39460564679",
          "image": "registry.connect.redhat.com/neuvector/manager@sha256:b49ba8bba9aaf292603896d5d3b9e5328b23260dfd977c70e7f3e39460564679",
          "name": "manager"
        },
        {
          "digest": "sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "name": "scanner"
        },
        {
          "digest": "sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "name": "updater"
        },
        {
          "digest": "sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "name": "scanner-d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038-annotation"
        },
        {
          "digest": "sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "name": "ubi8-228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "1.3.2",
      "version_original": "1.3.2"
    },
    {
      "_id": "61d326278093b97ef52e1b3e",
      "alm_examples": [
        {
          "kind": "OpenshiftArtifactoryHa",
          "metadata": {
            "name": "openshiftartifactoryha"
          },
          "spec": {
            "artifactory-ha": {
              "artifactory": {
                "image": {
                  "registry": "registry.connect.redhat.com",
                  "repository": "jfrog/artifactory-pro",
                  "tag": "7.27.9-1"
                },
                "joinKey": "OVERRIDE",
                "masterKey": "OVERRIDE",
                "node": {
                  "replicaCount": 2,
                  "waitForPrimaryStartup": {
                    "enabled": false
                  }
                },
                "uid": "1000721030"
              },
              "database": {
                "driver": "OVERRIDE",
                "password": "OVERRIDE",
                "type": "OVERRIDE",
                "url": "OVERRIDE",
                "user": "OVERRIDE"
              },
              "databaseUpgradeReady": true,
              "initContainerImage": "registry.connect.redhat.com/jfrog/init@sha256:9522611104cf958cc4322ed2d5d6ec0e3ffd75c39780a816f6f30d248c66ec02",
              "nginx": {
                "gid": "1000720107",
                "http": {
                  "externalPort": 80,
                  "internalPort": 8080
                },
                "https": {
                  "externalPort": 443,
                  "internalPort": 8443
                },
                "image": {
                  "registry": "registry.redhat.io",
                  "repository": "rhel8/nginx-116",
                  "tag": "latest"
                },
                "service": {
                  "ssloffload": false
                },
                "tlsSecretName": "OVERRIDE",
                "uid": "1000720104"
              },
              "postgresql": {
                "enabled": false
              },
              "waitForDatabase": true
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/jfrog/artifactory-operator-bundle@sha256:7f0eac75c3ad62bff844979c3f7cf1bf8553caa2c28e38c59299979a452bfb28",
      "bundle_path_digest": "sha256:7f0eac75c3ad62bff844979c3f7cf1bf8553caa2c28e38c59299979a452bfb28",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-01-03T16:36:55.343000+00:00",
      "csv_description": " ## Breaking change\nPlease update to version 1.1.10 of the operator.\nVersion 1.1.8 and 1.1.9 have issues. Please skip these versions.\n\n## Overview\nOpenshift Operator to deploy JFrog Artifactory Enterprise into your Openshift cluster.\n## Security Context Constraints\nTo deploy this helm chart you will need to be a cluster admin w/ access to the anyuid scc and add the operator service account to the anyuid scc.\n```\noc adm policy add-scc-to-user anyuid -z artifactory-ha-operator -n openshift-operators\n```\nAdd the service account for the Artifactory chart to deploy successfully:\n``` oc adm policy add-scc-to-user anyuid -z openshiftartifactoryha-artifactory-ha -n artifactory ```\n### Usage\n\nAn external DB is required. The operator will not deploy a DB but will require you to specify the configuration values to connect to it.\n\nSearch for JFrog and click JFrog Artifactory Enterprise Operator to install.\n\nGo to the Installed Operators.\n\nWait for the JFrog Artifactory Enterprise Operator to complete the installation.\n\nOpen the Operator and click on the provided API: Artifactory HA.\n\nClick Create New Instance and provide the following parameters for your DB configuration:\n\n```\nDATABASE_TYPE\nDATABASE_DRIVER\nDATABASE_URL\nDATABASE_USER\nDATABASE_PASSWORD\n```\nMaster key and Join key must be supplied. To generate a new key for each run the command below:\n\n```\n# Create a key\nexport JOIN_KEY=$(openssl rand -hex 32)\necho ${JOIN_KEY}\n```\n\nTo use TLS you will need to first create a k8s tls secret to store your .crt and .key file into.\nThen supply the value of this k8s secret into the TLS_SECRET field.\n``` oc create secret tls my_tls_secret --cert=tls.crt --key=tls.key --namespace=my_namespace ```\nClick Create for Artifactory Enterprise to deploy into OpenShift and connect to it on the external IP exposed by the load balancer.\n### Create a route\nTo expose Artifactory from Openshift we recommend you create a new route in Openshift.\nYou can either use the oc command line tool or the Openshift web console to generate a new route.\nDepending upon where you terminate TLS you will need to either specify pass through or edge.\nCommand Line (Edge):\n``` oc create route edge --service=openshiftartifactory-ha --cert=tls.crt --key=tls.key --ca-cert=ca.crt --hostname=www.example.com ```\nOr for more information visit the official Openshift documentation on routes here:\nhttps://docs.openshift.com/container-platform/4.6/networking/routes/route-configuration.html\n\n",
      "csv_display_name": "JFrog Artifactory Enterprise Operator",
      "csv_metadata_description": "JFrog Artifactory Enterprise deploys Artifactory in a high availability environment across multiple pods",
      "csv_name": "artifactory-ha-operator.v1.1.21",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T10:55:17.666000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "openshiftartifactoryha-operator",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "OpenshiftArtifactoryHa",
          "plural": "openshiftartifactoryhas",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:7f06776ddcaffa1f4c3ca74b0d71f7fd11a6af5b0f2f42ade89a7f4ef4011296",
          "image": "registry.connect.redhat.com/jfrog/artifactory-pro@sha256:7f06776ddcaffa1f4c3ca74b0d71f7fd11a6af5b0f2f42ade89a7f4ef4011296",
          "name": "artifactory-pro"
        },
        {
          "digest": "sha256:65fbf73f8affdafa2b4122daa2515164a6cd7e43864eda7ed7f4357465269e3f",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:65fbf73f8affdafa2b4122daa2515164a6cd7e43864eda7ed7f4357465269e3f",
          "name": "artifactory-operator"
        },
        {
          "digest": "sha256:bce2fa53c4e5b913c707183f49ab9dcde9e601b22f9fb85b98ba56f2e163c1a8",
          "image": "registry.redhat.io/rhel8/nginx-116@sha256:bce2fa53c4e5b913c707183f49ab9dcde9e601b22f9fb85b98ba56f2e163c1a8",
          "name": "nginx"
        },
        {
          "digest": "sha256:65fbf73f8affdafa2b4122daa2515164a6cd7e43864eda7ed7f4357465269e3f",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:65fbf73f8affdafa2b4122daa2515164a6cd7e43864eda7ed7f4357465269e3f",
          "name": "artifactory-operator-65fbf73f8affdafa2b4122daa2515164a6cd7e43864eda7ed7f4357465269e3f-annotation"
        },
        {
          "digest": "sha256:65fbf73f8affdafa2b4122daa2515164a6cd7e43864eda7ed7f4357465269e3f",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:65fbf73f8affdafa2b4122daa2515164a6cd7e43864eda7ed7f4357465269e3f",
          "name": "artifactory-ha-operator"
        },
        {
          "digest": "sha256:7f06776ddcaffa1f4c3ca74b0d71f7fd11a6af5b0f2f42ade89a7f4ef4011296",
          "image": "registry.connect.redhat.com/jfrog/artifactory-pro@sha256:7f06776ddcaffa1f4c3ca74b0d71f7fd11a6af5b0f2f42ade89a7f4ef4011296",
          "name": "artifactory_image_repository"
        },
        {
          "digest": "sha256:bce2fa53c4e5b913c707183f49ab9dcde9e601b22f9fb85b98ba56f2e163c1a8",
          "image": "registry.redhat.io/rhel8/nginx-116@sha256:bce2fa53c4e5b913c707183f49ab9dcde9e601b22f9fb85b98ba56f2e163c1a8",
          "name": "nginx_image_repository"
        },
        {
          "digest": "sha256:9522611104cf958cc4322ed2d5d6ec0e3ffd75c39780a816f6f30d248c66ec02",
          "image": "registry.connect.redhat.com/jfrog/init@sha256:9522611104cf958cc4322ed2d5d6ec0e3ffd75c39780a816f6f30d248c66ec02",
          "name": "init-9522611104cf958cc4322ed2d5d6ec0e3ffd75c39780a816f6f30d248c66ec02-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.1.21",
      "version_original": "1.1.21"
    },
    {
      "_id": "61d3266417f914cd723308f9",
      "alm_examples": [
        {
          "kind": "Cloudcasa",
          "metadata": {
            "name": "cloudcasa"
          },
          "spec": {
            "cluster_id": ""
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/catalogicsoftware/cloudcasa-bundle@sha256:c66f5091446dc889a29da265c8c17c21181fe0fb5409eccd71fc4349c3bf0131",
      "bundle_path_digest": "sha256:c66f5091446dc889a29da265c8c17c21181fe0fb5409eccd71fc4349c3bf0131",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-01-03T16:37:56.130000+00:00",
      "csv_description": "CloudCasa is a powerful and easy-to-use data protection service for Kubernetes and cloud databases.  Configuration is quick and easy, and basic service is free. \n\n\n### How to Install \n* Create Namespace cloudcasa-operator. \n* Install the CloudCasa Operator by following the instructions presented when you click the Install button. Select **cloudcasa-operator** namespace. \n* After installing the operator, you will need to create an instance of the CloudCasa resource to configure the agent. \n* In order to create the CloudCasa resource you will need to generate a Cluster ID in CloudCasa.\n* Login to https://home.cloudcasa.io and add your OCP cluster under the Protection tab. Note the returned **Cluster ID**.\n* See the CloudCasa [Getting Started Guide](https://cloudcasa.io/get-started) for more information.\n* Navigate to the installed CloudCasa Operator and Click on the CloudCasa tab.\n* Create the CloudCasa resource and provide the **Cluster ID** noted in the previous step.\n\n\n### Supported Features\n\n* **AWS RDS Backup**\n\n* **Kubernetes cluster Backup** \n\n* **Kubernetes cluster restore**\n\n### Installation Checkpoints\n\n* **cloudcasa-io** namespace should be created.\n\n* **kubagent** pod should be created under **cloudcasa-io** namespace and should be in **running state.** \n\n* State of the OCP cluster on CloudCasa web UI should be **Active**.",
      "csv_display_name": "CloudCasa",
      "csv_metadata_description": "CloudCasa is a powerful and easy-to-use data protection service for Kubernetes and cloud databases.",
      "csv_name": "cloudcasa-operator.v2.2.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T10:55:50.605000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "cloudcasa-operator",
      "provided_apis": [
        {
          "group": "apps.cloudcasa.io",
          "kind": "Cloudcasa",
          "plural": "cloudcasas",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:86e5fa1fa294987114be200890c2e516501e424aee0fb98ece25c95e7716295b",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:86e5fa1fa294987114be200890c2e516501e424aee0fb98ece25c95e7716295b",
          "name": "ose-kube-rbac-proxy"
        },
        {
          "digest": "sha256:31a6966d48485c58b6d136ac9a31c670b273b6f95ed6b3b96a11dbd34570a9cf",
          "image": "registry.connect.redhat.com/catalogicsoftware/cloudcasa-operator@sha256:31a6966d48485c58b6d136ac9a31c670b273b6f95ed6b3b96a11dbd34570a9cf",
          "name": "cloudcasa-operator"
        },
        {
          "digest": "sha256:86e5fa1fa294987114be200890c2e516501e424aee0fb98ece25c95e7716295b",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:86e5fa1fa294987114be200890c2e516501e424aee0fb98ece25c95e7716295b",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:31a6966d48485c58b6d136ac9a31c670b273b6f95ed6b3b96a11dbd34570a9cf",
          "image": "registry.connect.redhat.com/catalogicsoftware/cloudcasa-operator@sha256:31a6966d48485c58b6d136ac9a31c670b273b6f95ed6b3b96a11dbd34570a9cf",
          "name": "cloudcasa-operator-31a6966d48485c58b6d136ac9a31c670b273b6f95ed6b3b96a11dbd34570a9cf-annotation"
        },
        {
          "digest": "sha256:31a6966d48485c58b6d136ac9a31c670b273b6f95ed6b3b96a11dbd34570a9cf",
          "image": "registry.connect.redhat.com/catalogicsoftware/cloudcasa-operator@sha256:31a6966d48485c58b6d136ac9a31c670b273b6f95ed6b3b96a11dbd34570a9cf",
          "name": "manager"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2.2.0",
      "version_original": "2.2.0"
    },
    {
      "_id": "61d326fc17f914cd723308fa",
      "alm_examples": [
        {
          "kind": "Neuvector",
          "metadata": {
            "name": "neuvector"
          },
          "spec": {
            "admissionwebhook": {
              "type": "ClusterIP"
            },
            "bottlerocket": {
              "enabled": false,
              "runtimePath": "/run/dockershim.sock"
            },
            "containerd": {
              "enabled": false,
              "path": "/var/run/containerd/containerd.sock"
            },
            "controller": {
              "affinity": {
                "podAntiAffinity": {
                  "preferredDuringSchedulingIgnoredDuringExecution": [
                    {
                      "podAffinityTerm": {
                        "labelSelector": {
                          "matchExpressions": [
                            {
                              "key": "app",
                              "operator": "In",
                              "values": [
                                "neuvector-controller-pod"
                              ]
                            }
                          ]
                        },
                        "topologyKey": "kubernetes.io/hostname"
                      },
                      "weight": 100
                    }
                  ]
                }
              },
              "apisvc": {
                "annotations": {},
                "route": {
                  "enabled": false,
                  "host": "",
                  "termination": "passthrough"
                },
                "type": ""
              },
              "azureFileShare": {
                "enabled": false,
                "secretName": "",
                "shareName": ""
              },
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "configmap": {
                "data": "",
                "enabled": false
              },
              "disruptionbudget": 0,
              "enabled": true,
              "env": [],
              "federation": {
                "managedsvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                },
                "mastersvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                }
              },
              "image": "registry.connect.redhat.com/neuvector/controller",
              "ingress": {
                "annotations": {
                  "ingress.kubernetes.io/protocol": "https"
                },
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "pvc": {
                "accessModes": [
                  "ReadWriteMany"
                ],
                "capacity": "",
                "enabled": false,
                "storageClass": ""
              },
              "replicas": 3,
              "resources": {},
              "schedulerName": "",
              "secret": {
                "data": {},
                "enabled": false
              },
              "strategy": {
                "rollingUpdate": {
                  "maxSurge": 1,
                  "maxUnavailable": 0
                },
                "type": "RollingUpdate"
              },
              "tolerations": []
            },
            "crdwebhook": {
              "enabled": true,
              "type": "ClusterIP"
            },
            "crio": {
              "enabled": true,
              "path": "/var/run/crio/crio.sock"
            },
            "cve": {
              "scanner": {
                "affinity": {},
                "dockerPath": "",
                "enabled": true,
                "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
                "nodeSelector": {},
                "priorityClassName": "",
                "replicas": 3,
                "resources": {},
                "strategy": {
                  "rollingUpdate": {
                    "maxSurge": 1,
                    "maxUnavailable": 0
                  },
                  "type": "RollingUpdate"
                },
                "tolerations": []
              },
              "updater": {
                "enabled": true,
                "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
                "priorityClassName": "",
                "schedule": "0 0 * * *",
                "secure": false
              }
            },
            "docker": {
              "enabled": false,
              "path": "/var/run/docker.sock"
            },
            "enforcer": {
              "enabled": true,
              "image": "registry.connect.redhat.com/neuvector/enforcer",
              "priorityClassName": "",
              "resources": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                }
              ]
            },
            "k3s": {
              "enabled": false,
              "runtimePath": "/run/k3s/containerd/containerd.sock"
            },
            "manager": {
              "affinity": {},
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "enabled": true,
              "env": {
                "ssl": true
              },
              "image": "registry.connect.redhat.com/neuvector/manager",
              "ingress": {
                "annotations": {},
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "resources": {},
              "route": {
                "enabled": true,
                "host": "",
                "termination": "passthrough"
              },
              "svc": {
                "annotations": {},
                "loadBalancerIP": "",
                "type": "NodePort"
              },
              "tolerations": []
            },
            "openshift": true,
            "psp": false,
            "resources": {},
            "serviceAccount": "default"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/neuvector/neuvector-operator-bundle@sha256:bb9a141e7420196baf0bfc456ae28d7d150f6b40de987b214d0833207fcc1a3e",
      "bundle_path_digest": "sha256:bb9a141e7420196baf0bfc456ae28d7d150f6b40de987b214d0833207fcc1a3e",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-01-03T16:40:28.234000+00:00",
      "csv_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.\n\nThe NeuVector Operator runs  in the openshift container platform to deploy and manage the NeuVector Security cluster components. The NeuVector operator contains all necessary information to deploy NeuVector using helm charts. You simply need to install the NeuVector operator from the OpenShift embeded operator hub and create NeuVector instance. You can modify the NeuVector installation configuration by modifying yaml while creating the NeuVector instance such as imagePullSecrets, tag version, etc. Please refer to [github link](https://github.com/neuvector/neuvector-helm/tree/master/charts/core) for the values that can be modifed during installation. To upgrade to a newer version of NeuVector, just reapply the NeuVector instance with desired tag , which in turn pulls the specified NeuVector image tags and upgrades as per upgrade plan configured on the helm chart.  NeuVector Operator versions are tied to NeuVector product versions. Version 1.3.2 of the NeuVector Certified Operator deploys version 4.4.2 of NeuVector.\n\n**Complete below steps to Grant Service Account Access to the Privileged SCC before installation.**\n\nCreate the NeuVector namespace\n\n         oc new-project  neuvector\nLogin as system:admin account\n\n         oc login -u system:admin\n\nGrant Service Account Access to the Privileged SCC\n\n         oc -n neuvector adm policy add-scc-to-user privileged -z default\n\nThe following info will be added in the Privileged SCC users:\n\n         - system:serviceaccount:neuvector:default\n\nIn OpenShift 4.6+ use the following to check:\n\n         oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide\n         system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/default\n\n\n**Add NeuVector license from NeuVector WebUI->setting**\n\n\n#Deploying the NeuVector Operator#\n\n\nPlease refer to the instructions [here](https://github.com/neuvector/neuvector-operator/blob/master/README.md)\n\n\n",
      "csv_display_name": "NeuVector Operator",
      "csv_metadata_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.",
      "csv_name": "neuvector-operator.v1.3.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:30:16.807000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "neuvector-certified-operator",
      "provided_apis": [
        {
          "group": "apm.neuvector.com",
          "kind": "Neuvector",
          "plural": "neuvectors",
          "version": "v1alpha1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "name": "neuvector-operator-a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0-annotation"
        },
        {
          "digest": "sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "name": "neuvector-operator"
        },
        {
          "digest": "sha256:ecc4814bf9e38d41898ae2354bbafd2f1ed7c6e5602bb30cb40486e67725395c",
          "image": "registry.connect.redhat.com/neuvector/controller@sha256:ecc4814bf9e38d41898ae2354bbafd2f1ed7c6e5602bb30cb40486e67725395c",
          "name": "controller"
        },
        {
          "digest": "sha256:4621d69ca47929eedcab2c9163fc9d73ede09e0cd14f2a14db495e610590f5c2",
          "image": "registry.connect.redhat.com/neuvector/enforcer@sha256:4621d69ca47929eedcab2c9163fc9d73ede09e0cd14f2a14db495e610590f5c2",
          "name": "enforcer"
        },
        {
          "digest": "sha256:b49ba8bba9aaf292603896d5d3b9e5328b23260dfd977c70e7f3e39460564679",
          "image": "registry.connect.redhat.com/neuvector/manager@sha256:b49ba8bba9aaf292603896d5d3b9e5328b23260dfd977c70e7f3e39460564679",
          "name": "manager"
        },
        {
          "digest": "sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "name": "scanner"
        },
        {
          "digest": "sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "name": "updater"
        },
        {
          "digest": "sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "name": "scanner-d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038-annotation"
        },
        {
          "digest": "sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "name": "ubi8-228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.3.2",
      "version_original": "1.3.2"
    },
    {
      "_id": "61d3270a8093b97ef52e1b40",
      "alm_examples": [
        {
          "kind": "OpenLibertyApplication",
          "metadata": {
            "name": "openliberty-app-sample"
          },
          "spec": {
            "applicationImage": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
            "expose": true,
            "replicas": 1
          }
        },
        {
          "kind": "OpenLibertyDump",
          "metadata": {
            "name": "openliberty-dump-sample"
          },
          "spec": {
            "include": [
              "thread",
              "heap"
            ],
            "podName": "Specify_Pod_Name_Here"
          }
        },
        {
          "kind": "OpenLibertyTrace",
          "metadata": {
            "name": "openliberty-trace-sample"
          },
          "spec": {
            "maxFileSize": 20,
            "maxFiles": 5,
            "podName": "Specify_Pod_Name_Here",
            "traceSpecification": "*=info:com.ibm.ws.webcontainer*=all"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/open-liberty-operator-bundle@sha256:88ff3cd847c4b606466b1e782cec0dfbdb62fb3dd0e4e1bc8b9c2d1016c74132",
      "bundle_path_digest": "sha256:88ff3cd847c4b606466b1e782cec0dfbdb62fb3dd0e4e1bc8b9c2d1016c74132",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "beta2",
      "creation_date": "2022-01-03T16:40:42.169000+00:00",
      "csv_description": "This advanced Operator can be used to deploy and manage Open Liberty applications with consistent, production-grade QoS. This operator is based on the [Runtime Component Operator](https://github.com/application-stacks/runtime-component-operator) and provides all of its capabilities in addition to Open Liberty specific features such as gathering traces and dumps (Day-2 operations) and easily configuring and managing the single sign-on information for your Open Liberty applications.\n\nOpen Liberty Operator enables enterprise architects to govern the way their applications get deployed & managed in the cluster, while dramatically reducing the learning curve for developers to deploy into Kubernetes - allowing them to focus on writing the code! Here are some key features:\n\n#### Application Lifecyle\nYou can deploy your Open Liberty application container by either pointing to a container image, or an OpenShift ImageStream. When using an ImageStream the Operator will watch for any updates and will re-deploy the modified image.\n\n#### Custom RBAC\nThis Operator is capable of using a custom ServiceAccount from the caller, allowing it to follow RBAC restrictions. By default it creates a ServiceAccount if one is not specified, which can also be bound with specific roles.\n\n#### Environment Configuration\nYou can configure a variety of artifacts with your deployment, such as: labels, annotations, and environment variables from a ConfigMap, a Secret or a value.\n\n#### Routing\nExpose your application to external users via a single toggle to create a Route on OpenShift or an Ingress on other Kubernetes environments. Advanced configuration, such as TLS settings, are also easily enabled. Expiring Route certificates are re-issued.\n\n#### High Availability via Horizontal Pod Autoscaling\nRun multiple instances of your application for high availability. Either specify a static number of replicas or easily configure horizontal auto scaling to create (and delete) instances based on resource consumption.\n\n#### Persistence and advanced storage\nEnable persistence for your application by specifying simple requirements: just tell us the size of the storage and where you would like it to be mounted and We will create and manage that storage for you.\nThis toggles a StatefulSet resource instead of a Deployment resource, so your container can recover transactions and state upon a pod restart.\nWe offer an advanced mode where the user specifies a built-in PersistentVolumeClaim, allowing them to configure many details of the persistent volume, such as its storage class and access mode.\nYou can also easily configure and use a single storage for serviceability related Day-2 operations, such as gatherig server traces and dumps.\n\n#### Service Binding\nYour runtime components can expose services by a simple toggle. We take care of the heavy lifting such as creating kubernetes Secrets with information other services can use to bind. We also keep the bindable information synchronized, so your applications can dynamically reconnect to its required services without any intervention or interruption.\n\n#### Single Sign-On (SSO)\nOpen Liberty provides capabilities to delegate authentication to external providers. Your application users can log in using their existing social media credentials from providers such as Google, Facebook, LinkedIn, Twitter, GitHub, and any OpenID Connect (OIDC) or OAuth 2.0 clients. Open Liberty Operator allows to easily configure and manage the single sign-on information for your applications.\n\n#### Exposing metrics to Prometheus\nThe Open Liberty Operator exposes the runtime container's metrics via the [Prometheus Operator](https://operatorhub.io/operator/prometheus).\nUsers can pick between a basic mode, where they simply specify the label that Prometheus is watching to scrape the metrics from the container, or they can specify the full `ServiceMonitor` spec embedded into the OpenLibertyApplication's `spec.monitoring` key controlling things like the poll internal and security credentials.\n\n#### Easily mount logs and transaction directories\nIf you need to mount the logs and transaction data from your application to an external volume such as NFS (or any storage supported in your cluster), simply add the following (customizing the folder location and size) to your OpenLibertyApplication CR:\n``` storage: size: 2Gi mountPath: \"/logs\" ```\n\n#### Integration with OpenShift Serverless\nDeploy your serverless runtime component using a single toggle.  The Operator will convert all of its generated resources into [Knative](https://knative.dev) resources, allowing your pod to automatically scale to 0 when it is idle.\n\n#### Integration with OpenShift's Topology UI\nWe set the corresponding labels to support OpenShift's Developer Topology UI, which allows you to visualize your entire set of deployments and how they are connected.\n\nSee our [**documentation**](https://github.com/OpenLiberty/open-liberty-operator/tree/main/doc/) for more information.\n",
      "csv_display_name": "Open Liberty",
      "csv_metadata_description": "Deploy and manage applications running on Liberty",
      "csv_name": "open-liberty-operator.v0.8.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:30:36.360000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "open-liberty-certified",
      "provided_apis": [
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyDump",
          "plural": "openlibertydumps",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyTrace",
          "plural": "openlibertytraces",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyApplication",
          "plural": "openlibertyapplications",
          "version": "v1beta2"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:43b3f004a19c91c80ba815aedc1b361b87cd12daa28bb215e6775e64ef890af1",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:43b3f004a19c91c80ba815aedc1b361b87cd12daa28bb215e6775e64ef890af1",
          "name": "open-liberty-operator-controller-43b3f004a19c91c80ba815aedc1b361b87cd12daa28bb215e6775e64ef890af1-annotation"
        },
        {
          "digest": "sha256:43b3f004a19c91c80ba815aedc1b361b87cd12daa28bb215e6775e64ef890af1",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:43b3f004a19c91c80ba815aedc1b361b87cd12daa28bb215e6775e64ef890af1",
          "name": "manager"
        },
        {
          "digest": "sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "image": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "name": "open-liberty-samples-8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4-annotation"
        }
      ],
      "skip_range": "<0.8.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "0.8.0",
      "version_original": "0.8.0"
    },
    {
      "_id": "61d32748c6d6ba37322fd9e7",
      "alm_examples": [
        {
          "kind": "CouchDBCluster",
          "metadata": {
            "name": "example-couchdbcluster"
          },
          "spec": {
            "cpu": "1",
            "disk": "1Gi",
            "environment": {
              "adminPassword": "changeme",
              "search": true
            },
            "memory": "1Gi",
            "size": 3,
            "storageClass": ""
          }
        },
        {
          "kind": "FormationLock",
          "metadata": {
            "name": "example-formationlock"
          },
          "spec": {}
        },
        {
          "kind": "Recipe",
          "metadata": {
            "name": "example-recipe"
          },
          "spec": {}
        },
        {
          "kind": "RecipeTemplate",
          "metadata": {
            "name": "example-recipetemplate"
          },
          "spec": {}
        },
        {
          "kind": "Backup",
          "metadata": {
            "name": "example-backup"
          },
          "spec": {}
        },
        {
          "kind": "Bucket",
          "metadata": {
            "name": "example-bucket"
          },
          "spec": {}
        },
        {
          "kind": "Formation",
          "metadata": {
            "name": "example-formation"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [
        "amd64"
      ],
      "bundle_path": "registry.connect.redhat.com/ibm/couchdb-operator-certified-bundle@sha256:96a04fb99af74bc88406278004fbbdad4ae9b11189fd35347ebc86f065f8ae4b",
      "bundle_path_digest": "sha256:96a04fb99af74bc88406278004fbbdad4ae9b11189fd35347ebc86f065f8ae4b",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-01-03T16:41:44.377000+00:00",
      "csv_description": "Apache CouchDB lets you access your data where you need it. The [Couch Replication Protocol](http://docs.couchdb.org/en/master/replication/protocol.html) is implemented in a variety of projects and products that span every imaginable computing environment from globally distributed server-clusters, over mobile phones to web browsers.\n\nStore your data safely, on your own servers, or with any leading cloud provider. Your web- and native applications love CouchDB, because it speaks JSON natively and supports binary data for all your data storage needs.\n\nThe [Couch Replication Protocol](http://docs.couchdb.org/en/master/replication/protocol.html) lets your data flow seamlessly between server clusters to mobile phones and web browsers, enabling a compelling [offline-first](http://offlinefirst.org/) user-experience while maintaining high performance and strong reliability. CouchDB comes with a developer-friendly query language, and optionally MapReduce for simple, efficient, and comprehensive data retrieval.\n\n### Operator for Apache CouchDB Features\n* Fully automated deployment and configuration of Apache CouchDB clusters.\n* Support single, multiple, or all namespace install modes.\n\n#### Security\n* TLS - TLS  is supported using Red Hat Service certificates or user-provided certificates.\n* Authentication - The parameter `require_valid_user` defaults to `true`, which means that no requests are allowed from anonymous users. Every request must be authenticated.\n* Authorization - Databases are initially accessible by Apache CouchDB admins only.\n\n#### High Availability\n* Nodes - Each database node in an Apache CouchDB cluster requires its own Kubernetes node. It's recommended that you run it with a minimum of three nodes for any production deployment.\n* Zones - The Apache CouchDB cluster database nodes are spread across available Kubernetes fault zones where available.\n* Replicas - The default configuration for each database is two shards (Q=2) and three shard copies (N=3), where each shard copy is deployed on a separate node in the cluster.\n\n### Reading and writing to Apache CouchDB\n\nThe Operator for Apache CouchDB automatically generates a Service. This can be accessed using port-forwarding e.g. `kubectl port-forward svc/my-couchdb-cluster 443:443 -u admin:mypassword`. Alternatively, configure an OpenShift Route to expose the service externally.\n\n### CouchDB 2.3.1 Update Instructions\nWhen the operator is updated to v2.0 or above any existing CouchDB 2.3.1 cluster will not be automatically upgraded to CouchDB 3. The user must manually trigger this process by removing the version statement `version: 2.3.1` in the CouchDBCluster CR for each CouchDB cluster\nThe operator will then perform a rolling update, with the new pods running CouchDB3.\nIt is advised that customers do this straightaway as CouchDB 2.3.1 is no longer supported.\n\n[Read the complete guide to using the Operator for Apache CouchDB](https://ibm.biz/BdfGQy)\n",
      "csv_display_name": "Operator for Apache CouchDB",
      "csv_metadata_description": "Apache CouchDB is a highly available NOSQL database for web and mobile applications\n",
      "csv_name": "couchdb-operator.v2.2.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-05T10:56:12.939000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "couchdb-operator-certified",
      "provided_apis": [
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "Formation",
          "plural": "formations",
          "version": "v1"
        },
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "Recipe",
          "plural": "recipes",
          "version": "v1"
        },
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "RecipeTemplate",
          "plural": "recipetemplates",
          "version": "v1"
        },
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "Backup",
          "plural": "backups",
          "version": "v1"
        },
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "Bucket",
          "plural": "buckets",
          "version": "v1"
        },
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "CouchDBCluster",
          "plural": "couchdbclusters",
          "version": "v1"
        },
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "FormationLock",
          "plural": "formationlocks",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:6af02557f1f9e12ca4037be71804eb5dc4c53134b937278cb779e58b350afb53",
          "image": "registry.connect.redhat.com/ibm/couchdb3@sha256:6af02557f1f9e12ca4037be71804eb5dc4c53134b937278cb779e58b350afb53",
          "name": "COUCHDB3"
        },
        {
          "digest": "sha256:29c2509791ece532864c02ce3a429085afc197354308bded80de267ed2586fde",
          "image": "registry.connect.redhat.com/ibm/couchdb-operator-mgmt@sha256:29c2509791ece532864c02ce3a429085afc197354308bded80de267ed2586fde",
          "name": "COUCHDB-MGMT"
        },
        {
          "digest": "sha256:4c04bf6b3259fd8251744974dacdd427ef1ddfb1713c61ea673f14bc12906ce4",
          "image": "registry.connect.redhat.com/ibm/couchdb-operator@sha256:4c04bf6b3259fd8251744974dacdd427ef1ddfb1713c61ea673f14bc12906ce4",
          "name": "couchdb-operator-4c04bf6b3259fd8251744974dacdd427ef1ddfb1713c61ea673f14bc12906ce4-annotation"
        },
        {
          "digest": "sha256:4c04bf6b3259fd8251744974dacdd427ef1ddfb1713c61ea673f14bc12906ce4",
          "image": "registry.connect.redhat.com/ibm/couchdb-operator@sha256:4c04bf6b3259fd8251744974dacdd427ef1ddfb1713c61ea673f14bc12906ce4",
          "name": "couchdb-operator"
        },
        {
          "digest": "sha256:6af02557f1f9e12ca4037be71804eb5dc4c53134b937278cb779e58b350afb53",
          "image": "registry.connect.redhat.com/ibm/couchdb3@sha256:6af02557f1f9e12ca4037be71804eb5dc4c53134b937278cb779e58b350afb53",
          "name": "couchdb3"
        },
        {
          "digest": "sha256:29c2509791ece532864c02ce3a429085afc197354308bded80de267ed2586fde",
          "image": "registry.connect.redhat.com/ibm/couchdb-operator-mgmt@sha256:29c2509791ece532864c02ce3a429085afc197354308bded80de267ed2586fde",
          "name": "mgmt"
        }
      ],
      "skip_range": ">=1.0.0 <2.2.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2.2.0",
      "version_original": "2.2.0"
    },
    {
      "_id": "61d3274b17f914cd723308fb",
      "alm_examples": [
        {
          "kind": "CouchDBCluster",
          "metadata": {
            "name": "example-couchdbcluster"
          },
          "spec": {
            "cpu": "1",
            "disk": "1Gi",
            "environment": {
              "adminPassword": "changeme",
              "search": true
            },
            "memory": "1Gi",
            "size": 3,
            "storageClass": ""
          }
        },
        {
          "kind": "FormationLock",
          "metadata": {
            "name": "example-formationlock"
          },
          "spec": {}
        },
        {
          "kind": "Recipe",
          "metadata": {
            "name": "example-recipe"
          },
          "spec": {}
        },
        {
          "kind": "RecipeTemplate",
          "metadata": {
            "name": "example-recipetemplate"
          },
          "spec": {}
        },
        {
          "kind": "Backup",
          "metadata": {
            "name": "example-backup"
          },
          "spec": {}
        },
        {
          "kind": "Bucket",
          "metadata": {
            "name": "example-bucket"
          },
          "spec": {}
        },
        {
          "kind": "Formation",
          "metadata": {
            "name": "example-formation"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [
        "amd64"
      ],
      "bundle_path": "registry.connect.redhat.com/ibm/couchdb-operator-certified-bundle@sha256:96a04fb99af74bc88406278004fbbdad4ae9b11189fd35347ebc86f065f8ae4b",
      "bundle_path_digest": "sha256:96a04fb99af74bc88406278004fbbdad4ae9b11189fd35347ebc86f065f8ae4b",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "v2.2",
      "creation_date": "2022-01-03T16:41:47.540000+00:00",
      "csv_description": "Apache CouchDB lets you access your data where you need it. The [Couch Replication Protocol](http://docs.couchdb.org/en/master/replication/protocol.html) is implemented in a variety of projects and products that span every imaginable computing environment from globally distributed server-clusters, over mobile phones to web browsers.\n\nStore your data safely, on your own servers, or with any leading cloud provider. Your web- and native applications love CouchDB, because it speaks JSON natively and supports binary data for all your data storage needs.\n\nThe [Couch Replication Protocol](http://docs.couchdb.org/en/master/replication/protocol.html) lets your data flow seamlessly between server clusters to mobile phones and web browsers, enabling a compelling [offline-first](http://offlinefirst.org/) user-experience while maintaining high performance and strong reliability. CouchDB comes with a developer-friendly query language, and optionally MapReduce for simple, efficient, and comprehensive data retrieval.\n\n### Operator for Apache CouchDB Features\n* Fully automated deployment and configuration of Apache CouchDB clusters.\n* Support single, multiple, or all namespace install modes.\n\n#### Security\n* TLS - TLS  is supported using Red Hat Service certificates or user-provided certificates.\n* Authentication - The parameter `require_valid_user` defaults to `true`, which means that no requests are allowed from anonymous users. Every request must be authenticated.\n* Authorization - Databases are initially accessible by Apache CouchDB admins only.\n\n#### High Availability\n* Nodes - Each database node in an Apache CouchDB cluster requires its own Kubernetes node. It's recommended that you run it with a minimum of three nodes for any production deployment.\n* Zones - The Apache CouchDB cluster database nodes are spread across available Kubernetes fault zones where available.\n* Replicas - The default configuration for each database is two shards (Q=2) and three shard copies (N=3), where each shard copy is deployed on a separate node in the cluster.\n\n### Reading and writing to Apache CouchDB\n\nThe Operator for Apache CouchDB automatically generates a Service. This can be accessed using port-forwarding e.g. `kubectl port-forward svc/my-couchdb-cluster 443:443 -u admin:mypassword`. Alternatively, configure an OpenShift Route to expose the service externally.\n\n### CouchDB 2.3.1 Update Instructions\nWhen the operator is updated to v2.0 or above any existing CouchDB 2.3.1 cluster will not be automatically upgraded to CouchDB 3. The user must manually trigger this process by removing the version statement `version: 2.3.1` in the CouchDBCluster CR for each CouchDB cluster\nThe operator will then perform a rolling update, with the new pods running CouchDB3.\nIt is advised that customers do this straightaway as CouchDB 2.3.1 is no longer supported.\n\n[Read the complete guide to using the Operator for Apache CouchDB](https://ibm.biz/BdfGQy)\n",
      "csv_display_name": "Operator for Apache CouchDB",
      "csv_metadata_description": "Apache CouchDB is a highly available NOSQL database for web and mobile applications\n",
      "csv_name": "couchdb-operator.v2.2.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T10:56:15.875000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "couchdb-operator-certified",
      "provided_apis": [
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "Formation",
          "plural": "formations",
          "version": "v1"
        },
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "Recipe",
          "plural": "recipes",
          "version": "v1"
        },
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "RecipeTemplate",
          "plural": "recipetemplates",
          "version": "v1"
        },
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "Backup",
          "plural": "backups",
          "version": "v1"
        },
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "Bucket",
          "plural": "buckets",
          "version": "v1"
        },
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "CouchDBCluster",
          "plural": "couchdbclusters",
          "version": "v1"
        },
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "FormationLock",
          "plural": "formationlocks",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:6af02557f1f9e12ca4037be71804eb5dc4c53134b937278cb779e58b350afb53",
          "image": "registry.connect.redhat.com/ibm/couchdb3@sha256:6af02557f1f9e12ca4037be71804eb5dc4c53134b937278cb779e58b350afb53",
          "name": "COUCHDB3"
        },
        {
          "digest": "sha256:29c2509791ece532864c02ce3a429085afc197354308bded80de267ed2586fde",
          "image": "registry.connect.redhat.com/ibm/couchdb-operator-mgmt@sha256:29c2509791ece532864c02ce3a429085afc197354308bded80de267ed2586fde",
          "name": "COUCHDB-MGMT"
        },
        {
          "digest": "sha256:4c04bf6b3259fd8251744974dacdd427ef1ddfb1713c61ea673f14bc12906ce4",
          "image": "registry.connect.redhat.com/ibm/couchdb-operator@sha256:4c04bf6b3259fd8251744974dacdd427ef1ddfb1713c61ea673f14bc12906ce4",
          "name": "couchdb-operator-4c04bf6b3259fd8251744974dacdd427ef1ddfb1713c61ea673f14bc12906ce4-annotation"
        },
        {
          "digest": "sha256:4c04bf6b3259fd8251744974dacdd427ef1ddfb1713c61ea673f14bc12906ce4",
          "image": "registry.connect.redhat.com/ibm/couchdb-operator@sha256:4c04bf6b3259fd8251744974dacdd427ef1ddfb1713c61ea673f14bc12906ce4",
          "name": "couchdb-operator"
        },
        {
          "digest": "sha256:6af02557f1f9e12ca4037be71804eb5dc4c53134b937278cb779e58b350afb53",
          "image": "registry.connect.redhat.com/ibm/couchdb3@sha256:6af02557f1f9e12ca4037be71804eb5dc4c53134b937278cb779e58b350afb53",
          "name": "couchdb3"
        },
        {
          "digest": "sha256:29c2509791ece532864c02ce3a429085afc197354308bded80de267ed2586fde",
          "image": "registry.connect.redhat.com/ibm/couchdb-operator-mgmt@sha256:29c2509791ece532864c02ce3a429085afc197354308bded80de267ed2586fde",
          "name": "mgmt"
        }
      ],
      "skip_range": ">=1.0.0 <2.2.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2.2.0",
      "version_original": "2.2.0"
    },
    {
      "_id": "61d328b1c6d6ba37322fd9e8",
      "alm_examples": [
        {
          "kind": "SymphonyCluster",
          "metadata": {
            "name": "symcluster"
          },
          "spec": {
            "client": [
              {
                "build": {
                  "git": {
                    "branch": "master",
                    "path": "samples/sampleapp_cpp",
                    "repository": "https://github.com/IBM/ibm-spectrum-symphony-operator.git"
                  },
                  "image": "registry.connect.redhat.com/ibm/spectrum-symphony@sha256:d6860f11eea6024e51134e58bc1968c41d797bd9555c4e0283224c52ccf17774",
                  "resources": {
                    "limits": {
                      "cpu": "500m",
                      "memory": "2Gi"
                    },
                    "requests": {
                      "cpu": "500m",
                      "memory": "2Gi"
                    }
                  },
                  "serviceAccountName": "builder"
                },
                "image": "",
                "imagePullPolicy": "Always",
                "name": "SampleAppCPP1",
                "resources": {
                  "limits": {
                    "cpu": "250m",
                    "memory": "1Gi"
                  },
                  "requests": {
                    "cpu": "250m",
                    "memory": "1Gi"
                  }
                },
                "serviceAccountName": ""
              }
            ],
            "cluster": {
              "adminPasswordSecretName": "",
              "cacheImages": true,
              "clusterName": "",
              "enableSharedSubdir": false,
              "entitlementSecretName": "",
              "logsOnShared": false,
              "scriptsSecretName": "",
              "storage": {
                "pvcName": "",
                "pvcSize": "1Gi",
                "selector": {
                  "label": "",
                  "value": ""
                },
                "storageClassName": ""
              },
              "usersPasswordsSecretName": ""
            },
            "compute": {
              "image": "registry.connect.redhat.com/ibm/spectrum-symphony@sha256:1722eae3debcab3354a17c019cb38dc15acb71c6fed33585f669c9caceefc877",
              "imagePullPolicy": "Always",
              "maxReplicas": 64,
              "minReplicas": 1,
              "replicaCount": 1,
              "resources": {
                "limits": {
                  "cpu": "250m",
                  "memory": "1Gi"
                },
                "requests": {
                  "cpu": "250m",
                  "memory": "1Gi"
                }
              },
              "targetCPUUtilizationPercentage": 70,
              "usePodAutoscaler": true
            },
            "licenceAccepted": true,
            "master": {
              "egoRestEnabled": false,
              "image": "registry.connect.redhat.com/ibm/spectrum-symphony@sha256:d6860f11eea6024e51134e58bc1968c41d797bd9555c4e0283224c52ccf17774",
              "imagePullPolicy": "Always",
              "replicaCount": 0,
              "resources": {
                "limits": {
                  "cpu": "1000m",
                  "memory": "4Gi"
                },
                "requests": {
                  "cpu": "1000m",
                  "memory": "4Gi"
                }
              },
              "symRestEnabled": false,
              "uiEnabled": true
            },
            "serviceAccountName": ""
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/spectrum-symphony-operator-bundle@sha256:64d375f9e471f8f9918f9257ecc4f80b8a31379c3e4495b38c9039a0bfe0b779",
      "bundle_path_digest": "sha256:64d375f9e471f8f9918f9257ecc4f80b8a31379c3e4495b38c9039a0bfe0b779",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-01-03T16:47:45.055000+00:00",
      "csv_description": "Creates IBM Spectrum Symphony Cluster",
      "csv_display_name": "IBM Spectrum Symphony Cluster",
      "csv_metadata_description": "IBM Spectrum Symphony cluster",
      "csv_name": "ibm-spectrum-symphony-operator.v1.1.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T10:57:51.208000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "ibm-spectrum-symphony-operator",
      "provided_apis": [
        {
          "group": "symphony.spectrumcomputing.ibm.com",
          "kind": "SymphonyCluster",
          "plural": "symphonyclusters",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:1e93089d93c0dc97b60f0425c62f42b2ecaa46ecd5b9a14c6a3e3c3b80f16d33",
          "image": "registry.connect.redhat.com/ibm/spectrum-symphony-operator@sha256:1e93089d93c0dc97b60f0425c62f42b2ecaa46ecd5b9a14c6a3e3c3b80f16d33",
          "name": "spectrum-symphony-operator-1e93089d93c0dc97b60f0425c62f42b2ecaa46ecd5b9a14c6a3e3c3b80f16d33-annotation"
        },
        {
          "digest": "sha256:1e93089d93c0dc97b60f0425c62f42b2ecaa46ecd5b9a14c6a3e3c3b80f16d33",
          "image": "registry.connect.redhat.com/ibm/spectrum-symphony-operator@sha256:1e93089d93c0dc97b60f0425c62f42b2ecaa46ecd5b9a14c6a3e3c3b80f16d33",
          "name": "manager"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:d6860f11eea6024e51134e58bc1968c41d797bd9555c4e0283224c52ccf17774",
          "image": "registry.connect.redhat.com/ibm/spectrum-symphony@sha256:d6860f11eea6024e51134e58bc1968c41d797bd9555c4e0283224c52ccf17774",
          "name": "spectrum-symphony-d6860f11eea6024e51134e58bc1968c41d797bd9555c4e0283224c52ccf17774-annotation"
        },
        {
          "digest": "sha256:1722eae3debcab3354a17c019cb38dc15acb71c6fed33585f669c9caceefc877",
          "image": "registry.connect.redhat.com/ibm/spectrum-symphony@sha256:1722eae3debcab3354a17c019cb38dc15acb71c6fed33585f669c9caceefc877",
          "name": "spectrum-symphony-1722eae3debcab3354a17c019cb38dc15acb71c6fed33585f669c9caceefc877-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.1.2",
      "version_original": "1.1.2"
    },
    {
      "_id": "61d328c78093b97ef52e1b42",
      "alm_examples": [
        {
          "kind": "InfoScaleCluster",
          "metadata": {
            "name": "infoscalecluster-dev"
          },
          "spec": {
            "clusterInfo": [
              {},
              {}
            ],
            "version": "8.0.1"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/veritas-technologies/infoscale-operator-bundle@sha256:69ba6ea88e09e1fdf823bf4b53fa8c9aa38cedf4f1bd332800ee2537ae7839cf",
      "bundle_path_digest": "sha256:69ba6ea88e09e1fdf823bf4b53fa8c9aa38cedf4f1bd332800ee2537ae7839cf",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-01-03T16:48:07.032000+00:00",
      "csv_description": "## InfoScale\u2122 SDS Operator\n\nInfoScale\u2122 SDS Operator manages the lifecycle of the InfoScale\u2122 cluster\n\n## Overview\n\n- Veritas InfoScale\u2122 delivers Infrastructure resiliency and persistent storage for your critical containerized applications for OpenShift\u00ae and Kubernetes Native deployments\n- Engineered to support stateful workloads generated for mission-critical containerized applications.\n\n---\n\n## Data Services & Benefits\n\n**1. Software-Defined Persistent Storage Volumes:** Enables customers to support multiple container application requirements leveraging existing SAN or DAS storage\n\n**2. CSI API Driver:** Facilitates static and dynamic provisioning for applications with RWX, RWO and ROX access modes\n\n**3. Life Cycle Management:** Enables automated deployment, configuration and upgrades of InfoScale Software-defined container images. Certified and Integrated with Red Hat OpenShift for a single-click deployment\n\n**4. Availability:** Provides scaling, mounting and/or movement of InfoScale persistent storage volumes on cluster nodes with minimal disruption\n\n**5. Data Integrity:** Prevents data corruption by allowing only the active cluster nodes to write to the volume. The I/O fencing feature recovers from cluster disruptions quickly by ensuring that application pods are moved to another node to continue normal operations\n\n**6. Point-in-Time Data Copies:** Create snapshots of Persistent Volumes for backup products, data analytics or forensic discovery and analysis\n\n**7. Disaster Recovery (DR) Tech Preview:** This DR feature provides the ability to test and validate disaster recovery capabilities by migrating Kubernetes cluster metadata and application components to peer cluster in case of a local or remote disaster\n\n---\n\n## Pre-requisites\n\n- [Please refer to pre-requisite section from official documentation](https://www.veritas.com/support/en_US/doc/151215298-151215302-0)\n\n\n## InfoScale Cluster custom resource\n\n```\nkind: InfoScaleCluster\nmetadata:\n  name:  < Infoscale Cluster Name >\n\nspec:\n  version: \"8.0.1\"\n\n  clusterInfo:\n  - nodeName: <Name of the first node>\n  ip:\n  - <Optional - First IP address of the first node >\n  - <Optional - Second IP address of the first node>\n  excludeDevice:\n  - <Optional - Device path of the disk on the node that you want to exclude from Infoscale disk group.>\n\n  - nodeName: <Name of the second node>\n  ip:\n  - <Optional - First IP address of the second node >\n  - <Optional - Second IP address of the second node>\n  excludeDevice:\n  - <Optional - Device path of the disk on the node that you want to exclude from Infoscale disk group.>\n\n  # You can add up to 16 nodes.\n\n  licenseServer: < Optional - License server name/IP address >\n  licensePort: < Optional - License port number >\n\n  customImageRegistry: < Optional \u2013 Registry for Infoscale Container images>\n\n```\n\n#### Note\n\nYou can specify up to 16 worker nodes in CR. Although cluster configuration is allowed even with one Network Interface Card,\nVeritas recommends a minimum of two physical links for performance and High Availability (HA). Number of links for each network link must be same on all\nnodes. Optionally, you can enter node level IP addresses. If IP addresses are not provided, IP addresses of OpenShift cluster nodes are used.\n",
      "csv_display_name": "InfoScale\u2122 SDS Operator",
      "csv_metadata_description": "InfoScale\u2122 SDS Operator manages the lifecycle of the InfoScale\u2122 cluster",
      "csv_name": "infoscale-operator.v8.0.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T10:58:02.723000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "infoscale-operator",
      "provided_apis": [
        {
          "group": "infoscale.veritas.com",
          "kind": "InfoScaleCluster",
          "plural": "infoscaleclusters",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:dbb7d15302dafe9bbde82bfe3fd9f3fa3cc014e18143ef22f5dd568b0c1ae132",
          "image": "registry.connect.redhat.com/veritas-technologies/infoscale-operator@sha256:dbb7d15302dafe9bbde82bfe3fd9f3fa3cc014e18143ef22f5dd568b0c1ae132",
          "name": "manager"
        },
        {
          "digest": "sha256:dbb7d15302dafe9bbde82bfe3fd9f3fa3cc014e18143ef22f5dd568b0c1ae132",
          "image": "registry.connect.redhat.com/veritas-technologies/infoscale-operator@sha256:dbb7d15302dafe9bbde82bfe3fd9f3fa3cc014e18143ef22f5dd568b0c1ae132",
          "name": "pre-manager"
        },
        {
          "digest": "sha256:dbb7d15302dafe9bbde82bfe3fd9f3fa3cc014e18143ef22f5dd568b0c1ae132",
          "image": "registry.connect.redhat.com/veritas-technologies/infoscale-operator@sha256:dbb7d15302dafe9bbde82bfe3fd9f3fa3cc014e18143ef22f5dd568b0c1ae132",
          "name": "infoscale-operator-dbb7d15302dafe9bbde82bfe3fd9f3fa3cc014e18143ef22f5dd568b0c1ae132-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "8.0.1",
      "version_original": "8.0.1"
    },
    {
      "_id": "61d328ca8093b97ef52e1b43",
      "alm_examples": [
        {
          "kind": "InfoScaleCluster",
          "metadata": {
            "name": "infoscalecluster-dev"
          },
          "spec": {
            "clusterInfo": [
              {},
              {}
            ],
            "version": "8.0.1"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/veritas-technologies/infoscale-operator-bundle@sha256:f05e531495fcf80fa65b325d0a74e00003bbfb4474f6e597c59fdda986f8153f",
      "bundle_path_digest": "sha256:f05e531495fcf80fa65b325d0a74e00003bbfb4474f6e597c59fdda986f8153f",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-01-03T16:48:10.023000+00:00",
      "csv_description": "## InfoScale\u2122 SDS Operator\n\nInfoScale\u2122 SDS Operator manages the lifecycle of the InfoScale\u2122 cluster\n\n## Overview\n\n- Veritas InfoScale\u2122 delivers Infrastructure resiliency and persistent storage for your critical containerized applications for OpenShift\u00ae and Kubernetes Native deployments\n- Engineered to support stateful workloads generated for mission-critical containerized applications.\n\n---\n\n## Data Services & Benefits\n\n**1. Software-Defined Persistent Storage Volumes:** Enables customers to support multiple container application requirements leveraging existing SAN or DAS storage\n\n**2. CSI API Driver:** Facilitates static and dynamic provisioning for applications with RWX, RWO and ROX access modes\n\n**3. Life Cycle Management:** Enables automated deployment, configuration and upgrades of InfoScale Software-defined container images. Certified and Integrated with Red Hat OpenShift for a single-click deployment\n\n**4. Availability:** Provides scaling, mounting and/or movement of InfoScale persistent storage volumes on cluster nodes with minimal disruption\n\n**5. Data Integrity:** Prevents data corruption by allowing only the active cluster nodes to write to the volume. The I/O fencing feature recovers from cluster disruptions quickly by ensuring that application pods are moved to another node to continue normal operations\n\n**6. Point-in-Time Data Copies:** Create snapshots of Persistent Volumes for backup products, data analytics or forensic discovery and analysis\n\n**7. Disaster Recovery (DR) Tech Preview:** This DR feature provides the ability to test and validate disaster recovery capabilities by migrating Kubernetes cluster metadata and application components to peer cluster in case of a local or remote disaster\n\n---\n\n## Pre-requisites\n\n- [Please refer to pre-requisite section from official documentation](https://www.veritas.com/support/en_US/doc/151215298-151215302-0)\n\n\n## InfoScale Cluster custom resource\n\n```\nkind: InfoScaleCluster\nmetadata:\n  name:  < Infoscale Cluster Name >\n\nspec:\n  version: \"8.0.1\"\n\n  clusterInfo:\n  - nodeName: <Name of the first node>\n  ip:\n  - <Optional - First IP address of the first node >\n  - <Optional - Second IP address of the first node>\n  excludeDevice:\n  - <Optional - Device path of the disk on the node that you want to exclude from Infoscale disk group.>\n\n  - nodeName: <Name of the second node>\n  ip:\n  - <Optional - First IP address of the second node >\n  - <Optional - Second IP address of the second node>\n  excludeDevice:\n  - <Optional - Device path of the disk on the node that you want to exclude from Infoscale disk group.>\n\n  # You can add up to 16 nodes.\n\n  licenseServer: < Optional - License server name/IP address >\n  licensePort: < Optional - License port number >\n\n  customImageRegistry: < Optional \u2013 Registry for Infoscale Container images>\n\n```\n\n#### Note\n\nYou can specify up to 16 worker nodes in CR. Although cluster configuration is allowed even with one Network Interface Card,\nVeritas recommends a minimum of two physical links for performance and High Availability (HA). Number of links for each network link must be same on all\nnodes. Optionally, you can enter node level IP addresses. If IP addresses are not provided, IP addresses of OpenShift cluster nodes are used.\n",
      "csv_display_name": "InfoScale\u2122 SDS Operator",
      "csv_metadata_description": "InfoScale\u2122 SDS Operator manages the lifecycle of the InfoScale\u2122 cluster",
      "csv_name": "infoscale-operator.v8.0.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T10:58:05.667000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "infoscale-operator",
      "provided_apis": [
        {
          "group": "infoscale.veritas.com",
          "kind": "InfoScaleCluster",
          "plural": "infoscaleclusters",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:dbb7d15302dafe9bbde82bfe3fd9f3fa3cc014e18143ef22f5dd568b0c1ae132",
          "image": "registry.connect.redhat.com/veritas-technologies/infoscale-operator@sha256:dbb7d15302dafe9bbde82bfe3fd9f3fa3cc014e18143ef22f5dd568b0c1ae132",
          "name": "manager"
        },
        {
          "digest": "sha256:dbb7d15302dafe9bbde82bfe3fd9f3fa3cc014e18143ef22f5dd568b0c1ae132",
          "image": "registry.connect.redhat.com/veritas-technologies/infoscale-operator@sha256:dbb7d15302dafe9bbde82bfe3fd9f3fa3cc014e18143ef22f5dd568b0c1ae132",
          "name": "pre-manager"
        },
        {
          "digest": "sha256:dbb7d15302dafe9bbde82bfe3fd9f3fa3cc014e18143ef22f5dd568b0c1ae132",
          "image": "registry.connect.redhat.com/veritas-technologies/infoscale-operator@sha256:dbb7d15302dafe9bbde82bfe3fd9f3fa3cc014e18143ef22f5dd568b0c1ae132",
          "name": "infoscale-operator-dbb7d15302dafe9bbde82bfe3fd9f3fa3cc014e18143ef22f5dd568b0c1ae132-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "8.0.2",
      "version_original": "8.0.2"
    },
    {
      "_id": "61d32a15d467cd4ec03ef495",
      "alm_examples": [
        {
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:acad9af174541d2b39a02a216dd462ee0d47d8dc3c9cb44371f0a6bbf1c83d3d",
      "bundle_path_digest": "sha256:acad9af174541d2b39a02a216dd462ee0d47d8dc3c9cb44371f0a6bbf1c83d3d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-01-03T16:53:41.773000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.4.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T10:58:54.450000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "name": "kubeturbo-operator-879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d-annotation"
        },
        {
          "digest": "sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:490db38c4cc1aa124f6ddd020f3ef6f8f1dfdf0913a25b2cfba9952dd2c0d6d5",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:490db38c4cc1aa124f6ddd020f3ef6f8f1dfdf0913a25b2cfba9952dd2c0d6d5",
          "name": "kubeturbo"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "8.4.1",
      "version_original": "8.4.1"
    },
    {
      "_id": "61d32b5617f914cd723308ff",
      "alm_examples": [
        {
          "kind": "Neuvector",
          "metadata": {
            "name": "neuvector"
          },
          "spec": {
            "admissionwebhook": {
              "type": "ClusterIP"
            },
            "bottlerocket": {
              "enabled": false,
              "runtimePath": "/run/dockershim.sock"
            },
            "containerd": {
              "enabled": false,
              "path": "/var/run/containerd/containerd.sock"
            },
            "controller": {
              "affinity": {
                "podAntiAffinity": {
                  "preferredDuringSchedulingIgnoredDuringExecution": [
                    {
                      "podAffinityTerm": {
                        "labelSelector": {
                          "matchExpressions": [
                            {
                              "key": "app",
                              "operator": "In",
                              "values": [
                                "neuvector-controller-pod"
                              ]
                            }
                          ]
                        },
                        "topologyKey": "kubernetes.io/hostname"
                      },
                      "weight": 100
                    }
                  ]
                }
              },
              "apisvc": {
                "annotations": {},
                "route": {
                  "enabled": false,
                  "host": "",
                  "termination": "passthrough"
                },
                "type": ""
              },
              "azureFileShare": {
                "enabled": false,
                "secretName": "",
                "shareName": ""
              },
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "configmap": {
                "data": "",
                "enabled": false
              },
              "disruptionbudget": 0,
              "enabled": true,
              "env": [],
              "federation": {
                "managedsvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                },
                "mastersvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                }
              },
              "image": "registry.connect.redhat.com/neuvector/controller",
              "ingress": {
                "annotations": {
                  "ingress.kubernetes.io/protocol": "https"
                },
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "pvc": {
                "accessModes": [
                  "ReadWriteMany"
                ],
                "capacity": "",
                "enabled": false,
                "storageClass": ""
              },
              "replicas": 3,
              "resources": {},
              "schedulerName": "",
              "secret": {
                "data": {},
                "enabled": false
              },
              "strategy": {
                "rollingUpdate": {
                  "maxSurge": 1,
                  "maxUnavailable": 0
                },
                "type": "RollingUpdate"
              },
              "tolerations": []
            },
            "crdwebhook": {
              "enabled": true,
              "type": "ClusterIP"
            },
            "crio": {
              "enabled": true,
              "path": "/var/run/crio/crio.sock"
            },
            "cve": {
              "scanner": {
                "affinity": {},
                "dockerPath": "",
                "enabled": true,
                "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
                "nodeSelector": {},
                "priorityClassName": "",
                "replicas": 3,
                "resources": {},
                "strategy": {
                  "rollingUpdate": {
                    "maxSurge": 1,
                    "maxUnavailable": 0
                  },
                  "type": "RollingUpdate"
                },
                "tolerations": []
              },
              "updater": {
                "enabled": true,
                "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
                "priorityClassName": "",
                "schedule": "0 0 * * *",
                "secure": false
              }
            },
            "docker": {
              "enabled": false,
              "path": "/var/run/docker.sock"
            },
            "enforcer": {
              "enabled": true,
              "image": "registry.connect.redhat.com/neuvector/enforcer",
              "priorityClassName": "",
              "resources": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                }
              ]
            },
            "k3s": {
              "enabled": false,
              "runtimePath": "/run/k3s/containerd/containerd.sock"
            },
            "manager": {
              "affinity": {},
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "enabled": true,
              "env": {
                "ssl": true
              },
              "image": "registry.connect.redhat.com/neuvector/manager",
              "ingress": {
                "annotations": {},
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "resources": {},
              "route": {
                "enabled": true,
                "host": "",
                "termination": "passthrough"
              },
              "svc": {
                "annotations": {},
                "loadBalancerIP": "",
                "type": "NodePort"
              },
              "tolerations": []
            },
            "openshift": true,
            "psp": false,
            "resources": {},
            "serviceAccount": "default"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/neuvector/neuvector-operator-bundle@sha256:bb9a141e7420196baf0bfc456ae28d7d150f6b40de987b214d0833207fcc1a3e",
      "bundle_path_digest": "sha256:bb9a141e7420196baf0bfc456ae28d7d150f6b40de987b214d0833207fcc1a3e",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-01-03T16:59:02.829000+00:00",
      "csv_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.\n\nThe NeuVector Operator runs  in the openshift container platform to deploy and manage the NeuVector Security cluster components. The NeuVector operator contains all necessary information to deploy NeuVector using helm charts. You simply need to install the NeuVector operator from the OpenShift embeded operator hub and create NeuVector instance. You can modify the NeuVector installation configuration by modifying yaml while creating the NeuVector instance such as imagePullSecrets, tag version, etc. Please refer to [github link](https://github.com/neuvector/neuvector-helm/tree/master/charts/core) for the values that can be modifed during installation. To upgrade to a newer version of NeuVector, just reapply the NeuVector instance with desired tag , which in turn pulls the specified NeuVector image tags and upgrades as per upgrade plan configured on the helm chart.  NeuVector Operator versions are tied to NeuVector product versions. Version 1.3.2 of the NeuVector Certified Operator deploys version 4.4.2 of NeuVector.\n\n**Complete below steps to Grant Service Account Access to the Privileged SCC before installation.**\n\nCreate the NeuVector namespace\n\n         oc new-project  neuvector\nLogin as system:admin account\n\n         oc login -u system:admin\n\nGrant Service Account Access to the Privileged SCC\n\n         oc -n neuvector adm policy add-scc-to-user privileged -z default\n\nThe following info will be added in the Privileged SCC users:\n\n         - system:serviceaccount:neuvector:default\n\nIn OpenShift 4.6+ use the following to check:\n\n         oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide\n         system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/default\n\n\n**Add NeuVector license from NeuVector WebUI->setting**\n\n\n#Deploying the NeuVector Operator#\n\n\nPlease refer to the instructions [here](https://github.com/neuvector/neuvector-operator/blob/master/README.md)\n\n\n",
      "csv_display_name": "NeuVector Operator",
      "csv_metadata_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.",
      "csv_name": "neuvector-operator.v1.3.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T10:59:43.404000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "neuvector-certified-operator",
      "provided_apis": [
        {
          "group": "apm.neuvector.com",
          "kind": "Neuvector",
          "plural": "neuvectors",
          "version": "v1alpha1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "name": "neuvector-operator-a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0-annotation"
        },
        {
          "digest": "sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "name": "neuvector-operator"
        },
        {
          "digest": "sha256:ecc4814bf9e38d41898ae2354bbafd2f1ed7c6e5602bb30cb40486e67725395c",
          "image": "registry.connect.redhat.com/neuvector/controller@sha256:ecc4814bf9e38d41898ae2354bbafd2f1ed7c6e5602bb30cb40486e67725395c",
          "name": "controller"
        },
        {
          "digest": "sha256:4621d69ca47929eedcab2c9163fc9d73ede09e0cd14f2a14db495e610590f5c2",
          "image": "registry.connect.redhat.com/neuvector/enforcer@sha256:4621d69ca47929eedcab2c9163fc9d73ede09e0cd14f2a14db495e610590f5c2",
          "name": "enforcer"
        },
        {
          "digest": "sha256:b49ba8bba9aaf292603896d5d3b9e5328b23260dfd977c70e7f3e39460564679",
          "image": "registry.connect.redhat.com/neuvector/manager@sha256:b49ba8bba9aaf292603896d5d3b9e5328b23260dfd977c70e7f3e39460564679",
          "name": "manager"
        },
        {
          "digest": "sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "name": "scanner"
        },
        {
          "digest": "sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "name": "updater"
        },
        {
          "digest": "sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "name": "scanner-d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038-annotation"
        },
        {
          "digest": "sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "name": "ubi8-228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.3.2",
      "version_original": "1.3.2"
    },
    {
      "_id": "61d32b778093b97ef52e1b46",
      "alm_examples": [
        {
          "kind": "OpenLibertyApplication",
          "metadata": {
            "name": "openliberty-app-sample"
          },
          "spec": {
            "applicationImage": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
            "expose": true,
            "replicas": 1
          }
        },
        {
          "kind": "OpenLibertyDump",
          "metadata": {
            "name": "openliberty-dump-sample"
          },
          "spec": {
            "include": [
              "thread",
              "heap"
            ],
            "podName": "Specify_Pod_Name_Here"
          }
        },
        {
          "kind": "OpenLibertyTrace",
          "metadata": {
            "name": "openliberty-trace-sample"
          },
          "spec": {
            "maxFileSize": 20,
            "maxFiles": 5,
            "podName": "Specify_Pod_Name_Here",
            "traceSpecification": "*=info:com.ibm.ws.webcontainer*=all"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/open-liberty-operator-bundle@sha256:88ff3cd847c4b606466b1e782cec0dfbdb62fb3dd0e4e1bc8b9c2d1016c74132",
      "bundle_path_digest": "sha256:88ff3cd847c4b606466b1e782cec0dfbdb62fb3dd0e4e1bc8b9c2d1016c74132",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "beta2",
      "creation_date": "2022-01-03T16:59:35.470000+00:00",
      "csv_description": "This advanced Operator can be used to deploy and manage Open Liberty applications with consistent, production-grade QoS. This operator is based on the [Runtime Component Operator](https://github.com/application-stacks/runtime-component-operator) and provides all of its capabilities in addition to Open Liberty specific features such as gathering traces and dumps (Day-2 operations) and easily configuring and managing the single sign-on information for your Open Liberty applications.\n\nOpen Liberty Operator enables enterprise architects to govern the way their applications get deployed & managed in the cluster, while dramatically reducing the learning curve for developers to deploy into Kubernetes - allowing them to focus on writing the code! Here are some key features:\n\n#### Application Lifecyle\nYou can deploy your Open Liberty application container by either pointing to a container image, or an OpenShift ImageStream. When using an ImageStream the Operator will watch for any updates and will re-deploy the modified image.\n\n#### Custom RBAC\nThis Operator is capable of using a custom ServiceAccount from the caller, allowing it to follow RBAC restrictions. By default it creates a ServiceAccount if one is not specified, which can also be bound with specific roles.\n\n#### Environment Configuration\nYou can configure a variety of artifacts with your deployment, such as: labels, annotations, and environment variables from a ConfigMap, a Secret or a value.\n\n#### Routing\nExpose your application to external users via a single toggle to create a Route on OpenShift or an Ingress on other Kubernetes environments. Advanced configuration, such as TLS settings, are also easily enabled. Expiring Route certificates are re-issued.\n\n#### High Availability via Horizontal Pod Autoscaling\nRun multiple instances of your application for high availability. Either specify a static number of replicas or easily configure horizontal auto scaling to create (and delete) instances based on resource consumption.\n\n#### Persistence and advanced storage\nEnable persistence for your application by specifying simple requirements: just tell us the size of the storage and where you would like it to be mounted and We will create and manage that storage for you.\nThis toggles a StatefulSet resource instead of a Deployment resource, so your container can recover transactions and state upon a pod restart.\nWe offer an advanced mode where the user specifies a built-in PersistentVolumeClaim, allowing them to configure many details of the persistent volume, such as its storage class and access mode.\nYou can also easily configure and use a single storage for serviceability related Day-2 operations, such as gatherig server traces and dumps.\n\n#### Service Binding\nYour runtime components can expose services by a simple toggle. We take care of the heavy lifting such as creating kubernetes Secrets with information other services can use to bind. We also keep the bindable information synchronized, so your applications can dynamically reconnect to its required services without any intervention or interruption.\n\n#### Single Sign-On (SSO)\nOpen Liberty provides capabilities to delegate authentication to external providers. Your application users can log in using their existing social media credentials from providers such as Google, Facebook, LinkedIn, Twitter, GitHub, and any OpenID Connect (OIDC) or OAuth 2.0 clients. Open Liberty Operator allows to easily configure and manage the single sign-on information for your applications.\n\n#### Exposing metrics to Prometheus\nThe Open Liberty Operator exposes the runtime container's metrics via the [Prometheus Operator](https://operatorhub.io/operator/prometheus).\nUsers can pick between a basic mode, where they simply specify the label that Prometheus is watching to scrape the metrics from the container, or they can specify the full `ServiceMonitor` spec embedded into the OpenLibertyApplication's `spec.monitoring` key controlling things like the poll internal and security credentials.\n\n#### Easily mount logs and transaction directories\nIf you need to mount the logs and transaction data from your application to an external volume such as NFS (or any storage supported in your cluster), simply add the following (customizing the folder location and size) to your OpenLibertyApplication CR:\n``` storage: size: 2Gi mountPath: \"/logs\" ```\n\n#### Integration with OpenShift Serverless\nDeploy your serverless runtime component using a single toggle.  The Operator will convert all of its generated resources into [Knative](https://knative.dev) resources, allowing your pod to automatically scale to 0 when it is idle.\n\n#### Integration with OpenShift's Topology UI\nWe set the corresponding labels to support OpenShift's Developer Topology UI, which allows you to visualize your entire set of deployments and how they are connected.\n\nSee our [**documentation**](https://github.com/OpenLiberty/open-liberty-operator/tree/main/doc/) for more information.\n",
      "csv_display_name": "Open Liberty",
      "csv_metadata_description": "Deploy and manage applications running on Liberty",
      "csv_name": "open-liberty-operator.v0.8.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:00:09.134000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "open-liberty-certified",
      "provided_apis": [
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyApplication",
          "plural": "openlibertyapplications",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyDump",
          "plural": "openlibertydumps",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyTrace",
          "plural": "openlibertytraces",
          "version": "v1beta2"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:43b3f004a19c91c80ba815aedc1b361b87cd12daa28bb215e6775e64ef890af1",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:43b3f004a19c91c80ba815aedc1b361b87cd12daa28bb215e6775e64ef890af1",
          "name": "open-liberty-operator-controller-43b3f004a19c91c80ba815aedc1b361b87cd12daa28bb215e6775e64ef890af1-annotation"
        },
        {
          "digest": "sha256:43b3f004a19c91c80ba815aedc1b361b87cd12daa28bb215e6775e64ef890af1",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:43b3f004a19c91c80ba815aedc1b361b87cd12daa28bb215e6775e64ef890af1",
          "name": "manager"
        },
        {
          "digest": "sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "image": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "name": "open-liberty-samples-8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4-annotation"
        }
      ],
      "skip_range": "<0.8.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "0.8.0",
      "version_original": "0.8.0"
    },
    {
      "_id": "61d32b838093b97ef52e1b47",
      "alm_examples": [
        {
          "kind": "PanCnSeriesFirewall",
          "metadata": {
            "name": "pancnseriesfirewall-sample"
          },
          "spec": {
            "affinity": {},
            "cni": {
              "image": "gcr.io/itp-ext-cnseries/10.1.3/pan_cni",
              "version": "latest"
            },
            "csp": {},
            "dp": {
              "cpuLimit": 2,
              "image": "gcr.io/itp-ext-cnseries/10.1.3/panos_cn_ngfw"
            },
            "firewall": {
              "failoverMode": "failopen",
              "licenseBundle": "bundle2"
            },
            "fullnameOverride": "",
            "imagePullSecrets": [],
            "mp": {
              "cpuLimit": 4,
              "image": "gcr.io/itp-ext-cnseries/10.1.3/panos_cn_mgmt",
              "initImage": "gcr.io/itp-ext-cnseries/10.1.3/pan_cn_mgmt_init",
              "initVersion": "latest"
            },
            "nameOverride": "",
            "nodeSelector": {},
            "panorama": {
              "authKey": "",
              "ip": "x.x.x.x"
            },
            "podSecurityContext": {},
            "resources": {},
            "securityContext": {},
            "tolerations": []
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/paloalto/not-applicable@sha256:606f6f43f543d631a463d2f581f2b30cc76ad0ba6b0302fc7ae3c52a578cbcb2",
      "bundle_path_digest": "sha256:606f6f43f543d631a463d2f581f2b30cc76ad0ba6b0302fc7ae3c52a578cbcb2",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-01-03T16:59:47.489000+00:00",
      "csv_description": "**Palo Alto CN-Series NGFW (container firewall)**\n\n**Product Overview:** \nThe CN-Series firewall enables you to:\n1. Gain Layer-7 traffic visibility and control within the cluster\n2. Stop lateral movement of threats\n3. Prevent known and unknown inbound attacks\n4. Apply egress filtering to prevent data exfiltration and unwanted outbound connections\n5. Dynamically scale security without compromising DevOps agility.\n6. Ensure a frictionless CI/CD pipeline deployment.\n7. Unify management across all your firewalls using Panorama.\n\nDeploy CN-Series as-a-Kubernetes service and manage the fleet of firewalls from Panorama, alongside our hardware and VM-Series NGFW appliances to ensure consistent security posture everywhere. This subscription also includes industry-leading Threat Prevention, WildFire, URL Filtering, and DNS Security subscriptions that provide best-in-class runtime network security for East-West, Outbound and Inbound traffic.\n\n[Pre-Install Steps and Documentation](https://docs.paloaltonetworks.com/cn-series/10-1/cn-series-deployment/secure-kubernetes-workloads-with-cn-series.html)\n\n[Post-Install Steps and Documentation](https://github.com/PaloAltoNetworks/Kubernetes/tree/v2.0) -- Instructions at bottom of README (Multus and Openshift)",
      "csv_display_name": "pan-cn-series-operator",
      "csv_metadata_description": "",
      "csv_name": "pan-cn-series-operator.v1.0.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:00:17.182000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "pan-cn-series-operator",
      "provided_apis": [
        {
          "group": "charts.paloaltonetworks.com",
          "kind": "PanCnSeriesFirewall",
          "plural": "pancnseriesfirewalls",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:56d6c27633fa632bf6449ee8de8061cbcd705d90327a9fa8b665d9dd5ef50323",
          "image": "us.gcr.io/panw-gcp-team-testing/paloaltonetworks/pan-cn-series-operator@sha256:56d6c27633fa632bf6449ee8de8061cbcd705d90327a9fa8b665d9dd5ef50323",
          "name": "pan-cn-series-operator"
        },
        {
          "digest": "sha256:56d6c27633fa632bf6449ee8de8061cbcd705d90327a9fa8b665d9dd5ef50323",
          "image": "us.gcr.io/panw-gcp-team-testing/paloaltonetworks/pan-cn-series-operator@sha256:56d6c27633fa632bf6449ee8de8061cbcd705d90327a9fa8b665d9dd5ef50323",
          "name": "paloaltonetworks/pan-cn-series-operator-56d6c27633fa632bf6449ee8de8061cbcd705d90327a9fa8b665d9dd5ef50323-annotation"
        },
        {
          "digest": "sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:56d6c27633fa632bf6449ee8de8061cbcd705d90327a9fa8b665d9dd5ef50323",
          "image": "us.gcr.io/panw-gcp-team-testing/paloaltonetworks/pan-cn-series-operator@sha256:56d6c27633fa632bf6449ee8de8061cbcd705d90327a9fa8b665d9dd5ef50323",
          "name": "manager"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.0.0",
      "version_original": "1.0.0"
    },
    {
      "_id": "61d32b8cc6d6ba37322fd9ec",
      "alm_examples": [
        {
          "kind": "PerconaServerMongoDB",
          "metadata": {
            "name": "my-cluster-name"
          },
          "spec": {
            "allowUnsafeConfigurations": false,
            "backup": {
              "enabled": true,
              "image": "registry.connect.redhat.com/percona/percona-server-mongodb-operator-containers@sha256:071ac076bdd1ddec2754f4a8e784b09dc1ab457ce1aaf29ba292df993005abff",
              "pitr": {
                "enabled": false
              },
              "restartOnFailure": true,
              "serviceAccountName": "percona-server-mongodb-operator"
            },
            "crVersion": "1.11.0",
            "image": "registry.connect.redhat.com/percona/percona-server-mongodb-operator-containers@sha256:580f6eaf815f9bce04185d62c9c6c28a67443c6d379912dff1f28af68af98a5f",
            "imagePullPolicy": "Always",
            "mongod": {
              "net": {
                "hostPort": 0,
                "port": 27017
              },
              "operationProfiling": {
                "mode": "slowOp",
                "rateLimit": 100,
                "slowOpThresholdMs": 100
              },
              "security": {
                "enableEncryption": true,
                "encryptionCipherMode": "AES256-CBC",
                "encryptionKeySecret": "my-cluster-name-mongodb-encryption-key",
                "redactClientLogData": false
              },
              "setParameter": {
                "ttlMonitorSleepSecs": 60,
                "wiredTigerConcurrentReadTransactions": 128,
                "wiredTigerConcurrentWriteTransactions": 128
              },
              "storage": {
                "engine": "wiredTiger",
                "inMemory": {
                  "engineConfig": {
                    "inMemorySizeRatio": 0.9
                  }
                },
                "wiredTiger": {
                  "collectionConfig": {
                    "blockCompressor": "snappy"
                  },
                  "engineConfig": {
                    "cacheSizeRatio": 0.5,
                    "directoryForIndexes": false,
                    "journalCompressor": "snappy"
                  },
                  "indexConfig": {
                    "prefixCompression": true
                  }
                }
              }
            },
            "pmm": {
              "enabled": false,
              "image": "registry.connect.redhat.com/percona/percona-server-mongodb-operator-containers@sha256:2cb5ae10f470c71ba760fb2259659c80ddcee1f374e340bf896574325c198614",
              "serverHost": "monitoring-service"
            },
            "replsets": [
              {
                "affinity": {
                  "antiAffinityTopologyKey": "kubernetes.io/hostname"
                },
                "arbiter": {
                  "affinity": {
                    "antiAffinityTopologyKey": "kubernetes.io/hostname"
                  },
                  "enabled": false,
                  "size": 1
                },
                "expose": {
                  "enabled": false,
                  "exposeType": "ClusterIP"
                },
                "name": "rs0",
                "nonvoting": {
                  "affinity": {
                    "antiAffinityTopologyKey": "kubernetes.io/hostname"
                  },
                  "enabled": false,
                  "podDisruptionBudget": {
                    "maxUnavailable": 1
                  },
                  "resources": {
                    "limits": {
                      "cpu": "300m",
                      "memory": "0.5G"
                    },
                    "requests": {
                      "cpu": "300m",
                      "memory": "0.5G"
                    }
                  },
                  "size": 3,
                  "volumeSpec": {
                    "persistentVolumeClaim": {
                      "resources": {
                        "requests": {
                          "storage": "1Gi"
                        }
                      }
                    }
                  }
                },
                "podDisruptionBudget": {
                  "maxUnavailable": 1
                },
                "resources": {
                  "limits": {
                    "cpu": "300m",
                    "memory": "0.5G"
                  },
                  "requests": {
                    "cpu": "300m",
                    "memory": "0.5G"
                  }
                },
                "size": 3,
                "volumeSpec": {
                  "persistentVolumeClaim": {
                    "resources": {
                      "requests": {
                        "storage": "3Gi"
                      }
                    }
                  }
                }
              }
            ],
            "secrets": {
              "users": "my-cluster-name-secrets"
            },
            "sharding": {
              "configsvrReplSet": {
                "affinity": {
                  "antiAffinityTopologyKey": "kubernetes.io/hostname"
                },
                "expose": {
                  "enabled": false,
                  "exposeType": "ClusterIP"
                },
                "podDisruptionBudget": {
                  "maxUnavailable": 1
                },
                "resources": {
                  "limits": {
                    "cpu": "300m",
                    "memory": "0.5G"
                  },
                  "requests": {
                    "cpu": "300m",
                    "memory": "0.5G"
                  }
                },
                "size": 3,
                "volumeSpec": {
                  "persistentVolumeClaim": {
                    "resources": {
                      "requests": {
                        "storage": "3Gi"
                      }
                    }
                  }
                }
              },
              "enabled": true,
              "mongos": {
                "affinity": {
                  "antiAffinityTopologyKey": "kubernetes.io/hostname"
                },
                "expose": {
                  "exposeType": "ClusterIP"
                },
                "podDisruptionBudget": {
                  "maxUnavailable": 1
                },
                "resources": {
                  "limits": {
                    "cpu": "300m",
                    "memory": "0.5G"
                  },
                  "requests": {
                    "cpu": "300m",
                    "memory": "0.5G"
                  }
                },
                "size": 3
              }
            },
            "updateStrategy": "SmartUpdate",
            "upgradeOptions": {
              "apply": "disabled",
              "schedule": "0 2 * * *",
              "setFCV": false,
              "versionServiceEndpoint": "https://check.percona.com"
            }
          }
        },
        {
          "kind": "PerconaServerMongoDBBackup",
          "metadata": {
            "name": "backup1"
          },
          "spec": {
            "psmdbCluster": "my-cluster-name",
            "storageName": "s3-us-west"
          }
        },
        {
          "kind": "PerconaServerMongoDBRestore",
          "metadata": {
            "name": "restore1"
          },
          "spec": {
            "backupName": "backup1",
            "clusterName": "my-cluster-name"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/percona/percona-server-mongodb-operator-bundle@sha256:7ae55f5f3de98de4044cfe63a921a3b871fb6e8e1c70bdf2b1a7348c63fb1397",
      "bundle_path_digest": "sha256:7ae55f5f3de98de4044cfe63a921a3b871fb6e8e1c70bdf2b1a7348c63fb1397",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-01-03T16:59:56.085000+00:00",
      "csv_description": "\n## Percona is Cloud Native\n\nThe Percona Distribution for MongoDB Kubernetes Operator automates the creation, modification, or deletion of items in your Percona Server for MongoDB environment. The Operator contains the necessary Kubernetes settings to maintain a consistent Percona Server for MongoDB instance modification, or deletion of items in your Percona Server for MongoDB environment. The Operator contains the necessary Kubernetes settings to maintain a consistent Percona Server for MongoDB instance.\n\nConsult the [documentation](https://www.percona.com/doc/kubernetes-operator-for-psmongodb/index.html/) on the Percona Kubernetes Operator for Percona Server for MongoDB for complete details on capabilities and options.\n\n### Supported Features\n\n* **Scale Your Cluster** - change the `size` parameter to [add or remove members](https://www.percona.com/doc/kubernetes-operator-for-psmongodb/scaling.html) of the replica set. Three is the minimum recommended size for a functioning replica set.\n\n* **Add Monitoring** - [Percona Monitoring and Management (PMM) can be easily deployed](https://www.percona.com/doc/kubernetes-operator-for-psmongodb/monitoring.html) to monitor your Percona Server for MongoDB replica set(s). The recommended installation process uses Helm, the package manager for Kubernetes.\n\n* **Automate Your Backups** - [configure automatic backups](https://www.percona.com/doc/kubernetes-operator-for-psmongodb/backups.html) to run on a scheduled basis or run an on-demand backup at any time. Backups are performed using Percona Backup for MongoDB (PBM) and can be stored on local PVs or in any S3-compatible cloud storage provider.\n\n### Common Configurations\n\n* **Set Member as Arbiter** - [Set up a replica set which contains an arbiter](https://www.percona.com/doc/kubernetes-operator-for-psmongodb/arbiter.html), which participates in elections but does not store any data.  This reduces storage costs while helping maintain replica set integrity.\n\n* **Expose Members Outside K8S** - [by appropriately configuring the ServiceType](https://www.percona.com/doc/kubernetes-operator-for-psmongodb/expose.html) you can expose replica set members outside of Kubernetes or provide statically assigned IP addresses.\n\n* **Utilize Local Storage Options** - [with support for Local Storage you can mount existing data directories](https://www.percona.com/doc/kubernetes-operator-for-psmongodb/storage.html) into your replica set managed by Kubernetes or utilize high performance hardware for local storage rather than network storage for your database.\n\n### Before You Start\n\nAdd the PSMDB user `Secret` to Kubernetes. User information must be placed in the data section of the `secrets.yaml`\nfile with Base64-encoded logins and passwords for the user accounts.\n\nBelow is a sample `secrets.yaml` file for the correct formatting.\n\n```\napiVersion: v1\nkind: Secret\nmetadata:\n  name: my-cluster-name-secrets\ntype: Opaque\ndata:\n  MONGODB_BACKUP_USER: YmFja3Vw\n  MONGODB_BACKUP_PASSWORD: YmFja3VwMTIzNDU2\n  MONGODB_CLUSTER_ADMIN_USER: Y2x1c3RlckFkbWlu\n  MONGODB_CLUSTER_ADMIN_PASSWORD: Y2x1c3RlckFkbWluMTIzNDU2\n  MONGODB_CLUSTER_MONITOR_USER: Y2x1c3Rlck1vbml0b3I=\n  MONGODB_CLUSTER_MONITOR_PASSWORD: Y2x1c3Rlck1vbml0b3IxMjM0NTY=\n  MONGODB_USER_ADMIN_USER: dXNlckFkbWlu\n  MONGODB_USER_ADMIN_PASSWORD: dXNlckFkbWluMTIzNDU2\n  PMM_SERVER_USER: cG1t\n  PMM_SERVER_PASSWORD: c3VwYXxefHBheno=\n```\n### Release Highlights\n\n* In addition to S3-compatible storage, you can now configure backups to use Microsoft Azure Blob storage.\n  This feature makes the Operator fully compatible with Azure Cloud.\n* Custom sidecar containers allow users to customize Percona Distribution for MongoDB and other Operator components without changing the container images.\n  In this release, we enable even more customization, by allowing users to mount volumes into the sidecar containers.\n* It is now possible to set annotations to backup cron jobs (Thanks to Aliaksandr Karavai for contribution) * Mongos readiness probe now avoids running listDatabases command for all databases in the cluster to avoid unneeded delays on\n  clusters with an extremely large amount of databases\n* Timeout parameters for liveness and readiness probes can be customized to avoid false-positives for heavy-loaded clusters * Update backup status as error if it`s not started for a long time * New backup.pitr.oplogSpanMin option controls how often oplogs are uploaded to the cloud storage\n\n\n",
      "csv_display_name": "Percona Distribution for MongoDB Operator",
      "csv_metadata_description": "Percona Distribution for MongoDB Operator automates the creation, modification, or deletion of items in your Percona Server for MongoDB environment",
      "csv_name": "percona-server-mongodb-operator-certified.v1.11.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:00:23.799000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "percona-server-mongodb-operator-certified",
      "provided_apis": [
        {
          "group": "psmdb.percona.com",
          "kind": "PerconaServerMongoDB",
          "plural": "perconaservermongodbs",
          "version": "v1-11-0"
        },
        {
          "group": "psmdb.percona.com",
          "kind": "PerconaServerMongoDB",
          "plural": "perconaservermongodbs",
          "version": "v1-6-0"
        },
        {
          "group": "psmdb.percona.com",
          "kind": "PerconaServerMongoDB",
          "plural": "perconaservermongodbs",
          "version": "v1alpha1"
        },
        {
          "group": "psmdb.percona.com",
          "kind": "PerconaServerMongoDB",
          "plural": "perconaservermongodbs",
          "version": "v1-8-0"
        },
        {
          "group": "psmdb.percona.com",
          "kind": "PerconaServerMongoDBRestore",
          "plural": "perconaservermongodbrestores",
          "version": "v1"
        },
        {
          "group": "psmdb.percona.com",
          "kind": "PerconaServerMongoDB",
          "plural": "perconaservermongodbs",
          "version": "v1-5-0"
        },
        {
          "group": "psmdb.percona.com",
          "kind": "PerconaServerMongoDB",
          "plural": "perconaservermongodbs",
          "version": "v1-9-0"
        },
        {
          "group": "psmdb.percona.com",
          "kind": "PerconaServerMongoDBBackup",
          "plural": "perconaservermongodbbackups",
          "version": "v1"
        },
        {
          "group": "psmdb.percona.com",
          "kind": "PerconaServerMongoDB",
          "plural": "perconaservermongodbs",
          "version": "v1"
        },
        {
          "group": "psmdb.percona.com",
          "kind": "PerconaServerMongoDB",
          "plural": "perconaservermongodbs",
          "version": "v1-1-0"
        },
        {
          "group": "psmdb.percona.com",
          "kind": "PerconaServerMongoDB",
          "plural": "perconaservermongodbs",
          "version": "v1-4-0"
        },
        {
          "group": "psmdb.percona.com",
          "kind": "PerconaServerMongoDB",
          "plural": "perconaservermongodbs",
          "version": "v1-2-0"
        },
        {
          "group": "psmdb.percona.com",
          "kind": "PerconaServerMongoDB",
          "plural": "perconaservermongodbs",
          "version": "v1-3-0"
        },
        {
          "group": "psmdb.percona.com",
          "kind": "PerconaServerMongoDB",
          "plural": "perconaservermongodbs",
          "version": "v1-7-0"
        },
        {
          "group": "psmdb.percona.com",
          "kind": "PerconaServerMongoDB",
          "plural": "perconaservermongodbs",
          "version": "v1-10-0"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:f16d8d2437a49d7c8dfe30f3c9c36764d8f86e35fde64db5148f40612b1a361b",
          "image": "registry.connect.redhat.com/percona/percona-server-mongodb-operator-containers@sha256:f16d8d2437a49d7c8dfe30f3c9c36764d8f86e35fde64db5148f40612b1a361b",
          "name": "mongod4.0"
        },
        {
          "digest": "sha256:a3154bc9ca7ef19371308e90e9cb9051879e48f02c95842b4b39a3208698d312",
          "image": "registry.connect.redhat.com/percona/percona-server-mongodb-operator-containers@sha256:a3154bc9ca7ef19371308e90e9cb9051879e48f02c95842b4b39a3208698d312",
          "name": "mongod4.2"
        },
        {
          "digest": "sha256:580f6eaf815f9bce04185d62c9c6c28a67443c6d379912dff1f28af68af98a5f",
          "image": "registry.connect.redhat.com/percona/percona-server-mongodb-operator-containers@sha256:580f6eaf815f9bce04185d62c9c6c28a67443c6d379912dff1f28af68af98a5f",
          "name": "mongod4.4"
        },
        {
          "digest": "sha256:b14f566236d51a3dfb5e523ab1ce70a72b16f95783f1baf460547893e50dadcf",
          "image": "registry.connect.redhat.com/percona/percona-server-mongodb-operator-containers@sha256:b14f566236d51a3dfb5e523ab1ce70a72b16f95783f1baf460547893e50dadcf",
          "name": "mongod5.0"
        },
        {
          "digest": "sha256:071ac076bdd1ddec2754f4a8e784b09dc1ab457ce1aaf29ba292df993005abff",
          "image": "registry.connect.redhat.com/percona/percona-server-mongodb-operator-containers@sha256:071ac076bdd1ddec2754f4a8e784b09dc1ab457ce1aaf29ba292df993005abff",
          "name": "backup"
        },
        {
          "digest": "sha256:662a64a539a23a8bbad653c71af3bee3dd1038ea575e1d67293b9e2ad4a1d3f1",
          "image": "registry.connect.redhat.com/percona/percona-server-mongodb-operator@sha256:662a64a539a23a8bbad653c71af3bee3dd1038ea575e1d67293b9e2ad4a1d3f1",
          "name": "operator"
        },
        {
          "digest": "sha256:662a64a539a23a8bbad653c71af3bee3dd1038ea575e1d67293b9e2ad4a1d3f1",
          "image": "registry.connect.redhat.com/percona/percona-server-mongodb-operator@sha256:662a64a539a23a8bbad653c71af3bee3dd1038ea575e1d67293b9e2ad4a1d3f1",
          "name": "percona-server-mongodb-operator-662a64a539a23a8bbad653c71af3bee3dd1038ea575e1d67293b9e2ad4a1d3f1-annotation"
        },
        {
          "digest": "sha256:662a64a539a23a8bbad653c71af3bee3dd1038ea575e1d67293b9e2ad4a1d3f1",
          "image": "registry.connect.redhat.com/percona/percona-server-mongodb-operator@sha256:662a64a539a23a8bbad653c71af3bee3dd1038ea575e1d67293b9e2ad4a1d3f1",
          "name": "percona-server-mongodb-operator"
        },
        {
          "digest": "sha256:071ac076bdd1ddec2754f4a8e784b09dc1ab457ce1aaf29ba292df993005abff",
          "image": "registry.connect.redhat.com/percona/percona-server-mongodb-operator-containers@sha256:071ac076bdd1ddec2754f4a8e784b09dc1ab457ce1aaf29ba292df993005abff",
          "name": "percona-server-mongodb-operator-containers-071ac076bdd1ddec2754f4a8e784b09dc1ab457ce1aaf29ba292df993005abff-annotation"
        },
        {
          "digest": "sha256:2cb5ae10f470c71ba760fb2259659c80ddcee1f374e340bf896574325c198614",
          "image": "registry.connect.redhat.com/percona/percona-server-mongodb-operator-containers@sha256:2cb5ae10f470c71ba760fb2259659c80ddcee1f374e340bf896574325c198614",
          "name": "percona-server-mongodb-operator-containers-2cb5ae10f470c71ba760fb2259659c80ddcee1f374e340bf896574325c198614-annotation"
        },
        {
          "digest": "sha256:580f6eaf815f9bce04185d62c9c6c28a67443c6d379912dff1f28af68af98a5f",
          "image": "registry.connect.redhat.com/percona/percona-server-mongodb-operator-containers@sha256:580f6eaf815f9bce04185d62c9c6c28a67443c6d379912dff1f28af68af98a5f",
          "name": "percona-server-mongodb-operator-containers-580f6eaf815f9bce04185d62c9c6c28a67443c6d379912dff1f28af68af98a5f-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.11.0",
      "version_original": "1.11.0"
    },
    {
      "_id": "61d32b8f8093b97ef52e1b48",
      "alm_examples": [
        {
          "kind": "PerconaXtraDBCluster",
          "metadata": {
            "finalizers": [
              "delete-pxc-pods-in-order"
            ],
            "name": "cluster1"
          },
          "spec": {
            "allowUnsafeConfigurations": false,
            "backup": {
              "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:6ab8efb3804d1e519e49ee10eb46b428a837cfdcee222cc5ae2089cc1dc02a6d",
              "pitr": {
                "enabled": false,
                "storageName": "STORAGE-NAME-HERE",
                "timeBetweenUploads": 60
              },
              "schedule": [
                {
                  "keep": 3,
                  "name": "sat-night-backup",
                  "schedule": "0 0 * * 6",
                  "storageName": "s3-us-west"
                },
                {
                  "keep": 5,
                  "name": "daily-backup",
                  "schedule": "0 0 * * *",
                  "storageName": "fs-pvc"
                }
              ],
              "storages": {
                "fs-pvc": {
                  "type": "filesystem",
                  "volume": {
                    "persistentVolumeClaim": {
                      "accessModes": [
                        "ReadWriteOnce"
                      ],
                      "resources": {
                        "requests": {
                          "storage": "6G"
                        }
                      }
                    }
                  }
                },
                "s3-us-west": {
                  "s3": {
                    "bucket": "S3-BACKUP-BUCKET-NAME-HERE",
                    "credentialsSecret": "my-cluster-name-backup-s3",
                    "region": "us-west-2"
                  },
                  "type": "s3"
                }
              }
            },
            "crVersion": "1.10.0",
            "haproxy": {
              "affinity": {
                "antiAffinityTopologyKey": "kubernetes.io/hostname"
              },
              "enabled": true,
              "gracePeriod": 30,
              "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:2f06ac4a0f39b2c0253421c3d024291d5ba19d41e35e633ff6ddcf4ba67fd51a",
              "podDisruptionBudget": {
                "maxUnavailable": 1
              },
              "resources": {
                "requests": {
                  "cpu": "600m",
                  "memory": "1G"
                }
              },
              "size": 3
            },
            "logCollectorSecretName": "my-log-collector-secrets",
            "logcollector": {
              "enabled": true,
              "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:6e5a945b2a824ee34befd864b98d85727fe3849d83f8942463bca87210c19bca",
              "resources": {
                "requests": {
                  "cpu": "200m",
                  "memory": "100M"
                }
              }
            },
            "pmm": {
              "enabled": false,
              "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:d25b59fc82a22f65fe90fee6b1b6938fcd8172f534a5d6573914009a39578e1e",
              "resources": {
                "requests": {
                  "cpu": "300m",
                  "memory": "150M"
                }
              },
              "serverHost": "monitoring-service",
              "serverUser": "admin"
            },
            "proxysql": {
              "affinity": {
                "antiAffinityTopologyKey": "kubernetes.io/hostname"
              },
              "enabled": false,
              "gracePeriod": 30,
              "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:a727ccc8d9f17bc715309e9cf05b4903f38518a0cfee02a4822c8ac301cb01d6",
              "podDisruptionBudget": {
                "maxUnavailable": 1
              },
              "resources": {
                "requests": {
                  "cpu": "600m",
                  "memory": "1G"
                }
              },
              "size": 3,
              "volumeSpec": {
                "persistentVolumeClaim": {
                  "resources": {
                    "requests": {
                      "storage": "2G"
                    }
                  }
                }
              }
            },
            "pxc": {
              "affinity": {
                "antiAffinityTopologyKey": "kubernetes.io/hostname"
              },
              "autoRecovery": true,
              "gracePeriod": 600,
              "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:dbb944de701dbcd030aacd430a09f5c329c95991bd4257aed8a7407169b7e4b2",
              "podDisruptionBudget": {
                "maxUnavailable": 1
              },
              "resources": {
                "requests": {
                  "cpu": "600m",
                  "memory": "1G"
                }
              },
              "size": 3,
              "volumeSpec": {
                "persistentVolumeClaim": {
                  "resources": {
                    "requests": {
                      "storage": "6G"
                    }
                  }
                }
              }
            },
            "secretsName": "my-cluster-secrets",
            "sslInternalSecretName": "my-cluster-ssl-internal",
            "sslSecretName": "my-cluster-ssl",
            "updateStrategy": "SmartUpdate",
            "upgradeOptions": {
              "apply": "8.0-recommended",
              "schedule": "0 4 * * *",
              "versionServiceEndpoint": "https://check.percona.com"
            },
            "vaultSecretName": "keyring-secret-vault"
          }
        },
        {
          "kind": "PerconaXtraDBClusterBackup",
          "metadata": {
            "name": "backup1"
          },
          "spec": {
            "pxcCluster": "cluster1",
            "storageName": "fs-pvc"
          }
        },
        {
          "kind": "PerconaXtraDBBackup",
          "metadata": {
            "name": "backup1"
          },
          "spec": {
            "pxcCluster": "cluster1",
            "storageName": "s3-us-west"
          }
        },
        {
          "kind": "PerconaXtraDBClusterRestore",
          "metadata": {
            "name": "restore1"
          },
          "spec": {
            "backupName": "backup1",
            "pxcCluster": "cluster1"
          }
        },
        {
          "kind": "PerconaXtraDBClusterBackup",
          "metadata": {
            "name": "backup1"
          },
          "spec": {
            "pxcCluster": "cluster1",
            "storageName": "fs-pvc"
          }
        },
        {
          "kind": "PerconaXtraDBBackup",
          "metadata": {
            "name": "backup1"
          },
          "spec": {
            "pxcCluster": "cluster1",
            "storageName": "s3-us-west"
          }
        },
        {
          "kind": "PerconaXtraDBClusterRestore",
          "metadata": {
            "name": "restore1"
          },
          "spec": {
            "backupName": "backup1",
            "pxcCluster": "cluster1"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-bundle@sha256:fefce85e617428a43eebe47f6d99d31ff298b797945b0fccb9eff498d133b0fb",
      "bundle_path_digest": "sha256:fefce85e617428a43eebe47f6d99d31ff298b797945b0fccb9eff498d133b0fb",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-01-03T16:59:59.620000+00:00",
      "csv_description": "\n## Percona is Cloud Native\n\nPercona Distribution for MySQL Operator is an open-source drop in replacement for MySQL Enterprise with synchronous replication running on Kubernetes. It automates the deployment and management of the members in your Percona XtraDB Cluster environment. It can be used to instantiate a new Percona XtraDB Cluster, or to scale an existing environment.\n\nConsult the [documentation](https://percona.github.io/percona-xtradb-cluster-operator/) on the Percona Distribution for MySQL Operator for complete details on capabilities and options.\n\n### Supported Features\n\n* **Scale Your Cluster**  change the `size` parameter to [add or remove members](https://percona.github.io/percona-xtradb-cluster-operator/install/scaling) of the cluster. Three is the minimum recommended size for a functioning cluster.\n\n* **Manage Your Users**  [add, remove, or change](https://percona.github.io/percona-xtradb-cluster-operator/configure/users) the privileges of database users\n\n* **Automate Your Backups**  [configure cluster backups](https://percona.github.io/percona-xtradb-cluster-operator/configure/operator) to run on a scheduled basis. Backups can be stored on a persistent volume or S3-compatible storage. Leverage [Point-in-time recovery](https://www.percona.com/doc/kubernetes-operator-for-pxc/backups.html#storing-binary-logs-for-point-in-time-recovery) to reduce RPO/RTO.\n* **Proxy integration**  choose HAProxy or ProxySQL as a proxy in front of the Percona XtraDB Cluster. Proxies are deployed and configured automatically with the Operator.\n\n### Common Configurations\n\n* **Set Resource Limits** - set limitation on requests to CPU and memory resources.\n\n* **Customize Storage** - set the desired Storage Class and Access Mode for your database cluster data.\n\n* **Control Scheduling** - define how your PXC Pods are scheduled onto the K8S cluster with tolerations, pod disruption budgets, node selector and affinity settings.\n* Automatic synchronization of MySQL users with ProxySQL\n* HAProxy Support\n* Fully automated minor version updates (Smart Update)\n* Update Reader members before Writer member at cluster upgrades\n* Support MySQL versions 5.7 and 8.0\n### Before You Start\n\nAdd the PXC user `Secret` to Kubernetes. User information must be placed in the data section of the `secrets.yaml`\nfile with Base64-encoded logins and passwords for the user accounts.\n\nBelow is a sample `secrets.yaml` file for the correct formatting.\n\n```\napiVersion: v1\nkind: Secret\nmetadata:\n  name: my-cluster-secrets\ntype: Opaque\ndata:\n  root: cm9vdF9wYXNzd29yZA==\n  xtrabackup: YmFja3VwX3Bhc3N3b3Jk\n  monitor: bW9uaXRvcg==\n  clustercheck: Y2x1c3RlcmNoZWNrcGFzc3dvcmQ=\n  proxyadmin: YWRtaW5fcGFzc3dvcmQ=\n  pmmserver: c3VwYXxefHBheno=\n  operator: b3BlcmF0b3JhZG1pbg==\n```\n###  Release Highlights\n* Custom sidecar containers allow users to customize Percona XtraDB Cluster and other Operator components without changing the container images. In this release, we enable\n  even more customization, by allowing users to mount volumes into the sidecar containers.\n* In this release, we put a lot of effort into fixing bugs that were reported by the community. We appreciate everyone who helped us with discovering these issues and\n  contributed to the fixes.\n* Mount volumes into sidecar containers to enable customization (Thanks to Sridhar L for contributing) * spec.Backup.serviceAccount and spec.automountServiceAccountToken Custom Resource options can now be used in the Helm chart\n  (Thanks to Gerwin van de Steeg for reporting this issue)\n* The logrotate command now doesn\u2019t use verbose mode to avoid flooding the log with rotate information * Logs are now strictly following JSON specification to simplify parsing * New source_retry_count and source_connect_retry options were added to tune source retries for replication between two clusters * New replicasServiceEnabled option was added to allow disabling the Kubernetes Service for haproxy-replicas, which may be useful to avoid the unwanted forwarding of the\n  application write requests to all Percona XtraDB Cluster instances\n* Logrotate now doesn\u2019t rotate GRA logs (binlog events in ROW format representing the failed transaction) as ordinary log files, storing them for 7 days instead which\n  gives additional time to debug the problem\n\n",
      "csv_display_name": "Percona Distribution for MySQL Operator",
      "csv_metadata_description": "Percona Distribution for MySQL Operator manages the lifecycle of Percona XtraDB cluster instances.",
      "csv_name": "percona-xtradb-cluster-operator-certified.v1.10.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:00:26.047000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "percona-xtradb-cluster-operator-certified",
      "provided_apis": [
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1-6-0"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1-8-0"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1-1-0"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1-4-0"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBClusterBackup",
          "plural": "perconaxtradbclusterbackups",
          "version": "v1"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1-7-0"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1-5-0"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1-9-0"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1-10-0"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBBackup",
          "plural": "perconaxtradbbackups",
          "version": "v1alpha1"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1alpha1"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1-3-0"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBClusterRestore",
          "plural": "perconaxtradbclusterrestores",
          "version": "v1"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1-2-0"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:0e25cf04d10058443c95571e039e8437dcf5875f2b14abcad7a21b0c36826dcf",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:0e25cf04d10058443c95571e039e8437dcf5875f2b14abcad7a21b0c36826dcf",
          "name": "pxc5.7"
        },
        {
          "digest": "sha256:2ff5992220ba251cf064cc2b4d5929e0fdb963db18e35d6c672f9aacb0be3bed",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:2ff5992220ba251cf064cc2b4d5929e0fdb963db18e35d6c672f9aacb0be3bed",
          "name": "pxc5.7-backup"
        },
        {
          "digest": "sha256:dbb944de701dbcd030aacd430a09f5c329c95991bd4257aed8a7407169b7e4b2",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:dbb944de701dbcd030aacd430a09f5c329c95991bd4257aed8a7407169b7e4b2",
          "name": "pxc8.0"
        },
        {
          "digest": "sha256:6ab8efb3804d1e519e49ee10eb46b428a837cfdcee222cc5ae2089cc1dc02a6d",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:6ab8efb3804d1e519e49ee10eb46b428a837cfdcee222cc5ae2089cc1dc02a6d",
          "name": "pxc8.0-backup"
        },
        {
          "digest": "sha256:73d2266258b700a691db6196f4b5c830845d34d57bdef5be5ffbd45e88407309",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator@sha256:73d2266258b700a691db6196f4b5c830845d34d57bdef5be5ffbd45e88407309",
          "name": "operator"
        },
        {
          "digest": "sha256:2f06ac4a0f39b2c0253421c3d024291d5ba19d41e35e633ff6ddcf4ba67fd51a",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:2f06ac4a0f39b2c0253421c3d024291d5ba19d41e35e633ff6ddcf4ba67fd51a",
          "name": "haproxy"
        },
        {
          "digest": "sha256:a727ccc8d9f17bc715309e9cf05b4903f38518a0cfee02a4822c8ac301cb01d6",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:a727ccc8d9f17bc715309e9cf05b4903f38518a0cfee02a4822c8ac301cb01d6",
          "name": "proxysql"
        },
        {
          "digest": "sha256:6e5a945b2a824ee34befd864b98d85727fe3849d83f8942463bca87210c19bca",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:6e5a945b2a824ee34befd864b98d85727fe3849d83f8942463bca87210c19bca",
          "name": "logcollector"
        },
        {
          "digest": "sha256:d25b59fc82a22f65fe90fee6b1b6938fcd8172f534a5d6573914009a39578e1e",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:d25b59fc82a22f65fe90fee6b1b6938fcd8172f534a5d6573914009a39578e1e",
          "name": "pmmclient"
        },
        {
          "digest": "sha256:73d2266258b700a691db6196f4b5c830845d34d57bdef5be5ffbd45e88407309",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator@sha256:73d2266258b700a691db6196f4b5c830845d34d57bdef5be5ffbd45e88407309",
          "name": "percona-xtradb-cluster-operator-73d2266258b700a691db6196f4b5c830845d34d57bdef5be5ffbd45e88407309-annotation"
        },
        {
          "digest": "sha256:73d2266258b700a691db6196f4b5c830845d34d57bdef5be5ffbd45e88407309",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator@sha256:73d2266258b700a691db6196f4b5c830845d34d57bdef5be5ffbd45e88407309",
          "name": "percona-xtradb-cluster-operator"
        },
        {
          "digest": "sha256:6ab8efb3804d1e519e49ee10eb46b428a837cfdcee222cc5ae2089cc1dc02a6d",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:6ab8efb3804d1e519e49ee10eb46b428a837cfdcee222cc5ae2089cc1dc02a6d",
          "name": "percona-xtradb-cluster-operator-containers-6ab8efb3804d1e519e49ee10eb46b428a837cfdcee222cc5ae2089cc1dc02a6d-annotation"
        },
        {
          "digest": "sha256:d25b59fc82a22f65fe90fee6b1b6938fcd8172f534a5d6573914009a39578e1e",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:d25b59fc82a22f65fe90fee6b1b6938fcd8172f534a5d6573914009a39578e1e",
          "name": "percona-xtradb-cluster-operator-containers-d25b59fc82a22f65fe90fee6b1b6938fcd8172f534a5d6573914009a39578e1e-annotation"
        },
        {
          "digest": "sha256:6e5a945b2a824ee34befd864b98d85727fe3849d83f8942463bca87210c19bca",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:6e5a945b2a824ee34befd864b98d85727fe3849d83f8942463bca87210c19bca",
          "name": "percona-xtradb-cluster-operator-containers-6e5a945b2a824ee34befd864b98d85727fe3849d83f8942463bca87210c19bca-annotation"
        },
        {
          "digest": "sha256:a727ccc8d9f17bc715309e9cf05b4903f38518a0cfee02a4822c8ac301cb01d6",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:a727ccc8d9f17bc715309e9cf05b4903f38518a0cfee02a4822c8ac301cb01d6",
          "name": "percona-xtradb-cluster-operator-containers-a727ccc8d9f17bc715309e9cf05b4903f38518a0cfee02a4822c8ac301cb01d6-annotation"
        },
        {
          "digest": "sha256:2f06ac4a0f39b2c0253421c3d024291d5ba19d41e35e633ff6ddcf4ba67fd51a",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:2f06ac4a0f39b2c0253421c3d024291d5ba19d41e35e633ff6ddcf4ba67fd51a",
          "name": "percona-xtradb-cluster-operator-containers-2f06ac4a0f39b2c0253421c3d024291d5ba19d41e35e633ff6ddcf4ba67fd51a-annotation"
        },
        {
          "digest": "sha256:dbb944de701dbcd030aacd430a09f5c329c95991bd4257aed8a7407169b7e4b2",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:dbb944de701dbcd030aacd430a09f5c329c95991bd4257aed8a7407169b7e4b2",
          "name": "percona-xtradb-cluster-operator-containers-dbb944de701dbcd030aacd430a09f5c329c95991bd4257aed8a7407169b7e4b2-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.10.0",
      "version_original": "1.10.0"
    },
    {
      "_id": "61d3be8dc6d6ba37322fda25",
      "alm_examples": [
        {
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent": {
              "configuration_yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n",
              "endpointHost": "ingress-red-saas.instana.io",
              "endpointPort": "443",
              "env": {},
              "key": "replace-key"
            },
            "cluster": {
              "name": "my-cluster"
            },
            "zone": {
              "name": "edited-zone"
            }
          }
        },
        {
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent.endpoint.host": "ingress-red-saas.instana.io",
            "agent.endpoint.port": 443,
            "agent.env": {
              "INSTANA_AGENT_TAGS": "example"
            },
            "agent.key": "replace-me",
            "agent.zone.name": "my-zone",
            "cluster.name": "replace-me",
            "config.files": {
              "configuration.yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/instana/instana-agent-operator-bundle@sha256:db3c857f8a1248703a1c34578d044f75390a7838f9a80111d1eeb3be79f5d2d4",
      "bundle_path_digest": "sha256:db3c857f8a1248703a1c34578d044f75390a7838f9a80111d1eeb3be79f5d2d4",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-01-04T03:27:09.839000+00:00",
      "csv_description": "# Instana\n\nInstana is an [APM solution](https://www.instana.com/product-overview/) built for microservices that enables IT Ops to build applications faster and deliver higher quality services by automating monitoring, tracing and root cause analysis. The solution is optimized for [Kubernetes](https://www.instana.com/automatic-kubernetes-monitoring/) and [OpenShift](https://www.instana.com/blog/automatic-root-cause-analysis-for-openshift-applications/).\n\n## Instana Agent Operator\n\nThis is the Kubernetes Operator for installing the Instana Agent on Kubernetes or OpenShift.\n\n## Prerequisites for OpenShift\n\nBefore the agent will be able to run in OpenShift, you need to perform a couple of extra configuration steps.\n\nYou need to set up a project for the Instana Agent and configure it's permissions.\n\nThe project you create here needs to be the namespace where you create the Instana Agent custom resource that the operator will use to deploy the agent.\n\nFor example, create the `instana-agent` project:\n\n    oc new-project instana-agent\n\nThen, ensure the `instana-agent` service account is in the privileged security context:\n\n    oc adm policy add-scc-to-user privileged -z instana-agent\n\nThis service account will be created by the operator.\n\nNow you can proceed with installing the operator for the Instana agent.\n\n## Installation and Configuration\n\nFirst, install this operator from [OperatorHub.io](https://operatorhub.io/), [OpenShift Container Platform](https://www.openshift.com/), or [OKD](https://www.okd.io/).\n\nSecond, create a custom resource with the agent configuration in the target namespace (for now, this MUST always be the `instana-agent` namespace). The operator will pick up the custom resource and install the Instana agent accordingly.\n\nThe following is a minimal template of the custom resource:\n\n```yaml\napiVersion: instana.io/v1\nkind: InstanaAgent\nmetadata:\n  name: instana-agent\n  namespace: instana-agent\nspec:\n  zone:\n    name: my-zone # (optional) name of the zone of the host\n  cluster:\n    name: replace-me # replace with the name of your Kubernetes cluster\n  agent:\n    key: replace-me # replace with your Instana agent key\n    endpointHost: ingress-red-saas.instana.io # the monitoring ingress endpoint\n    endpointPort: \"443\" # the monitoring ingress endpoint port, wrapped in quotes\n    env:\n      INSTANA_AGENT_TAGS: example\n    configuration_yaml: |\n      # You can leave this empty, or use this to configure your instana agent.\n      # See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n```\n\nSave the template in a file `instana-agent.yaml` and edit the following values:\n\n* If your target namespace is not `instana-agent`, replace the `namespace:` accordingly.\n* `agent.key` must be set with your Instana agent key.\n* `agent.endpointHost` must be set with the monitoring ingress endpoint, generally either `saas-us-west-2.instana.io` or `saas-eu-west-1.instana.io`.\n* `agent.endpointPort` must be set with the monitoring ingress port, generally \"443\" (wrapped in quotes).\n* `zone.name` should be set with the name of the Kubernetes cluster that is be displayed in Instana.\n\nFor advanced configuration, you can edit the contents of the `configuration.yaml` file. View documentation [here](https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/).\n\nApply the custom resource with `kubectl apply -f instana-agent.yaml`. After some time, you should see `instana-agent` Pods being created on each node of your cluster, and your cluster should show on the infrastructure map on your Instana Web interface.\n\n## Uninstalling\n\nIn order to uninstall the Instana agent, simply remove the custom resource with `kubectl delete -f instana-agent.yaml`.\n\n## Source Code\n\nThe Instana agent operator is an open source project hosted on [https://github.com/instana/instana-agent-operator](https://github.com/instana/instana-agent-operator/).\n",
      "csv_display_name": "Instana Agent Operator",
      "csv_metadata_description": "Fully automated Application Performance Monitoring (APM) for microservices.",
      "csv_name": "instana-agent-operator.v2.0.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:41:48.789000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.5",
      "organization": "certified-operators",
      "package": "instana-agent-operator",
      "provided_apis": [
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1"
        },
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1beta1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:36bfdad2a0d2a92ab119676e7c918919516c0ac33eab36a61129c7b614d3398c",
          "image": "instana/instana-agent-operator@sha256:36bfdad2a0d2a92ab119676e7c918919516c0ac33eab36a61129c7b614d3398c",
          "name": "instana-agent-operator"
        },
        {
          "digest": "sha256:6acfc65f6bcfb653c89f0fd1ec61f59902296666b781c3c3f89688f32b7547ba",
          "image": "instana/agent@sha256:6acfc65f6bcfb653c89f0fd1ec61f59902296666b781c3c3f89688f32b7547ba",
          "name": "instana-agent"
        },
        {
          "digest": "sha256:36bfdad2a0d2a92ab119676e7c918919516c0ac33eab36a61129c7b614d3398c",
          "image": "instana/instana-agent-operator@sha256:36bfdad2a0d2a92ab119676e7c918919516c0ac33eab36a61129c7b614d3398c",
          "name": "instana-agent-operator-36bfdad2a0d2a92ab119676e7c918919516c0ac33eab36a61129c7b614d3398c-annotation"
        },
        {
          "digest": "sha256:36bfdad2a0d2a92ab119676e7c918919516c0ac33eab36a61129c7b614d3398c",
          "image": "instana/instana-agent-operator@sha256:36bfdad2a0d2a92ab119676e7c918919516c0ac33eab36a61129c7b614d3398c",
          "name": "manager"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.5",
      "version": "2.0.3",
      "version_original": "2.0.3"
    },
    {
      "_id": "61d3beb017f914cd72330946",
      "alm_examples": [
        {
          "kind": "Cloudcasa",
          "metadata": {
            "name": "cloudcasa"
          },
          "spec": {
            "cluster_id": ""
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/catalogicsoftware/cloudcasa-bundle@sha256:c66f5091446dc889a29da265c8c17c21181fe0fb5409eccd71fc4349c3bf0131",
      "bundle_path_digest": "sha256:c66f5091446dc889a29da265c8c17c21181fe0fb5409eccd71fc4349c3bf0131",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-01-04T03:27:44.006000+00:00",
      "csv_description": "CloudCasa is a powerful and easy-to-use data protection service for Kubernetes and cloud databases.  Configuration is quick and easy, and basic service is free. \n\n\n### How to Install \n* Create Namespace cloudcasa-operator. \n* Install the CloudCasa Operator by following the instructions presented when you click the Install button. Select **cloudcasa-operator** namespace. \n* After installing the operator, you will need to create an instance of the CloudCasa resource to configure the agent. \n* In order to create the CloudCasa resource you will need to generate a Cluster ID in CloudCasa.\n* Login to https://home.cloudcasa.io and add your OCP cluster under the Protection tab. Note the returned **Cluster ID**.\n* See the CloudCasa [Getting Started Guide](https://cloudcasa.io/get-started) for more information.\n* Navigate to the installed CloudCasa Operator and Click on the CloudCasa tab.\n* Create the CloudCasa resource and provide the **Cluster ID** noted in the previous step.\n\n\n### Supported Features\n\n* **AWS RDS Backup**\n\n* **Kubernetes cluster Backup** \n\n* **Kubernetes cluster restore**\n\n### Installation Checkpoints\n\n* **cloudcasa-io** namespace should be created.\n\n* **kubagent** pod should be created under **cloudcasa-io** namespace and should be in **running state.** \n\n* State of the OCP cluster on CloudCasa web UI should be **Active**.",
      "csv_display_name": "CloudCasa",
      "csv_metadata_description": "CloudCasa is a powerful and easy-to-use data protection service for Kubernetes and cloud databases.",
      "csv_name": "cloudcasa-operator.v2.2.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:14:56.076000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "cloudcasa-operator",
      "provided_apis": [
        {
          "group": "apps.cloudcasa.io",
          "kind": "Cloudcasa",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:86e5fa1fa294987114be200890c2e516501e424aee0fb98ece25c95e7716295b",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:86e5fa1fa294987114be200890c2e516501e424aee0fb98ece25c95e7716295b",
          "name": "ose-kube-rbac-proxy"
        },
        {
          "digest": "sha256:31a6966d48485c58b6d136ac9a31c670b273b6f95ed6b3b96a11dbd34570a9cf",
          "image": "registry.connect.redhat.com/catalogicsoftware/cloudcasa-operator@sha256:31a6966d48485c58b6d136ac9a31c670b273b6f95ed6b3b96a11dbd34570a9cf",
          "name": "cloudcasa-operator"
        },
        {
          "digest": "sha256:86e5fa1fa294987114be200890c2e516501e424aee0fb98ece25c95e7716295b",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:86e5fa1fa294987114be200890c2e516501e424aee0fb98ece25c95e7716295b",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:31a6966d48485c58b6d136ac9a31c670b273b6f95ed6b3b96a11dbd34570a9cf",
          "image": "registry.connect.redhat.com/catalogicsoftware/cloudcasa-operator@sha256:31a6966d48485c58b6d136ac9a31c670b273b6f95ed6b3b96a11dbd34570a9cf",
          "name": "cloudcasa-operator-31a6966d48485c58b6d136ac9a31c670b273b6f95ed6b3b96a11dbd34570a9cf-annotation"
        },
        {
          "digest": "sha256:31a6966d48485c58b6d136ac9a31c670b273b6f95ed6b3b96a11dbd34570a9cf",
          "image": "registry.connect.redhat.com/catalogicsoftware/cloudcasa-operator@sha256:31a6966d48485c58b6d136ac9a31c670b273b6f95ed6b3b96a11dbd34570a9cf",
          "name": "manager"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2.2.0",
      "version_original": "2.2.0"
    },
    {
      "_id": "61d3beb1c6d6ba37322fda2a",
      "alm_examples": [
        {
          "kind": "SymphonyCluster",
          "metadata": {
            "name": "symcluster"
          },
          "spec": {
            "client": [
              {
                "build": {
                  "git": {
                    "branch": "master",
                    "path": "samples/sampleapp_cpp",
                    "repository": "https://github.com/IBM/ibm-spectrum-symphony-operator.git"
                  },
                  "image": "registry.connect.redhat.com/ibm/spectrum-symphony@sha256:d6860f11eea6024e51134e58bc1968c41d797bd9555c4e0283224c52ccf17774",
                  "resources": {
                    "limits": {
                      "cpu": "500m",
                      "memory": "2Gi"
                    },
                    "requests": {
                      "cpu": "500m",
                      "memory": "2Gi"
                    }
                  },
                  "serviceAccountName": "builder"
                },
                "image": "",
                "imagePullPolicy": "Always",
                "name": "SampleAppCPP1",
                "resources": {
                  "limits": {
                    "cpu": "250m",
                    "memory": "1Gi"
                  },
                  "requests": {
                    "cpu": "250m",
                    "memory": "1Gi"
                  }
                },
                "serviceAccountName": ""
              }
            ],
            "cluster": {
              "adminPasswordSecretName": "",
              "cacheImages": true,
              "clusterName": "",
              "enableSharedSubdir": false,
              "entitlementSecretName": "",
              "logsOnShared": false,
              "scriptsSecretName": "",
              "storage": {
                "pvcName": "",
                "pvcSize": "1Gi",
                "selector": {
                  "label": "",
                  "value": ""
                },
                "storageClassName": ""
              },
              "usersPasswordsSecretName": ""
            },
            "compute": {
              "image": "registry.connect.redhat.com/ibm/spectrum-symphony@sha256:1722eae3debcab3354a17c019cb38dc15acb71c6fed33585f669c9caceefc877",
              "imagePullPolicy": "Always",
              "maxReplicas": 64,
              "minReplicas": 1,
              "replicaCount": 1,
              "resources": {
                "limits": {
                  "cpu": "250m",
                  "memory": "1Gi"
                },
                "requests": {
                  "cpu": "250m",
                  "memory": "1Gi"
                }
              },
              "targetCPUUtilizationPercentage": 70,
              "usePodAutoscaler": true
            },
            "licenceAccepted": true,
            "master": {
              "egoRestEnabled": false,
              "image": "registry.connect.redhat.com/ibm/spectrum-symphony@sha256:d6860f11eea6024e51134e58bc1968c41d797bd9555c4e0283224c52ccf17774",
              "imagePullPolicy": "Always",
              "replicaCount": 0,
              "resources": {
                "limits": {
                  "cpu": "1000m",
                  "memory": "4Gi"
                },
                "requests": {
                  "cpu": "1000m",
                  "memory": "4Gi"
                }
              },
              "symRestEnabled": false,
              "uiEnabled": true
            },
            "serviceAccountName": ""
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/spectrum-symphony-operator-bundle@sha256:64d375f9e471f8f9918f9257ecc4f80b8a31379c3e4495b38c9039a0bfe0b779",
      "bundle_path_digest": "sha256:64d375f9e471f8f9918f9257ecc4f80b8a31379c3e4495b38c9039a0bfe0b779",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-01-04T03:27:45.603000+00:00",
      "csv_description": "Creates IBM Spectrum Symphony Cluster",
      "csv_display_name": "IBM Spectrum Symphony Cluster",
      "csv_metadata_description": "IBM Spectrum Symphony cluster",
      "csv_name": "ibm-spectrum-symphony-operator.v1.1.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:14:47.710000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "ibm-spectrum-symphony-operator",
      "provided_apis": [
        {
          "group": "symphony.spectrumcomputing.ibm.com",
          "kind": "SymphonyCluster",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:1e93089d93c0dc97b60f0425c62f42b2ecaa46ecd5b9a14c6a3e3c3b80f16d33",
          "image": "registry.connect.redhat.com/ibm/spectrum-symphony-operator@sha256:1e93089d93c0dc97b60f0425c62f42b2ecaa46ecd5b9a14c6a3e3c3b80f16d33",
          "name": "spectrum-symphony-operator-1e93089d93c0dc97b60f0425c62f42b2ecaa46ecd5b9a14c6a3e3c3b80f16d33-annotation"
        },
        {
          "digest": "sha256:1e93089d93c0dc97b60f0425c62f42b2ecaa46ecd5b9a14c6a3e3c3b80f16d33",
          "image": "registry.connect.redhat.com/ibm/spectrum-symphony-operator@sha256:1e93089d93c0dc97b60f0425c62f42b2ecaa46ecd5b9a14c6a3e3c3b80f16d33",
          "name": "manager"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:d6860f11eea6024e51134e58bc1968c41d797bd9555c4e0283224c52ccf17774",
          "image": "registry.connect.redhat.com/ibm/spectrum-symphony@sha256:d6860f11eea6024e51134e58bc1968c41d797bd9555c4e0283224c52ccf17774",
          "name": "spectrum-symphony-d6860f11eea6024e51134e58bc1968c41d797bd9555c4e0283224c52ccf17774-annotation"
        },
        {
          "digest": "sha256:1722eae3debcab3354a17c019cb38dc15acb71c6fed33585f669c9caceefc877",
          "image": "registry.connect.redhat.com/ibm/spectrum-symphony@sha256:1722eae3debcab3354a17c019cb38dc15acb71c6fed33585f669c9caceefc877",
          "name": "spectrum-symphony-1722eae3debcab3354a17c019cb38dc15acb71c6fed33585f669c9caceefc877-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.1.2",
      "version_original": "1.1.2"
    },
    {
      "_id": "61d3bf13d467cd4ec03ef4e6",
      "alm_examples": [
        {
          "kind": "Neuvector",
          "metadata": {
            "name": "neuvector"
          },
          "spec": {
            "admissionwebhook": {
              "type": "ClusterIP"
            },
            "bottlerocket": {
              "enabled": false,
              "runtimePath": "/run/dockershim.sock"
            },
            "containerd": {
              "enabled": false,
              "path": "/var/run/containerd/containerd.sock"
            },
            "controller": {
              "affinity": {
                "podAntiAffinity": {
                  "preferredDuringSchedulingIgnoredDuringExecution": [
                    {
                      "podAffinityTerm": {
                        "labelSelector": {
                          "matchExpressions": [
                            {
                              "key": "app",
                              "operator": "In",
                              "values": [
                                "neuvector-controller-pod"
                              ]
                            }
                          ]
                        },
                        "topologyKey": "kubernetes.io/hostname"
                      },
                      "weight": 100
                    }
                  ]
                }
              },
              "apisvc": {
                "annotations": {},
                "route": {
                  "enabled": false,
                  "host": "",
                  "termination": "passthrough"
                },
                "type": ""
              },
              "azureFileShare": {
                "enabled": false,
                "secretName": "",
                "shareName": ""
              },
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "configmap": {
                "data": "",
                "enabled": false
              },
              "disruptionbudget": 0,
              "enabled": true,
              "env": [],
              "federation": {
                "managedsvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                },
                "mastersvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                }
              },
              "image": "registry.connect.redhat.com/neuvector/controller",
              "ingress": {
                "annotations": {
                  "ingress.kubernetes.io/protocol": "https"
                },
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "pvc": {
                "accessModes": [
                  "ReadWriteMany"
                ],
                "capacity": "",
                "enabled": false,
                "storageClass": ""
              },
              "replicas": 3,
              "resources": {},
              "schedulerName": "",
              "secret": {
                "data": {},
                "enabled": false
              },
              "strategy": {
                "rollingUpdate": {
                  "maxSurge": 1,
                  "maxUnavailable": 0
                },
                "type": "RollingUpdate"
              },
              "tolerations": []
            },
            "crdwebhook": {
              "enabled": true,
              "type": "ClusterIP"
            },
            "crio": {
              "enabled": true,
              "path": "/var/run/crio/crio.sock"
            },
            "cve": {
              "scanner": {
                "affinity": {},
                "dockerPath": "",
                "enabled": true,
                "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
                "nodeSelector": {},
                "priorityClassName": "",
                "replicas": 3,
                "resources": {},
                "strategy": {
                  "rollingUpdate": {
                    "maxSurge": 1,
                    "maxUnavailable": 0
                  },
                  "type": "RollingUpdate"
                },
                "tolerations": []
              },
              "updater": {
                "enabled": true,
                "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
                "priorityClassName": "",
                "schedule": "0 0 * * *",
                "secure": false
              }
            },
            "docker": {
              "enabled": false,
              "path": "/var/run/docker.sock"
            },
            "enforcer": {
              "enabled": true,
              "image": "registry.connect.redhat.com/neuvector/enforcer",
              "priorityClassName": "",
              "resources": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                }
              ]
            },
            "k3s": {
              "enabled": false,
              "runtimePath": "/run/k3s/containerd/containerd.sock"
            },
            "manager": {
              "affinity": {},
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "enabled": true,
              "env": {
                "ssl": true
              },
              "image": "registry.connect.redhat.com/neuvector/manager",
              "ingress": {
                "annotations": {},
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "resources": {},
              "route": {
                "enabled": true,
                "host": "",
                "termination": "passthrough"
              },
              "svc": {
                "annotations": {},
                "loadBalancerIP": "",
                "type": "NodePort"
              },
              "tolerations": []
            },
            "openshift": true,
            "psp": false,
            "resources": {},
            "serviceAccount": "default"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/neuvector/neuvector-operator-bundle@sha256:bb9a141e7420196baf0bfc456ae28d7d150f6b40de987b214d0833207fcc1a3e",
      "bundle_path_digest": "sha256:bb9a141e7420196baf0bfc456ae28d7d150f6b40de987b214d0833207fcc1a3e",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-01-04T03:29:23.624000+00:00",
      "csv_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.\n\nThe NeuVector Operator runs  in the openshift container platform to deploy and manage the NeuVector Security cluster components. The NeuVector operator contains all necessary information to deploy NeuVector using helm charts. You simply need to install the NeuVector operator from the OpenShift embeded operator hub and create NeuVector instance. You can modify the NeuVector installation configuration by modifying yaml while creating the NeuVector instance such as imagePullSecrets, tag version, etc. Please refer to [github link](https://github.com/neuvector/neuvector-helm/tree/master/charts/core) for the values that can be modifed during installation. To upgrade to a newer version of NeuVector, just reapply the NeuVector instance with desired tag , which in turn pulls the specified NeuVector image tags and upgrades as per upgrade plan configured on the helm chart.  NeuVector Operator versions are tied to NeuVector product versions. Version 1.3.2 of the NeuVector Certified Operator deploys version 4.4.2 of NeuVector.\n\n**Complete below steps to Grant Service Account Access to the Privileged SCC before installation.**\n\nCreate the NeuVector namespace\n\n         oc new-project  neuvector\nLogin as system:admin account\n\n         oc login -u system:admin\n\nGrant Service Account Access to the Privileged SCC\n\n         oc -n neuvector adm policy add-scc-to-user privileged -z default\n\nThe following info will be added in the Privileged SCC users:\n\n         - system:serviceaccount:neuvector:default\n\nIn OpenShift 4.6+ use the following to check:\n\n         oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide\n         system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/default\n\n\n**Add NeuVector license from NeuVector WebUI->setting**\n\n\n#Deploying the NeuVector Operator#\n\n\nPlease refer to the instructions [here](https://github.com/neuvector/neuvector-operator/blob/master/README.md)\n\n\n",
      "csv_display_name": "NeuVector Operator",
      "csv_metadata_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.",
      "csv_name": "neuvector-operator.v1.3.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-04T14:45:41.772000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.5",
      "organization": "certified-operators",
      "package": "neuvector-certified-operator",
      "provided_apis": [
        {
          "group": "apm.neuvector.com",
          "kind": "Neuvector",
          "plural": "neuvectors",
          "version": "v1alpha1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "name": "neuvector-operator-a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0-annotation"
        },
        {
          "digest": "sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "name": "neuvector-operator"
        },
        {
          "digest": "sha256:ecc4814bf9e38d41898ae2354bbafd2f1ed7c6e5602bb30cb40486e67725395c",
          "image": "registry.connect.redhat.com/neuvector/controller@sha256:ecc4814bf9e38d41898ae2354bbafd2f1ed7c6e5602bb30cb40486e67725395c",
          "name": "controller"
        },
        {
          "digest": "sha256:4621d69ca47929eedcab2c9163fc9d73ede09e0cd14f2a14db495e610590f5c2",
          "image": "registry.connect.redhat.com/neuvector/enforcer@sha256:4621d69ca47929eedcab2c9163fc9d73ede09e0cd14f2a14db495e610590f5c2",
          "name": "enforcer"
        },
        {
          "digest": "sha256:b49ba8bba9aaf292603896d5d3b9e5328b23260dfd977c70e7f3e39460564679",
          "image": "registry.connect.redhat.com/neuvector/manager@sha256:b49ba8bba9aaf292603896d5d3b9e5328b23260dfd977c70e7f3e39460564679",
          "name": "manager"
        },
        {
          "digest": "sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "name": "scanner"
        },
        {
          "digest": "sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "name": "updater"
        },
        {
          "digest": "sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "name": "scanner-d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038-annotation"
        },
        {
          "digest": "sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "name": "ubi8-228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.5",
      "version": "1.3.2",
      "version_original": "1.3.2"
    },
    {
      "_id": "61d3bfa68093b97ef52e1ba6",
      "alm_examples": [
        {
          "kind": "CouchDBCluster",
          "metadata": {
            "name": "example-couchdbcluster"
          },
          "spec": {
            "cpu": "1",
            "disk": "1Gi",
            "environment": {
              "adminPassword": "changeme",
              "search": true
            },
            "memory": "1Gi",
            "size": 3,
            "storageClass": ""
          }
        },
        {
          "kind": "FormationLock",
          "metadata": {
            "name": "example-formationlock"
          },
          "spec": {}
        },
        {
          "kind": "Recipe",
          "metadata": {
            "name": "example-recipe"
          },
          "spec": {}
        },
        {
          "kind": "RecipeTemplate",
          "metadata": {
            "name": "example-recipetemplate"
          },
          "spec": {}
        },
        {
          "kind": "Backup",
          "metadata": {
            "name": "example-backup"
          },
          "spec": {}
        },
        {
          "kind": "Bucket",
          "metadata": {
            "name": "example-bucket"
          },
          "spec": {}
        },
        {
          "kind": "Formation",
          "metadata": {
            "name": "example-formation"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [
        "amd64"
      ],
      "bundle_path": "registry.connect.redhat.com/ibm/couchdb-operator-certified-bundle@sha256:96a04fb99af74bc88406278004fbbdad4ae9b11189fd35347ebc86f065f8ae4b",
      "bundle_path_digest": "sha256:96a04fb99af74bc88406278004fbbdad4ae9b11189fd35347ebc86f065f8ae4b",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-01-04T03:31:50.522000+00:00",
      "csv_description": "Apache CouchDB lets you access your data where you need it. The [Couch Replication Protocol](http://docs.couchdb.org/en/master/replication/protocol.html) is implemented in a variety of projects and products that span every imaginable computing environment from globally distributed server-clusters, over mobile phones to web browsers.\n\nStore your data safely, on your own servers, or with any leading cloud provider. Your web- and native applications love CouchDB, because it speaks JSON natively and supports binary data for all your data storage needs.\n\nThe [Couch Replication Protocol](http://docs.couchdb.org/en/master/replication/protocol.html) lets your data flow seamlessly between server clusters to mobile phones and web browsers, enabling a compelling [offline-first](http://offlinefirst.org/) user-experience while maintaining high performance and strong reliability. CouchDB comes with a developer-friendly query language, and optionally MapReduce for simple, efficient, and comprehensive data retrieval.\n\n### Operator for Apache CouchDB Features\n* Fully automated deployment and configuration of Apache CouchDB clusters.\n* Support single, multiple, or all namespace install modes.\n\n#### Security\n* TLS - TLS  is supported using Red Hat Service certificates or user-provided certificates.\n* Authentication - The parameter `require_valid_user` defaults to `true`, which means that no requests are allowed from anonymous users. Every request must be authenticated.\n* Authorization - Databases are initially accessible by Apache CouchDB admins only.\n\n#### High Availability\n* Nodes - Each database node in an Apache CouchDB cluster requires its own Kubernetes node. It's recommended that you run it with a minimum of three nodes for any production deployment.\n* Zones - The Apache CouchDB cluster database nodes are spread across available Kubernetes fault zones where available.\n* Replicas - The default configuration for each database is two shards (Q=2) and three shard copies (N=3), where each shard copy is deployed on a separate node in the cluster.\n\n### Reading and writing to Apache CouchDB\n\nThe Operator for Apache CouchDB automatically generates a Service. This can be accessed using port-forwarding e.g. `kubectl port-forward svc/my-couchdb-cluster 443:443 -u admin:mypassword`. Alternatively, configure an OpenShift Route to expose the service externally.\n\n### CouchDB 2.3.1 Update Instructions\nWhen the operator is updated to v2.0 or above any existing CouchDB 2.3.1 cluster will not be automatically upgraded to CouchDB 3. The user must manually trigger this process by removing the version statement `version: 2.3.1` in the CouchDBCluster CR for each CouchDB cluster\nThe operator will then perform a rolling update, with the new pods running CouchDB3.\nIt is advised that customers do this straightaway as CouchDB 2.3.1 is no longer supported.\n\n[Read the complete guide to using the Operator for Apache CouchDB](https://ibm.biz/BdfGQy)\n",
      "csv_display_name": "Operator for Apache CouchDB",
      "csv_metadata_description": "Apache CouchDB is a highly available NOSQL database for web and mobile applications\n",
      "csv_name": "couchdb-operator.v2.2.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-05T11:15:09.302000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "couchdb-operator-certified",
      "provided_apis": [
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "Recipe",
          "plural": "recipes",
          "version": "v1"
        },
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "RecipeTemplate",
          "plural": "recipetemplates",
          "version": "v1"
        },
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "Backup",
          "plural": "backups",
          "version": "v1"
        },
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "Bucket",
          "plural": "buckets",
          "version": "v1"
        },
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "CouchDBCluster",
          "plural": "couchdbclusters",
          "version": "v1"
        },
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "FormationLock",
          "plural": "formationlocks",
          "version": "v1"
        },
        {
          "group": "couchdb.databases.cloud.ibm.com",
          "kind": "Formation",
          "plural": "formations",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:6af02557f1f9e12ca4037be71804eb5dc4c53134b937278cb779e58b350afb53",
          "image": "registry.connect.redhat.com/ibm/couchdb3@sha256:6af02557f1f9e12ca4037be71804eb5dc4c53134b937278cb779e58b350afb53",
          "name": "COUCHDB3"
        },
        {
          "digest": "sha256:29c2509791ece532864c02ce3a429085afc197354308bded80de267ed2586fde",
          "image": "registry.connect.redhat.com/ibm/couchdb-operator-mgmt@sha256:29c2509791ece532864c02ce3a429085afc197354308bded80de267ed2586fde",
          "name": "COUCHDB-MGMT"
        },
        {
          "digest": "sha256:4c04bf6b3259fd8251744974dacdd427ef1ddfb1713c61ea673f14bc12906ce4",
          "image": "registry.connect.redhat.com/ibm/couchdb-operator@sha256:4c04bf6b3259fd8251744974dacdd427ef1ddfb1713c61ea673f14bc12906ce4",
          "name": "couchdb-operator-4c04bf6b3259fd8251744974dacdd427ef1ddfb1713c61ea673f14bc12906ce4-annotation"
        },
        {
          "digest": "sha256:4c04bf6b3259fd8251744974dacdd427ef1ddfb1713c61ea673f14bc12906ce4",
          "image": "registry.connect.redhat.com/ibm/couchdb-operator@sha256:4c04bf6b3259fd8251744974dacdd427ef1ddfb1713c61ea673f14bc12906ce4",
          "name": "couchdb-operator"
        },
        {
          "digest": "sha256:6af02557f1f9e12ca4037be71804eb5dc4c53134b937278cb779e58b350afb53",
          "image": "registry.connect.redhat.com/ibm/couchdb3@sha256:6af02557f1f9e12ca4037be71804eb5dc4c53134b937278cb779e58b350afb53",
          "name": "couchdb3"
        },
        {
          "digest": "sha256:29c2509791ece532864c02ce3a429085afc197354308bded80de267ed2586fde",
          "image": "registry.connect.redhat.com/ibm/couchdb-operator-mgmt@sha256:29c2509791ece532864c02ce3a429085afc197354308bded80de267ed2586fde",
          "name": "mgmt"
        }
      ],
      "skip_range": ">=1.0.0 <2.2.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2.2.0",
      "version_original": "2.2.0"
    },
    {
      "_id": "61d3c66e17f914cd72330986",
      "alm_examples": [
        {
          "kind": "PerconaXtraDBCluster",
          "metadata": {
            "finalizers": [
              "delete-pxc-pods-in-order"
            ],
            "name": "cluster1"
          },
          "spec": {
            "allowUnsafeConfigurations": false,
            "backup": {
              "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:6ab8efb3804d1e519e49ee10eb46b428a837cfdcee222cc5ae2089cc1dc02a6d",
              "pitr": {
                "enabled": false,
                "storageName": "STORAGE-NAME-HERE",
                "timeBetweenUploads": 60
              },
              "schedule": [
                {
                  "keep": 3,
                  "name": "sat-night-backup",
                  "schedule": "0 0 * * 6",
                  "storageName": "s3-us-west"
                },
                {
                  "keep": 5,
                  "name": "daily-backup",
                  "schedule": "0 0 * * *",
                  "storageName": "fs-pvc"
                }
              ],
              "storages": {
                "fs-pvc": {
                  "type": "filesystem",
                  "volume": {
                    "persistentVolumeClaim": {
                      "accessModes": [
                        "ReadWriteOnce"
                      ],
                      "resources": {
                        "requests": {
                          "storage": "6G"
                        }
                      }
                    }
                  }
                },
                "s3-us-west": {
                  "s3": {
                    "bucket": "S3-BACKUP-BUCKET-NAME-HERE",
                    "credentialsSecret": "my-cluster-name-backup-s3",
                    "region": "us-west-2"
                  },
                  "type": "s3"
                }
              }
            },
            "crVersion": "1.10.0",
            "haproxy": {
              "affinity": {
                "antiAffinityTopologyKey": "kubernetes.io/hostname"
              },
              "enabled": true,
              "gracePeriod": 30,
              "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:2f06ac4a0f39b2c0253421c3d024291d5ba19d41e35e633ff6ddcf4ba67fd51a",
              "podDisruptionBudget": {
                "maxUnavailable": 1
              },
              "resources": {
                "requests": {
                  "cpu": "600m",
                  "memory": "1G"
                }
              },
              "size": 3
            },
            "logCollectorSecretName": "my-log-collector-secrets",
            "logcollector": {
              "enabled": true,
              "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:6e5a945b2a824ee34befd864b98d85727fe3849d83f8942463bca87210c19bca",
              "resources": {
                "requests": {
                  "cpu": "200m",
                  "memory": "100M"
                }
              }
            },
            "pmm": {
              "enabled": false,
              "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:d25b59fc82a22f65fe90fee6b1b6938fcd8172f534a5d6573914009a39578e1e",
              "resources": {
                "requests": {
                  "cpu": "300m",
                  "memory": "150M"
                }
              },
              "serverHost": "monitoring-service",
              "serverUser": "admin"
            },
            "proxysql": {
              "affinity": {
                "antiAffinityTopologyKey": "kubernetes.io/hostname"
              },
              "enabled": false,
              "gracePeriod": 30,
              "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:a727ccc8d9f17bc715309e9cf05b4903f38518a0cfee02a4822c8ac301cb01d6",
              "podDisruptionBudget": {
                "maxUnavailable": 1
              },
              "resources": {
                "requests": {
                  "cpu": "600m",
                  "memory": "1G"
                }
              },
              "size": 3,
              "volumeSpec": {
                "persistentVolumeClaim": {
                  "resources": {
                    "requests": {
                      "storage": "2G"
                    }
                  }
                }
              }
            },
            "pxc": {
              "affinity": {
                "antiAffinityTopologyKey": "kubernetes.io/hostname"
              },
              "autoRecovery": true,
              "gracePeriod": 600,
              "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:dbb944de701dbcd030aacd430a09f5c329c95991bd4257aed8a7407169b7e4b2",
              "podDisruptionBudget": {
                "maxUnavailable": 1
              },
              "resources": {
                "requests": {
                  "cpu": "600m",
                  "memory": "1G"
                }
              },
              "size": 3,
              "volumeSpec": {
                "persistentVolumeClaim": {
                  "resources": {
                    "requests": {
                      "storage": "6G"
                    }
                  }
                }
              }
            },
            "secretsName": "my-cluster-secrets",
            "sslInternalSecretName": "my-cluster-ssl-internal",
            "sslSecretName": "my-cluster-ssl",
            "updateStrategy": "SmartUpdate",
            "upgradeOptions": {
              "apply": "8.0-recommended",
              "schedule": "0 4 * * *",
              "versionServiceEndpoint": "https://check.percona.com"
            },
            "vaultSecretName": "keyring-secret-vault"
          }
        },
        {
          "kind": "PerconaXtraDBClusterBackup",
          "metadata": {
            "name": "backup1"
          },
          "spec": {
            "pxcCluster": "cluster1",
            "storageName": "fs-pvc"
          }
        },
        {
          "kind": "PerconaXtraDBBackup",
          "metadata": {
            "name": "backup1"
          },
          "spec": {
            "pxcCluster": "cluster1",
            "storageName": "s3-us-west"
          }
        },
        {
          "kind": "PerconaXtraDBClusterRestore",
          "metadata": {
            "name": "restore1"
          },
          "spec": {
            "backupName": "backup1",
            "pxcCluster": "cluster1"
          }
        },
        {
          "kind": "PerconaXtraDBClusterBackup",
          "metadata": {
            "name": "backup1"
          },
          "spec": {
            "pxcCluster": "cluster1",
            "storageName": "fs-pvc"
          }
        },
        {
          "kind": "PerconaXtraDBBackup",
          "metadata": {
            "name": "backup1"
          },
          "spec": {
            "pxcCluster": "cluster1",
            "storageName": "s3-us-west"
          }
        },
        {
          "kind": "PerconaXtraDBClusterRestore",
          "metadata": {
            "name": "restore1"
          },
          "spec": {
            "backupName": "backup1",
            "pxcCluster": "cluster1"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-bundle@sha256:fefce85e617428a43eebe47f6d99d31ff298b797945b0fccb9eff498d133b0fb",
      "bundle_path_digest": "sha256:fefce85e617428a43eebe47f6d99d31ff298b797945b0fccb9eff498d133b0fb",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-01-04T04:00:46.348000+00:00",
      "csv_description": "\n## Percona is Cloud Native\n\nPercona Distribution for MySQL Operator is an open-source drop in replacement for MySQL Enterprise with synchronous replication running on Kubernetes. It automates the deployment and management of the members in your Percona XtraDB Cluster environment. It can be used to instantiate a new Percona XtraDB Cluster, or to scale an existing environment.\n\nConsult the [documentation](https://percona.github.io/percona-xtradb-cluster-operator/) on the Percona Distribution for MySQL Operator for complete details on capabilities and options.\n\n### Supported Features\n\n* **Scale Your Cluster**  change the `size` parameter to [add or remove members](https://percona.github.io/percona-xtradb-cluster-operator/install/scaling) of the cluster. Three is the minimum recommended size for a functioning cluster.\n\n* **Manage Your Users**  [add, remove, or change](https://percona.github.io/percona-xtradb-cluster-operator/configure/users) the privileges of database users\n\n* **Automate Your Backups**  [configure cluster backups](https://percona.github.io/percona-xtradb-cluster-operator/configure/operator) to run on a scheduled basis. Backups can be stored on a persistent volume or S3-compatible storage. Leverage [Point-in-time recovery](https://www.percona.com/doc/kubernetes-operator-for-pxc/backups.html#storing-binary-logs-for-point-in-time-recovery) to reduce RPO/RTO.\n* **Proxy integration**  choose HAProxy or ProxySQL as a proxy in front of the Percona XtraDB Cluster. Proxies are deployed and configured automatically with the Operator.\n\n### Common Configurations\n\n* **Set Resource Limits** - set limitation on requests to CPU and memory resources.\n\n* **Customize Storage** - set the desired Storage Class and Access Mode for your database cluster data.\n\n* **Control Scheduling** - define how your PXC Pods are scheduled onto the K8S cluster with tolerations, pod disruption budgets, node selector and affinity settings.\n* Automatic synchronization of MySQL users with ProxySQL\n* HAProxy Support\n* Fully automated minor version updates (Smart Update)\n* Update Reader members before Writer member at cluster upgrades\n* Support MySQL versions 5.7 and 8.0\n### Before You Start\n\nAdd the PXC user `Secret` to Kubernetes. User information must be placed in the data section of the `secrets.yaml`\nfile with Base64-encoded logins and passwords for the user accounts.\n\nBelow is a sample `secrets.yaml` file for the correct formatting.\n\n```\napiVersion: v1\nkind: Secret\nmetadata:\n  name: my-cluster-secrets\ntype: Opaque\ndata:\n  root: cm9vdF9wYXNzd29yZA==\n  xtrabackup: YmFja3VwX3Bhc3N3b3Jk\n  monitor: bW9uaXRvcg==\n  clustercheck: Y2x1c3RlcmNoZWNrcGFzc3dvcmQ=\n  proxyadmin: YWRtaW5fcGFzc3dvcmQ=\n  pmmserver: c3VwYXxefHBheno=\n  operator: b3BlcmF0b3JhZG1pbg==\n```\n###  Release Highlights\n* Custom sidecar containers allow users to customize Percona XtraDB Cluster and other Operator components without changing the container images. In this release, we enable\n  even more customization, by allowing users to mount volumes into the sidecar containers.\n* In this release, we put a lot of effort into fixing bugs that were reported by the community. We appreciate everyone who helped us with discovering these issues and\n  contributed to the fixes.\n* Mount volumes into sidecar containers to enable customization (Thanks to Sridhar L for contributing) * spec.Backup.serviceAccount and spec.automountServiceAccountToken Custom Resource options can now be used in the Helm chart\n  (Thanks to Gerwin van de Steeg for reporting this issue)\n* The logrotate command now doesn\u2019t use verbose mode to avoid flooding the log with rotate information * Logs are now strictly following JSON specification to simplify parsing * New source_retry_count and source_connect_retry options were added to tune source retries for replication between two clusters * New replicasServiceEnabled option was added to allow disabling the Kubernetes Service for haproxy-replicas, which may be useful to avoid the unwanted forwarding of the\n  application write requests to all Percona XtraDB Cluster instances\n* Logrotate now doesn\u2019t rotate GRA logs (binlog events in ROW format representing the failed transaction) as ordinary log files, storing them for 7 days instead which\n  gives additional time to debug the problem\n\n",
      "csv_display_name": "Percona Distribution for MySQL Operator",
      "csv_metadata_description": "Percona Distribution for MySQL Operator manages the lifecycle of Percona XtraDB cluster instances.",
      "csv_name": "percona-xtradb-cluster-operator-certified.v1.10.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:13:06.200000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "percona-xtradb-cluster-operator-certified",
      "provided_apis": [
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBClusterBackup",
          "plural": "perconaxtradbclusterbackups",
          "version": "v1"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1-10-0"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "version": "v1-8-0"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1-1-0"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1-7-0"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBBackup",
          "plural": "perconaxtradbbackups",
          "version": "v1alpha1"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1-4-0"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1-3-0"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1-5-0"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1-9-0"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1alpha1"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBClusterRestore",
          "plural": "perconaxtradbclusterrestores",
          "version": "v1"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1-2-0"
        },
        {
          "group": "pxc.percona.com",
          "kind": "PerconaXtraDBCluster",
          "plural": "perconaxtradbclusters",
          "version": "v1-6-0"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:0e25cf04d10058443c95571e039e8437dcf5875f2b14abcad7a21b0c36826dcf",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:0e25cf04d10058443c95571e039e8437dcf5875f2b14abcad7a21b0c36826dcf",
          "name": "pxc5.7"
        },
        {
          "digest": "sha256:2ff5992220ba251cf064cc2b4d5929e0fdb963db18e35d6c672f9aacb0be3bed",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:2ff5992220ba251cf064cc2b4d5929e0fdb963db18e35d6c672f9aacb0be3bed",
          "name": "pxc5.7-backup"
        },
        {
          "digest": "sha256:dbb944de701dbcd030aacd430a09f5c329c95991bd4257aed8a7407169b7e4b2",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:dbb944de701dbcd030aacd430a09f5c329c95991bd4257aed8a7407169b7e4b2",
          "name": "pxc8.0"
        },
        {
          "digest": "sha256:6ab8efb3804d1e519e49ee10eb46b428a837cfdcee222cc5ae2089cc1dc02a6d",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:6ab8efb3804d1e519e49ee10eb46b428a837cfdcee222cc5ae2089cc1dc02a6d",
          "name": "pxc8.0-backup"
        },
        {
          "digest": "sha256:73d2266258b700a691db6196f4b5c830845d34d57bdef5be5ffbd45e88407309",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator@sha256:73d2266258b700a691db6196f4b5c830845d34d57bdef5be5ffbd45e88407309",
          "name": "operator"
        },
        {
          "digest": "sha256:2f06ac4a0f39b2c0253421c3d024291d5ba19d41e35e633ff6ddcf4ba67fd51a",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:2f06ac4a0f39b2c0253421c3d024291d5ba19d41e35e633ff6ddcf4ba67fd51a",
          "name": "haproxy"
        },
        {
          "digest": "sha256:a727ccc8d9f17bc715309e9cf05b4903f38518a0cfee02a4822c8ac301cb01d6",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:a727ccc8d9f17bc715309e9cf05b4903f38518a0cfee02a4822c8ac301cb01d6",
          "name": "proxysql"
        },
        {
          "digest": "sha256:6e5a945b2a824ee34befd864b98d85727fe3849d83f8942463bca87210c19bca",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:6e5a945b2a824ee34befd864b98d85727fe3849d83f8942463bca87210c19bca",
          "name": "logcollector"
        },
        {
          "digest": "sha256:d25b59fc82a22f65fe90fee6b1b6938fcd8172f534a5d6573914009a39578e1e",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:d25b59fc82a22f65fe90fee6b1b6938fcd8172f534a5d6573914009a39578e1e",
          "name": "pmmclient"
        },
        {
          "digest": "sha256:73d2266258b700a691db6196f4b5c830845d34d57bdef5be5ffbd45e88407309",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator@sha256:73d2266258b700a691db6196f4b5c830845d34d57bdef5be5ffbd45e88407309",
          "name": "percona-xtradb-cluster-operator-73d2266258b700a691db6196f4b5c830845d34d57bdef5be5ffbd45e88407309-annotation"
        },
        {
          "digest": "sha256:73d2266258b700a691db6196f4b5c830845d34d57bdef5be5ffbd45e88407309",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator@sha256:73d2266258b700a691db6196f4b5c830845d34d57bdef5be5ffbd45e88407309",
          "name": "percona-xtradb-cluster-operator"
        },
        {
          "digest": "sha256:6ab8efb3804d1e519e49ee10eb46b428a837cfdcee222cc5ae2089cc1dc02a6d",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:6ab8efb3804d1e519e49ee10eb46b428a837cfdcee222cc5ae2089cc1dc02a6d",
          "name": "percona-xtradb-cluster-operator-containers-6ab8efb3804d1e519e49ee10eb46b428a837cfdcee222cc5ae2089cc1dc02a6d-annotation"
        },
        {
          "digest": "sha256:d25b59fc82a22f65fe90fee6b1b6938fcd8172f534a5d6573914009a39578e1e",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:d25b59fc82a22f65fe90fee6b1b6938fcd8172f534a5d6573914009a39578e1e",
          "name": "percona-xtradb-cluster-operator-containers-d25b59fc82a22f65fe90fee6b1b6938fcd8172f534a5d6573914009a39578e1e-annotation"
        },
        {
          "digest": "sha256:6e5a945b2a824ee34befd864b98d85727fe3849d83f8942463bca87210c19bca",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:6e5a945b2a824ee34befd864b98d85727fe3849d83f8942463bca87210c19bca",
          "name": "percona-xtradb-cluster-operator-containers-6e5a945b2a824ee34befd864b98d85727fe3849d83f8942463bca87210c19bca-annotation"
        },
        {
          "digest": "sha256:a727ccc8d9f17bc715309e9cf05b4903f38518a0cfee02a4822c8ac301cb01d6",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:a727ccc8d9f17bc715309e9cf05b4903f38518a0cfee02a4822c8ac301cb01d6",
          "name": "percona-xtradb-cluster-operator-containers-a727ccc8d9f17bc715309e9cf05b4903f38518a0cfee02a4822c8ac301cb01d6-annotation"
        },
        {
          "digest": "sha256:2f06ac4a0f39b2c0253421c3d024291d5ba19d41e35e633ff6ddcf4ba67fd51a",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:2f06ac4a0f39b2c0253421c3d024291d5ba19d41e35e633ff6ddcf4ba67fd51a",
          "name": "percona-xtradb-cluster-operator-containers-2f06ac4a0f39b2c0253421c3d024291d5ba19d41e35e633ff6ddcf4ba67fd51a-annotation"
        },
        {
          "digest": "sha256:dbb944de701dbcd030aacd430a09f5c329c95991bd4257aed8a7407169b7e4b2",
          "image": "registry.connect.redhat.com/percona/percona-xtradb-cluster-operator-containers@sha256:dbb944de701dbcd030aacd430a09f5c329c95991bd4257aed8a7407169b7e4b2",
          "name": "percona-xtradb-cluster-operator-containers-dbb944de701dbcd030aacd430a09f5c329c95991bd4257aed8a7407169b7e4b2-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.10.0",
      "version_original": "1.10.0"
    },
    {
      "_id": "61d3c6a68093b97ef52e1bc9",
      "alm_examples": [
        {
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:acad9af174541d2b39a02a216dd462ee0d47d8dc3c9cb44371f0a6bbf1c83d3d",
      "bundle_path_digest": "sha256:acad9af174541d2b39a02a216dd462ee0d47d8dc3c9cb44371f0a6bbf1c83d3d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-01-04T04:01:42.365000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.4.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:21:11.351000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "name": "kubeturbo-operator-879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d-annotation"
        },
        {
          "digest": "sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:879dfbb577866b48ee6c7e77094c6fda4b733accecdb7cc30755a5f579ec246d",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:490db38c4cc1aa124f6ddd020f3ef6f8f1dfdf0913a25b2cfba9952dd2c0d6d5",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:490db38c4cc1aa124f6ddd020f3ef6f8f1dfdf0913a25b2cfba9952dd2c0d6d5",
          "name": "kubeturbo"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "8.4.1",
      "version_original": "8.4.1"
    },
    {
      "_id": "61d3c6af17f914cd72330992",
      "alm_examples": [
        {
          "kind": "OpenshiftArtifactoryHa",
          "metadata": {
            "name": "openshiftartifactoryha"
          },
          "spec": {
            "artifactory-ha": {
              "artifactory": {
                "image": {
                  "registry": "registry.connect.redhat.com",
                  "repository": "jfrog/artifactory-pro",
                  "tag": "7.27.9-1"
                },
                "joinKey": "OVERRIDE",
                "masterKey": "OVERRIDE",
                "node": {
                  "replicaCount": 2,
                  "waitForPrimaryStartup": {
                    "enabled": false
                  }
                },
                "uid": "1000721030"
              },
              "database": {
                "driver": "OVERRIDE",
                "password": "OVERRIDE",
                "type": "OVERRIDE",
                "url": "OVERRIDE",
                "user": "OVERRIDE"
              },
              "databaseUpgradeReady": true,
              "initContainerImage": "registry.connect.redhat.com/jfrog/init@sha256:9522611104cf958cc4322ed2d5d6ec0e3ffd75c39780a816f6f30d248c66ec02",
              "nginx": {
                "gid": "1000720107",
                "http": {
                  "externalPort": 80,
                  "internalPort": 8080
                },
                "https": {
                  "externalPort": 443,
                  "internalPort": 8443
                },
                "image": {
                  "registry": "registry.redhat.io",
                  "repository": "rhel8/nginx-116",
                  "tag": "latest"
                },
                "service": {
                  "ssloffload": false
                },
                "tlsSecretName": "OVERRIDE",
                "uid": "1000720104"
              },
              "postgresql": {
                "enabled": false
              },
              "waitForDatabase": true
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/jfrog/artifactory-operator-bundle@sha256:7f0eac75c3ad62bff844979c3f7cf1bf8553caa2c28e38c59299979a452bfb28",
      "bundle_path_digest": "sha256:7f0eac75c3ad62bff844979c3f7cf1bf8553caa2c28e38c59299979a452bfb28",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-01-04T04:01:51.617000+00:00",
      "csv_description": " ## Breaking change\nPlease update to version 1.1.10 of the operator.\nVersion 1.1.8 and 1.1.9 have issues. Please skip these versions.\n\n## Overview\nOpenshift Operator to deploy JFrog Artifactory Enterprise into your Openshift cluster.\n## Security Context Constraints\nTo deploy this helm chart you will need to be a cluster admin w/ access to the anyuid scc and add the operator service account to the anyuid scc.\n```\noc adm policy add-scc-to-user anyuid -z artifactory-ha-operator -n openshift-operators\n```\nAdd the service account for the Artifactory chart to deploy successfully:\n``` oc adm policy add-scc-to-user anyuid -z openshiftartifactoryha-artifactory-ha -n artifactory ```\n### Usage\n\nAn external DB is required. The operator will not deploy a DB but will require you to specify the configuration values to connect to it.\n\nSearch for JFrog and click JFrog Artifactory Enterprise Operator to install.\n\nGo to the Installed Operators.\n\nWait for the JFrog Artifactory Enterprise Operator to complete the installation.\n\nOpen the Operator and click on the provided API: Artifactory HA.\n\nClick Create New Instance and provide the following parameters for your DB configuration:\n\n```\nDATABASE_TYPE\nDATABASE_DRIVER\nDATABASE_URL\nDATABASE_USER\nDATABASE_PASSWORD\n```\nMaster key and Join key must be supplied. To generate a new key for each run the command below:\n\n```\n# Create a key\nexport JOIN_KEY=$(openssl rand -hex 32)\necho ${JOIN_KEY}\n```\n\nTo use TLS you will need to first create a k8s tls secret to store your .crt and .key file into.\nThen supply the value of this k8s secret into the TLS_SECRET field.\n``` oc create secret tls my_tls_secret --cert=tls.crt --key=tls.key --namespace=my_namespace ```\nClick Create for Artifactory Enterprise to deploy into OpenShift and connect to it on the external IP exposed by the load balancer.\n### Create a route\nTo expose Artifactory from Openshift we recommend you create a new route in Openshift.\nYou can either use the oc command line tool or the Openshift web console to generate a new route.\nDepending upon where you terminate TLS you will need to either specify pass through or edge.\nCommand Line (Edge):\n``` oc create route edge --service=openshiftartifactory-ha --cert=tls.crt --key=tls.key --ca-cert=ca.crt --hostname=www.example.com ```\nOr for more information visit the official Openshift documentation on routes here:\nhttps://docs.openshift.com/container-platform/4.6/networking/routes/route-configuration.html\n\n",
      "csv_display_name": "JFrog Artifactory Enterprise Operator",
      "csv_metadata_description": "JFrog Artifactory Enterprise deploys Artifactory in a high availability environment across multiple pods",
      "csv_name": "artifactory-ha-operator.v1.1.21",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:17:44.363000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "openshiftartifactoryha-operator",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "OpenshiftArtifactoryHa",
          "plural": "openshiftartifactoryhas",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:7f06776ddcaffa1f4c3ca74b0d71f7fd11a6af5b0f2f42ade89a7f4ef4011296",
          "image": "registry.connect.redhat.com/jfrog/artifactory-pro@sha256:7f06776ddcaffa1f4c3ca74b0d71f7fd11a6af5b0f2f42ade89a7f4ef4011296",
          "name": "artifactory-pro"
        },
        {
          "digest": "sha256:65fbf73f8affdafa2b4122daa2515164a6cd7e43864eda7ed7f4357465269e3f",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:65fbf73f8affdafa2b4122daa2515164a6cd7e43864eda7ed7f4357465269e3f",
          "name": "artifactory-operator"
        },
        {
          "digest": "sha256:bce2fa53c4e5b913c707183f49ab9dcde9e601b22f9fb85b98ba56f2e163c1a8",
          "image": "registry.redhat.io/rhel8/nginx-116@sha256:bce2fa53c4e5b913c707183f49ab9dcde9e601b22f9fb85b98ba56f2e163c1a8",
          "name": "nginx"
        },
        {
          "digest": "sha256:65fbf73f8affdafa2b4122daa2515164a6cd7e43864eda7ed7f4357465269e3f",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:65fbf73f8affdafa2b4122daa2515164a6cd7e43864eda7ed7f4357465269e3f",
          "name": "artifactory-operator-65fbf73f8affdafa2b4122daa2515164a6cd7e43864eda7ed7f4357465269e3f-annotation"
        },
        {
          "digest": "sha256:65fbf73f8affdafa2b4122daa2515164a6cd7e43864eda7ed7f4357465269e3f",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:65fbf73f8affdafa2b4122daa2515164a6cd7e43864eda7ed7f4357465269e3f",
          "name": "artifactory-ha-operator"
        },
        {
          "digest": "sha256:7f06776ddcaffa1f4c3ca74b0d71f7fd11a6af5b0f2f42ade89a7f4ef4011296",
          "image": "registry.connect.redhat.com/jfrog/artifactory-pro@sha256:7f06776ddcaffa1f4c3ca74b0d71f7fd11a6af5b0f2f42ade89a7f4ef4011296",
          "name": "artifactory_image_repository"
        },
        {
          "digest": "sha256:bce2fa53c4e5b913c707183f49ab9dcde9e601b22f9fb85b98ba56f2e163c1a8",
          "image": "registry.redhat.io/rhel8/nginx-116@sha256:bce2fa53c4e5b913c707183f49ab9dcde9e601b22f9fb85b98ba56f2e163c1a8",
          "name": "nginx_image_repository"
        },
        {
          "digest": "sha256:9522611104cf958cc4322ed2d5d6ec0e3ffd75c39780a816f6f30d248c66ec02",
          "image": "registry.connect.redhat.com/jfrog/init@sha256:9522611104cf958cc4322ed2d5d6ec0e3ffd75c39780a816f6f30d248c66ec02",
          "name": "init-9522611104cf958cc4322ed2d5d6ec0e3ffd75c39780a816f6f30d248c66ec02-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.1.21",
      "version_original": "1.1.21"
    },
    {
      "_id": "61d3c6d0c6d6ba37322fda75",
      "alm_examples": [
        {
          "kind": "AirgappedDeployment",
          "metadata": {
            "name": "airgappeddeployment"
          },
          "spec": {
            "airgapped": {
              "backup_deletion_frequency": "@daily",
              "backup_retention_period": 7
            },
            "allowed_domains": "*",
            "db_archive": {
              "frequency": "@monthly",
              "persistent_storage": {
                "storage#": "10G",
                "storage_class": "ibmc-file-bronze-gid"
              },
              "retention_age": 6
            },
            "env_type": "lite",
            "event_scheduler_frequency": "@hourly",
            "image_pull_secret": "bas-images-pull-secret",
            "kafka": {
              "storage#": "5G",
              "storage_class": "ibmc-block-bronze",
              "zookeeper_storage#": "5G",
              "zookeeper_storage_class": "ibmc-block-bronze"
            },
            "postgres": {
              "storage#": "10G",
              "storage_class": "ibmc-block-bronze"
            }
          }
        },
        {
          "kind": "AnalyticsProxy",
          "metadata": {
            "name": "analyticsproxy"
          },
          "spec": {
            "airgapped": {
              "backup_deletion_frequency": "@daily",
              "backup_retention_period": 7,
              "enabled": false
            },
            "allowed_domains": "*",
            "db_archive": {
              "frequency": "@monthly",
              "persistent_storage": {
                "storage#": "10G",
                "storage_class": "ibmc-file-bronze-gid"
              },
              "retention_age": 6
            },
            "env_type": "lite",
            "event_scheduler_frequency": "@hourly",
            "ibmproxyurl": "https://iaps.ibm.com",
            "image_pull_secret": "bas-images-pull-secret",
            "kafka": {
              "storage#": "5G",
              "storage_class": "ibmc-block-bronze",
              "zookeeper_storage#": "5G",
              "zookeeper_storage_class": "ibmc-block-bronze"
            },
            "postgres": {
              "storage#": "10G",
              "storage_class": "ibmc-block-bronze"
            }
          }
        },
        {
          "kind": "DeleteCluster",
          "metadata": {
            "name": "deletecluster"
          },
          "spec": {
            "image_pull_secret": "bas-images-pull-secret"
          }
        },
        {
          "kind": "FullDeployment",
          "metadata": {
            "name": "fulldeployment"
          },
          "spec": {
            "airgapped": {
              "backup_deletion_frequency": "@daily",
              "backup_retention_period": 7,
              "enabled": false
            },
            "allowed_domains": "*",
            "db_archive": {
              "frequency": "@monthly",
              "persistent_storage": {
                "storage#": "10G",
                "storage_class": "ibmc-file-bronze-gid"
              },
              "retention_age": 6
            },
            "env_type": "lite",
            "event_scheduler_frequency": "@hourly",
            "ibmproxyurl": "https://iaps.ibm.com",
            "image_pull_secret": "bas-images-pull-secret",
            "kafka": {
              "storage#": "5G",
              "storage_class": "ibmc-block-bronze",
              "zookeeper_storage#": "5G",
              "zookeeper_storage_class": "ibmc-block-bronze"
            },
            "postgres": {
              "storage#": "10G",
              "storage_class": "ibmc-block-bronze"
            },
            "prometheus_metrics": [],
            "prometheus_scheduler_frequency": "@daily"
          }
        },
        {
          "kind": "GenerateKey",
          "metadata": {
            "name": "bas-api-key"
          },
          "spec": {
            "image_pull_secret": "bas-images-pull-secret"
          }
        },
        {
          "kind": "StoreForwardMetric",
          "metadata": {
            "name": "storeforwardmetric"
          },
          "spec": {
            "db_archive": {
              "frequency": "@monthly",
              "persistent_storage": {
                "storage#": "10G",
                "storage_class": "ibmc-file-bronze-gid"
              },
              "retention_age": 6
            },
            "env_type": "lite",
            "event_scheduler_frequency": "@hourly",
            "ibmproxyurl": "https://iaps.ibm.com",
            "image_pull_secret": "bas-images-pull-secret",
            "postgres": {
              "storage#": "10G",
              "storage_class": "ibmc-block-bronze"
            },
            "prometheus_metrics": [],
            "prometheus_scheduler_frequency": "@daily"
          }
        },
        {
          "kind": "Dashboard",
          "metadata": {
            "name": "dashboard"
          },
          "spec": {
            "enable_test_api": true,
            "image_pull_secret": "bas-images-pull-secret"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm-edge/behavior-analytics-services-operator-bundle@sha256:1113bb05d4dae37249cbdea23dc0b72eac99bd33e7a6ad1d723e74d423c14be9",
      "bundle_path_digest": "sha256:1113bb05d4dae37249cbdea23dc0b72eac99bd33e7a6ad1d723e74d423c14be9",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-01-04T04:02:24.499000+00:00",
      "csv_description": "Behavior Analytics Services Operator is a service that collects, transforms and transmits product usage data.\nThe Operator supports deployments using-\nA. Dashboard\nB. Openshift portal or CLI\n\n**A. Dashboard**\n----\nWhen the Operator is installed, the Dashboard is installed too. Goto the Dashboard Custom Resource to get the URL to the Dashboard.\n\n\n**B. Openshift portal or CLI**\n----\n----\nFor manual installation using Openshift portal or CLI, follow the steps below\n\n\n**Pre-requisites**\n----\nStep 1: Create a new Project\n```sh\noc new-project <project-name>\n```\n\nStep 2: Create a secret named \"database-credentials\" for PostgreSQL DB\n```sh\n oc create secret generic database-credentials --from-literal=db_username=<DB Username> --from-literal=db_password=<DB Password> -n <project-name>\n```\n\nStep 3: [Optional] If the images require a secret to pull the container images, create a secret of type dockerconfigjson. Pass this secret name in the CR spec image\\_pull\\_secret\n```sh\noc create secret generic bas-images-pull-secret --from-file=.dockerconfigjson=<path/to/.docker/config.json>  --type=kubernetes.io/dockerconfigjson\n```\n\nStep 4: Create a secret named \"mtls-proxy-secret\" which has the client key and certificate to connect to IBM Proxy service. If you don't have certificates then refer link https://developers.cloudflare.com/access/service-auth/mtls-testing#generating-the-root-ca to create root and client certificates. Please ensure to share root certificate with edge@us.ibm.com to allow access to IBM proxy service using client certificate.\n```sh\noc create secret tls mtls-proxy-secret --key client-key.pem --cert client.pem\n```\n\n**Installing the Behavior Analytics Services**\n----\n\nSelect any one of the deployments to setup the Behavior Analytics Services\n1. Full Deployment\n2. Analytics Proxy Deployment\n3. Store and Forward metrics Deployment\n4. Airgapped Analytics Proxy Deployment\n\n| Spec                                                      | Description                                                      | Default Value          |\n| --------------------------------------------------------- | ------------------------------------------------------------ | ---------------------- |\n| `ibmproxyurl`                                               | URL of IBM Proxy Service                                     | `https://iaps.ibm.com`   |\n| `postgres.storage_class`                                    | Storage class of type ReadWriteOnce                          | Required user input        |\n| `postgres.size`                                             | Size (in G) of the storage to be attached to Database        | `10G`                    |\n| `kafka.storage_class`                                       | Storage class of type ReadWriteOnce                          | Required user input        |\n| `kafka.storage_size`                                        | Size (in G) of the storage to be attached to Kafka  | `5G`                     |\n| `kafka.zookeeper_storage_class`                                 | Storage class of type ReadWriteOnce                          | Required user input        |\n| `kafka.zookeeper_storage_size`                                 | Size (in G) of the storage to be attached to Zookeeper | `5G`                     |\n| `airgapped.enabled`                                         | Set value to \"true\" if airgapped setup is to be enabled otherwise keep the default value \"false\" | `false`                  |\n| `airgapped.backup_retention_period`   | Number of days to keep the backup files in the storage       | `7`                     |\n| `airgapped.backup_deletion_frequency` | Frequency of job to delete files from the storage. It accepts values in Cron format (https://en.wikipedia.org/wiki/Cron) | `@daily`                 |\n| `event_scheduler_frequency`                               | Frequency at which events will be forwarded to proxy in Cron format. In case if internet connection available on the cluster only during a certain time frame, specify time in UTC equivalent Cron format. | `@hourly`                |\n| `prometheus_scheduler_frequency`                          | Frequency in Cronjob format to pull metrics from Prometheus  | `@daily`                |\n| `image_pull_secret`                                       | Secret to pull container images from registry                | `bas-images-pull-secret` |\n| `db_archive.frequency`                                    | Frequency in Cronjob format to run archive job                                                           | `@monthly`             |\n| `db_archive.retention_age`                                | Number of months to retain the data in Database              | `6`                    |\n| `db_archive.persistent_storage.storage_class`             |Storage class of type ReadWriteMany         | Required user input    |\n| `db_archive.persistent_storage.storage_size`              | Size (in G) of the storage to be attached for saving airgapped files | `10G`                  |\n| `prometheus_metrics`                                      | Array of metrics information to be send to destination at desired frequency | []\n| `env_type`              | Type of environment. Can be **prod** (HA) or **lite** (non HA)   | `lite`                  |\n| `allowed_domains`                                         | Comma separated values of domains allowed by BAS. By default all domains are allowed | '*'\n\n\n**Generating the API Key**\n----\nOnce the deployment is complete, to use the Behavior Analytics Services Endpoints, generate an API key using the CR GenerateKey. This API key to be used to authenticate Behavior Analytics Services Endpoints.\n\nNote- Key can be retrieved from the secret with same name used while creating Generate Key CR's instance.\nOnce you get key from the secret, decode it using below command:\n```sh\necho -n <secret key> | base64 -d\n```\n\n**Deleting the API Key**\n----\nTo revoke the Key, delete the corresponding GenerateKey instance.\n\n**Using Behavior Analytics Services Endpoints**\n---\nFor all BAS APIs, use the Generated API Key for Authentication. Pass it as the Header- X-API-KEY and the key while using the APIs.\n",
      "csv_display_name": "Behavior Analytics Services",
      "csv_metadata_description": "Behavior Analytics Services is a service that collects, transforms and transmits product usage data.",
      "csv_name": "behavior-analytics-services-operator-certified.v1.1.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:15:38.077000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "behavior-analytics-services-operator-certified",
      "provided_apis": [
        {
          "group": "bas.ibm.com",
          "kind": "DeleteCluster",
          "plural": "deleteclusters",
          "version": "v1"
        },
        {
          "group": "bas.ibm.com",
          "kind": "FullDeployment",
          "plural": "fulldeployments",
          "version": "v1"
        },
        {
          "group": "bas.ibm.com",
          "kind": "GenerateKey",
          "plural": "generatekeys",
          "version": "v1"
        },
        {
          "group": "bas.ibm.com",
          "kind": "StoreForwardMetric",
          "plural": "storeforwardmetrics",
          "version": "v1"
        },
        {
          "group": "bas.ibm.com",
          "kind": "AirgappedDeployment",
          "plural": "airgappeddeployments",
          "version": "v1"
        },
        {
          "group": "bas.ibm.com",
          "kind": "AnalyticsProxy",
          "plural": "analyticsproxies",
          "version": "v1"
        },
        {
          "group": "bas.ibm.com",
          "kind": "Dashboard",
          "plural": "dashboards",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:609c19d1718947ee814b829334c37e1d720acf5fb642b0712b8ab1b14d57f53f",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:609c19d1718947ee814b829334c37e1d720acf5fb642b0712b8ab1b14d57f53f",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:c30a58a4f7a6457bf7da404ccde64f58f26162eeee0be9cc01ad517542027e2a",
          "image": "registry.connect.redhat.com/ibm-edge/behavior-analytics-services-operator@sha256:c30a58a4f7a6457bf7da404ccde64f58f26162eeee0be9cc01ad517542027e2a",
          "name": "behavior-analytics-services-operator"
        },
        {
          "digest": "sha256:8e0f1d33edf005eb2dfafed9b8367435b0f33ef4adf006bc75338f2a88e8942c",
          "image": "registry.redhat.io/openshift4/ose-cli@sha256:8e0f1d33edf005eb2dfafed9b8367435b0f33ef4adf006bc75338f2a88e8942c",
          "name": "dashboardinstaller"
        },
        {
          "digest": "sha256:b35f209bb491f88da6a9e6ca2b55675a4d0eeb69c4a369a07704cd9a9443a058",
          "image": "registry.connect.redhat.com/ibm-edge/event-api@sha256:b35f209bb491f88da6a9e6ca2b55675a4d0eeb69c4a369a07704cd9a9443a058",
          "name": "event_api"
        },
        {
          "digest": "sha256:a606caf41cb689bb3496d1e76312ebbbe531ab5df52d4d0813bd7763cc170da1",
          "image": "registry.connect.redhat.com/ibm-edge/store-api@sha256:a606caf41cb689bb3496d1e76312ebbbe531ab5df52d4d0813bd7763cc170da1",
          "name": "store_api"
        },
        {
          "digest": "sha256:0b5a7b02e4cb4baf0e08171fdd1d7d35a16bb82254ff2e245e051e483f6cd08c",
          "image": "registry.connect.redhat.com/ibm-edge/event-reader@sha256:0b5a7b02e4cb4baf0e08171fdd1d7d35a16bb82254ff2e245e051e483f6cd08c",
          "name": "reader"
        },
        {
          "digest": "sha256:caf7464165c82783ec83f0cffd1163cbfdffc4bad1f81def00dd3a25ae8a806c",
          "image": "registry.connect.redhat.com/ibm-edge/event-scheduler@sha256:caf7464165c82783ec83f0cffd1163cbfdffc4bad1f81def00dd3a25ae8a806c",
          "name": "event_scheduler"
        },
        {
          "digest": "sha256:08ba04c0c3a0966568538ac709f7bb243f7768c1f200c1a7c99e2761144a9a6b",
          "image": "registry.connect.redhat.com/ibm-edge/prometheus-scheduler@sha256:08ba04c0c3a0966568538ac709f7bb243f7768c1f200c1a7c99e2761144a9a6b",
          "name": "prometheus_scheduler"
        },
        {
          "digest": "sha256:90ddecb54abe2880b86016a407507cecf77a113b4c7724235ab0abd21ad1d9aa",
          "image": "registry.connect.redhat.com/ibm-edge/pgo-client@sha256:90ddecb54abe2880b86016a407507cecf77a113b4c7724235ab0abd21ad1d9aa",
          "name": "pgo_client"
        },
        {
          "digest": "sha256:815630d23e8d88664907fbf8096952adfd22593a4989063e9dd55549e674ee15",
          "image": "registry.connect.redhat.com/ibm-edge/reverse-proxy@sha256:815630d23e8d88664907fbf8096952adfd22593a4989063e9dd55549e674ee15",
          "name": "nginx"
        },
        {
          "digest": "sha256:a2e20cac50352c1ad13cd03185f326484ee20202c8a60313ba116920d6d6da88",
          "image": "registry.redhat.io/openshift4/ose-grafana@sha256:a2e20cac50352c1ad13cd03185f326484ee20202c8a60313ba116920d6d6da88",
          "name": "grafana"
        },
        {
          "digest": "sha256:c305e8a59ed5a6f100dd263c34743ad688c999c82cfdef76806d9e01b93834b6",
          "image": "registry.redhat.io/openshift3/ose-kube-rbac-proxy@sha256:c305e8a59ed5a6f100dd263c34743ad688c999c82cfdef76806d9e01b93834b6",
          "name": "ksm"
        },
        {
          "digest": "sha256:0c53b2cd52735491f15c39898c7d1347de6518a7cbff2c1bfc20623e29351361",
          "image": "registry.connect.redhat.com/ibm-edge/growth-stack-base@sha256:0c53b2cd52735491f15c39898c7d1347de6518a7cbff2c1bfc20623e29351361",
          "name": "init_container"
        },
        {
          "digest": "sha256:d748c21a55796827da82c61f162b505c59451cba24f1874e5185f21275b6bddc",
          "image": "registry.access.redhat.com/ubi8/ubi@sha256:d748c21a55796827da82c61f162b505c59451cba24f1874e5185f21275b6bddc",
          "name": "ubi"
        },
        {
          "digest": "sha256:19a8b33e2f4c2beee5266d5243abb7f43d85322fc62800899759cdf6ec568fee",
          "image": "registry.connect.redhat.com/ibm-edge/airgap-download-ui@sha256:19a8b33e2f4c2beee5266d5243abb7f43d85322fc62800899759cdf6ec568fee",
          "name": "download_ui"
        },
        {
          "digest": "sha256:d9034bf774c1cdf7933706eb76f274c57d1aeded7f59db747bfd9f0f2ac7581a",
          "image": "registry.connect.redhat.com/ibm-edge/bas-operator-dashboard@sha256:d9034bf774c1cdf7933706eb76f274c57d1aeded7f59db747bfd9f0f2ac7581a",
          "name": "dashboard_ui"
        },
        {
          "digest": "sha256:5e31ce8745926e0116827b1b658800dd3e8b91cd1800be4f9943a84a1c023f78",
          "image": "registry.redhat.io/openshift4/ose-oauth-proxy@sha256:5e31ce8745926e0116827b1b658800dd3e8b91cd1800be4f9943a84a1c023f78",
          "name": "oauth_proxy"
        },
        {
          "digest": "sha256:4c5f605669edc2125a6aea31c66c89cef524b57284eac302f35bbfa4680d1467",
          "image": "registry.connect.redhat.com/crunchydata/pgo-deployer@sha256:4c5f605669edc2125a6aea31c66c89cef524b57284eac302f35bbfa4680d1467",
          "name": "pgo_deployer"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.1.1",
      "version_original": "1.1.1"
    },
    {
      "_id": "61d3f29017f914cd72330a18",
      "alm_examples": [
        {
          "kind": "SymphonyCluster",
          "metadata": {
            "name": "symcluster"
          },
          "spec": {
            "client": [
              {
                "build": {
                  "git": {
                    "branch": "master",
                    "path": "samples/sampleapp_cpp",
                    "repository": "https://github.com/IBM/ibm-spectrum-symphony-operator.git"
                  },
                  "image": "registry.connect.redhat.com/ibm/spectrum-symphony@sha256:d6860f11eea6024e51134e58bc1968c41d797bd9555c4e0283224c52ccf17774",
                  "resources": {
                    "limits": {
                      "cpu": "500m",
                      "memory": "2Gi"
                    },
                    "requests": {
                      "cpu": "500m",
                      "memory": "2Gi"
                    }
                  },
                  "serviceAccountName": "builder"
                },
                "image": "",
                "imagePullPolicy": "Always",
                "name": "SampleAppCPP1",
                "resources": {
                  "limits": {
                    "cpu": "250m",
                    "memory": "1Gi"
                  },
                  "requests": {
                    "cpu": "250m",
                    "memory": "1Gi"
                  }
                },
                "serviceAccountName": ""
              }
            ],
            "cluster": {
              "adminPasswordSecretName": "",
              "cacheImages": true,
              "clusterName": "",
              "enableSharedSubdir": false,
              "entitlementSecretName": "",
              "logsOnShared": false,
              "scriptsSecretName": "",
              "storage": {
                "pvcName": "",
                "pvcSize": "1Gi",
                "selector": {
                  "label": "",
                  "value": ""
                },
                "storageClassName": ""
              },
              "usersPasswordsSecretName": ""
            },
            "compute": {
              "image": "registry.connect.redhat.com/ibm/spectrum-symphony@sha256:1722eae3debcab3354a17c019cb38dc15acb71c6fed33585f669c9caceefc877",
              "imagePullPolicy": "Always",
              "maxReplicas": 64,
              "minReplicas": 1,
              "replicaCount": 1,
              "resources": {
                "limits": {
                  "cpu": "250m",
                  "memory": "1Gi"
                },
                "requests": {
                  "cpu": "250m",
                  "memory": "1Gi"
                }
              },
              "targetCPUUtilizationPercentage": 70,
              "usePodAutoscaler": true
            },
            "licenceAccepted": true,
            "master": {
              "egoRestEnabled": false,
              "image": "registry.connect.redhat.com/ibm/spectrum-symphony@sha256:d6860f11eea6024e51134e58bc1968c41d797bd9555c4e0283224c52ccf17774",
              "imagePullPolicy": "Always",
              "replicaCount": 0,
              "resources": {
                "limits": {
                  "cpu": "1000m",
                  "memory": "4Gi"
                },
                "requests": {
                  "cpu": "1000m",
                  "memory": "4Gi"
                }
              },
              "symRestEnabled": false,
              "uiEnabled": true
            },
            "serviceAccountName": ""
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/spectrum-symphony-operator-bundle@sha256:64d375f9e471f8f9918f9257ecc4f80b8a31379c3e4495b38c9039a0bfe0b779",
      "bundle_path_digest": "sha256:64d375f9e471f8f9918f9257ecc4f80b8a31379c3e4495b38c9039a0bfe0b779",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-01-04T07:09:04.004000+00:00",
      "csv_description": "Creates IBM Spectrum Symphony Cluster",
      "csv_display_name": "IBM Spectrum Symphony Cluster",
      "csv_metadata_description": "IBM Spectrum Symphony cluster",
      "csv_name": "ibm-spectrum-symphony-operator.v1.1.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-05T11:15:14.804000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "ibm-spectrum-symphony-operator",
      "provided_apis": [
        {
          "group": "symphony.spectrumcomputing.ibm.com",
          "kind": "SymphonyCluster",
          "plural": "symphonyclusters",
          "version": "v1"
        }
      ],
      "related_images": [
        {
          "digest": "sha256:1e93089d93c0dc97b60f0425c62f42b2ecaa46ecd5b9a14c6a3e3c3b80f16d33",
          "image": "registry.connect.redhat.com/ibm/spectrum-symphony-operator@sha256:1e93089d93c0dc97b60f0425c62f42b2ecaa46ecd5b9a14c6a3e3c3b80f16d33",
          "name": "spectrum-symphony-operator-1e93089d93c0dc97b60f0425c62f42b2ecaa46ecd5b9a14c6a3e3c3b80f16d33-annotation"
        },
        {
          "digest": "sha256:1e93089d93c0dc97b60f0425c62f42b2ecaa46ecd5b9a14c6a3e3c3b80f16d33",
          "image": "registry.connect.redhat.com/ibm/spectrum-symphony-operator@sha256:1e93089d93c0dc97b60f0425c62f42b2ecaa46ecd5b9a14c6a3e3c3b80f16d33",
          "name": "manager"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:d6860f11eea6024e51134e58bc1968c41d797bd9555c4e0283224c52ccf17774",
          "image": "registry.connect.redhat.com/ibm/spectrum-symphony@sha256:d6860f11eea6024e51134e58bc1968c41d797bd9555c4e0283224c52ccf17774",
          "name": "spectrum-symphony-d6860f11eea6024e51134e58bc1968c41d797bd9555c4e0283224c52ccf17774-annotation"
        },
        {
          "digest": "sha256:1722eae3debcab3354a17c019cb38dc15acb71c6fed33585f669c9caceefc877",
          "image": "registry.connect.redhat.com/ibm/spectrum-symphony@sha256:1722eae3debcab3354a17c019cb38dc15acb71c6fed33585f669c9caceefc877",
          "name": "spectrum-symphony-1722eae3debcab3354a17c019cb38dc15acb71c6fed33585f669c9caceefc877-annotation"
        }
      ],
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "1.1.2",
      "version_original": "1.1.2"
    }
  ],
  "page": 21,
  "page_size": 100,
  "total": 3345
}
