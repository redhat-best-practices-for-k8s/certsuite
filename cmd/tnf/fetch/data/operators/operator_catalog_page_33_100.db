{
  "data": [
    {
      "_id": "6281c4beded3b14cfb80e776",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:c4611b427d4fcc9b7ae59ff170cb2336c162cd3a1672d19f41305aa4fa7aaa6b",
      "bundle_path_digest": "sha256:c4611b427d4fcc9b7ae59ff170cb2336c162cd3a1672d19f41305aa4fa7aaa6b",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-16T03:27:58.226000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.5.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:13:53.952000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator-e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47-annotation"
        },
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:c766014cd4f4ba08c4daec2486866e89428c35f121661d40ab7f9876db639dd4",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:c766014cd4f4ba08c4daec2486866e89428c35f121661d40ab7f9876db639dd4",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "8.5.3",
      "version_original": "8.5.3"
    },
    {
      "_id": "6282d0075cbc1cba9c78cbdd",
      "alm_examples": [
        {
          "api_version": "deviceplugin.intel.com/v1",
          "kind": "SgxDevicePlugin",
          "metadata": {
            "name": "sgxdeviceplugin-sample"
          },
          "spec": {
            "enclaveLimit": 110,
            "image": "registry.connect.redhat.com/intel/intel-sgx-plugin@sha256:c0423b149b909472460f84a299b087a5104ed40a3572687d6b450609e3bb3076",
            "initImage": "registry.connect.redhat.com/intel/intel-sgx-initcontainer@sha256:236cc06aea0b957eb0a67aa2c8b2778a485b34f8d4aeec691f0de4a6baccf364",
            "logLevel": 4,
            "nodeSelector": {
              "intel.feature.node.kubernetes.io/sgx": "true"
            },
            "provisionLimit": 110
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/intel/intel-device-plugins-operator-bundle@sha256:47efe9eb7a9d540931ceacf85abfaef8ef4208703174b17ee9ce908d62cca9ed",
      "bundle_path_digest": "sha256:47efe9eb7a9d540931ceacf85abfaef8ef4208703174b17ee9ce908d62cca9ed",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-05-16T22:28:23.382000+00:00",
      "csv_description": "[Intel Device Plugins for Kubernetes](https://github.com/intel/intel-device-plugins-for-kubernetes) is a collection of\n[device plugins](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/) advertising Intel specific hardware resources\nto the kubelet. Currently the operator only supports the Intel SGX device plugin. Other device plugins like Intel GPU, Intel QAT, Intel DSA, Intel IAA will be supported in future releases.\n",
      "csv_display_name": "Intel Device Plugins Operator",
      "csv_metadata_description": "This operator is a Kubernetes custom controller whose goal is to serve the installation and lifecycle management of Intel device plugins for Kubernetes.",
      "csv_name": "intel-device-plugins-operator.v0.24.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:25:42.455000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "intel-device-plugins-operator",
      "provided_apis": [
        {
          "group": "deviceplugin.intel.com",
          "kind": "SgxDevicePlugin",
          "version": "v1"
        }
      ],
      "provider": "Intel\u00ae Corporation",
      "related_images": [
        {
          "digest": "sha256:c92c19d283f5292916258b393e765d0d00f81e9150be75d4d8ec68796d408ecd",
          "image": "registry.connect.redhat.com/intel/intel-deviceplugin-operator@sha256:c92c19d283f5292916258b393e765d0d00f81e9150be75d4d8ec68796d408ecd",
          "name": "intel-deviceplugin-operator-c92c19d283f5292916258b393e765d0d00f81e9150be75d4d8ec68796d408ecd-annotation"
        },
        {
          "digest": "sha256:c92c19d283f5292916258b393e765d0d00f81e9150be75d4d8ec68796d408ecd",
          "image": "registry.connect.redhat.com/intel/intel-deviceplugin-operator@sha256:c92c19d283f5292916258b393e765d0d00f81e9150be75d4d8ec68796d408ecd",
          "name": "manager"
        },
        {
          "digest": "sha256:e10d1d982dd653db74ca87a1d1ad017bc5ef1aeb651bdea089debf16485b080b",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:e10d1d982dd653db74ca87a1d1ad017bc5ef1aeb651bdea089debf16485b080b",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:236cc06aea0b957eb0a67aa2c8b2778a485b34f8d4aeec691f0de4a6baccf364",
          "image": "registry.connect.redhat.com/intel/intel-sgx-initcontainer@sha256:236cc06aea0b957eb0a67aa2c8b2778a485b34f8d4aeec691f0de4a6baccf364",
          "name": "intel-sgx-initcontainer-236cc06aea0b957eb0a67aa2c8b2778a485b34f8d4aeec691f0de4a6baccf364-annotation"
        },
        {
          "digest": "sha256:c0423b149b909472460f84a299b087a5104ed40a3572687d6b450609e3bb3076",
          "image": "registry.connect.redhat.com/intel/intel-sgx-plugin@sha256:c0423b149b909472460f84a299b087a5104ed40a3572687d6b450609e3bb3076",
          "name": "intel-sgx-plugin-c0423b149b909472460f84a299b087a5104ed40a3572687d6b450609e3bb3076-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "0.24.0",
      "version_original": "0.24.0"
    },
    {
      "_id": "6282d1cbc8a338bed8baf0b2",
      "alm_examples": [
        {
          "api_version": "deviceplugin.intel.com/v1",
          "kind": "SgxDevicePlugin",
          "metadata": {
            "name": "sgxdeviceplugin-sample"
          },
          "spec": {
            "enclaveLimit": 110,
            "image": "registry.connect.redhat.com/intel/intel-sgx-plugin@sha256:c0423b149b909472460f84a299b087a5104ed40a3572687d6b450609e3bb3076",
            "initImage": "registry.connect.redhat.com/intel/intel-sgx-initcontainer@sha256:236cc06aea0b957eb0a67aa2c8b2778a485b34f8d4aeec691f0de4a6baccf364",
            "logLevel": 4,
            "nodeSelector": {
              "intel.feature.node.kubernetes.io/sgx": "true"
            },
            "provisionLimit": 110
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/intel/intel-device-plugins-operator-bundle@sha256:47efe9eb7a9d540931ceacf85abfaef8ef4208703174b17ee9ce908d62cca9ed",
      "bundle_path_digest": "sha256:47efe9eb7a9d540931ceacf85abfaef8ef4208703174b17ee9ce908d62cca9ed",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-05-16T22:35:55.932000+00:00",
      "csv_description": "[Intel Device Plugins for Kubernetes](https://github.com/intel/intel-device-plugins-for-kubernetes) is a collection of\n[device plugins](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/) advertising Intel specific hardware resources\nto the kubelet. Currently the operator only supports the Intel SGX device plugin. Other device plugins like Intel GPU, Intel QAT, Intel DSA, Intel IAA will be supported in future releases.\n",
      "csv_display_name": "Intel Device Plugins Operator",
      "csv_metadata_description": "This operator is a Kubernetes custom controller whose goal is to serve the installation and lifecycle management of Intel device plugins for Kubernetes.",
      "csv_name": "intel-device-plugins-operator.v0.24.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:01:48.308000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "intel-device-plugins-operator",
      "provided_apis": [
        {
          "group": "deviceplugin.intel.com",
          "kind": "SgxDevicePlugin",
          "plural": "sgxdeviceplugins",
          "version": "v1"
        }
      ],
      "provider": "Intel\u00ae Corporation",
      "related_images": [
        {
          "digest": "sha256:c92c19d283f5292916258b393e765d0d00f81e9150be75d4d8ec68796d408ecd",
          "image": "registry.connect.redhat.com/intel/intel-deviceplugin-operator@sha256:c92c19d283f5292916258b393e765d0d00f81e9150be75d4d8ec68796d408ecd",
          "name": "intel-deviceplugin-operator-c92c19d283f5292916258b393e765d0d00f81e9150be75d4d8ec68796d408ecd-annotation"
        },
        {
          "digest": "sha256:c92c19d283f5292916258b393e765d0d00f81e9150be75d4d8ec68796d408ecd",
          "image": "registry.connect.redhat.com/intel/intel-deviceplugin-operator@sha256:c92c19d283f5292916258b393e765d0d00f81e9150be75d4d8ec68796d408ecd",
          "name": "manager"
        },
        {
          "digest": "sha256:e10d1d982dd653db74ca87a1d1ad017bc5ef1aeb651bdea089debf16485b080b",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:e10d1d982dd653db74ca87a1d1ad017bc5ef1aeb651bdea089debf16485b080b",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:236cc06aea0b957eb0a67aa2c8b2778a485b34f8d4aeec691f0de4a6baccf364",
          "image": "registry.connect.redhat.com/intel/intel-sgx-initcontainer@sha256:236cc06aea0b957eb0a67aa2c8b2778a485b34f8d4aeec691f0de4a6baccf364",
          "name": "intel-sgx-initcontainer-236cc06aea0b957eb0a67aa2c8b2778a485b34f8d4aeec691f0de4a6baccf364-annotation"
        },
        {
          "digest": "sha256:c0423b149b909472460f84a299b087a5104ed40a3572687d6b450609e3bb3076",
          "image": "registry.connect.redhat.com/intel/intel-sgx-plugin@sha256:c0423b149b909472460f84a299b087a5104ed40a3572687d6b450609e3bb3076",
          "name": "intel-sgx-plugin-c0423b149b909472460f84a299b087a5104ed40a3572687d6b450609e3bb3076-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "0.24.0",
      "version_original": "0.24.0"
    },
    {
      "_id": "62834d5ec8a338bed8bafe28",
      "alm_examples": [
        {
          "api_version": "app.joget.com/v1alpha1",
          "kind": "JogetDX",
          "metadata": {
            "name": "example-joget"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/joget/joget-dx-operator-bundle@sha256:37008543a382b540053595c4210bed1ee3062128be472eeade9b037528192092",
      "bundle_path_digest": "sha256:37008543a382b540053595c4210bed1ee3062128be472eeade9b037528192092",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-05-17T07:23:10.906000+00:00",
      "csv_description": "Joget DX is the next generation open source no-code / low-code application platform that combines the best of Rapid Application Development, Business Process Automation and Workflow Management. \nJoget DX empowers business users, non-coders or coders with a single platform to easily build, deliver, monitor and maintain enterprise applications.\n\nThis operator installs a Joget DX cluster running on JBoss EAP 7.\n\n### Features\n* Build full-fledged apps e.g. CRM, HR, Healthcare, etc\n* Drag and drop forms, lists, UI\n* Add workflow to automate processes\n* Extend via plugins\n* Apps are mobile optimized and cloud ready\n* Download ready-made apps from the Joget Marketplace\n\n### Before You Start\nDeploy a [MySQL](https://docs.openshift.com/online/pro/using_images/db_images/mysql.html) or [MariaDB](https://docs.openshift.com/online/pro/using_images/db_images/mariadb.html) database.\n\n### Post Deployment\nAccess the service URL and complete the one-time [Database Setup](https://dev.joget.org/community/display/DX7/Setting+Up+Database)\n\n### More Information\nMore information about Joget DX on JBoss EAP 7 is available in the [Joget Knowledge Base](https://dev.joget.org/community/display/DX7/Automated+Deployment+on+Red+Hat+OpenShift+with+the+Joget+Operator)\n",
      "csv_display_name": "Joget DX Operator",
      "csv_metadata_description": "No-code/low-code application platform to visually build, run and maintain apps",
      "csv_name": "joget-dx-openshift-operator.v0.0.29",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:14:22.395000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "joget-dx-operator",
      "provided_apis": [
        {
          "group": "app.joget.com",
          "kind": "JogetDX",
          "version": "v1alpha1"
        }
      ],
      "provider": "Joget, Inc",
      "related_images": [
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "joget-dx-operator-79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749-annotation"
        },
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "operator"
        },
        {
          "digest": "sha256:9db5627766c81e99d6ef6cb40b6532a766b991881d8197ab543a35d5c6e3a87a",
          "image": "registry.connect.redhat.com/joget/joget-dx7-eap7@sha256:9db5627766c81e99d6ef6cb40b6532a766b991881d8197ab543a35d5c6e3a87a",
          "name": "joget"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "0.0.29",
      "version_original": "0.0.29"
    },
    {
      "_id": "62835186ded3b14cfb8100e1",
      "alm_examples": [
        {
          "api_version": "app.joget.com/v1alpha1",
          "kind": "JogetDX",
          "metadata": {
            "name": "example-joget"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/joget/joget-dx-operator-bundle@sha256:37008543a382b540053595c4210bed1ee3062128be472eeade9b037528192092",
      "bundle_path_digest": "sha256:37008543a382b540053595c4210bed1ee3062128be472eeade9b037528192092",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-05-17T07:40:54.438000+00:00",
      "csv_description": "Joget DX is the next generation open source no-code / low-code application platform that combines the best of Rapid Application Development, Business Process Automation and Workflow Management. \nJoget DX empowers business users, non-coders or coders with a single platform to easily build, deliver, monitor and maintain enterprise applications.\n\nThis operator installs a Joget DX cluster running on JBoss EAP 7.\n\n### Features\n* Build full-fledged apps e.g. CRM, HR, Healthcare, etc\n* Drag and drop forms, lists, UI\n* Add workflow to automate processes\n* Extend via plugins\n* Apps are mobile optimized and cloud ready\n* Download ready-made apps from the Joget Marketplace\n\n### Before You Start\nDeploy a [MySQL](https://docs.openshift.com/online/pro/using_images/db_images/mysql.html) or [MariaDB](https://docs.openshift.com/online/pro/using_images/db_images/mariadb.html) database.\n\n### Post Deployment\nAccess the service URL and complete the one-time [Database Setup](https://dev.joget.org/community/display/DX7/Setting+Up+Database)\n\n### More Information\nMore information about Joget DX on JBoss EAP 7 is available in the [Joget Knowledge Base](https://dev.joget.org/community/display/DX7/Automated+Deployment+on+Red+Hat+OpenShift+with+the+Joget+Operator)\n",
      "csv_display_name": "Joget DX Operator",
      "csv_metadata_description": "No-code/low-code application platform to visually build, run and maintain apps",
      "csv_name": "joget-dx-openshift-operator.v0.0.29",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:02:44.936000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "joget-dx-operator",
      "provided_apis": [
        {
          "group": "app.joget.com",
          "kind": "JogetDX",
          "plural": "jogetdx",
          "version": "v1alpha1"
        }
      ],
      "provider": "Joget, Inc",
      "related_images": [
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "joget-dx-operator-79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749-annotation"
        },
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "operator"
        },
        {
          "digest": "sha256:9db5627766c81e99d6ef6cb40b6532a766b991881d8197ab543a35d5c6e3a87a",
          "image": "registry.connect.redhat.com/joget/joget-dx7-eap7@sha256:9db5627766c81e99d6ef6cb40b6532a766b991881d8197ab543a35d5c6e3a87a",
          "name": "joget"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "0.0.29",
      "version_original": "0.0.29"
    },
    {
      "_id": "62835261ded3b14cfb8100ee",
      "alm_examples": [
        {
          "api_version": "app.joget.com/v1alpha1",
          "kind": "JogetDX",
          "metadata": {
            "name": "example-joget"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/joget/joget-dx-operator-bundle@sha256:37008543a382b540053595c4210bed1ee3062128be472eeade9b037528192092",
      "bundle_path_digest": "sha256:37008543a382b540053595c4210bed1ee3062128be472eeade9b037528192092",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-05-17T07:44:33.046000+00:00",
      "csv_description": "Joget DX is the next generation open source no-code / low-code application platform that combines the best of Rapid Application Development, Business Process Automation and Workflow Management. \nJoget DX empowers business users, non-coders or coders with a single platform to easily build, deliver, monitor and maintain enterprise applications.\n\nThis operator installs a Joget DX cluster running on JBoss EAP 7.\n\n### Features\n* Build full-fledged apps e.g. CRM, HR, Healthcare, etc\n* Drag and drop forms, lists, UI\n* Add workflow to automate processes\n* Extend via plugins\n* Apps are mobile optimized and cloud ready\n* Download ready-made apps from the Joget Marketplace\n\n### Before You Start\nDeploy a [MySQL](https://docs.openshift.com/online/pro/using_images/db_images/mysql.html) or [MariaDB](https://docs.openshift.com/online/pro/using_images/db_images/mariadb.html) database.\n\n### Post Deployment\nAccess the service URL and complete the one-time [Database Setup](https://dev.joget.org/community/display/DX7/Setting+Up+Database)\n\n### More Information\nMore information about Joget DX on JBoss EAP 7 is available in the [Joget Knowledge Base](https://dev.joget.org/community/display/DX7/Automated+Deployment+on+Red+Hat+OpenShift+with+the+Joget+Operator)\n",
      "csv_display_name": "Joget DX Operator",
      "csv_metadata_description": "No-code/low-code application platform to visually build, run and maintain apps",
      "csv_name": "joget-dx-openshift-operator.v0.0.29",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:04:54.046000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "joget-dx-operator",
      "provided_apis": [
        {
          "group": "app.joget.com",
          "kind": "JogetDX",
          "plural": "jogetdx",
          "version": "v1alpha1"
        }
      ],
      "provider": "Joget, Inc",
      "related_images": [
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "joget-dx-operator-79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749-annotation"
        },
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "operator"
        },
        {
          "digest": "sha256:9db5627766c81e99d6ef6cb40b6532a766b991881d8197ab543a35d5c6e3a87a",
          "image": "registry.connect.redhat.com/joget/joget-dx7-eap7@sha256:9db5627766c81e99d6ef6cb40b6532a766b991881d8197ab543a35d5c6e3a87a",
          "name": "joget"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "0.0.29",
      "version_original": "0.0.29"
    },
    {
      "_id": "6283530fded3b14cfb8100f9",
      "alm_examples": [
        {
          "api_version": "app.joget.com/v1alpha1",
          "kind": "JogetDX",
          "metadata": {
            "name": "example-joget"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/joget/joget-dx-operator-bundle@sha256:37008543a382b540053595c4210bed1ee3062128be472eeade9b037528192092",
      "bundle_path_digest": "sha256:37008543a382b540053595c4210bed1ee3062128be472eeade9b037528192092",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-05-17T07:47:27.349000+00:00",
      "csv_description": "Joget DX is the next generation open source no-code / low-code application platform that combines the best of Rapid Application Development, Business Process Automation and Workflow Management. \nJoget DX empowers business users, non-coders or coders with a single platform to easily build, deliver, monitor and maintain enterprise applications.\n\nThis operator installs a Joget DX cluster running on JBoss EAP 7.\n\n### Features\n* Build full-fledged apps e.g. CRM, HR, Healthcare, etc\n* Drag and drop forms, lists, UI\n* Add workflow to automate processes\n* Extend via plugins\n* Apps are mobile optimized and cloud ready\n* Download ready-made apps from the Joget Marketplace\n\n### Before You Start\nDeploy a [MySQL](https://docs.openshift.com/online/pro/using_images/db_images/mysql.html) or [MariaDB](https://docs.openshift.com/online/pro/using_images/db_images/mariadb.html) database.\n\n### Post Deployment\nAccess the service URL and complete the one-time [Database Setup](https://dev.joget.org/community/display/DX7/Setting+Up+Database)\n\n### More Information\nMore information about Joget DX on JBoss EAP 7 is available in the [Joget Knowledge Base](https://dev.joget.org/community/display/DX7/Automated+Deployment+on+Red+Hat+OpenShift+with+the+Joget+Operator)\n",
      "csv_display_name": "Joget DX Operator",
      "csv_metadata_description": "No-code/low-code application platform to visually build, run and maintain apps",
      "csv_name": "joget-dx-openshift-operator.v0.0.29",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:00:55.507000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "joget-dx-operator",
      "provided_apis": [
        {
          "group": "app.joget.com",
          "kind": "JogetDX",
          "plural": "jogetdx",
          "version": "v1alpha1"
        }
      ],
      "provider": "Joget, Inc",
      "related_images": [
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "joget-dx-operator-79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749-annotation"
        },
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "operator"
        },
        {
          "digest": "sha256:9db5627766c81e99d6ef6cb40b6532a766b991881d8197ab543a35d5c6e3a87a",
          "image": "registry.connect.redhat.com/joget/joget-dx7-eap7@sha256:9db5627766c81e99d6ef6cb40b6532a766b991881d8197ab543a35d5c6e3a87a",
          "name": "joget"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "0.0.29",
      "version_original": "0.0.29"
    },
    {
      "_id": "62835377ded3b14cfb810102",
      "alm_examples": [
        {
          "api_version": "app.joget.com/v1alpha1",
          "kind": "JogetDX",
          "metadata": {
            "name": "example-joget"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/joget/joget-dx-operator-bundle@sha256:37008543a382b540053595c4210bed1ee3062128be472eeade9b037528192092",
      "bundle_path_digest": "sha256:37008543a382b540053595c4210bed1ee3062128be472eeade9b037528192092",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-05-17T07:49:11.347000+00:00",
      "csv_description": "Joget DX is the next generation open source no-code / low-code application platform that combines the best of Rapid Application Development, Business Process Automation and Workflow Management. \nJoget DX empowers business users, non-coders or coders with a single platform to easily build, deliver, monitor and maintain enterprise applications.\n\nThis operator installs a Joget DX cluster running on JBoss EAP 7.\n\n### Features\n* Build full-fledged apps e.g. CRM, HR, Healthcare, etc\n* Drag and drop forms, lists, UI\n* Add workflow to automate processes\n* Extend via plugins\n* Apps are mobile optimized and cloud ready\n* Download ready-made apps from the Joget Marketplace\n\n### Before You Start\nDeploy a [MySQL](https://docs.openshift.com/online/pro/using_images/db_images/mysql.html) or [MariaDB](https://docs.openshift.com/online/pro/using_images/db_images/mariadb.html) database.\n\n### Post Deployment\nAccess the service URL and complete the one-time [Database Setup](https://dev.joget.org/community/display/DX7/Setting+Up+Database)\n\n### More Information\nMore information about Joget DX on JBoss EAP 7 is available in the [Joget Knowledge Base](https://dev.joget.org/community/display/DX7/Automated+Deployment+on+Red+Hat+OpenShift+with+the+Joget+Operator)\n",
      "csv_display_name": "Joget DX Operator",
      "csv_metadata_description": "No-code/low-code application platform to visually build, run and maintain apps",
      "csv_name": "joget-dx-openshift-operator.v0.0.29",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:35:54.530000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "joget-dx-operator",
      "provided_apis": [
        {
          "group": "app.joget.com",
          "kind": "JogetDX",
          "plural": "jogetdx",
          "version": "v1alpha1"
        }
      ],
      "provider": "Joget, Inc",
      "related_images": [
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "joget-dx-operator-79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749-annotation"
        },
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "operator"
        },
        {
          "digest": "sha256:9db5627766c81e99d6ef6cb40b6532a766b991881d8197ab543a35d5c6e3a87a",
          "image": "registry.connect.redhat.com/joget/joget-dx7-eap7@sha256:9db5627766c81e99d6ef6cb40b6532a766b991881d8197ab543a35d5c6e3a87a",
          "name": "joget"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "0.0.29",
      "version_original": "0.0.29"
    },
    {
      "_id": "6283f5167aa88cb2990559c1",
      "alm_examples": [
        {
          "api_version": "sts.silicom.com/v1alpha1",
          "kind": "StsConfig",
          "metadata": {
            "name": "gm-1",
            "namespace": "openshift-operators"
          },
          "spec": {
            "interfaces": [
              {
                "ethName": "enp2s0f0",
                "ethPort": 0,
                "holdoff": 500,
                "mode": "Master",
                "synce": 1
              },
              {
                "ethName": "enp2s0f1",
                "ethPort": 1,
                "holdoff": 500,
                "mode": "Master",
                "synce": 1
              }
            ],
            "mode": "T-GM.8275.1",
            "namespace": "openshift-operators",
            "nodeSelector": {
              "sts.silicom.com/config": "gm-1"
            }
          }
        },
        {
          "api_version": "sts.silicom.com/v1alpha1",
          "kind": "StsConfig",
          "metadata": {
            "name": "bc-1"
          },
          "spec": {
            "aprLevel": 0,
            "domainNumber": 24,
            "esmcMode": 1,
            "forwardable": 0,
            "interfaces": [
              {
                "ethName": "enp2s0f0",
                "ethPort": 0,
                "holdoff": 500,
                "ipv4": 1,
                "ipv6": 1,
                "mode": "Slave",
                "ql": 4,
                "qlEnable": 1,
                "synce": 1
              },
              {
                "ethName": "enp2s0f1",
                "ethPort": 1,
                "holdoff": 500,
                "ipv4": 1,
                "ipv6": 1,
                "mode": "Master",
                "ql": 4,
                "qlEnable": 1,
                "synce": 1
              },
              {
                "ethName": "enp2s0f2",
                "ethPort": 2,
                "holdoff": 500,
                "ipv4": 1,
                "mode": "Master",
                "ql": 4,
                "qlEnable": 1,
                "synce": 1
              }
            ],
            "mode": "T-TBC.8275.1",
            "mode10MHz": 2,
            "modePPS": 2,
            "namespace": "openshift-operators",
            "nodeSelector": {
              "sts.silicom.com/config": "bc-1"
            },
            "phyLedsCtl": 0,
            "priority2": 128,
            "src10MHz": 1,
            "srcPPS": 1,
            "syncOption": 1,
            "synceCpu": 10,
            "synceRecClkPort": 0,
            "tracePtpMsg": -1,
            "twoStep": 0
          }
        },
        {
          "api_version": "sts.silicom.com/v1alpha1",
          "kind": "StsNode",
          "metadata": {
            "name": "worker2"
          },
          "spec": {}
        },
        {
          "api_version": "sts.silicom.com/v1alpha1",
          "kind": "StsOperatorConfig",
          "metadata": {
            "name": "sts-operator-config",
            "namespace": "openshift-operators"
          },
          "spec": {
            "images": {},
            "sro": {}
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [
        "amd64"
      ],
      "bundle_path": "registry.connect.redhat.com/silicomltd/silicom-sts-operator@sha256:3d60984e2c198e8defe3cbd56dd784d2bdf0b30c9b4cfcd1709f19e10aa227b5",
      "bundle_path_digest": "sha256:3d60984e2c198e8defe3cbd56dd784d2bdf0b30c9b4cfcd1709f19e10aa227b5",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-05-17T19:18:46.766000+00:00",
      "csv_description": "Silicom STS line card for 4G and 5G NIC enable real-time data transmission\nwith high timing accuracy at the lowest cost to power 5G DRAN and CRAN edge\ndeployments.\n\n* Support 1588/PTP over IPv4 / IPV6, IEEE1588v2\n* Support SyncE /ITU-T G.8262\n* T-BC/T-TSC Boundary Clock and TSC Slave Clock /G.8273.2\n* T-GM Grand Master /G.8273.1 per G.8275.1 PTP Profile\n* PRTC Primary Reference Time Clock Class B/G.8272\n* T-TC Transparent Clock /G.8273.3\n* 1588 Software Stack and Servo Software in x86\n* [Silicom STS2 Card](https://www.silicom-usa.com/pr/server-adapters/networking-adapters/10-gigabit-ethernet-networking-adapters/p410g8ts81-timesync-server-adapter)\n\n### Prequisites:\n* [NFD Operator](https://operatorhub.io/operator/nfd-operator \"NFD operator needed for the discovery of STS cards\").\n* [SRO Operator](https://github.com/openshift/special-resource-operator)\n",
      "csv_display_name": "Silicom STS Operator",
      "csv_metadata_description": "This Operator is a Kubernetes custom controller whose goal\nis to serve the installation and lifecycle management of\nSilicom STS device plugins for Kubernetes.\n",
      "csv_name": "silicom-sts-operator.v0.0.7",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:17:47.521000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "silicom-sts-operator",
      "provided_apis": [
        {
          "group": "sts.silicom.com",
          "kind": "StsConfig",
          "version": "v1alpha1"
        },
        {
          "group": "sts.silicom.com",
          "kind": "StsNode",
          "version": "v1alpha1"
        },
        {
          "group": "sts.silicom.com",
          "kind": "StsOperatorConfig",
          "version": "v1alpha1"
        }
      ],
      "provider": "Silicom Ltd.",
      "related_images": [
        {
          "digest": "sha256:649e8a6c524920e1c564d8f797b8d64235b2527aa923f94bc9c7a0b7aba8ae7f",
          "image": "quay.io/silicom/gpsd@sha256:649e8a6c524920e1c564d8f797b8d64235b2527aa923f94bc9c7a0b7aba8ae7f",
          "name": "gpsd"
        },
        {
          "digest": "sha256:0f3b63a3059b7d6158a916814281097f0d418b99a5fac9e8e5fd9bae58fb0b74",
          "image": "quay.io/silicom/phc2sys@sha256:0f3b63a3059b7d6158a916814281097f0d418b99a5fac9e8e5fd9bae58fb0b74",
          "name": "phc2sys"
        },
        {
          "digest": "sha256:78be78ec8939f025f9a8b899693ab77b3990116d1c7ffb2115c620b7c3382d9d",
          "image": "quay.io/silicom/tsyncd@sha256:78be78ec8939f025f9a8b899693ab77b3990116d1c7ffb2115c620b7c3382d9d",
          "name": "tsyncd"
        },
        {
          "digest": "sha256:aac7233423439e352d8eb39cef63e479c30c2f80b063c84ffc8797cc5a045117",
          "image": "quay.io/silicom/grpc-tsyncd@sha256:aac7233423439e352d8eb39cef63e479c30c2f80b063c84ffc8797cc5a045117",
          "name": "grpc-tsyncd"
        },
        {
          "digest": "sha256:be6a5950a5fdc6fdf8015767901856bf173d01bdc803be7141e4f9795ab1478a",
          "image": "quay.io/silicom/tsync_extts@sha256:be6a5950a5fdc6fdf8015767901856bf173d01bdc803be7141e4f9795ab1478a",
          "name": "tsync_extts"
        },
        {
          "digest": "sha256:86562c40a07ef8dc198bd53562ae332d89d9ea5d45b8e8aa9d3685bc6f7ee60f",
          "image": "quay.io/silicom/sts-plugin@sha256:86562c40a07ef8dc198bd53562ae332d89d9ea5d45b8e8aa9d3685bc6f7ee60f",
          "name": "sts-plugin"
        },
        {
          "digest": "sha256:6bb07b26f669d9fe853a06a0262c5ee033fbb26bab202d84572b099ef852751c",
          "image": "quay.io/silicom/ice-driver-src@sha256:6bb07b26f669d9fe853a06a0262c5ee033fbb26bab202d84572b099ef852751c",
          "name": "ice-driver-src"
        },
        {
          "digest": "sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "image": "quay.io/silicom/sts-operator@sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "name": "sts-operator"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "image": "quay.io/silicom/sts-operator@sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "name": "sts-operator-a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5-annotation"
        },
        {
          "digest": "sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "image": "quay.io/silicom/sts-operator@sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "0.0.7",
      "version_original": "0.0.7"
    },
    {
      "_id": "6283f5ad5a88c04949a599c7",
      "alm_examples": [
        {
          "api_version": "sts.silicom.com/v1alpha1",
          "kind": "StsConfig",
          "metadata": {
            "name": "gm-1",
            "namespace": "openshift-operators"
          },
          "spec": {
            "interfaces": [
              {
                "ethName": "enp2s0f0",
                "ethPort": 0,
                "holdoff": 500,
                "mode": "Master",
                "synce": 1
              },
              {
                "ethName": "enp2s0f1",
                "ethPort": 1,
                "holdoff": 500,
                "mode": "Master",
                "synce": 1
              }
            ],
            "mode": "T-GM.8275.1",
            "namespace": "openshift-operators",
            "nodeSelector": {
              "sts.silicom.com/config": "gm-1"
            }
          }
        },
        {
          "api_version": "sts.silicom.com/v1alpha1",
          "kind": "StsConfig",
          "metadata": {
            "name": "bc-1"
          },
          "spec": {
            "aprLevel": 0,
            "domainNumber": 24,
            "esmcMode": 1,
            "forwardable": 0,
            "interfaces": [
              {
                "ethName": "enp2s0f0",
                "ethPort": 0,
                "holdoff": 500,
                "ipv4": 1,
                "ipv6": 1,
                "mode": "Slave",
                "ql": 4,
                "qlEnable": 1,
                "synce": 1
              },
              {
                "ethName": "enp2s0f1",
                "ethPort": 1,
                "holdoff": 500,
                "ipv4": 1,
                "ipv6": 1,
                "mode": "Master",
                "ql": 4,
                "qlEnable": 1,
                "synce": 1
              },
              {
                "ethName": "enp2s0f2",
                "ethPort": 2,
                "holdoff": 500,
                "ipv4": 1,
                "mode": "Master",
                "ql": 4,
                "qlEnable": 1,
                "synce": 1
              }
            ],
            "mode": "T-TBC.8275.1",
            "mode10MHz": 2,
            "modePPS": 2,
            "namespace": "openshift-operators",
            "nodeSelector": {
              "sts.silicom.com/config": "bc-1"
            },
            "phyLedsCtl": 0,
            "priority2": 128,
            "src10MHz": 1,
            "srcPPS": 1,
            "syncOption": 1,
            "synceCpu": 10,
            "synceRecClkPort": 0,
            "tracePtpMsg": -1,
            "twoStep": 0
          }
        },
        {
          "api_version": "sts.silicom.com/v1alpha1",
          "kind": "StsNode",
          "metadata": {
            "name": "worker2"
          },
          "spec": {}
        },
        {
          "api_version": "sts.silicom.com/v1alpha1",
          "kind": "StsOperatorConfig",
          "metadata": {
            "name": "sts-operator-config",
            "namespace": "openshift-operators"
          },
          "spec": {
            "images": {},
            "sro": {}
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [
        "amd64"
      ],
      "bundle_path": "registry.connect.redhat.com/silicomltd/silicom-sts-operator@sha256:3d60984e2c198e8defe3cbd56dd784d2bdf0b30c9b4cfcd1709f19e10aa227b5",
      "bundle_path_digest": "sha256:3d60984e2c198e8defe3cbd56dd784d2bdf0b30c9b4cfcd1709f19e10aa227b5",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-05-17T19:21:17.813000+00:00",
      "csv_description": "Silicom STS line card for 4G and 5G NIC enable real-time data transmission\nwith high timing accuracy at the lowest cost to power 5G DRAN and CRAN edge\ndeployments.\n\n* Support 1588/PTP over IPv4 / IPV6, IEEE1588v2\n* Support SyncE /ITU-T G.8262\n* T-BC/T-TSC Boundary Clock and TSC Slave Clock /G.8273.2\n* T-GM Grand Master /G.8273.1 per G.8275.1 PTP Profile\n* PRTC Primary Reference Time Clock Class B/G.8272\n* T-TC Transparent Clock /G.8273.3\n* 1588 Software Stack and Servo Software in x86\n* [Silicom STS2 Card](https://www.silicom-usa.com/pr/server-adapters/networking-adapters/10-gigabit-ethernet-networking-adapters/p410g8ts81-timesync-server-adapter)\n\n### Prequisites:\n* [NFD Operator](https://operatorhub.io/operator/nfd-operator \"NFD operator needed for the discovery of STS cards\").\n* [SRO Operator](https://github.com/openshift/special-resource-operator)\n",
      "csv_display_name": "Silicom STS Operator",
      "csv_metadata_description": "This Operator is a Kubernetes custom controller whose goal\nis to serve the installation and lifecycle management of\nSilicom STS device plugins for Kubernetes.\n",
      "csv_name": "silicom-sts-operator.v0.0.7",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:11:15.180000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "silicom-sts-operator",
      "provided_apis": [
        {
          "group": "sts.silicom.com",
          "kind": "StsConfig",
          "version": "v1alpha1"
        },
        {
          "group": "sts.silicom.com",
          "kind": "StsNode",
          "version": "v1alpha1"
        },
        {
          "group": "sts.silicom.com",
          "kind": "StsOperatorConfig",
          "version": "v1alpha1"
        }
      ],
      "provider": "Silicom Ltd.",
      "related_images": [
        {
          "digest": "sha256:649e8a6c524920e1c564d8f797b8d64235b2527aa923f94bc9c7a0b7aba8ae7f",
          "image": "quay.io/silicom/gpsd@sha256:649e8a6c524920e1c564d8f797b8d64235b2527aa923f94bc9c7a0b7aba8ae7f",
          "name": "gpsd"
        },
        {
          "digest": "sha256:0f3b63a3059b7d6158a916814281097f0d418b99a5fac9e8e5fd9bae58fb0b74",
          "image": "quay.io/silicom/phc2sys@sha256:0f3b63a3059b7d6158a916814281097f0d418b99a5fac9e8e5fd9bae58fb0b74",
          "name": "phc2sys"
        },
        {
          "digest": "sha256:78be78ec8939f025f9a8b899693ab77b3990116d1c7ffb2115c620b7c3382d9d",
          "image": "quay.io/silicom/tsyncd@sha256:78be78ec8939f025f9a8b899693ab77b3990116d1c7ffb2115c620b7c3382d9d",
          "name": "tsyncd"
        },
        {
          "digest": "sha256:aac7233423439e352d8eb39cef63e479c30c2f80b063c84ffc8797cc5a045117",
          "image": "quay.io/silicom/grpc-tsyncd@sha256:aac7233423439e352d8eb39cef63e479c30c2f80b063c84ffc8797cc5a045117",
          "name": "grpc-tsyncd"
        },
        {
          "digest": "sha256:be6a5950a5fdc6fdf8015767901856bf173d01bdc803be7141e4f9795ab1478a",
          "image": "quay.io/silicom/tsync_extts@sha256:be6a5950a5fdc6fdf8015767901856bf173d01bdc803be7141e4f9795ab1478a",
          "name": "tsync_extts"
        },
        {
          "digest": "sha256:86562c40a07ef8dc198bd53562ae332d89d9ea5d45b8e8aa9d3685bc6f7ee60f",
          "image": "quay.io/silicom/sts-plugin@sha256:86562c40a07ef8dc198bd53562ae332d89d9ea5d45b8e8aa9d3685bc6f7ee60f",
          "name": "sts-plugin"
        },
        {
          "digest": "sha256:6bb07b26f669d9fe853a06a0262c5ee033fbb26bab202d84572b099ef852751c",
          "image": "quay.io/silicom/ice-driver-src@sha256:6bb07b26f669d9fe853a06a0262c5ee033fbb26bab202d84572b099ef852751c",
          "name": "ice-driver-src"
        },
        {
          "digest": "sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "image": "quay.io/silicom/sts-operator@sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "name": "sts-operator"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "image": "quay.io/silicom/sts-operator@sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "name": "sts-operator-a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5-annotation"
        },
        {
          "digest": "sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "image": "quay.io/silicom/sts-operator@sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "0.0.7",
      "version_original": "0.0.7"
    },
    {
      "_id": "6283f7f23fcd237f697187d6",
      "alm_examples": [
        {
          "api_version": "sts.silicom.com/v1alpha1",
          "kind": "StsConfig",
          "metadata": {
            "name": "gm-1",
            "namespace": "openshift-operators"
          },
          "spec": {
            "interfaces": [
              {
                "ethName": "enp2s0f0",
                "ethPort": 0,
                "holdoff": 500,
                "mode": "Master",
                "synce": 1
              },
              {
                "ethName": "enp2s0f1",
                "ethPort": 1,
                "holdoff": 500,
                "mode": "Master",
                "synce": 1
              }
            ],
            "mode": "T-GM.8275.1",
            "namespace": "openshift-operators",
            "nodeSelector": {
              "sts.silicom.com/config": "gm-1"
            }
          }
        },
        {
          "api_version": "sts.silicom.com/v1alpha1",
          "kind": "StsConfig",
          "metadata": {
            "name": "bc-1"
          },
          "spec": {
            "aprLevel": 0,
            "domainNumber": 24,
            "esmcMode": 1,
            "forwardable": 0,
            "interfaces": [
              {
                "ethName": "enp2s0f0",
                "ethPort": 0,
                "holdoff": 500,
                "ipv4": 1,
                "ipv6": 1,
                "mode": "Slave",
                "ql": 4,
                "qlEnable": 1,
                "synce": 1
              },
              {
                "ethName": "enp2s0f1",
                "ethPort": 1,
                "holdoff": 500,
                "ipv4": 1,
                "ipv6": 1,
                "mode": "Master",
                "ql": 4,
                "qlEnable": 1,
                "synce": 1
              },
              {
                "ethName": "enp2s0f2",
                "ethPort": 2,
                "holdoff": 500,
                "ipv4": 1,
                "mode": "Master",
                "ql": 4,
                "qlEnable": 1,
                "synce": 1
              }
            ],
            "mode": "T-TBC.8275.1",
            "mode10MHz": 2,
            "modePPS": 2,
            "namespace": "openshift-operators",
            "nodeSelector": {
              "sts.silicom.com/config": "bc-1"
            },
            "phyLedsCtl": 0,
            "priority2": 128,
            "src10MHz": 1,
            "srcPPS": 1,
            "syncOption": 1,
            "synceCpu": 10,
            "synceRecClkPort": 0,
            "tracePtpMsg": -1,
            "twoStep": 0
          }
        },
        {
          "api_version": "sts.silicom.com/v1alpha1",
          "kind": "StsNode",
          "metadata": {
            "name": "worker2"
          },
          "spec": {}
        },
        {
          "api_version": "sts.silicom.com/v1alpha1",
          "kind": "StsOperatorConfig",
          "metadata": {
            "name": "sts-operator-config",
            "namespace": "openshift-operators"
          },
          "spec": {
            "images": {},
            "sro": {}
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [
        "amd64"
      ],
      "bundle_path": "registry.connect.redhat.com/silicomltd/silicom-sts-operator@sha256:3d60984e2c198e8defe3cbd56dd784d2bdf0b30c9b4cfcd1709f19e10aa227b5",
      "bundle_path_digest": "sha256:3d60984e2c198e8defe3cbd56dd784d2bdf0b30c9b4cfcd1709f19e10aa227b5",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-05-17T19:30:58.745000+00:00",
      "csv_description": "Silicom STS line card for 4G and 5G NIC enable real-time data transmission\nwith high timing accuracy at the lowest cost to power 5G DRAN and CRAN edge\ndeployments.\n\n* Support 1588/PTP over IPv4 / IPV6, IEEE1588v2\n* Support SyncE /ITU-T G.8262\n* T-BC/T-TSC Boundary Clock and TSC Slave Clock /G.8273.2\n* T-GM Grand Master /G.8273.1 per G.8275.1 PTP Profile\n* PRTC Primary Reference Time Clock Class B/G.8272\n* T-TC Transparent Clock /G.8273.3\n* 1588 Software Stack and Servo Software in x86\n* [Silicom STS2 Card](https://www.silicom-usa.com/pr/server-adapters/networking-adapters/10-gigabit-ethernet-networking-adapters/p410g8ts81-timesync-server-adapter)\n\n### Prequisites:\n* [NFD Operator](https://operatorhub.io/operator/nfd-operator \"NFD operator needed for the discovery of STS cards\").\n* [SRO Operator](https://github.com/openshift/special-resource-operator)\n",
      "csv_display_name": "Silicom STS Operator",
      "csv_metadata_description": "This Operator is a Kubernetes custom controller whose goal\nis to serve the installation and lifecycle management of\nSilicom STS device plugins for Kubernetes.\n",
      "csv_name": "silicom-sts-operator.v0.0.7",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:11:07.494000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "silicom-sts-operator",
      "provided_apis": [
        {
          "group": "sts.silicom.com",
          "kind": "StsConfig",
          "version": "v1alpha1"
        },
        {
          "group": "sts.silicom.com",
          "kind": "StsNode",
          "version": "v1alpha1"
        },
        {
          "group": "sts.silicom.com",
          "kind": "StsOperatorConfig",
          "version": "v1alpha1"
        }
      ],
      "provider": "Silicom Ltd.",
      "related_images": [
        {
          "digest": "sha256:649e8a6c524920e1c564d8f797b8d64235b2527aa923f94bc9c7a0b7aba8ae7f",
          "image": "quay.io/silicom/gpsd@sha256:649e8a6c524920e1c564d8f797b8d64235b2527aa923f94bc9c7a0b7aba8ae7f",
          "name": "gpsd"
        },
        {
          "digest": "sha256:0f3b63a3059b7d6158a916814281097f0d418b99a5fac9e8e5fd9bae58fb0b74",
          "image": "quay.io/silicom/phc2sys@sha256:0f3b63a3059b7d6158a916814281097f0d418b99a5fac9e8e5fd9bae58fb0b74",
          "name": "phc2sys"
        },
        {
          "digest": "sha256:78be78ec8939f025f9a8b899693ab77b3990116d1c7ffb2115c620b7c3382d9d",
          "image": "quay.io/silicom/tsyncd@sha256:78be78ec8939f025f9a8b899693ab77b3990116d1c7ffb2115c620b7c3382d9d",
          "name": "tsyncd"
        },
        {
          "digest": "sha256:aac7233423439e352d8eb39cef63e479c30c2f80b063c84ffc8797cc5a045117",
          "image": "quay.io/silicom/grpc-tsyncd@sha256:aac7233423439e352d8eb39cef63e479c30c2f80b063c84ffc8797cc5a045117",
          "name": "grpc-tsyncd"
        },
        {
          "digest": "sha256:be6a5950a5fdc6fdf8015767901856bf173d01bdc803be7141e4f9795ab1478a",
          "image": "quay.io/silicom/tsync_extts@sha256:be6a5950a5fdc6fdf8015767901856bf173d01bdc803be7141e4f9795ab1478a",
          "name": "tsync_extts"
        },
        {
          "digest": "sha256:86562c40a07ef8dc198bd53562ae332d89d9ea5d45b8e8aa9d3685bc6f7ee60f",
          "image": "quay.io/silicom/sts-plugin@sha256:86562c40a07ef8dc198bd53562ae332d89d9ea5d45b8e8aa9d3685bc6f7ee60f",
          "name": "sts-plugin"
        },
        {
          "digest": "sha256:6bb07b26f669d9fe853a06a0262c5ee033fbb26bab202d84572b099ef852751c",
          "image": "quay.io/silicom/ice-driver-src@sha256:6bb07b26f669d9fe853a06a0262c5ee033fbb26bab202d84572b099ef852751c",
          "name": "ice-driver-src"
        },
        {
          "digest": "sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "image": "quay.io/silicom/sts-operator@sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "name": "sts-operator"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "image": "quay.io/silicom/sts-operator@sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "name": "sts-operator-a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5-annotation"
        },
        {
          "digest": "sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "image": "quay.io/silicom/sts-operator@sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "0.0.7",
      "version_original": "0.0.7"
    },
    {
      "_id": "6283fbff5a88c04949a599f5",
      "alm_examples": [
        {
          "api_version": "sts.silicom.com/v1alpha1",
          "kind": "StsConfig",
          "metadata": {
            "name": "gm-1",
            "namespace": "openshift-operators"
          },
          "spec": {
            "interfaces": [
              {
                "ethName": "enp2s0f0",
                "ethPort": 0,
                "holdoff": 500,
                "mode": "Master",
                "synce": 1
              },
              {
                "ethName": "enp2s0f1",
                "ethPort": 1,
                "holdoff": 500,
                "mode": "Master",
                "synce": 1
              }
            ],
            "mode": "T-GM.8275.1",
            "namespace": "openshift-operators",
            "nodeSelector": {
              "sts.silicom.com/config": "gm-1"
            }
          }
        },
        {
          "api_version": "sts.silicom.com/v1alpha1",
          "kind": "StsConfig",
          "metadata": {
            "name": "bc-1"
          },
          "spec": {
            "aprLevel": 0,
            "domainNumber": 24,
            "esmcMode": 1,
            "forwardable": 0,
            "interfaces": [
              {
                "ethName": "enp2s0f0",
                "ethPort": 0,
                "holdoff": 500,
                "ipv4": 1,
                "ipv6": 1,
                "mode": "Slave",
                "ql": 4,
                "qlEnable": 1,
                "synce": 1
              },
              {
                "ethName": "enp2s0f1",
                "ethPort": 1,
                "holdoff": 500,
                "ipv4": 1,
                "ipv6": 1,
                "mode": "Master",
                "ql": 4,
                "qlEnable": 1,
                "synce": 1
              },
              {
                "ethName": "enp2s0f2",
                "ethPort": 2,
                "holdoff": 500,
                "ipv4": 1,
                "mode": "Master",
                "ql": 4,
                "qlEnable": 1,
                "synce": 1
              }
            ],
            "mode": "T-TBC.8275.1",
            "mode10MHz": 2,
            "modePPS": 2,
            "namespace": "openshift-operators",
            "nodeSelector": {
              "sts.silicom.com/config": "bc-1"
            },
            "phyLedsCtl": 0,
            "priority2": 128,
            "src10MHz": 1,
            "srcPPS": 1,
            "syncOption": 1,
            "synceCpu": 10,
            "synceRecClkPort": 0,
            "tracePtpMsg": -1,
            "twoStep": 0
          }
        },
        {
          "api_version": "sts.silicom.com/v1alpha1",
          "kind": "StsNode",
          "metadata": {
            "name": "worker2"
          },
          "spec": {}
        },
        {
          "api_version": "sts.silicom.com/v1alpha1",
          "kind": "StsOperatorConfig",
          "metadata": {
            "name": "sts-operator-config",
            "namespace": "openshift-operators"
          },
          "spec": {
            "images": {},
            "sro": {}
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [
        "amd64"
      ],
      "bundle_path": "registry.connect.redhat.com/silicomltd/silicom-sts-operator@sha256:3d60984e2c198e8defe3cbd56dd784d2bdf0b30c9b4cfcd1709f19e10aa227b5",
      "bundle_path_digest": "sha256:3d60984e2c198e8defe3cbd56dd784d2bdf0b30c9b4cfcd1709f19e10aa227b5",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-05-17T19:48:15.422000+00:00",
      "csv_description": "Silicom STS line card for 4G and 5G NIC enable real-time data transmission\nwith high timing accuracy at the lowest cost to power 5G DRAN and CRAN edge\ndeployments.\n\n* Support 1588/PTP over IPv4 / IPV6, IEEE1588v2\n* Support SyncE /ITU-T G.8262\n* T-BC/T-TSC Boundary Clock and TSC Slave Clock /G.8273.2\n* T-GM Grand Master /G.8273.1 per G.8275.1 PTP Profile\n* PRTC Primary Reference Time Clock Class B/G.8272\n* T-TC Transparent Clock /G.8273.3\n* 1588 Software Stack and Servo Software in x86\n* [Silicom STS2 Card](https://www.silicom-usa.com/pr/server-adapters/networking-adapters/10-gigabit-ethernet-networking-adapters/p410g8ts81-timesync-server-adapter)\n\n### Prequisites:\n* [NFD Operator](https://operatorhub.io/operator/nfd-operator \"NFD operator needed for the discovery of STS cards\").\n* [SRO Operator](https://github.com/openshift/special-resource-operator)\n",
      "csv_display_name": "Silicom STS Operator",
      "csv_metadata_description": "This Operator is a Kubernetes custom controller whose goal\nis to serve the installation and lifecycle management of\nSilicom STS device plugins for Kubernetes.\n",
      "csv_name": "silicom-sts-operator.v0.0.7",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T12:53:56.654000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "silicom-sts-operator",
      "provided_apis": [
        {
          "group": "sts.silicom.com",
          "kind": "StsConfig",
          "version": "v1alpha1"
        },
        {
          "group": "sts.silicom.com",
          "kind": "StsNode",
          "version": "v1alpha1"
        },
        {
          "group": "sts.silicom.com",
          "kind": "StsOperatorConfig",
          "version": "v1alpha1"
        }
      ],
      "provider": "Silicom Ltd.",
      "related_images": [
        {
          "digest": "sha256:649e8a6c524920e1c564d8f797b8d64235b2527aa923f94bc9c7a0b7aba8ae7f",
          "image": "quay.io/silicom/gpsd@sha256:649e8a6c524920e1c564d8f797b8d64235b2527aa923f94bc9c7a0b7aba8ae7f",
          "name": "gpsd"
        },
        {
          "digest": "sha256:0f3b63a3059b7d6158a916814281097f0d418b99a5fac9e8e5fd9bae58fb0b74",
          "image": "quay.io/silicom/phc2sys@sha256:0f3b63a3059b7d6158a916814281097f0d418b99a5fac9e8e5fd9bae58fb0b74",
          "name": "phc2sys"
        },
        {
          "digest": "sha256:78be78ec8939f025f9a8b899693ab77b3990116d1c7ffb2115c620b7c3382d9d",
          "image": "quay.io/silicom/tsyncd@sha256:78be78ec8939f025f9a8b899693ab77b3990116d1c7ffb2115c620b7c3382d9d",
          "name": "tsyncd"
        },
        {
          "digest": "sha256:aac7233423439e352d8eb39cef63e479c30c2f80b063c84ffc8797cc5a045117",
          "image": "quay.io/silicom/grpc-tsyncd@sha256:aac7233423439e352d8eb39cef63e479c30c2f80b063c84ffc8797cc5a045117",
          "name": "grpc-tsyncd"
        },
        {
          "digest": "sha256:be6a5950a5fdc6fdf8015767901856bf173d01bdc803be7141e4f9795ab1478a",
          "image": "quay.io/silicom/tsync_extts@sha256:be6a5950a5fdc6fdf8015767901856bf173d01bdc803be7141e4f9795ab1478a",
          "name": "tsync_extts"
        },
        {
          "digest": "sha256:86562c40a07ef8dc198bd53562ae332d89d9ea5d45b8e8aa9d3685bc6f7ee60f",
          "image": "quay.io/silicom/sts-plugin@sha256:86562c40a07ef8dc198bd53562ae332d89d9ea5d45b8e8aa9d3685bc6f7ee60f",
          "name": "sts-plugin"
        },
        {
          "digest": "sha256:6bb07b26f669d9fe853a06a0262c5ee033fbb26bab202d84572b099ef852751c",
          "image": "quay.io/silicom/ice-driver-src@sha256:6bb07b26f669d9fe853a06a0262c5ee033fbb26bab202d84572b099ef852751c",
          "name": "ice-driver-src"
        },
        {
          "digest": "sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "image": "quay.io/silicom/sts-operator@sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "name": "sts-operator"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "image": "quay.io/silicom/sts-operator@sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "name": "sts-operator-a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5-annotation"
        },
        {
          "digest": "sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "image": "quay.io/silicom/sts-operator@sha256:a79a5cf99f5238ee08c509efe0b6142197ef0b79a6b209c125d9f7b7235758e5",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "0.0.7",
      "version_original": "0.0.7"
    },
    {
      "_id": "628670c65a88c04949a66fd5",
      "alm_examples": [
        {
          "api_version": "instana.io/v1",
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent": {
              "configuration_yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n",
              "endpointHost": "ingress-red-saas.instana.io",
              "endpointPort": "443",
              "env": {},
              "key": "replace-key"
            },
            "cluster": {
              "name": "my-cluster"
            },
            "zone": {
              "name": "edited-zone"
            }
          }
        },
        {
          "api_version": "instana.io/v1beta1",
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent.endpoint.host": "ingress-red-saas.instana.io",
            "agent.endpoint.port": 443,
            "agent.env": {
              "INSTANA_AGENT_TAGS": "example"
            },
            "agent.key": "replace-me",
            "agent.zone.name": "my-zone",
            "cluster.name": "replace-me",
            "config.files": {
              "configuration.yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/instana/instana-agent-operator-bundle@sha256:2d61f1228ddb30ff1853ea95f0752fb9eed200ceba67e3a3d37b54f810a74976",
      "bundle_path_digest": "sha256:2d61f1228ddb30ff1853ea95f0752fb9eed200ceba67e3a3d37b54f810a74976",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-19T16:31:02.597000+00:00",
      "csv_description": "# Instana\n\nInstana is an [APM solution](https://www.instana.com/product-overview/) built for microservices that enables IT Ops to build applications faster and deliver higher quality services by automating monitoring, tracing and root cause analysis. The solution is optimized for [Kubernetes](https://www.instana.com/automatic-kubernetes-monitoring/) and [OpenShift](https://www.instana.com/blog/automatic-root-cause-analysis-for-openshift-applications/).\n\n## Instana Agent Operator\n\nThis is the Kubernetes Operator for installing the Instana Agent on Kubernetes or OpenShift.\n\n## Prerequisites for OpenShift\n\nBefore the agent will be able to run in OpenShift, you need to perform a couple of extra configuration steps.\n\nYou need to set up a project for the Instana Agent and configure it's permissions.\n\nThe project you create here needs to be the namespace where you create the Instana Agent custom resource that the operator will use to deploy the agent.\n\nFor example, create the `instana-agent` project:\n\n    oc new-project instana-agent\n\nThen, ensure the `instana-agent` service account is in the privileged security context:\n\n    oc adm policy add-scc-to-user privileged -z instana-agent\n\nThis service account will be created by the operator.\n\nNow you can proceed with installing the operator for the Instana agent.\n\n## Installation and Configuration\n\nFirst, install this operator from [OperatorHub.io](https://operatorhub.io/), [OpenShift Container Platform](https://www.openshift.com/), or [OKD](https://www.okd.io/).\n\nSecond, create a custom resource with the agent configuration in the target namespace (for now, this MUST always be the `instana-agent` namespace). The operator will pick up the custom resource and install the Instana agent accordingly.\n\nThe following is a minimal template of the custom resource:\n\n```yaml\napiVersion: instana.io/v1\nkind: InstanaAgent\nmetadata:\n  name: instana-agent\n  namespace: instana-agent\nspec:\n  zone:\n    name: my-zone # (optional) name of the zone of the host\n  cluster:\n    name: replace-me # replace with the name of your Kubernetes cluster\n  agent:\n    key: replace-me # replace with your Instana agent key\n    endpointHost: ingress-red-saas.instana.io # the monitoring ingress endpoint\n    endpointPort: \"443\" # the monitoring ingress endpoint port, wrapped in quotes\n    env:\n      INSTANA_AGENT_TAGS: example\n    configuration_yaml: |\n      # You can leave this empty, or use this to configure your instana agent.\n      # See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n```\n\nSave the template in a file `instana-agent.yaml` and edit the following values:\n\n* If your target namespace is not `instana-agent`, replace the `namespace:` accordingly.\n* `agent.key` must be set with your Instana agent key.\n* `agent.endpointHost` must be set with the monitoring ingress endpoint, generally either `saas-us-west-2.instana.io` or `saas-eu-west-1.instana.io`.\n* `agent.endpointPort` must be set with the monitoring ingress port, generally \"443\" (wrapped in quotes).\n* `zone.name` should be set with the name of the Kubernetes cluster that is be displayed in Instana.\n\nFor advanced configuration, you can edit the contents of the `configuration.yaml` file. View documentation [here](https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/).\n\nApply the custom resource with `kubectl apply -f instana-agent.yaml`. After some time, you should see `instana-agent` Pods being created on each node of your cluster, and your cluster should show on the infrastructure map on your Instana Web interface.\n\n## Uninstalling\n\nIn order to uninstall the Instana agent, simply remove the custom resource with `kubectl delete -f instana-agent.yaml`.\n\n## Source Code\n\nThe Instana agent operator is an open source project hosted on [https://github.com/instana/instana-agent-operator](https://github.com/instana/instana-agent-operator/).\n",
      "csv_display_name": "Instana Agent Operator",
      "csv_metadata_description": "Fully automated Application Performance Monitoring (APM) for microservices.",
      "csv_name": "instana-agent-operator.v2.0.5",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:26:29.844000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "instana-agent-operator",
      "provided_apis": [
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "version": "v1"
        },
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "version": "v1beta1"
        }
      ],
      "provider": "Instana",
      "related_images": [
        {
          "digest": "sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "image": "icr.io/instana/instana-agent-operator@sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "name": "instana-agent-operator"
        },
        {
          "digest": "sha256:faaaa00d062b891e66438bce4317fd0b7fae3eb6be3d6a990beb4e891044bc09",
          "image": "icr.io/instana/agent@sha256:faaaa00d062b891e66438bce4317fd0b7fae3eb6be3d6a990beb4e891044bc09",
          "name": "instana-agent"
        },
        {
          "digest": "sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "image": "icr.io/instana/instana-agent-operator@sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "name": "instana-agent-operator-2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11-annotation"
        },
        {
          "digest": "sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "image": "icr.io/instana/instana-agent-operator@sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2.0.5",
      "version_original": "2.0.5"
    },
    {
      "_id": "628674283fcd237f69725df8",
      "alm_examples": [
        {
          "api_version": "instana.io/v1",
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent": {
              "configuration_yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n",
              "endpointHost": "ingress-red-saas.instana.io",
              "endpointPort": "443",
              "env": {},
              "key": "replace-key"
            },
            "cluster": {
              "name": "my-cluster"
            },
            "zone": {
              "name": "edited-zone"
            }
          }
        },
        {
          "api_version": "instana.io/v1beta1",
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent.endpoint.host": "ingress-red-saas.instana.io",
            "agent.endpoint.port": 443,
            "agent.env": {
              "INSTANA_AGENT_TAGS": "example"
            },
            "agent.key": "replace-me",
            "agent.zone.name": "my-zone",
            "cluster.name": "replace-me",
            "config.files": {
              "configuration.yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/instana/instana-agent-operator-bundle@sha256:2d61f1228ddb30ff1853ea95f0752fb9eed200ceba67e3a3d37b54f810a74976",
      "bundle_path_digest": "sha256:2d61f1228ddb30ff1853ea95f0752fb9eed200ceba67e3a3d37b54f810a74976",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-19T16:45:28.475000+00:00",
      "csv_description": "# Instana\n\nInstana is an [APM solution](https://www.instana.com/product-overview/) built for microservices that enables IT Ops to build applications faster and deliver higher quality services by automating monitoring, tracing and root cause analysis. The solution is optimized for [Kubernetes](https://www.instana.com/automatic-kubernetes-monitoring/) and [OpenShift](https://www.instana.com/blog/automatic-root-cause-analysis-for-openshift-applications/).\n\n## Instana Agent Operator\n\nThis is the Kubernetes Operator for installing the Instana Agent on Kubernetes or OpenShift.\n\n## Prerequisites for OpenShift\n\nBefore the agent will be able to run in OpenShift, you need to perform a couple of extra configuration steps.\n\nYou need to set up a project for the Instana Agent and configure it's permissions.\n\nThe project you create here needs to be the namespace where you create the Instana Agent custom resource that the operator will use to deploy the agent.\n\nFor example, create the `instana-agent` project:\n\n    oc new-project instana-agent\n\nThen, ensure the `instana-agent` service account is in the privileged security context:\n\n    oc adm policy add-scc-to-user privileged -z instana-agent\n\nThis service account will be created by the operator.\n\nNow you can proceed with installing the operator for the Instana agent.\n\n## Installation and Configuration\n\nFirst, install this operator from [OperatorHub.io](https://operatorhub.io/), [OpenShift Container Platform](https://www.openshift.com/), or [OKD](https://www.okd.io/).\n\nSecond, create a custom resource with the agent configuration in the target namespace (for now, this MUST always be the `instana-agent` namespace). The operator will pick up the custom resource and install the Instana agent accordingly.\n\nThe following is a minimal template of the custom resource:\n\n```yaml\napiVersion: instana.io/v1\nkind: InstanaAgent\nmetadata:\n  name: instana-agent\n  namespace: instana-agent\nspec:\n  zone:\n    name: my-zone # (optional) name of the zone of the host\n  cluster:\n    name: replace-me # replace with the name of your Kubernetes cluster\n  agent:\n    key: replace-me # replace with your Instana agent key\n    endpointHost: ingress-red-saas.instana.io # the monitoring ingress endpoint\n    endpointPort: \"443\" # the monitoring ingress endpoint port, wrapped in quotes\n    env:\n      INSTANA_AGENT_TAGS: example\n    configuration_yaml: |\n      # You can leave this empty, or use this to configure your instana agent.\n      # See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n```\n\nSave the template in a file `instana-agent.yaml` and edit the following values:\n\n* If your target namespace is not `instana-agent`, replace the `namespace:` accordingly.\n* `agent.key` must be set with your Instana agent key.\n* `agent.endpointHost` must be set with the monitoring ingress endpoint, generally either `saas-us-west-2.instana.io` or `saas-eu-west-1.instana.io`.\n* `agent.endpointPort` must be set with the monitoring ingress port, generally \"443\" (wrapped in quotes).\n* `zone.name` should be set with the name of the Kubernetes cluster that is be displayed in Instana.\n\nFor advanced configuration, you can edit the contents of the `configuration.yaml` file. View documentation [here](https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/).\n\nApply the custom resource with `kubectl apply -f instana-agent.yaml`. After some time, you should see `instana-agent` Pods being created on each node of your cluster, and your cluster should show on the infrastructure map on your Instana Web interface.\n\n## Uninstalling\n\nIn order to uninstall the Instana agent, simply remove the custom resource with `kubectl delete -f instana-agent.yaml`.\n\n## Source Code\n\nThe Instana agent operator is an open source project hosted on [https://github.com/instana/instana-agent-operator](https://github.com/instana/instana-agent-operator/).\n",
      "csv_display_name": "Instana Agent Operator",
      "csv_metadata_description": "Fully automated Application Performance Monitoring (APM) for microservices.",
      "csv_name": "instana-agent-operator.v2.0.5",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:01:43.490000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "instana-agent-operator",
      "provided_apis": [
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1"
        },
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1beta1"
        }
      ],
      "provider": "Instana",
      "related_images": [
        {
          "digest": "sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "image": "icr.io/instana/instana-agent-operator@sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "name": "instana-agent-operator"
        },
        {
          "digest": "sha256:faaaa00d062b891e66438bce4317fd0b7fae3eb6be3d6a990beb4e891044bc09",
          "image": "icr.io/instana/agent@sha256:faaaa00d062b891e66438bce4317fd0b7fae3eb6be3d6a990beb4e891044bc09",
          "name": "instana-agent"
        },
        {
          "digest": "sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "image": "icr.io/instana/instana-agent-operator@sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "name": "instana-agent-operator-2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11-annotation"
        },
        {
          "digest": "sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "image": "icr.io/instana/instana-agent-operator@sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "2.0.5",
      "version_original": "2.0.5"
    },
    {
      "_id": "628676b77aa88cb299062efc",
      "alm_examples": [
        {
          "api_version": "instana.io/v1",
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent": {
              "configuration_yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n",
              "endpointHost": "ingress-red-saas.instana.io",
              "endpointPort": "443",
              "env": {},
              "key": "replace-key"
            },
            "cluster": {
              "name": "my-cluster"
            },
            "zone": {
              "name": "edited-zone"
            }
          }
        },
        {
          "api_version": "instana.io/v1beta1",
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent.endpoint.host": "ingress-red-saas.instana.io",
            "agent.endpoint.port": 443,
            "agent.env": {
              "INSTANA_AGENT_TAGS": "example"
            },
            "agent.key": "replace-me",
            "agent.zone.name": "my-zone",
            "cluster.name": "replace-me",
            "config.files": {
              "configuration.yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/instana/instana-agent-operator-bundle@sha256:2d61f1228ddb30ff1853ea95f0752fb9eed200ceba67e3a3d37b54f810a74976",
      "bundle_path_digest": "sha256:2d61f1228ddb30ff1853ea95f0752fb9eed200ceba67e3a3d37b54f810a74976",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-19T16:56:23.410000+00:00",
      "csv_description": "# Instana\n\nInstana is an [APM solution](https://www.instana.com/product-overview/) built for microservices that enables IT Ops to build applications faster and deliver higher quality services by automating monitoring, tracing and root cause analysis. The solution is optimized for [Kubernetes](https://www.instana.com/automatic-kubernetes-monitoring/) and [OpenShift](https://www.instana.com/blog/automatic-root-cause-analysis-for-openshift-applications/).\n\n## Instana Agent Operator\n\nThis is the Kubernetes Operator for installing the Instana Agent on Kubernetes or OpenShift.\n\n## Prerequisites for OpenShift\n\nBefore the agent will be able to run in OpenShift, you need to perform a couple of extra configuration steps.\n\nYou need to set up a project for the Instana Agent and configure it's permissions.\n\nThe project you create here needs to be the namespace where you create the Instana Agent custom resource that the operator will use to deploy the agent.\n\nFor example, create the `instana-agent` project:\n\n    oc new-project instana-agent\n\nThen, ensure the `instana-agent` service account is in the privileged security context:\n\n    oc adm policy add-scc-to-user privileged -z instana-agent\n\nThis service account will be created by the operator.\n\nNow you can proceed with installing the operator for the Instana agent.\n\n## Installation and Configuration\n\nFirst, install this operator from [OperatorHub.io](https://operatorhub.io/), [OpenShift Container Platform](https://www.openshift.com/), or [OKD](https://www.okd.io/).\n\nSecond, create a custom resource with the agent configuration in the target namespace (for now, this MUST always be the `instana-agent` namespace). The operator will pick up the custom resource and install the Instana agent accordingly.\n\nThe following is a minimal template of the custom resource:\n\n```yaml\napiVersion: instana.io/v1\nkind: InstanaAgent\nmetadata:\n  name: instana-agent\n  namespace: instana-agent\nspec:\n  zone:\n    name: my-zone # (optional) name of the zone of the host\n  cluster:\n    name: replace-me # replace with the name of your Kubernetes cluster\n  agent:\n    key: replace-me # replace with your Instana agent key\n    endpointHost: ingress-red-saas.instana.io # the monitoring ingress endpoint\n    endpointPort: \"443\" # the monitoring ingress endpoint port, wrapped in quotes\n    env:\n      INSTANA_AGENT_TAGS: example\n    configuration_yaml: |\n      # You can leave this empty, or use this to configure your instana agent.\n      # See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n```\n\nSave the template in a file `instana-agent.yaml` and edit the following values:\n\n* If your target namespace is not `instana-agent`, replace the `namespace:` accordingly.\n* `agent.key` must be set with your Instana agent key.\n* `agent.endpointHost` must be set with the monitoring ingress endpoint, generally either `saas-us-west-2.instana.io` or `saas-eu-west-1.instana.io`.\n* `agent.endpointPort` must be set with the monitoring ingress port, generally \"443\" (wrapped in quotes).\n* `zone.name` should be set with the name of the Kubernetes cluster that is be displayed in Instana.\n\nFor advanced configuration, you can edit the contents of the `configuration.yaml` file. View documentation [here](https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/).\n\nApply the custom resource with `kubectl apply -f instana-agent.yaml`. After some time, you should see `instana-agent` Pods being created on each node of your cluster, and your cluster should show on the infrastructure map on your Instana Web interface.\n\n## Uninstalling\n\nIn order to uninstall the Instana agent, simply remove the custom resource with `kubectl delete -f instana-agent.yaml`.\n\n## Source Code\n\nThe Instana agent operator is an open source project hosted on [https://github.com/instana/instana-agent-operator](https://github.com/instana/instana-agent-operator/).\n",
      "csv_display_name": "Instana Agent Operator",
      "csv_metadata_description": "Fully automated Application Performance Monitoring (APM) for microservices.",
      "csv_name": "instana-agent-operator.v2.0.5",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T12:59:51.183000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "instana-agent-operator",
      "provided_apis": [
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1"
        },
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1beta1"
        }
      ],
      "provider": "Instana",
      "related_images": [
        {
          "digest": "sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "image": "icr.io/instana/instana-agent-operator@sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "name": "instana-agent-operator"
        },
        {
          "digest": "sha256:faaaa00d062b891e66438bce4317fd0b7fae3eb6be3d6a990beb4e891044bc09",
          "image": "icr.io/instana/agent@sha256:faaaa00d062b891e66438bce4317fd0b7fae3eb6be3d6a990beb4e891044bc09",
          "name": "instana-agent"
        },
        {
          "digest": "sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "image": "icr.io/instana/instana-agent-operator@sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "name": "instana-agent-operator-2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11-annotation"
        },
        {
          "digest": "sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "image": "icr.io/instana/instana-agent-operator@sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2.0.5",
      "version_original": "2.0.5"
    },
    {
      "_id": "62867a055a88c04949a672b8",
      "alm_examples": [
        {
          "api_version": "instana.io/v1",
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent": {
              "configuration_yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n",
              "endpointHost": "ingress-red-saas.instana.io",
              "endpointPort": "443",
              "env": {},
              "key": "replace-key"
            },
            "cluster": {
              "name": "my-cluster"
            },
            "zone": {
              "name": "edited-zone"
            }
          }
        },
        {
          "api_version": "instana.io/v1beta1",
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent.endpoint.host": "ingress-red-saas.instana.io",
            "agent.endpoint.port": 443,
            "agent.env": {
              "INSTANA_AGENT_TAGS": "example"
            },
            "agent.key": "replace-me",
            "agent.zone.name": "my-zone",
            "cluster.name": "replace-me",
            "config.files": {
              "configuration.yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/instana/instana-agent-operator-bundle@sha256:2d61f1228ddb30ff1853ea95f0752fb9eed200ceba67e3a3d37b54f810a74976",
      "bundle_path_digest": "sha256:2d61f1228ddb30ff1853ea95f0752fb9eed200ceba67e3a3d37b54f810a74976",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-19T17:10:29.969000+00:00",
      "csv_description": "# Instana\n\nInstana is an [APM solution](https://www.instana.com/product-overview/) built for microservices that enables IT Ops to build applications faster and deliver higher quality services by automating monitoring, tracing and root cause analysis. The solution is optimized for [Kubernetes](https://www.instana.com/automatic-kubernetes-monitoring/) and [OpenShift](https://www.instana.com/blog/automatic-root-cause-analysis-for-openshift-applications/).\n\n## Instana Agent Operator\n\nThis is the Kubernetes Operator for installing the Instana Agent on Kubernetes or OpenShift.\n\n## Prerequisites for OpenShift\n\nBefore the agent will be able to run in OpenShift, you need to perform a couple of extra configuration steps.\n\nYou need to set up a project for the Instana Agent and configure it's permissions.\n\nThe project you create here needs to be the namespace where you create the Instana Agent custom resource that the operator will use to deploy the agent.\n\nFor example, create the `instana-agent` project:\n\n    oc new-project instana-agent\n\nThen, ensure the `instana-agent` service account is in the privileged security context:\n\n    oc adm policy add-scc-to-user privileged -z instana-agent\n\nThis service account will be created by the operator.\n\nNow you can proceed with installing the operator for the Instana agent.\n\n## Installation and Configuration\n\nFirst, install this operator from [OperatorHub.io](https://operatorhub.io/), [OpenShift Container Platform](https://www.openshift.com/), or [OKD](https://www.okd.io/).\n\nSecond, create a custom resource with the agent configuration in the target namespace (for now, this MUST always be the `instana-agent` namespace). The operator will pick up the custom resource and install the Instana agent accordingly.\n\nThe following is a minimal template of the custom resource:\n\n```yaml\napiVersion: instana.io/v1\nkind: InstanaAgent\nmetadata:\n  name: instana-agent\n  namespace: instana-agent\nspec:\n  zone:\n    name: my-zone # (optional) name of the zone of the host\n  cluster:\n    name: replace-me # replace with the name of your Kubernetes cluster\n  agent:\n    key: replace-me # replace with your Instana agent key\n    endpointHost: ingress-red-saas.instana.io # the monitoring ingress endpoint\n    endpointPort: \"443\" # the monitoring ingress endpoint port, wrapped in quotes\n    env:\n      INSTANA_AGENT_TAGS: example\n    configuration_yaml: |\n      # You can leave this empty, or use this to configure your instana agent.\n      # See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n```\n\nSave the template in a file `instana-agent.yaml` and edit the following values:\n\n* If your target namespace is not `instana-agent`, replace the `namespace:` accordingly.\n* `agent.key` must be set with your Instana agent key.\n* `agent.endpointHost` must be set with the monitoring ingress endpoint, generally either `saas-us-west-2.instana.io` or `saas-eu-west-1.instana.io`.\n* `agent.endpointPort` must be set with the monitoring ingress port, generally \"443\" (wrapped in quotes).\n* `zone.name` should be set with the name of the Kubernetes cluster that is be displayed in Instana.\n\nFor advanced configuration, you can edit the contents of the `configuration.yaml` file. View documentation [here](https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/).\n\nApply the custom resource with `kubectl apply -f instana-agent.yaml`. After some time, you should see `instana-agent` Pods being created on each node of your cluster, and your cluster should show on the infrastructure map on your Instana Web interface.\n\n## Uninstalling\n\nIn order to uninstall the Instana agent, simply remove the custom resource with `kubectl delete -f instana-agent.yaml`.\n\n## Source Code\n\nThe Instana agent operator is an open source project hosted on [https://github.com/instana/instana-agent-operator](https://github.com/instana/instana-agent-operator/).\n",
      "csv_display_name": "Instana Agent Operator",
      "csv_metadata_description": "Fully automated Application Performance Monitoring (APM) for microservices.",
      "csv_name": "instana-agent-operator.v2.0.5",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:15:49.560000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "instana-agent-operator",
      "provided_apis": [
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1"
        },
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1beta1"
        }
      ],
      "provider": "Instana",
      "related_images": [
        {
          "digest": "sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "image": "icr.io/instana/instana-agent-operator@sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "name": "instana-agent-operator"
        },
        {
          "digest": "sha256:faaaa00d062b891e66438bce4317fd0b7fae3eb6be3d6a990beb4e891044bc09",
          "image": "icr.io/instana/agent@sha256:faaaa00d062b891e66438bce4317fd0b7fae3eb6be3d6a990beb4e891044bc09",
          "name": "instana-agent"
        },
        {
          "digest": "sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "image": "icr.io/instana/instana-agent-operator@sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "name": "instana-agent-operator-2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11-annotation"
        },
        {
          "digest": "sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "image": "icr.io/instana/instana-agent-operator@sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2.0.5",
      "version_original": "2.0.5"
    },
    {
      "_id": "62867bf231755c747c35f311",
      "alm_examples": [
        {
          "api_version": "instana.io/v1",
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent": {
              "configuration_yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n",
              "endpointHost": "ingress-red-saas.instana.io",
              "endpointPort": "443",
              "env": {},
              "key": "replace-key"
            },
            "cluster": {
              "name": "my-cluster"
            },
            "zone": {
              "name": "edited-zone"
            }
          }
        },
        {
          "api_version": "instana.io/v1beta1",
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent.endpoint.host": "ingress-red-saas.instana.io",
            "agent.endpoint.port": 443,
            "agent.env": {
              "INSTANA_AGENT_TAGS": "example"
            },
            "agent.key": "replace-me",
            "agent.zone.name": "my-zone",
            "cluster.name": "replace-me",
            "config.files": {
              "configuration.yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/instana/instana-agent-operator-bundle@sha256:2d61f1228ddb30ff1853ea95f0752fb9eed200ceba67e3a3d37b54f810a74976",
      "bundle_path_digest": "sha256:2d61f1228ddb30ff1853ea95f0752fb9eed200ceba67e3a3d37b54f810a74976",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-19T17:18:42.706000+00:00",
      "csv_description": "# Instana\n\nInstana is an [APM solution](https://www.instana.com/product-overview/) built for microservices that enables IT Ops to build applications faster and deliver higher quality services by automating monitoring, tracing and root cause analysis. The solution is optimized for [Kubernetes](https://www.instana.com/automatic-kubernetes-monitoring/) and [OpenShift](https://www.instana.com/blog/automatic-root-cause-analysis-for-openshift-applications/).\n\n## Instana Agent Operator\n\nThis is the Kubernetes Operator for installing the Instana Agent on Kubernetes or OpenShift.\n\n## Prerequisites for OpenShift\n\nBefore the agent will be able to run in OpenShift, you need to perform a couple of extra configuration steps.\n\nYou need to set up a project for the Instana Agent and configure it's permissions.\n\nThe project you create here needs to be the namespace where you create the Instana Agent custom resource that the operator will use to deploy the agent.\n\nFor example, create the `instana-agent` project:\n\n    oc new-project instana-agent\n\nThen, ensure the `instana-agent` service account is in the privileged security context:\n\n    oc adm policy add-scc-to-user privileged -z instana-agent\n\nThis service account will be created by the operator.\n\nNow you can proceed with installing the operator for the Instana agent.\n\n## Installation and Configuration\n\nFirst, install this operator from [OperatorHub.io](https://operatorhub.io/), [OpenShift Container Platform](https://www.openshift.com/), or [OKD](https://www.okd.io/).\n\nSecond, create a custom resource with the agent configuration in the target namespace (for now, this MUST always be the `instana-agent` namespace). The operator will pick up the custom resource and install the Instana agent accordingly.\n\nThe following is a minimal template of the custom resource:\n\n```yaml\napiVersion: instana.io/v1\nkind: InstanaAgent\nmetadata:\n  name: instana-agent\n  namespace: instana-agent\nspec:\n  zone:\n    name: my-zone # (optional) name of the zone of the host\n  cluster:\n    name: replace-me # replace with the name of your Kubernetes cluster\n  agent:\n    key: replace-me # replace with your Instana agent key\n    endpointHost: ingress-red-saas.instana.io # the monitoring ingress endpoint\n    endpointPort: \"443\" # the monitoring ingress endpoint port, wrapped in quotes\n    env:\n      INSTANA_AGENT_TAGS: example\n    configuration_yaml: |\n      # You can leave this empty, or use this to configure your instana agent.\n      # See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n```\n\nSave the template in a file `instana-agent.yaml` and edit the following values:\n\n* If your target namespace is not `instana-agent`, replace the `namespace:` accordingly.\n* `agent.key` must be set with your Instana agent key.\n* `agent.endpointHost` must be set with the monitoring ingress endpoint, generally either `saas-us-west-2.instana.io` or `saas-eu-west-1.instana.io`.\n* `agent.endpointPort` must be set with the monitoring ingress port, generally \"443\" (wrapped in quotes).\n* `zone.name` should be set with the name of the Kubernetes cluster that is be displayed in Instana.\n\nFor advanced configuration, you can edit the contents of the `configuration.yaml` file. View documentation [here](https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/).\n\nApply the custom resource with `kubectl apply -f instana-agent.yaml`. After some time, you should see `instana-agent` Pods being created on each node of your cluster, and your cluster should show on the infrastructure map on your Instana Web interface.\n\n## Uninstalling\n\nIn order to uninstall the Instana agent, simply remove the custom resource with `kubectl delete -f instana-agent.yaml`.\n\n## Source Code\n\nThe Instana agent operator is an open source project hosted on [https://github.com/instana/instana-agent-operator](https://github.com/instana/instana-agent-operator/).\n",
      "csv_display_name": "Instana Agent Operator",
      "csv_metadata_description": "Fully automated Application Performance Monitoring (APM) for microservices.",
      "csv_name": "instana-agent-operator.v2.0.5",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:02:12.050000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "instana-agent-operator",
      "provided_apis": [
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1"
        },
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1beta1"
        }
      ],
      "provider": "Instana",
      "related_images": [
        {
          "digest": "sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "image": "icr.io/instana/instana-agent-operator@sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "name": "instana-agent-operator"
        },
        {
          "digest": "sha256:faaaa00d062b891e66438bce4317fd0b7fae3eb6be3d6a990beb4e891044bc09",
          "image": "icr.io/instana/agent@sha256:faaaa00d062b891e66438bce4317fd0b7fae3eb6be3d6a990beb4e891044bc09",
          "name": "instana-agent"
        },
        {
          "digest": "sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "image": "icr.io/instana/instana-agent-operator@sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "name": "instana-agent-operator-2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11-annotation"
        },
        {
          "digest": "sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "image": "icr.io/instana/instana-agent-operator@sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "2.0.5",
      "version_original": "2.0.5"
    },
    {
      "_id": "62867e045a88c04949a673f1",
      "alm_examples": [
        {
          "api_version": "instana.io/v1",
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent": {
              "configuration_yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n",
              "endpointHost": "ingress-red-saas.instana.io",
              "endpointPort": "443",
              "env": {},
              "key": "replace-key"
            },
            "cluster": {
              "name": "my-cluster"
            },
            "zone": {
              "name": "edited-zone"
            }
          }
        },
        {
          "api_version": "instana.io/v1beta1",
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent.endpoint.host": "ingress-red-saas.instana.io",
            "agent.endpoint.port": 443,
            "agent.env": {
              "INSTANA_AGENT_TAGS": "example"
            },
            "agent.key": "replace-me",
            "agent.zone.name": "my-zone",
            "cluster.name": "replace-me",
            "config.files": {
              "configuration.yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/instana/instana-agent-operator-bundle@sha256:2d61f1228ddb30ff1853ea95f0752fb9eed200ceba67e3a3d37b54f810a74976",
      "bundle_path_digest": "sha256:2d61f1228ddb30ff1853ea95f0752fb9eed200ceba67e3a3d37b54f810a74976",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-19T17:27:32.395000+00:00",
      "csv_description": "# Instana\n\nInstana is an [APM solution](https://www.instana.com/product-overview/) built for microservices that enables IT Ops to build applications faster and deliver higher quality services by automating monitoring, tracing and root cause analysis. The solution is optimized for [Kubernetes](https://www.instana.com/automatic-kubernetes-monitoring/) and [OpenShift](https://www.instana.com/blog/automatic-root-cause-analysis-for-openshift-applications/).\n\n## Instana Agent Operator\n\nThis is the Kubernetes Operator for installing the Instana Agent on Kubernetes or OpenShift.\n\n## Prerequisites for OpenShift\n\nBefore the agent will be able to run in OpenShift, you need to perform a couple of extra configuration steps.\n\nYou need to set up a project for the Instana Agent and configure it's permissions.\n\nThe project you create here needs to be the namespace where you create the Instana Agent custom resource that the operator will use to deploy the agent.\n\nFor example, create the `instana-agent` project:\n\n    oc new-project instana-agent\n\nThen, ensure the `instana-agent` service account is in the privileged security context:\n\n    oc adm policy add-scc-to-user privileged -z instana-agent\n\nThis service account will be created by the operator.\n\nNow you can proceed with installing the operator for the Instana agent.\n\n## Installation and Configuration\n\nFirst, install this operator from [OperatorHub.io](https://operatorhub.io/), [OpenShift Container Platform](https://www.openshift.com/), or [OKD](https://www.okd.io/).\n\nSecond, create a custom resource with the agent configuration in the target namespace (for now, this MUST always be the `instana-agent` namespace). The operator will pick up the custom resource and install the Instana agent accordingly.\n\nThe following is a minimal template of the custom resource:\n\n```yaml\napiVersion: instana.io/v1\nkind: InstanaAgent\nmetadata:\n  name: instana-agent\n  namespace: instana-agent\nspec:\n  zone:\n    name: my-zone # (optional) name of the zone of the host\n  cluster:\n    name: replace-me # replace with the name of your Kubernetes cluster\n  agent:\n    key: replace-me # replace with your Instana agent key\n    endpointHost: ingress-red-saas.instana.io # the monitoring ingress endpoint\n    endpointPort: \"443\" # the monitoring ingress endpoint port, wrapped in quotes\n    env:\n      INSTANA_AGENT_TAGS: example\n    configuration_yaml: |\n      # You can leave this empty, or use this to configure your instana agent.\n      # See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n```\n\nSave the template in a file `instana-agent.yaml` and edit the following values:\n\n* If your target namespace is not `instana-agent`, replace the `namespace:` accordingly.\n* `agent.key` must be set with your Instana agent key.\n* `agent.endpointHost` must be set with the monitoring ingress endpoint, generally either `saas-us-west-2.instana.io` or `saas-eu-west-1.instana.io`.\n* `agent.endpointPort` must be set with the monitoring ingress port, generally \"443\" (wrapped in quotes).\n* `zone.name` should be set with the name of the Kubernetes cluster that is be displayed in Instana.\n\nFor advanced configuration, you can edit the contents of the `configuration.yaml` file. View documentation [here](https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/).\n\nApply the custom resource with `kubectl apply -f instana-agent.yaml`. After some time, you should see `instana-agent` Pods being created on each node of your cluster, and your cluster should show on the infrastructure map on your Instana Web interface.\n\n## Uninstalling\n\nIn order to uninstall the Instana agent, simply remove the custom resource with `kubectl delete -f instana-agent.yaml`.\n\n## Source Code\n\nThe Instana agent operator is an open source project hosted on [https://github.com/instana/instana-agent-operator](https://github.com/instana/instana-agent-operator/).\n",
      "csv_display_name": "Instana Agent Operator",
      "csv_metadata_description": "Fully automated Application Performance Monitoring (APM) for microservices.",
      "csv_name": "instana-agent-operator.v2.0.5",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T12:57:03.681000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "instana-agent-operator",
      "provided_apis": [
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1"
        },
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1beta1"
        }
      ],
      "provider": "Instana",
      "related_images": [
        {
          "digest": "sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "image": "icr.io/instana/instana-agent-operator@sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "name": "instana-agent-operator"
        },
        {
          "digest": "sha256:faaaa00d062b891e66438bce4317fd0b7fae3eb6be3d6a990beb4e891044bc09",
          "image": "icr.io/instana/agent@sha256:faaaa00d062b891e66438bce4317fd0b7fae3eb6be3d6a990beb4e891044bc09",
          "name": "instana-agent"
        },
        {
          "digest": "sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "image": "icr.io/instana/instana-agent-operator@sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "name": "instana-agent-operator-2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11-annotation"
        },
        {
          "digest": "sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "image": "icr.io/instana/instana-agent-operator@sha256:2b36b6e98d7d96cb107e0d70ae9eaef2cde9138a77d9bb064043e8a444e05f11",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "2.0.5",
      "version_original": "2.0.5"
    },
    {
      "_id": "6286b1b47aa88cb2990642fb",
      "alm_examples": [
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIIsilon",
          "metadata": {
            "name": "isilon",
            "namespace": "test-isilon"
          },
          "spec": {
            "driver": {
              "common": {
                "envs": [
                  {
                    "name": "X_CSI_VERBOSE",
                    "value": "1"
                  },
                  {
                    "name": "X_CSI_ISI_PORT",
                    "value": "8080"
                  },
                  {
                    "name": "X_CSI_ISI_PATH",
                    "value": "/ifs/data/csi"
                  },
                  {
                    "name": "X_CSI_ISI_NO_PROBE_ON_START",
                    "value": "false"
                  },
                  {
                    "name": "X_CSI_ISI_AUTOPROBE",
                    "value": "true"
                  },
                  {
                    "name": "X_CSI_ISI_SKIP_CERTIFICATE_VALIDATION",
                    "value": "true"
                  },
                  {
                    "name": "X_CSI_ISI_AUTH_TYPE",
                    "value": "0"
                  },
                  {
                    "name": "X_CSI_CUSTOM_TOPOLOGY_ENABLED",
                    "value": "false"
                  }
                ],
                "image": "docker.io/dellemc/csi-isilon@sha256:220dd73f1eaa4b927e53f3827109c126ad5108f6d37e68949b95cfce66206fbe",
                "imagePullPolicy": "IfNotPresent"
              },
              "configVersion": "v2.2.0",
              "controller": {
                "envs": [
                  {
                    "name": "X_CSI_ISI_QUOTA_ENABLED",
                    "value": "true"
                  },
                  {
                    "name": "X_CSI_ISI_ACCESS_ZONE",
                    "value": "System"
                  },
                  {
                    "name": "X_CSI_ISI_VOLUME_PATH_PERMISSIONS",
                    "value": "0777"
                  }
                ]
              },
              "dnsPolicy": "ClusterFirstWithHostNet",
              "forceUpdate": false,
              "fsGroupPolicy": "ReadWriteOnceWithFSType",
              "node": {
                "envs": [
                  {
                    "name": "X_CSI_MAX_VOLUMES_PER_NODE",
                    "value": "0"
                  },
                  {
                    "name": "X_CSI_ALLOWED_NETWORKS",
                    "value": ""
                  }
                ]
              },
              "replicas": 2,
              "sideCars": [
                {
                  "args": [
                    "--leader-election-lease-duration=15s",
                    "--leader-election-renew-deadline=10s",
                    "--leader-election-retry-period=5s"
                  ],
                  "name": "common"
                },
                {
                  "args": [
                    "--volume-name-prefix=csipscale"
                  ],
                  "name": "provisioner"
                }
              ]
            }
          }
        },
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIPowerMax",
          "metadata": {
            "name": "test-powermax",
            "namespace": "test-powermax"
          },
          "spec": {
            "driver": {
              "common": {
                "envs": [
                  {
                    "name": "X_CSI_MANAGED_ARRAYS",
                    "value": "000000000000,000000000001"
                  },
                  {
                    "name": "X_CSI_POWERMAX_ENDPOINT",
                    "value": "https://0.0.0.0:8443/"
                  },
                  {
                    "name": "X_CSI_K8S_CLUSTER_PREFIX",
                    "value": "XYZ"
                  },
                  {
                    "name": "X_CSI_POWERMAX_PORTGROUPS",
                    "value": ""
                  },
                  {
                    "name": "X_CSI_TRANSPORT_PROTOCOL",
                    "value": ""
                  },
                  {
                    "name": "X_CSI_POWERMAX_PROXY_SERVICE_NAME",
                    "value": ""
                  },
                  {
                    "name": "X_CSI_GRPC_MAX_THREADS",
                    "value": "4"
                  }
                ],
                "image": "docker.io/dellemc/csi-powermax@sha256:2fc83456ec2fb2c0336725e039a3db699a0202468cd8e3fd12d7ef2423068fc8",
                "imagePullPolicy": "IfNotPresent"
              },
              "configVersion": "v2.2.0",
              "dnsPolicy": "ClusterFirstWithHostNet",
              "forceUpdate": false,
              "node": {
                "envs": [
                  {
                    "name": "X_CSI_POWERMAX_ISCSI_ENABLE_CHAP",
                    "value": "false"
                  }
                ]
              },
              "replicas": 2
            }
          }
        },
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIPowerMaxRevProxy",
          "metadata": {
            "name": "powermax-reverseproxy",
            "namespace": "test-powermax"
          },
          "spec": {
            "config": {
              "linkConfig": {
                "backup": {
                  "skipCertificateValidation": true,
                  "url": "https://0.0.0.0:8443"
                },
                "primary": {
                  "certSecret": "",
                  "skipCertificateValidation": true,
                  "url": "https://0.0.0.0:8443"
                }
              },
              "mode": "Linked"
            },
            "image": "docker.io/dellemc/csipowermax-reverseproxy@sha256:c236cb87d5799ef239b3e5df956761e1c042f3d5686c8e5728c06edfef3095b7",
            "imagePullPolicy": "IfNotPresent",
            "tlsSecret": "csirevproxy-tls-secret"
          }
        },
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIPowerStore",
          "metadata": {
            "name": "test-powerstore",
            "namespace": "test-powerstore"
          },
          "spec": {
            "driver": {
              "common": {
                "envs": [
                  {
                    "name": "X_CSI_POWERSTORE_NODE_NAME_PREFIX",
                    "value": "csi"
                  },
                  {
                    "name": "X_CSI_FC_PORTS_FILTER_FILE_PATH",
                    "value": "/etc/fc-ports-filter"
                  }
                ],
                "image": "docker.io/dellemc/csi-powerstore@sha256:08c5effefadf2e55103eb49ef2a5a325d9904e7391b6eeb72701dae6e682ad9e",
                "imagePullPolicy": "IfNotPresent"
              },
              "configVersion": "v2.2.0",
              "controller": {
                "envs": [
                  {
                    "name": "X_CSI_NFS_ACLS",
                    "value": "0777"
                  }
                ]
              },
              "dnsPolicy": "ClusterFirstWithHostNet",
              "forceUpdate": false,
              "fsGroupPolicy": "ReadWriteOnceWithFSType",
              "node": {
                "envs": [
                  {
                    "name": "X_CSI_POWERSTORE_ENABLE_CHAP",
                    "value": "true"
                  }
                ]
              },
              "replicas": 2
            }
          }
        },
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIUnity",
          "metadata": {
            "name": "test-unity",
            "namespace": "test-unity"
          },
          "spec": {
            "driver": {
              "common": {
                "image": "docker.io/dellemc/csi-unity@sha256:9fddd37cf5a6af47e05c6c148a928524d278f505dc0de53109fab3682963b652",
                "imagePullPolicy": "IfNotPresent"
              },
              "configVersion": "v2.2.0",
              "controller": {},
              "dnsPolicy": "ClusterFirstWithHostNet",
              "forceUpdate": false,
              "node": {},
              "replicas": 2,
              "sideCars": [
                {
                  "args": [
                    "--volume-name-prefix=csiunity",
                    "--default-fstype=ext4"
                  ],
                  "name": "provisioner"
                },
                {
                  "args": [
                    "--snapshot-name-prefix=csiunitysnap"
                  ],
                  "name": "snapshotter"
                }
              ]
            }
          }
        },
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIVXFlexOS",
          "metadata": {
            "name": "test-vxflexos",
            "namespace": "test-vxflexos"
          },
          "spec": {
            "driver": {
              "common": {
                "envs": [
                  {
                    "name": "X_CSI_VXFLEXOS_ENABLELISTVOLUMESNAPSHOT",
                    "value": "false"
                  },
                  {
                    "name": "X_CSI_VXFLEXOS_ENABLESNAPSHOTCGDELETE",
                    "value": "false"
                  },
                  {
                    "name": "X_CSI_DEBUG",
                    "value": "true"
                  },
                  {
                    "name": "X_CSI_ALLOW_RWO_MULTI_POD_ACCESS",
                    "value": "false"
                  }
                ],
                "image": "docker.io/dellemc/csi-vxflexos@sha256:7a52560cd0801315350bf7afab4707753aacb2d051511d0f42514107f0542b52",
                "imagePullPolicy": "IfNotPresent"
              },
              "configVersion": "v2.2.0",
              "dnsPolicy": "ClusterFirstWithHostNet",
              "forceUpdate": false,
              "initContainers": [
                {
                  "envs": [
                    {
                      "name": "MDM",
                      "value": "10.x.x.x,10.x.x.x"
                    }
                  ],
                  "image": "docker.io/dellemc/sdc@sha256:784b3ad7c0d5fbea8267e7e0be1830383f31d6bb57e4626c55cf5d0de344a272",
                  "imagePullPolicy": "IfNotPresent",
                  "name": "sdc"
                }
              ],
              "replicas": 1,
              "sideCars": [
                {
                  "envs": [
                    {
                      "name": "HOST_PID",
                      "value": "1"
                    },
                    {
                      "name": "MDM",
                      "value": ""
                    }
                  ],
                  "name": "sdc-monitor"
                }
              ]
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/dell-emc/dell-csiop-bundle-110@sha256:5b5ed897aa1626929c5ec762657587ea91470cf3609f7797832ba7ef9b6ab5ab",
      "bundle_path_digest": "sha256:5b5ed897aa1626929c5ec762657587ea91470cf3609f7797832ba7ef9b6ab5ab",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-19T21:08:04.098000+00:00",
      "csv_description": "Dell CSI Operator for Dell EMC CSI Drivers",
      "csv_display_name": "Dell CSI Operator",
      "csv_metadata_description": "",
      "csv_name": "dell-csi-operator-certified.v1.7.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:25:05.968000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "dell-csi-operator-certified",
      "provided_apis": [
        {
          "group": "storage.dell.com",
          "kind": "CSIIsilon",
          "version": "v1"
        },
        {
          "group": "storage.dell.com",
          "kind": "CSIPowerMax",
          "version": "v1"
        },
        {
          "group": "storage.dell.com",
          "kind": "CSIPowerMaxRevProxy",
          "version": "v1"
        },
        {
          "group": "storage.dell.com",
          "kind": "CSIPowerStore",
          "version": "v1"
        },
        {
          "group": "storage.dell.com",
          "kind": "CSIUnity",
          "version": "v1"
        },
        {
          "group": "storage.dell.com",
          "kind": "CSIVXFlexOS",
          "version": "v1"
        }
      ],
      "provider": "Dell EMC",
      "related_images": [
        {
          "digest": "sha256:5d849eca01387bbf2353017752ecb1f5937e8c6588d2de43cf0475c0b747dc90",
          "image": "docker.io/dellemc/dell-csi-operator@sha256:5d849eca01387bbf2353017752ecb1f5937e8c6588d2de43cf0475c0b747dc90",
          "name": "dell-csi-operator-5d849eca01387bbf2353017752ecb1f5937e8c6588d2de43cf0475c0b747dc90-annotation"
        },
        {
          "digest": "sha256:5d849eca01387bbf2353017752ecb1f5937e8c6588d2de43cf0475c0b747dc90",
          "image": "docker.io/dellemc/dell-csi-operator@sha256:5d849eca01387bbf2353017752ecb1f5937e8c6588d2de43cf0475c0b747dc90",
          "name": "dell-csi-operator-controller"
        },
        {
          "digest": "sha256:31a54a0cf86d7354788a8265f60ae6acb4b348a67efbcf7c1007dd3cf7af05ab",
          "image": "docker.io/busybox@sha256:31a54a0cf86d7354788a8265f60ae6acb4b348a67efbcf7c1007dd3cf7af05ab",
          "name": "config-copy"
        },
        {
          "digest": "sha256:784b3ad7c0d5fbea8267e7e0be1830383f31d6bb57e4626c55cf5d0de344a272",
          "image": "docker.io/dellemc/sdc@sha256:784b3ad7c0d5fbea8267e7e0be1830383f31d6bb57e4626c55cf5d0de344a272",
          "name": "sdc-784b3ad7c0d5fbea8267e7e0be1830383f31d6bb57e4626c55cf5d0de344a272-annotation"
        },
        {
          "digest": "sha256:7a52560cd0801315350bf7afab4707753aacb2d051511d0f42514107f0542b52",
          "image": "docker.io/dellemc/csi-vxflexos@sha256:7a52560cd0801315350bf7afab4707753aacb2d051511d0f42514107f0542b52",
          "name": "csi-vxflexos-7a52560cd0801315350bf7afab4707753aacb2d051511d0f42514107f0542b52-annotation"
        },
        {
          "digest": "sha256:9fddd37cf5a6af47e05c6c148a928524d278f505dc0de53109fab3682963b652",
          "image": "docker.io/dellemc/csi-unity@sha256:9fddd37cf5a6af47e05c6c148a928524d278f505dc0de53109fab3682963b652",
          "name": "csi-unity-9fddd37cf5a6af47e05c6c148a928524d278f505dc0de53109fab3682963b652-annotation"
        },
        {
          "digest": "sha256:08c5effefadf2e55103eb49ef2a5a325d9904e7391b6eeb72701dae6e682ad9e",
          "image": "docker.io/dellemc/csi-powerstore@sha256:08c5effefadf2e55103eb49ef2a5a325d9904e7391b6eeb72701dae6e682ad9e",
          "name": "csi-powerstore-08c5effefadf2e55103eb49ef2a5a325d9904e7391b6eeb72701dae6e682ad9e-annotation"
        },
        {
          "digest": "sha256:c236cb87d5799ef239b3e5df956761e1c042f3d5686c8e5728c06edfef3095b7",
          "image": "docker.io/dellemc/csipowermax-reverseproxy@sha256:c236cb87d5799ef239b3e5df956761e1c042f3d5686c8e5728c06edfef3095b7",
          "name": "csipowermax-reverseproxy-c236cb87d5799ef239b3e5df956761e1c042f3d5686c8e5728c06edfef3095b7-annotation"
        },
        {
          "digest": "sha256:2fc83456ec2fb2c0336725e039a3db699a0202468cd8e3fd12d7ef2423068fc8",
          "image": "docker.io/dellemc/csi-powermax@sha256:2fc83456ec2fb2c0336725e039a3db699a0202468cd8e3fd12d7ef2423068fc8",
          "name": "csi-powermax-2fc83456ec2fb2c0336725e039a3db699a0202468cd8e3fd12d7ef2423068fc8-annotation"
        },
        {
          "digest": "sha256:220dd73f1eaa4b927e53f3827109c126ad5108f6d37e68949b95cfce66206fbe",
          "image": "docker.io/dellemc/csi-isilon@sha256:220dd73f1eaa4b927e53f3827109c126ad5108f6d37e68949b95cfce66206fbe",
          "name": "csi-isilon-220dd73f1eaa4b927e53f3827109c126ad5108f6d37e68949b95cfce66206fbe-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.7.0",
      "version_original": "1.7.0"
    },
    {
      "_id": "6286b24931755c747c360652",
      "alm_examples": [
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIIsilon",
          "metadata": {
            "name": "isilon",
            "namespace": "test-isilon"
          },
          "spec": {
            "driver": {
              "common": {
                "envs": [
                  {
                    "name": "X_CSI_VERBOSE",
                    "value": "1"
                  },
                  {
                    "name": "X_CSI_ISI_PORT",
                    "value": "8080"
                  },
                  {
                    "name": "X_CSI_ISI_PATH",
                    "value": "/ifs/data/csi"
                  },
                  {
                    "name": "X_CSI_ISI_NO_PROBE_ON_START",
                    "value": "false"
                  },
                  {
                    "name": "X_CSI_ISI_AUTOPROBE",
                    "value": "true"
                  },
                  {
                    "name": "X_CSI_ISI_SKIP_CERTIFICATE_VALIDATION",
                    "value": "true"
                  },
                  {
                    "name": "X_CSI_ISI_AUTH_TYPE",
                    "value": "0"
                  },
                  {
                    "name": "X_CSI_CUSTOM_TOPOLOGY_ENABLED",
                    "value": "false"
                  }
                ],
                "image": "docker.io/dellemc/csi-isilon@sha256:220dd73f1eaa4b927e53f3827109c126ad5108f6d37e68949b95cfce66206fbe",
                "imagePullPolicy": "IfNotPresent"
              },
              "configVersion": "v2.2.0",
              "controller": {
                "envs": [
                  {
                    "name": "X_CSI_ISI_QUOTA_ENABLED",
                    "value": "true"
                  },
                  {
                    "name": "X_CSI_ISI_ACCESS_ZONE",
                    "value": "System"
                  },
                  {
                    "name": "X_CSI_ISI_VOLUME_PATH_PERMISSIONS",
                    "value": "0777"
                  }
                ]
              },
              "dnsPolicy": "ClusterFirstWithHostNet",
              "forceUpdate": false,
              "fsGroupPolicy": "ReadWriteOnceWithFSType",
              "node": {
                "envs": [
                  {
                    "name": "X_CSI_MAX_VOLUMES_PER_NODE",
                    "value": "0"
                  },
                  {
                    "name": "X_CSI_ALLOWED_NETWORKS",
                    "value": ""
                  }
                ]
              },
              "replicas": 2,
              "sideCars": [
                {
                  "args": [
                    "--leader-election-lease-duration=15s",
                    "--leader-election-renew-deadline=10s",
                    "--leader-election-retry-period=5s"
                  ],
                  "name": "common"
                },
                {
                  "args": [
                    "--volume-name-prefix=csipscale"
                  ],
                  "name": "provisioner"
                }
              ]
            }
          }
        },
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIPowerMax",
          "metadata": {
            "name": "test-powermax",
            "namespace": "test-powermax"
          },
          "spec": {
            "driver": {
              "common": {
                "envs": [
                  {
                    "name": "X_CSI_MANAGED_ARRAYS",
                    "value": "000000000000,000000000001"
                  },
                  {
                    "name": "X_CSI_POWERMAX_ENDPOINT",
                    "value": "https://0.0.0.0:8443/"
                  },
                  {
                    "name": "X_CSI_K8S_CLUSTER_PREFIX",
                    "value": "XYZ"
                  },
                  {
                    "name": "X_CSI_POWERMAX_PORTGROUPS",
                    "value": ""
                  },
                  {
                    "name": "X_CSI_TRANSPORT_PROTOCOL",
                    "value": ""
                  },
                  {
                    "name": "X_CSI_POWERMAX_PROXY_SERVICE_NAME",
                    "value": ""
                  },
                  {
                    "name": "X_CSI_GRPC_MAX_THREADS",
                    "value": "4"
                  }
                ],
                "image": "docker.io/dellemc/csi-powermax@sha256:2fc83456ec2fb2c0336725e039a3db699a0202468cd8e3fd12d7ef2423068fc8",
                "imagePullPolicy": "IfNotPresent"
              },
              "configVersion": "v2.2.0",
              "dnsPolicy": "ClusterFirstWithHostNet",
              "forceUpdate": false,
              "node": {
                "envs": [
                  {
                    "name": "X_CSI_POWERMAX_ISCSI_ENABLE_CHAP",
                    "value": "false"
                  }
                ]
              },
              "replicas": 2
            }
          }
        },
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIPowerMaxRevProxy",
          "metadata": {
            "name": "powermax-reverseproxy",
            "namespace": "test-powermax"
          },
          "spec": {
            "config": {
              "linkConfig": {
                "backup": {
                  "skipCertificateValidation": true,
                  "url": "https://0.0.0.0:8443"
                },
                "primary": {
                  "certSecret": "",
                  "skipCertificateValidation": true,
                  "url": "https://0.0.0.0:8443"
                }
              },
              "mode": "Linked"
            },
            "image": "docker.io/dellemc/csipowermax-reverseproxy@sha256:c236cb87d5799ef239b3e5df956761e1c042f3d5686c8e5728c06edfef3095b7",
            "imagePullPolicy": "IfNotPresent",
            "tlsSecret": "csirevproxy-tls-secret"
          }
        },
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIPowerStore",
          "metadata": {
            "name": "test-powerstore",
            "namespace": "test-powerstore"
          },
          "spec": {
            "driver": {
              "common": {
                "envs": [
                  {
                    "name": "X_CSI_POWERSTORE_NODE_NAME_PREFIX",
                    "value": "csi"
                  },
                  {
                    "name": "X_CSI_FC_PORTS_FILTER_FILE_PATH",
                    "value": "/etc/fc-ports-filter"
                  }
                ],
                "image": "docker.io/dellemc/csi-powerstore@sha256:08c5effefadf2e55103eb49ef2a5a325d9904e7391b6eeb72701dae6e682ad9e",
                "imagePullPolicy": "IfNotPresent"
              },
              "configVersion": "v2.2.0",
              "controller": {
                "envs": [
                  {
                    "name": "X_CSI_NFS_ACLS",
                    "value": "0777"
                  }
                ]
              },
              "dnsPolicy": "ClusterFirstWithHostNet",
              "forceUpdate": false,
              "fsGroupPolicy": "ReadWriteOnceWithFSType",
              "node": {
                "envs": [
                  {
                    "name": "X_CSI_POWERSTORE_ENABLE_CHAP",
                    "value": "true"
                  }
                ]
              },
              "replicas": 2
            }
          }
        },
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIUnity",
          "metadata": {
            "name": "test-unity",
            "namespace": "test-unity"
          },
          "spec": {
            "driver": {
              "common": {
                "image": "docker.io/dellemc/csi-unity@sha256:9fddd37cf5a6af47e05c6c148a928524d278f505dc0de53109fab3682963b652",
                "imagePullPolicy": "IfNotPresent"
              },
              "configVersion": "v2.2.0",
              "controller": {},
              "dnsPolicy": "ClusterFirstWithHostNet",
              "forceUpdate": false,
              "node": {},
              "replicas": 2,
              "sideCars": [
                {
                  "args": [
                    "--volume-name-prefix=csiunity",
                    "--default-fstype=ext4"
                  ],
                  "name": "provisioner"
                },
                {
                  "args": [
                    "--snapshot-name-prefix=csiunitysnap"
                  ],
                  "name": "snapshotter"
                }
              ]
            }
          }
        },
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIVXFlexOS",
          "metadata": {
            "name": "test-vxflexos",
            "namespace": "test-vxflexos"
          },
          "spec": {
            "driver": {
              "common": {
                "envs": [
                  {
                    "name": "X_CSI_VXFLEXOS_ENABLELISTVOLUMESNAPSHOT",
                    "value": "false"
                  },
                  {
                    "name": "X_CSI_VXFLEXOS_ENABLESNAPSHOTCGDELETE",
                    "value": "false"
                  },
                  {
                    "name": "X_CSI_DEBUG",
                    "value": "true"
                  },
                  {
                    "name": "X_CSI_ALLOW_RWO_MULTI_POD_ACCESS",
                    "value": "false"
                  }
                ],
                "image": "docker.io/dellemc/csi-vxflexos@sha256:7a52560cd0801315350bf7afab4707753aacb2d051511d0f42514107f0542b52",
                "imagePullPolicy": "IfNotPresent"
              },
              "configVersion": "v2.2.0",
              "dnsPolicy": "ClusterFirstWithHostNet",
              "forceUpdate": false,
              "initContainers": [
                {
                  "envs": [
                    {
                      "name": "MDM",
                      "value": "10.x.x.x,10.x.x.x"
                    }
                  ],
                  "image": "docker.io/dellemc/sdc@sha256:784b3ad7c0d5fbea8267e7e0be1830383f31d6bb57e4626c55cf5d0de344a272",
                  "imagePullPolicy": "IfNotPresent",
                  "name": "sdc"
                }
              ],
              "replicas": 1,
              "sideCars": [
                {
                  "envs": [
                    {
                      "name": "HOST_PID",
                      "value": "1"
                    },
                    {
                      "name": "MDM",
                      "value": ""
                    }
                  ],
                  "name": "sdc-monitor"
                }
              ]
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/dell-emc/dell-csiop-bundle-110@sha256:5b5ed897aa1626929c5ec762657587ea91470cf3609f7797832ba7ef9b6ab5ab",
      "bundle_path_digest": "sha256:5b5ed897aa1626929c5ec762657587ea91470cf3609f7797832ba7ef9b6ab5ab",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-19T21:10:33.614000+00:00",
      "csv_description": "Dell CSI Operator for Dell EMC CSI Drivers",
      "csv_display_name": "Dell CSI Operator",
      "csv_metadata_description": "",
      "csv_name": "dell-csi-operator-certified.v1.7.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T12:57:09.962000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "dell-csi-operator-certified",
      "provided_apis": [
        {
          "group": "storage.dell.com",
          "kind": "CSIIsilon",
          "plural": "csiisilons",
          "version": "v1"
        },
        {
          "group": "storage.dell.com",
          "kind": "CSIPowerMax",
          "plural": "csipowermaxes",
          "version": "v1"
        },
        {
          "group": "storage.dell.com",
          "kind": "CSIPowerMaxRevProxy",
          "plural": "csipowermaxrevproxies",
          "version": "v1"
        },
        {
          "group": "storage.dell.com",
          "kind": "CSIPowerStore",
          "plural": "csipowerstores",
          "version": "v1"
        },
        {
          "group": "storage.dell.com",
          "kind": "CSIUnity",
          "plural": "csiunities",
          "version": "v1"
        },
        {
          "group": "storage.dell.com",
          "kind": "CSIVXFlexOS",
          "plural": "csivxflexoses",
          "version": "v1"
        }
      ],
      "provider": "Dell EMC",
      "related_images": [
        {
          "digest": "sha256:5d849eca01387bbf2353017752ecb1f5937e8c6588d2de43cf0475c0b747dc90",
          "image": "docker.io/dellemc/dell-csi-operator@sha256:5d849eca01387bbf2353017752ecb1f5937e8c6588d2de43cf0475c0b747dc90",
          "name": "dell-csi-operator-5d849eca01387bbf2353017752ecb1f5937e8c6588d2de43cf0475c0b747dc90-annotation"
        },
        {
          "digest": "sha256:5d849eca01387bbf2353017752ecb1f5937e8c6588d2de43cf0475c0b747dc90",
          "image": "docker.io/dellemc/dell-csi-operator@sha256:5d849eca01387bbf2353017752ecb1f5937e8c6588d2de43cf0475c0b747dc90",
          "name": "dell-csi-operator-controller"
        },
        {
          "digest": "sha256:31a54a0cf86d7354788a8265f60ae6acb4b348a67efbcf7c1007dd3cf7af05ab",
          "image": "docker.io/busybox@sha256:31a54a0cf86d7354788a8265f60ae6acb4b348a67efbcf7c1007dd3cf7af05ab",
          "name": "config-copy"
        },
        {
          "digest": "sha256:784b3ad7c0d5fbea8267e7e0be1830383f31d6bb57e4626c55cf5d0de344a272",
          "image": "docker.io/dellemc/sdc@sha256:784b3ad7c0d5fbea8267e7e0be1830383f31d6bb57e4626c55cf5d0de344a272",
          "name": "sdc-784b3ad7c0d5fbea8267e7e0be1830383f31d6bb57e4626c55cf5d0de344a272-annotation"
        },
        {
          "digest": "sha256:7a52560cd0801315350bf7afab4707753aacb2d051511d0f42514107f0542b52",
          "image": "docker.io/dellemc/csi-vxflexos@sha256:7a52560cd0801315350bf7afab4707753aacb2d051511d0f42514107f0542b52",
          "name": "csi-vxflexos-7a52560cd0801315350bf7afab4707753aacb2d051511d0f42514107f0542b52-annotation"
        },
        {
          "digest": "sha256:9fddd37cf5a6af47e05c6c148a928524d278f505dc0de53109fab3682963b652",
          "image": "docker.io/dellemc/csi-unity@sha256:9fddd37cf5a6af47e05c6c148a928524d278f505dc0de53109fab3682963b652",
          "name": "csi-unity-9fddd37cf5a6af47e05c6c148a928524d278f505dc0de53109fab3682963b652-annotation"
        },
        {
          "digest": "sha256:08c5effefadf2e55103eb49ef2a5a325d9904e7391b6eeb72701dae6e682ad9e",
          "image": "docker.io/dellemc/csi-powerstore@sha256:08c5effefadf2e55103eb49ef2a5a325d9904e7391b6eeb72701dae6e682ad9e",
          "name": "csi-powerstore-08c5effefadf2e55103eb49ef2a5a325d9904e7391b6eeb72701dae6e682ad9e-annotation"
        },
        {
          "digest": "sha256:c236cb87d5799ef239b3e5df956761e1c042f3d5686c8e5728c06edfef3095b7",
          "image": "docker.io/dellemc/csipowermax-reverseproxy@sha256:c236cb87d5799ef239b3e5df956761e1c042f3d5686c8e5728c06edfef3095b7",
          "name": "csipowermax-reverseproxy-c236cb87d5799ef239b3e5df956761e1c042f3d5686c8e5728c06edfef3095b7-annotation"
        },
        {
          "digest": "sha256:2fc83456ec2fb2c0336725e039a3db699a0202468cd8e3fd12d7ef2423068fc8",
          "image": "docker.io/dellemc/csi-powermax@sha256:2fc83456ec2fb2c0336725e039a3db699a0202468cd8e3fd12d7ef2423068fc8",
          "name": "csi-powermax-2fc83456ec2fb2c0336725e039a3db699a0202468cd8e3fd12d7ef2423068fc8-annotation"
        },
        {
          "digest": "sha256:220dd73f1eaa4b927e53f3827109c126ad5108f6d37e68949b95cfce66206fbe",
          "image": "docker.io/dellemc/csi-isilon@sha256:220dd73f1eaa4b927e53f3827109c126ad5108f6d37e68949b95cfce66206fbe",
          "name": "csi-isilon-220dd73f1eaa4b927e53f3827109c126ad5108f6d37e68949b95cfce66206fbe-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.7.0",
      "version_original": "1.7.0"
    },
    {
      "_id": "6286b36431755c747c3606a6",
      "alm_examples": [
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIIsilon",
          "metadata": {
            "name": "isilon",
            "namespace": "test-isilon"
          },
          "spec": {
            "driver": {
              "common": {
                "envs": [
                  {
                    "name": "X_CSI_VERBOSE",
                    "value": "1"
                  },
                  {
                    "name": "X_CSI_ISI_PORT",
                    "value": "8080"
                  },
                  {
                    "name": "X_CSI_ISI_PATH",
                    "value": "/ifs/data/csi"
                  },
                  {
                    "name": "X_CSI_ISI_NO_PROBE_ON_START",
                    "value": "false"
                  },
                  {
                    "name": "X_CSI_ISI_AUTOPROBE",
                    "value": "true"
                  },
                  {
                    "name": "X_CSI_ISI_SKIP_CERTIFICATE_VALIDATION",
                    "value": "true"
                  },
                  {
                    "name": "X_CSI_ISI_AUTH_TYPE",
                    "value": "0"
                  },
                  {
                    "name": "X_CSI_CUSTOM_TOPOLOGY_ENABLED",
                    "value": "false"
                  }
                ],
                "image": "docker.io/dellemc/csi-isilon@sha256:220dd73f1eaa4b927e53f3827109c126ad5108f6d37e68949b95cfce66206fbe",
                "imagePullPolicy": "IfNotPresent"
              },
              "configVersion": "v2.2.0",
              "controller": {
                "envs": [
                  {
                    "name": "X_CSI_ISI_QUOTA_ENABLED",
                    "value": "true"
                  },
                  {
                    "name": "X_CSI_ISI_ACCESS_ZONE",
                    "value": "System"
                  },
                  {
                    "name": "X_CSI_ISI_VOLUME_PATH_PERMISSIONS",
                    "value": "0777"
                  }
                ]
              },
              "dnsPolicy": "ClusterFirstWithHostNet",
              "forceUpdate": false,
              "fsGroupPolicy": "ReadWriteOnceWithFSType",
              "node": {
                "envs": [
                  {
                    "name": "X_CSI_MAX_VOLUMES_PER_NODE",
                    "value": "0"
                  },
                  {
                    "name": "X_CSI_ALLOWED_NETWORKS",
                    "value": ""
                  }
                ]
              },
              "replicas": 2,
              "sideCars": [
                {
                  "args": [
                    "--leader-election-lease-duration=15s",
                    "--leader-election-renew-deadline=10s",
                    "--leader-election-retry-period=5s"
                  ],
                  "name": "common"
                },
                {
                  "args": [
                    "--volume-name-prefix=csipscale"
                  ],
                  "name": "provisioner"
                }
              ]
            }
          }
        },
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIPowerMax",
          "metadata": {
            "name": "test-powermax",
            "namespace": "test-powermax"
          },
          "spec": {
            "driver": {
              "common": {
                "envs": [
                  {
                    "name": "X_CSI_MANAGED_ARRAYS",
                    "value": "000000000000,000000000001"
                  },
                  {
                    "name": "X_CSI_POWERMAX_ENDPOINT",
                    "value": "https://0.0.0.0:8443/"
                  },
                  {
                    "name": "X_CSI_K8S_CLUSTER_PREFIX",
                    "value": "XYZ"
                  },
                  {
                    "name": "X_CSI_POWERMAX_PORTGROUPS",
                    "value": ""
                  },
                  {
                    "name": "X_CSI_TRANSPORT_PROTOCOL",
                    "value": ""
                  },
                  {
                    "name": "X_CSI_POWERMAX_PROXY_SERVICE_NAME",
                    "value": ""
                  },
                  {
                    "name": "X_CSI_GRPC_MAX_THREADS",
                    "value": "4"
                  }
                ],
                "image": "docker.io/dellemc/csi-powermax@sha256:2fc83456ec2fb2c0336725e039a3db699a0202468cd8e3fd12d7ef2423068fc8",
                "imagePullPolicy": "IfNotPresent"
              },
              "configVersion": "v2.2.0",
              "dnsPolicy": "ClusterFirstWithHostNet",
              "forceUpdate": false,
              "node": {
                "envs": [
                  {
                    "name": "X_CSI_POWERMAX_ISCSI_ENABLE_CHAP",
                    "value": "false"
                  }
                ]
              },
              "replicas": 2
            }
          }
        },
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIPowerMaxRevProxy",
          "metadata": {
            "name": "powermax-reverseproxy",
            "namespace": "test-powermax"
          },
          "spec": {
            "config": {
              "linkConfig": {
                "backup": {
                  "skipCertificateValidation": true,
                  "url": "https://0.0.0.0:8443"
                },
                "primary": {
                  "certSecret": "",
                  "skipCertificateValidation": true,
                  "url": "https://0.0.0.0:8443"
                }
              },
              "mode": "Linked"
            },
            "image": "docker.io/dellemc/csipowermax-reverseproxy@sha256:c236cb87d5799ef239b3e5df956761e1c042f3d5686c8e5728c06edfef3095b7",
            "imagePullPolicy": "IfNotPresent",
            "tlsSecret": "csirevproxy-tls-secret"
          }
        },
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIPowerStore",
          "metadata": {
            "name": "test-powerstore",
            "namespace": "test-powerstore"
          },
          "spec": {
            "driver": {
              "common": {
                "envs": [
                  {
                    "name": "X_CSI_POWERSTORE_NODE_NAME_PREFIX",
                    "value": "csi"
                  },
                  {
                    "name": "X_CSI_FC_PORTS_FILTER_FILE_PATH",
                    "value": "/etc/fc-ports-filter"
                  }
                ],
                "image": "docker.io/dellemc/csi-powerstore@sha256:08c5effefadf2e55103eb49ef2a5a325d9904e7391b6eeb72701dae6e682ad9e",
                "imagePullPolicy": "IfNotPresent"
              },
              "configVersion": "v2.2.0",
              "controller": {
                "envs": [
                  {
                    "name": "X_CSI_NFS_ACLS",
                    "value": "0777"
                  }
                ]
              },
              "dnsPolicy": "ClusterFirstWithHostNet",
              "forceUpdate": false,
              "fsGroupPolicy": "ReadWriteOnceWithFSType",
              "node": {
                "envs": [
                  {
                    "name": "X_CSI_POWERSTORE_ENABLE_CHAP",
                    "value": "true"
                  }
                ]
              },
              "replicas": 2
            }
          }
        },
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIUnity",
          "metadata": {
            "name": "test-unity",
            "namespace": "test-unity"
          },
          "spec": {
            "driver": {
              "common": {
                "image": "docker.io/dellemc/csi-unity@sha256:9fddd37cf5a6af47e05c6c148a928524d278f505dc0de53109fab3682963b652",
                "imagePullPolicy": "IfNotPresent"
              },
              "configVersion": "v2.2.0",
              "controller": {},
              "dnsPolicy": "ClusterFirstWithHostNet",
              "forceUpdate": false,
              "node": {},
              "replicas": 2,
              "sideCars": [
                {
                  "args": [
                    "--volume-name-prefix=csiunity",
                    "--default-fstype=ext4"
                  ],
                  "name": "provisioner"
                },
                {
                  "args": [
                    "--snapshot-name-prefix=csiunitysnap"
                  ],
                  "name": "snapshotter"
                }
              ]
            }
          }
        },
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIVXFlexOS",
          "metadata": {
            "name": "test-vxflexos",
            "namespace": "test-vxflexos"
          },
          "spec": {
            "driver": {
              "common": {
                "envs": [
                  {
                    "name": "X_CSI_VXFLEXOS_ENABLELISTVOLUMESNAPSHOT",
                    "value": "false"
                  },
                  {
                    "name": "X_CSI_VXFLEXOS_ENABLESNAPSHOTCGDELETE",
                    "value": "false"
                  },
                  {
                    "name": "X_CSI_DEBUG",
                    "value": "true"
                  },
                  {
                    "name": "X_CSI_ALLOW_RWO_MULTI_POD_ACCESS",
                    "value": "false"
                  }
                ],
                "image": "docker.io/dellemc/csi-vxflexos@sha256:7a52560cd0801315350bf7afab4707753aacb2d051511d0f42514107f0542b52",
                "imagePullPolicy": "IfNotPresent"
              },
              "configVersion": "v2.2.0",
              "dnsPolicy": "ClusterFirstWithHostNet",
              "forceUpdate": false,
              "initContainers": [
                {
                  "envs": [
                    {
                      "name": "MDM",
                      "value": "10.x.x.x,10.x.x.x"
                    }
                  ],
                  "image": "docker.io/dellemc/sdc@sha256:784b3ad7c0d5fbea8267e7e0be1830383f31d6bb57e4626c55cf5d0de344a272",
                  "imagePullPolicy": "IfNotPresent",
                  "name": "sdc"
                }
              ],
              "replicas": 1,
              "sideCars": [
                {
                  "envs": [
                    {
                      "name": "HOST_PID",
                      "value": "1"
                    },
                    {
                      "name": "MDM",
                      "value": ""
                    }
                  ],
                  "name": "sdc-monitor"
                }
              ]
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/dell-emc/dell-csiop-bundle-110@sha256:5b5ed897aa1626929c5ec762657587ea91470cf3609f7797832ba7ef9b6ab5ab",
      "bundle_path_digest": "sha256:5b5ed897aa1626929c5ec762657587ea91470cf3609f7797832ba7ef9b6ab5ab",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-19T21:15:16.001000+00:00",
      "csv_description": "Dell CSI Operator for Dell EMC CSI Drivers",
      "csv_display_name": "Dell CSI Operator",
      "csv_metadata_description": "",
      "csv_name": "dell-csi-operator-certified.v1.7.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T12:54:24.786000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "dell-csi-operator-certified",
      "provided_apis": [
        {
          "group": "storage.dell.com",
          "kind": "CSIPowerStore",
          "plural": "csipowerstores",
          "version": "v1"
        },
        {
          "group": "storage.dell.com",
          "kind": "CSIUnity",
          "plural": "csiunities",
          "version": "v1"
        },
        {
          "group": "storage.dell.com",
          "kind": "CSIVXFlexOS",
          "plural": "csivxflexoses",
          "version": "v1"
        },
        {
          "group": "storage.dell.com",
          "kind": "CSIIsilon",
          "plural": "csiisilons",
          "version": "v1"
        },
        {
          "group": "storage.dell.com",
          "kind": "CSIPowerMax",
          "plural": "csipowermaxes",
          "version": "v1"
        },
        {
          "group": "storage.dell.com",
          "kind": "CSIPowerMaxRevProxy",
          "plural": "csipowermaxrevproxies",
          "version": "v1"
        }
      ],
      "provider": "Dell EMC",
      "related_images": [
        {
          "digest": "sha256:5d849eca01387bbf2353017752ecb1f5937e8c6588d2de43cf0475c0b747dc90",
          "image": "docker.io/dellemc/dell-csi-operator@sha256:5d849eca01387bbf2353017752ecb1f5937e8c6588d2de43cf0475c0b747dc90",
          "name": "dell-csi-operator-5d849eca01387bbf2353017752ecb1f5937e8c6588d2de43cf0475c0b747dc90-annotation"
        },
        {
          "digest": "sha256:5d849eca01387bbf2353017752ecb1f5937e8c6588d2de43cf0475c0b747dc90",
          "image": "docker.io/dellemc/dell-csi-operator@sha256:5d849eca01387bbf2353017752ecb1f5937e8c6588d2de43cf0475c0b747dc90",
          "name": "dell-csi-operator-controller"
        },
        {
          "digest": "sha256:31a54a0cf86d7354788a8265f60ae6acb4b348a67efbcf7c1007dd3cf7af05ab",
          "image": "docker.io/busybox@sha256:31a54a0cf86d7354788a8265f60ae6acb4b348a67efbcf7c1007dd3cf7af05ab",
          "name": "config-copy"
        },
        {
          "digest": "sha256:784b3ad7c0d5fbea8267e7e0be1830383f31d6bb57e4626c55cf5d0de344a272",
          "image": "docker.io/dellemc/sdc@sha256:784b3ad7c0d5fbea8267e7e0be1830383f31d6bb57e4626c55cf5d0de344a272",
          "name": "sdc-784b3ad7c0d5fbea8267e7e0be1830383f31d6bb57e4626c55cf5d0de344a272-annotation"
        },
        {
          "digest": "sha256:7a52560cd0801315350bf7afab4707753aacb2d051511d0f42514107f0542b52",
          "image": "docker.io/dellemc/csi-vxflexos@sha256:7a52560cd0801315350bf7afab4707753aacb2d051511d0f42514107f0542b52",
          "name": "csi-vxflexos-7a52560cd0801315350bf7afab4707753aacb2d051511d0f42514107f0542b52-annotation"
        },
        {
          "digest": "sha256:9fddd37cf5a6af47e05c6c148a928524d278f505dc0de53109fab3682963b652",
          "image": "docker.io/dellemc/csi-unity@sha256:9fddd37cf5a6af47e05c6c148a928524d278f505dc0de53109fab3682963b652",
          "name": "csi-unity-9fddd37cf5a6af47e05c6c148a928524d278f505dc0de53109fab3682963b652-annotation"
        },
        {
          "digest": "sha256:08c5effefadf2e55103eb49ef2a5a325d9904e7391b6eeb72701dae6e682ad9e",
          "image": "docker.io/dellemc/csi-powerstore@sha256:08c5effefadf2e55103eb49ef2a5a325d9904e7391b6eeb72701dae6e682ad9e",
          "name": "csi-powerstore-08c5effefadf2e55103eb49ef2a5a325d9904e7391b6eeb72701dae6e682ad9e-annotation"
        },
        {
          "digest": "sha256:c236cb87d5799ef239b3e5df956761e1c042f3d5686c8e5728c06edfef3095b7",
          "image": "docker.io/dellemc/csipowermax-reverseproxy@sha256:c236cb87d5799ef239b3e5df956761e1c042f3d5686c8e5728c06edfef3095b7",
          "name": "csipowermax-reverseproxy-c236cb87d5799ef239b3e5df956761e1c042f3d5686c8e5728c06edfef3095b7-annotation"
        },
        {
          "digest": "sha256:2fc83456ec2fb2c0336725e039a3db699a0202468cd8e3fd12d7ef2423068fc8",
          "image": "docker.io/dellemc/csi-powermax@sha256:2fc83456ec2fb2c0336725e039a3db699a0202468cd8e3fd12d7ef2423068fc8",
          "name": "csi-powermax-2fc83456ec2fb2c0336725e039a3db699a0202468cd8e3fd12d7ef2423068fc8-annotation"
        },
        {
          "digest": "sha256:220dd73f1eaa4b927e53f3827109c126ad5108f6d37e68949b95cfce66206fbe",
          "image": "docker.io/dellemc/csi-isilon@sha256:220dd73f1eaa4b927e53f3827109c126ad5108f6d37e68949b95cfce66206fbe",
          "name": "csi-isilon-220dd73f1eaa4b927e53f3827109c126ad5108f6d37e68949b95cfce66206fbe-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.7.0",
      "version_original": "1.7.0"
    },
    {
      "_id": "6286b63d3fcd237f6972734b",
      "alm_examples": [
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIIsilon",
          "metadata": {
            "name": "isilon",
            "namespace": "test-isilon"
          },
          "spec": {
            "driver": {
              "common": {
                "envs": [
                  {
                    "name": "X_CSI_VERBOSE",
                    "value": "1"
                  },
                  {
                    "name": "X_CSI_ISI_PORT",
                    "value": "8080"
                  },
                  {
                    "name": "X_CSI_ISI_PATH",
                    "value": "/ifs/data/csi"
                  },
                  {
                    "name": "X_CSI_ISI_NO_PROBE_ON_START",
                    "value": "false"
                  },
                  {
                    "name": "X_CSI_ISI_AUTOPROBE",
                    "value": "true"
                  },
                  {
                    "name": "X_CSI_ISI_SKIP_CERTIFICATE_VALIDATION",
                    "value": "true"
                  },
                  {
                    "name": "X_CSI_ISI_AUTH_TYPE",
                    "value": "0"
                  },
                  {
                    "name": "X_CSI_CUSTOM_TOPOLOGY_ENABLED",
                    "value": "false"
                  }
                ],
                "image": "docker.io/dellemc/csi-isilon@sha256:220dd73f1eaa4b927e53f3827109c126ad5108f6d37e68949b95cfce66206fbe",
                "imagePullPolicy": "IfNotPresent"
              },
              "configVersion": "v2.2.0",
              "controller": {
                "envs": [
                  {
                    "name": "X_CSI_ISI_QUOTA_ENABLED",
                    "value": "true"
                  },
                  {
                    "name": "X_CSI_ISI_ACCESS_ZONE",
                    "value": "System"
                  },
                  {
                    "name": "X_CSI_ISI_VOLUME_PATH_PERMISSIONS",
                    "value": "0777"
                  }
                ]
              },
              "dnsPolicy": "ClusterFirstWithHostNet",
              "forceUpdate": false,
              "fsGroupPolicy": "ReadWriteOnceWithFSType",
              "node": {
                "envs": [
                  {
                    "name": "X_CSI_MAX_VOLUMES_PER_NODE",
                    "value": "0"
                  },
                  {
                    "name": "X_CSI_ALLOWED_NETWORKS",
                    "value": ""
                  }
                ]
              },
              "replicas": 2,
              "sideCars": [
                {
                  "args": [
                    "--leader-election-lease-duration=15s",
                    "--leader-election-renew-deadline=10s",
                    "--leader-election-retry-period=5s"
                  ],
                  "name": "common"
                },
                {
                  "args": [
                    "--volume-name-prefix=csipscale"
                  ],
                  "name": "provisioner"
                }
              ]
            }
          }
        },
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIPowerMax",
          "metadata": {
            "name": "test-powermax",
            "namespace": "test-powermax"
          },
          "spec": {
            "driver": {
              "common": {
                "envs": [
                  {
                    "name": "X_CSI_MANAGED_ARRAYS",
                    "value": "000000000000,000000000001"
                  },
                  {
                    "name": "X_CSI_POWERMAX_ENDPOINT",
                    "value": "https://0.0.0.0:8443/"
                  },
                  {
                    "name": "X_CSI_K8S_CLUSTER_PREFIX",
                    "value": "XYZ"
                  },
                  {
                    "name": "X_CSI_POWERMAX_PORTGROUPS",
                    "value": ""
                  },
                  {
                    "name": "X_CSI_TRANSPORT_PROTOCOL",
                    "value": ""
                  },
                  {
                    "name": "X_CSI_POWERMAX_PROXY_SERVICE_NAME",
                    "value": ""
                  },
                  {
                    "name": "X_CSI_GRPC_MAX_THREADS",
                    "value": "4"
                  }
                ],
                "image": "docker.io/dellemc/csi-powermax@sha256:2fc83456ec2fb2c0336725e039a3db699a0202468cd8e3fd12d7ef2423068fc8",
                "imagePullPolicy": "IfNotPresent"
              },
              "configVersion": "v2.2.0",
              "dnsPolicy": "ClusterFirstWithHostNet",
              "forceUpdate": false,
              "node": {
                "envs": [
                  {
                    "name": "X_CSI_POWERMAX_ISCSI_ENABLE_CHAP",
                    "value": "false"
                  }
                ]
              },
              "replicas": 2
            }
          }
        },
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIPowerMaxRevProxy",
          "metadata": {
            "name": "powermax-reverseproxy",
            "namespace": "test-powermax"
          },
          "spec": {
            "config": {
              "linkConfig": {
                "backup": {
                  "skipCertificateValidation": true,
                  "url": "https://0.0.0.0:8443"
                },
                "primary": {
                  "certSecret": "",
                  "skipCertificateValidation": true,
                  "url": "https://0.0.0.0:8443"
                }
              },
              "mode": "Linked"
            },
            "image": "docker.io/dellemc/csipowermax-reverseproxy@sha256:c236cb87d5799ef239b3e5df956761e1c042f3d5686c8e5728c06edfef3095b7",
            "imagePullPolicy": "IfNotPresent",
            "tlsSecret": "csirevproxy-tls-secret"
          }
        },
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIPowerStore",
          "metadata": {
            "name": "test-powerstore",
            "namespace": "test-powerstore"
          },
          "spec": {
            "driver": {
              "common": {
                "envs": [
                  {
                    "name": "X_CSI_POWERSTORE_NODE_NAME_PREFIX",
                    "value": "csi"
                  },
                  {
                    "name": "X_CSI_FC_PORTS_FILTER_FILE_PATH",
                    "value": "/etc/fc-ports-filter"
                  }
                ],
                "image": "docker.io/dellemc/csi-powerstore@sha256:08c5effefadf2e55103eb49ef2a5a325d9904e7391b6eeb72701dae6e682ad9e",
                "imagePullPolicy": "IfNotPresent"
              },
              "configVersion": "v2.2.0",
              "controller": {
                "envs": [
                  {
                    "name": "X_CSI_NFS_ACLS",
                    "value": "0777"
                  }
                ]
              },
              "dnsPolicy": "ClusterFirstWithHostNet",
              "forceUpdate": false,
              "fsGroupPolicy": "ReadWriteOnceWithFSType",
              "node": {
                "envs": [
                  {
                    "name": "X_CSI_POWERSTORE_ENABLE_CHAP",
                    "value": "true"
                  }
                ]
              },
              "replicas": 2
            }
          }
        },
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIUnity",
          "metadata": {
            "name": "test-unity",
            "namespace": "test-unity"
          },
          "spec": {
            "driver": {
              "common": {
                "image": "docker.io/dellemc/csi-unity@sha256:9fddd37cf5a6af47e05c6c148a928524d278f505dc0de53109fab3682963b652",
                "imagePullPolicy": "IfNotPresent"
              },
              "configVersion": "v2.2.0",
              "controller": {},
              "dnsPolicy": "ClusterFirstWithHostNet",
              "forceUpdate": false,
              "node": {},
              "replicas": 2,
              "sideCars": [
                {
                  "args": [
                    "--volume-name-prefix=csiunity",
                    "--default-fstype=ext4"
                  ],
                  "name": "provisioner"
                },
                {
                  "args": [
                    "--snapshot-name-prefix=csiunitysnap"
                  ],
                  "name": "snapshotter"
                }
              ]
            }
          }
        },
        {
          "api_version": "storage.dell.com/v1",
          "kind": "CSIVXFlexOS",
          "metadata": {
            "name": "test-vxflexos",
            "namespace": "test-vxflexos"
          },
          "spec": {
            "driver": {
              "common": {
                "envs": [
                  {
                    "name": "X_CSI_VXFLEXOS_ENABLELISTVOLUMESNAPSHOT",
                    "value": "false"
                  },
                  {
                    "name": "X_CSI_VXFLEXOS_ENABLESNAPSHOTCGDELETE",
                    "value": "false"
                  },
                  {
                    "name": "X_CSI_DEBUG",
                    "value": "true"
                  },
                  {
                    "name": "X_CSI_ALLOW_RWO_MULTI_POD_ACCESS",
                    "value": "false"
                  }
                ],
                "image": "docker.io/dellemc/csi-vxflexos@sha256:7a52560cd0801315350bf7afab4707753aacb2d051511d0f42514107f0542b52",
                "imagePullPolicy": "IfNotPresent"
              },
              "configVersion": "v2.2.0",
              "dnsPolicy": "ClusterFirstWithHostNet",
              "forceUpdate": false,
              "initContainers": [
                {
                  "envs": [
                    {
                      "name": "MDM",
                      "value": "10.x.x.x,10.x.x.x"
                    }
                  ],
                  "image": "docker.io/dellemc/sdc@sha256:784b3ad7c0d5fbea8267e7e0be1830383f31d6bb57e4626c55cf5d0de344a272",
                  "imagePullPolicy": "IfNotPresent",
                  "name": "sdc"
                }
              ],
              "replicas": 1,
              "sideCars": [
                {
                  "envs": [
                    {
                      "name": "HOST_PID",
                      "value": "1"
                    },
                    {
                      "name": "MDM",
                      "value": ""
                    }
                  ],
                  "name": "sdc-monitor"
                }
              ]
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/dell-emc/dell-csiop-bundle-110@sha256:5b5ed897aa1626929c5ec762657587ea91470cf3609f7797832ba7ef9b6ab5ab",
      "bundle_path_digest": "sha256:5b5ed897aa1626929c5ec762657587ea91470cf3609f7797832ba7ef9b6ab5ab",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-19T21:27:25.472000+00:00",
      "csv_description": "Dell CSI Operator for Dell EMC CSI Drivers",
      "csv_display_name": "Dell CSI Operator",
      "csv_metadata_description": "",
      "csv_name": "dell-csi-operator-certified.v1.7.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:38:26.780000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "dell-csi-operator-certified",
      "provided_apis": [
        {
          "group": "storage.dell.com",
          "kind": "CSIPowerMaxRevProxy",
          "plural": "csipowermaxrevproxies",
          "version": "v1"
        },
        {
          "group": "storage.dell.com",
          "kind": "CSIPowerStore",
          "plural": "csipowerstores",
          "version": "v1"
        },
        {
          "group": "storage.dell.com",
          "kind": "CSIUnity",
          "plural": "csiunities",
          "version": "v1"
        },
        {
          "group": "storage.dell.com",
          "kind": "CSIVXFlexOS",
          "plural": "csivxflexoses",
          "version": "v1"
        },
        {
          "group": "storage.dell.com",
          "kind": "CSIIsilon",
          "plural": "csiisilons",
          "version": "v1"
        },
        {
          "group": "storage.dell.com",
          "kind": "CSIPowerMax",
          "plural": "csipowermaxes",
          "version": "v1"
        }
      ],
      "provider": "Dell EMC",
      "related_images": [
        {
          "digest": "sha256:5d849eca01387bbf2353017752ecb1f5937e8c6588d2de43cf0475c0b747dc90",
          "image": "docker.io/dellemc/dell-csi-operator@sha256:5d849eca01387bbf2353017752ecb1f5937e8c6588d2de43cf0475c0b747dc90",
          "name": "dell-csi-operator-5d849eca01387bbf2353017752ecb1f5937e8c6588d2de43cf0475c0b747dc90-annotation"
        },
        {
          "digest": "sha256:5d849eca01387bbf2353017752ecb1f5937e8c6588d2de43cf0475c0b747dc90",
          "image": "docker.io/dellemc/dell-csi-operator@sha256:5d849eca01387bbf2353017752ecb1f5937e8c6588d2de43cf0475c0b747dc90",
          "name": "dell-csi-operator-controller"
        },
        {
          "digest": "sha256:31a54a0cf86d7354788a8265f60ae6acb4b348a67efbcf7c1007dd3cf7af05ab",
          "image": "docker.io/busybox@sha256:31a54a0cf86d7354788a8265f60ae6acb4b348a67efbcf7c1007dd3cf7af05ab",
          "name": "config-copy"
        },
        {
          "digest": "sha256:784b3ad7c0d5fbea8267e7e0be1830383f31d6bb57e4626c55cf5d0de344a272",
          "image": "docker.io/dellemc/sdc@sha256:784b3ad7c0d5fbea8267e7e0be1830383f31d6bb57e4626c55cf5d0de344a272",
          "name": "sdc-784b3ad7c0d5fbea8267e7e0be1830383f31d6bb57e4626c55cf5d0de344a272-annotation"
        },
        {
          "digest": "sha256:7a52560cd0801315350bf7afab4707753aacb2d051511d0f42514107f0542b52",
          "image": "docker.io/dellemc/csi-vxflexos@sha256:7a52560cd0801315350bf7afab4707753aacb2d051511d0f42514107f0542b52",
          "name": "csi-vxflexos-7a52560cd0801315350bf7afab4707753aacb2d051511d0f42514107f0542b52-annotation"
        },
        {
          "digest": "sha256:9fddd37cf5a6af47e05c6c148a928524d278f505dc0de53109fab3682963b652",
          "image": "docker.io/dellemc/csi-unity@sha256:9fddd37cf5a6af47e05c6c148a928524d278f505dc0de53109fab3682963b652",
          "name": "csi-unity-9fddd37cf5a6af47e05c6c148a928524d278f505dc0de53109fab3682963b652-annotation"
        },
        {
          "digest": "sha256:08c5effefadf2e55103eb49ef2a5a325d9904e7391b6eeb72701dae6e682ad9e",
          "image": "docker.io/dellemc/csi-powerstore@sha256:08c5effefadf2e55103eb49ef2a5a325d9904e7391b6eeb72701dae6e682ad9e",
          "name": "csi-powerstore-08c5effefadf2e55103eb49ef2a5a325d9904e7391b6eeb72701dae6e682ad9e-annotation"
        },
        {
          "digest": "sha256:c236cb87d5799ef239b3e5df956761e1c042f3d5686c8e5728c06edfef3095b7",
          "image": "docker.io/dellemc/csipowermax-reverseproxy@sha256:c236cb87d5799ef239b3e5df956761e1c042f3d5686c8e5728c06edfef3095b7",
          "name": "csipowermax-reverseproxy-c236cb87d5799ef239b3e5df956761e1c042f3d5686c8e5728c06edfef3095b7-annotation"
        },
        {
          "digest": "sha256:2fc83456ec2fb2c0336725e039a3db699a0202468cd8e3fd12d7ef2423068fc8",
          "image": "docker.io/dellemc/csi-powermax@sha256:2fc83456ec2fb2c0336725e039a3db699a0202468cd8e3fd12d7ef2423068fc8",
          "name": "csi-powermax-2fc83456ec2fb2c0336725e039a3db699a0202468cd8e3fd12d7ef2423068fc8-annotation"
        },
        {
          "digest": "sha256:220dd73f1eaa4b927e53f3827109c126ad5108f6d37e68949b95cfce66206fbe",
          "image": "docker.io/dellemc/csi-isilon@sha256:220dd73f1eaa4b927e53f3827109c126ad5108f6d37e68949b95cfce66206fbe",
          "name": "csi-isilon-220dd73f1eaa4b927e53f3827109c126ad5108f6d37e68949b95cfce66206fbe-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.7.0",
      "version_original": "1.7.0"
    },
    {
      "_id": "628e5ee70e22c919837331e9",
      "alm_examples": [
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDB",
          "metadata": {
            "name": "my-replica-set"
          },
          "spec": {
            "credentials": "my-credentials",
            "members": 3,
            "opsManager": {
              "configMapRef": {
                "name": "my-project"
              }
            },
            "persistent": true,
            "type": "ReplicaSet",
            "version": "4.4.0-ent"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDB",
          "metadata": {
            "name": "sample-sharded-cluster"
          },
          "spec": {
            "configServerCount": 3,
            "credentials": "my-credentials",
            "mongodsPerShardCount": 3,
            "mongosCount": 2,
            "opsManager": {
              "configMapRef": {
                "name": "my-project"
              }
            },
            "persistent": true,
            "shardCount": 1,
            "type": "ShardedCluster",
            "version": "4.4.0-ent"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDBMulti",
          "metadata": {
            "name": "multi-replica-set"
          },
          "spec": {
            "clusterSpecList": {
              "clusterSpecs": [
                {
                  "clusterName": "e2e.cluster1.mongokubernetes.com",
                  "members": 2
                },
                {
                  "clusterName": "e2e.cluster2.mongokubernetes.com",
                  "members": 1
                },
                {
                  "clusterName": "e2e.cluster3.mongokubernetes.com",
                  "members": 2
                }
              ]
            },
            "credentials": "my-credentials",
            "duplicateServiceObjects": false,
            "opsManager": {
              "configMapRef": {
                "name": "my-project"
              }
            },
            "persistent": false,
            "type": "ReplicaSet",
            "version": "4.4.0-ent"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDBOpsManager",
          "metadata": {
            "name": "ops-manager"
          },
          "spec": {
            "adminCredentials": "ops-manager-admin",
            "applicationDatabase": {
              "members": 3,
              "persistent": true,
              "podSpec": {
                "cpu": 1
              }
            },
            "configuration": {
              "mms.fromEmailAddr": "admin@thecompany.com"
            },
            "externalConnectivity": {
              "type": "LoadBalancer"
            },
            "version": "4.4.1"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDBUser",
          "metadata": {
            "name": "my-replica-set-x509-user"
          },
          "spec": {
            "db": "$external",
            "mongodbResourceRef": {
              "name": "my-replica-set"
            },
            "roles": [
              {
                "db": "admin",
                "name": "dbOwner"
              }
            ],
            "username": "CN=my-replica-set-x509-user,OU=cloud,O=MongoDB,L=New York,ST=New York,C=US"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/mongodb/enterprise-operator-bundle@sha256:d75a22a01799c23ff0093ee0458e9807116817141c645cc7e67633d133185cab",
      "bundle_path_digest": "sha256:d75a22a01799c23ff0093ee0458e9807116817141c645cc7e67633d133185cab",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-25T16:52:55.244000+00:00",
      "csv_description": "The MongoDB Enterprise Kubernetes Operator enables easy deploys of MongoDB\ninto Kubernetes clusters, using our management, monitoring and backup\nplatforms, Ops Manager and Cloud Manager.\n\n## Before You Start\n\nTo start using the operator you''ll need an account in MongoDB Cloud Manager or\na MongoDB Ops Manager deployment.\n\n* [Create a Secret with your OpsManager API key](https://docs.mongodb.com/kubernetes-operator/stable/tutorial/create-operator-credentials/#procedure)\n\n* [Create a ConfigMap with your OpsManager project ID and URL](https://docs.mongodb.com/kubernetes-operator/stable/tutorial/create-project-using-configmap/)\n\nBy installing this integration, you will be able to deploy MongoDB instances\nwith a single simple command.\n\n## Required Parameters\n\n* `opsManager` or `cloudManager` - Enter the name of the ConfigMap containing project information\n* `credentials` - Enter the name of the Secret containing your OpsManager credentials\n* `type` - Enter MongoDB Deployment Types (\"Standalone\", \"ReplicaSet\", \"ShardedCluster\"\n\n## Supported MongoDB Deployment Types ##\n\n* Standalone: An instance of mongod that is running as a single server and\nnot as part of a replica set, this is, it does not do any kind of\nreplication.\n\n* Replica Set: A replica set in MongoDB is a group of mongod processes that\nmaintain the same data set. Replica sets provide redundancy and high\navailability, and are the basis for all production deployments. This section\nintroduces replication in MongoDB as well as the components and architecture\nof replica sets. The section also provides tutorials for common tasks\nrelated to replica sets.\n\n* Sharded Cluster: The set of nodes comprising a sharded MongoDB deployment.\nA sharded cluster consists of config servers, shards, and one or more mongos\nrouting processes. Sharding is a A database architecture that partitions\ndata by key ranges and distributes the data among two or more database\ninstances. Sharding enables horizontal scaling.\n\n## Requirements for deploying MongoDB OpsManager\n\n* In order to deploy resources of type MongoDB OpsManager, you will need to\ncreate a secret containing the [credentials](https://docs.mongodb.com/kubernetes-operator/stable/tutorial/plan-om-resource/#om-rsrc-prereqs)\nfor the Global Onwer user\n\n## Security ##\n\nThe operator can enable TLS for all traffic between servers and also between\nclients and servers. Before enabling `security.tls.enabled` to `true` you\nshould create your certificates.  or you can leave the operator to create all\nthe certificates for you. The operator ability to create certs is been\ndepricted due to Kuberentes API changes.\n\nFor more information, please read the official MongoDB\nKubernetes Operator  [docs](https://docs.mongodb.com/kubernetes-operator/stable/).\n",
      "csv_display_name": "MongoDB Enterprise Operator",
      "csv_metadata_description": "The MongoDB Enterprise Kubernetes Operator enables easy deploys of MongoDB into Kubernetes clusters, using our management, monitoring and backup platforms, Ops Manager and Cloud Manager.",
      "csv_name": "mongodb-enterprise.v1.16.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:20:02.911000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "mongodb-enterprise",
      "provided_apis": [
        {
          "group": "mongodb.com",
          "kind": "MongoDB",
          "version": "v1"
        },
        {
          "group": "mongodb.com",
          "kind": "MongoDBMulti",
          "version": "v1"
        },
        {
          "group": "mongodb.com",
          "kind": "MongoDBOpsManager",
          "version": "v1"
        },
        {
          "group": "mongodb.com",
          "kind": "MongoDBUser",
          "version": "v1"
        }
      ],
      "provider": "MongoDB, Inc",
      "related_images": [
        {
          "digest": "sha256:735d9e1cb2366a1ac6d93ff0450085cea214967f594fe8a1e10130499a85c0bb",
          "image": "registry.connect.redhat.com/mongodb/enterprise-operator@sha256:735d9e1cb2366a1ac6d93ff0450085cea214967f594fe8a1e10130499a85c0bb",
          "name": "mongodb-enterprise-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.16.1",
      "version_original": "1.16.1"
    },
    {
      "_id": "628e5eeee07ae03809e4f767",
      "alm_examples": [
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDB",
          "metadata": {
            "name": "my-replica-set"
          },
          "spec": {
            "credentials": "my-credentials",
            "members": 3,
            "opsManager": {
              "configMapRef": {
                "name": "my-project"
              }
            },
            "persistent": true,
            "type": "ReplicaSet",
            "version": "4.4.0-ent"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDB",
          "metadata": {
            "name": "sample-sharded-cluster"
          },
          "spec": {
            "configServerCount": 3,
            "credentials": "my-credentials",
            "mongodsPerShardCount": 3,
            "mongosCount": 2,
            "opsManager": {
              "configMapRef": {
                "name": "my-project"
              }
            },
            "persistent": true,
            "shardCount": 1,
            "type": "ShardedCluster",
            "version": "4.4.0-ent"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDBMulti",
          "metadata": {
            "name": "multi-replica-set"
          },
          "spec": {
            "clusterSpecList": {
              "clusterSpecs": [
                {
                  "clusterName": "e2e.cluster1.mongokubernetes.com",
                  "members": 2
                },
                {
                  "clusterName": "e2e.cluster2.mongokubernetes.com",
                  "members": 1
                },
                {
                  "clusterName": "e2e.cluster3.mongokubernetes.com",
                  "members": 2
                }
              ]
            },
            "credentials": "my-credentials",
            "duplicateServiceObjects": false,
            "opsManager": {
              "configMapRef": {
                "name": "my-project"
              }
            },
            "persistent": false,
            "type": "ReplicaSet",
            "version": "4.4.0-ent"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDBOpsManager",
          "metadata": {
            "name": "ops-manager"
          },
          "spec": {
            "adminCredentials": "ops-manager-admin",
            "applicationDatabase": {
              "members": 3,
              "persistent": true,
              "podSpec": {
                "cpu": 1
              }
            },
            "configuration": {
              "mms.fromEmailAddr": "admin@thecompany.com"
            },
            "externalConnectivity": {
              "type": "LoadBalancer"
            },
            "version": "4.4.1"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDBUser",
          "metadata": {
            "name": "my-replica-set-x509-user"
          },
          "spec": {
            "db": "$external",
            "mongodbResourceRef": {
              "name": "my-replica-set"
            },
            "roles": [
              {
                "db": "admin",
                "name": "dbOwner"
              }
            ],
            "username": "CN=my-replica-set-x509-user,OU=cloud,O=MongoDB,L=New York,ST=New York,C=US"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/mongodb/enterprise-operator-bundle@sha256:d75a22a01799c23ff0093ee0458e9807116817141c645cc7e67633d133185cab",
      "bundle_path_digest": "sha256:d75a22a01799c23ff0093ee0458e9807116817141c645cc7e67633d133185cab",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-25T16:53:02.797000+00:00",
      "csv_description": "The MongoDB Enterprise Kubernetes Operator enables easy deploys of MongoDB\ninto Kubernetes clusters, using our management, monitoring and backup\nplatforms, Ops Manager and Cloud Manager.\n\n## Before You Start\n\nTo start using the operator you''ll need an account in MongoDB Cloud Manager or\na MongoDB Ops Manager deployment.\n\n* [Create a Secret with your OpsManager API key](https://docs.mongodb.com/kubernetes-operator/stable/tutorial/create-operator-credentials/#procedure)\n\n* [Create a ConfigMap with your OpsManager project ID and URL](https://docs.mongodb.com/kubernetes-operator/stable/tutorial/create-project-using-configmap/)\n\nBy installing this integration, you will be able to deploy MongoDB instances\nwith a single simple command.\n\n## Required Parameters\n\n* `opsManager` or `cloudManager` - Enter the name of the ConfigMap containing project information\n* `credentials` - Enter the name of the Secret containing your OpsManager credentials\n* `type` - Enter MongoDB Deployment Types (\"Standalone\", \"ReplicaSet\", \"ShardedCluster\"\n\n## Supported MongoDB Deployment Types ##\n\n* Standalone: An instance of mongod that is running as a single server and\nnot as part of a replica set, this is, it does not do any kind of\nreplication.\n\n* Replica Set: A replica set in MongoDB is a group of mongod processes that\nmaintain the same data set. Replica sets provide redundancy and high\navailability, and are the basis for all production deployments. This section\nintroduces replication in MongoDB as well as the components and architecture\nof replica sets. The section also provides tutorials for common tasks\nrelated to replica sets.\n\n* Sharded Cluster: The set of nodes comprising a sharded MongoDB deployment.\nA sharded cluster consists of config servers, shards, and one or more mongos\nrouting processes. Sharding is a A database architecture that partitions\ndata by key ranges and distributes the data among two or more database\ninstances. Sharding enables horizontal scaling.\n\n## Requirements for deploying MongoDB OpsManager\n\n* In order to deploy resources of type MongoDB OpsManager, you will need to\ncreate a secret containing the [credentials](https://docs.mongodb.com/kubernetes-operator/stable/tutorial/plan-om-resource/#om-rsrc-prereqs)\nfor the Global Onwer user\n\n## Security ##\n\nThe operator can enable TLS for all traffic between servers and also between\nclients and servers. Before enabling `security.tls.enabled` to `true` you\nshould create your certificates.  or you can leave the operator to create all\nthe certificates for you. The operator ability to create certs is been\ndepricted due to Kuberentes API changes.\n\nFor more information, please read the official MongoDB\nKubernetes Operator  [docs](https://docs.mongodb.com/kubernetes-operator/stable/).\n",
      "csv_display_name": "MongoDB Enterprise Operator",
      "csv_metadata_description": "The MongoDB Enterprise Kubernetes Operator enables easy deploys of MongoDB into Kubernetes clusters, using our management, monitoring and backup platforms, Ops Manager and Cloud Manager.",
      "csv_name": "mongodb-enterprise.v1.16.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:04:42.890000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "mongodb-enterprise",
      "provided_apis": [
        {
          "group": "mongodb.com",
          "kind": "MongoDB",
          "plural": "mongodb",
          "version": "v1"
        },
        {
          "group": "mongodb.com",
          "kind": "MongoDBMulti",
          "plural": "mongodbmulti",
          "version": "v1"
        },
        {
          "group": "mongodb.com",
          "kind": "MongoDBUser",
          "plural": "mongodbusers",
          "version": "v1"
        },
        {
          "group": "mongodb.com",
          "kind": "MongoDBOpsManager",
          "plural": "opsmanagers",
          "version": "v1"
        }
      ],
      "provider": "MongoDB, Inc",
      "related_images": [
        {
          "digest": "sha256:735d9e1cb2366a1ac6d93ff0450085cea214967f594fe8a1e10130499a85c0bb",
          "image": "registry.connect.redhat.com/mongodb/enterprise-operator@sha256:735d9e1cb2366a1ac6d93ff0450085cea214967f594fe8a1e10130499a85c0bb",
          "name": "mongodb-enterprise-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.16.1",
      "version_original": "1.16.1"
    },
    {
      "_id": "628e608fe07ae03809e4f77a",
      "alm_examples": [
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDB",
          "metadata": {
            "name": "my-replica-set"
          },
          "spec": {
            "credentials": "my-credentials",
            "members": 3,
            "opsManager": {
              "configMapRef": {
                "name": "my-project"
              }
            },
            "persistent": true,
            "type": "ReplicaSet",
            "version": "4.4.0-ent"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDB",
          "metadata": {
            "name": "sample-sharded-cluster"
          },
          "spec": {
            "configServerCount": 3,
            "credentials": "my-credentials",
            "mongodsPerShardCount": 3,
            "mongosCount": 2,
            "opsManager": {
              "configMapRef": {
                "name": "my-project"
              }
            },
            "persistent": true,
            "shardCount": 1,
            "type": "ShardedCluster",
            "version": "4.4.0-ent"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDBMulti",
          "metadata": {
            "name": "multi-replica-set"
          },
          "spec": {
            "clusterSpecList": {
              "clusterSpecs": [
                {
                  "clusterName": "e2e.cluster1.mongokubernetes.com",
                  "members": 2
                },
                {
                  "clusterName": "e2e.cluster2.mongokubernetes.com",
                  "members": 1
                },
                {
                  "clusterName": "e2e.cluster3.mongokubernetes.com",
                  "members": 2
                }
              ]
            },
            "credentials": "my-credentials",
            "duplicateServiceObjects": false,
            "opsManager": {
              "configMapRef": {
                "name": "my-project"
              }
            },
            "persistent": false,
            "type": "ReplicaSet",
            "version": "4.4.0-ent"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDBOpsManager",
          "metadata": {
            "name": "ops-manager"
          },
          "spec": {
            "adminCredentials": "ops-manager-admin",
            "applicationDatabase": {
              "members": 3,
              "persistent": true,
              "podSpec": {
                "cpu": 1
              }
            },
            "configuration": {
              "mms.fromEmailAddr": "admin@thecompany.com"
            },
            "externalConnectivity": {
              "type": "LoadBalancer"
            },
            "version": "4.4.1"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDBUser",
          "metadata": {
            "name": "my-replica-set-x509-user"
          },
          "spec": {
            "db": "$external",
            "mongodbResourceRef": {
              "name": "my-replica-set"
            },
            "roles": [
              {
                "db": "admin",
                "name": "dbOwner"
              }
            ],
            "username": "CN=my-replica-set-x509-user,OU=cloud,O=MongoDB,L=New York,ST=New York,C=US"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/mongodb/enterprise-operator-bundle@sha256:d75a22a01799c23ff0093ee0458e9807116817141c645cc7e67633d133185cab",
      "bundle_path_digest": "sha256:d75a22a01799c23ff0093ee0458e9807116817141c645cc7e67633d133185cab",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-25T16:59:59.384000+00:00",
      "csv_description": "The MongoDB Enterprise Kubernetes Operator enables easy deploys of MongoDB\ninto Kubernetes clusters, using our management, monitoring and backup\nplatforms, Ops Manager and Cloud Manager.\n\n## Before You Start\n\nTo start using the operator you''ll need an account in MongoDB Cloud Manager or\na MongoDB Ops Manager deployment.\n\n* [Create a Secret with your OpsManager API key](https://docs.mongodb.com/kubernetes-operator/stable/tutorial/create-operator-credentials/#procedure)\n\n* [Create a ConfigMap with your OpsManager project ID and URL](https://docs.mongodb.com/kubernetes-operator/stable/tutorial/create-project-using-configmap/)\n\nBy installing this integration, you will be able to deploy MongoDB instances\nwith a single simple command.\n\n## Required Parameters\n\n* `opsManager` or `cloudManager` - Enter the name of the ConfigMap containing project information\n* `credentials` - Enter the name of the Secret containing your OpsManager credentials\n* `type` - Enter MongoDB Deployment Types (\"Standalone\", \"ReplicaSet\", \"ShardedCluster\"\n\n## Supported MongoDB Deployment Types ##\n\n* Standalone: An instance of mongod that is running as a single server and\nnot as part of a replica set, this is, it does not do any kind of\nreplication.\n\n* Replica Set: A replica set in MongoDB is a group of mongod processes that\nmaintain the same data set. Replica sets provide redundancy and high\navailability, and are the basis for all production deployments. This section\nintroduces replication in MongoDB as well as the components and architecture\nof replica sets. The section also provides tutorials for common tasks\nrelated to replica sets.\n\n* Sharded Cluster: The set of nodes comprising a sharded MongoDB deployment.\nA sharded cluster consists of config servers, shards, and one or more mongos\nrouting processes. Sharding is a A database architecture that partitions\ndata by key ranges and distributes the data among two or more database\ninstances. Sharding enables horizontal scaling.\n\n## Requirements for deploying MongoDB OpsManager\n\n* In order to deploy resources of type MongoDB OpsManager, you will need to\ncreate a secret containing the [credentials](https://docs.mongodb.com/kubernetes-operator/stable/tutorial/plan-om-resource/#om-rsrc-prereqs)\nfor the Global Onwer user\n\n## Security ##\n\nThe operator can enable TLS for all traffic between servers and also between\nclients and servers. Before enabling `security.tls.enabled` to `true` you\nshould create your certificates.  or you can leave the operator to create all\nthe certificates for you. The operator ability to create certs is been\ndepricted due to Kuberentes API changes.\n\nFor more information, please read the official MongoDB\nKubernetes Operator  [docs](https://docs.mongodb.com/kubernetes-operator/stable/).\n",
      "csv_display_name": "MongoDB Enterprise Operator",
      "csv_metadata_description": "The MongoDB Enterprise Kubernetes Operator enables easy deploys of MongoDB into Kubernetes clusters, using our management, monitoring and backup platforms, Ops Manager and Cloud Manager.",
      "csv_name": "mongodb-enterprise.v1.16.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:03:11.635000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "mongodb-enterprise",
      "provided_apis": [
        {
          "group": "mongodb.com",
          "kind": "MongoDBMulti",
          "plural": "mongodbmulti",
          "version": "v1"
        },
        {
          "group": "mongodb.com",
          "kind": "MongoDBUser",
          "plural": "mongodbusers",
          "version": "v1"
        },
        {
          "group": "mongodb.com",
          "kind": "MongoDBOpsManager",
          "plural": "opsmanagers",
          "version": "v1"
        },
        {
          "group": "mongodb.com",
          "kind": "MongoDB",
          "plural": "mongodb",
          "version": "v1"
        }
      ],
      "provider": "MongoDB, Inc",
      "related_images": [
        {
          "digest": "sha256:735d9e1cb2366a1ac6d93ff0450085cea214967f594fe8a1e10130499a85c0bb",
          "image": "registry.connect.redhat.com/mongodb/enterprise-operator@sha256:735d9e1cb2366a1ac6d93ff0450085cea214967f594fe8a1e10130499a85c0bb",
          "name": "mongodb-enterprise-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.16.1",
      "version_original": "1.16.1"
    },
    {
      "_id": "628e653c19ff1144872e4979",
      "alm_examples": [
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDB",
          "metadata": {
            "name": "my-replica-set"
          },
          "spec": {
            "credentials": "my-credentials",
            "members": 3,
            "opsManager": {
              "configMapRef": {
                "name": "my-project"
              }
            },
            "persistent": true,
            "type": "ReplicaSet",
            "version": "4.4.0-ent"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDB",
          "metadata": {
            "name": "sample-sharded-cluster"
          },
          "spec": {
            "configServerCount": 3,
            "credentials": "my-credentials",
            "mongodsPerShardCount": 3,
            "mongosCount": 2,
            "opsManager": {
              "configMapRef": {
                "name": "my-project"
              }
            },
            "persistent": true,
            "shardCount": 1,
            "type": "ShardedCluster",
            "version": "4.4.0-ent"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDBMulti",
          "metadata": {
            "name": "multi-replica-set"
          },
          "spec": {
            "clusterSpecList": {
              "clusterSpecs": [
                {
                  "clusterName": "e2e.cluster1.mongokubernetes.com",
                  "members": 2
                },
                {
                  "clusterName": "e2e.cluster2.mongokubernetes.com",
                  "members": 1
                },
                {
                  "clusterName": "e2e.cluster3.mongokubernetes.com",
                  "members": 2
                }
              ]
            },
            "credentials": "my-credentials",
            "duplicateServiceObjects": false,
            "opsManager": {
              "configMapRef": {
                "name": "my-project"
              }
            },
            "persistent": false,
            "type": "ReplicaSet",
            "version": "4.4.0-ent"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDBOpsManager",
          "metadata": {
            "name": "ops-manager"
          },
          "spec": {
            "adminCredentials": "ops-manager-admin",
            "applicationDatabase": {
              "members": 3,
              "persistent": true,
              "podSpec": {
                "cpu": 1
              }
            },
            "configuration": {
              "mms.fromEmailAddr": "admin@thecompany.com"
            },
            "externalConnectivity": {
              "type": "LoadBalancer"
            },
            "version": "4.4.1"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDBUser",
          "metadata": {
            "name": "my-replica-set-x509-user"
          },
          "spec": {
            "db": "$external",
            "mongodbResourceRef": {
              "name": "my-replica-set"
            },
            "roles": [
              {
                "db": "admin",
                "name": "dbOwner"
              }
            ],
            "username": "CN=my-replica-set-x509-user,OU=cloud,O=MongoDB,L=New York,ST=New York,C=US"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/mongodb/enterprise-operator-bundle@sha256:d75a22a01799c23ff0093ee0458e9807116817141c645cc7e67633d133185cab",
      "bundle_path_digest": "sha256:d75a22a01799c23ff0093ee0458e9807116817141c645cc7e67633d133185cab",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-25T17:19:56.522000+00:00",
      "csv_description": "The MongoDB Enterprise Kubernetes Operator enables easy deploys of MongoDB\ninto Kubernetes clusters, using our management, monitoring and backup\nplatforms, Ops Manager and Cloud Manager.\n\n## Before You Start\n\nTo start using the operator you''ll need an account in MongoDB Cloud Manager or\na MongoDB Ops Manager deployment.\n\n* [Create a Secret with your OpsManager API key](https://docs.mongodb.com/kubernetes-operator/stable/tutorial/create-operator-credentials/#procedure)\n\n* [Create a ConfigMap with your OpsManager project ID and URL](https://docs.mongodb.com/kubernetes-operator/stable/tutorial/create-project-using-configmap/)\n\nBy installing this integration, you will be able to deploy MongoDB instances\nwith a single simple command.\n\n## Required Parameters\n\n* `opsManager` or `cloudManager` - Enter the name of the ConfigMap containing project information\n* `credentials` - Enter the name of the Secret containing your OpsManager credentials\n* `type` - Enter MongoDB Deployment Types (\"Standalone\", \"ReplicaSet\", \"ShardedCluster\"\n\n## Supported MongoDB Deployment Types ##\n\n* Standalone: An instance of mongod that is running as a single server and\nnot as part of a replica set, this is, it does not do any kind of\nreplication.\n\n* Replica Set: A replica set in MongoDB is a group of mongod processes that\nmaintain the same data set. Replica sets provide redundancy and high\navailability, and are the basis for all production deployments. This section\nintroduces replication in MongoDB as well as the components and architecture\nof replica sets. The section also provides tutorials for common tasks\nrelated to replica sets.\n\n* Sharded Cluster: The set of nodes comprising a sharded MongoDB deployment.\nA sharded cluster consists of config servers, shards, and one or more mongos\nrouting processes. Sharding is a A database architecture that partitions\ndata by key ranges and distributes the data among two or more database\ninstances. Sharding enables horizontal scaling.\n\n## Requirements for deploying MongoDB OpsManager\n\n* In order to deploy resources of type MongoDB OpsManager, you will need to\ncreate a secret containing the [credentials](https://docs.mongodb.com/kubernetes-operator/stable/tutorial/plan-om-resource/#om-rsrc-prereqs)\nfor the Global Onwer user\n\n## Security ##\n\nThe operator can enable TLS for all traffic between servers and also between\nclients and servers. Before enabling `security.tls.enabled` to `true` you\nshould create your certificates.  or you can leave the operator to create all\nthe certificates for you. The operator ability to create certs is been\ndepricted due to Kuberentes API changes.\n\nFor more information, please read the official MongoDB\nKubernetes Operator  [docs](https://docs.mongodb.com/kubernetes-operator/stable/).\n",
      "csv_display_name": "MongoDB Enterprise Operator",
      "csv_metadata_description": "The MongoDB Enterprise Kubernetes Operator enables easy deploys of MongoDB into Kubernetes clusters, using our management, monitoring and backup platforms, Ops Manager and Cloud Manager.",
      "csv_name": "mongodb-enterprise.v1.16.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:21:34.841000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "mongodb-enterprise",
      "provided_apis": [
        {
          "group": "mongodb.com",
          "kind": "MongoDBMulti",
          "plural": "mongodbmulti",
          "version": "v1"
        },
        {
          "group": "mongodb.com",
          "kind": "MongoDBUser",
          "plural": "mongodbusers",
          "version": "v1"
        },
        {
          "group": "mongodb.com",
          "kind": "MongoDBOpsManager",
          "plural": "opsmanagers",
          "version": "v1"
        },
        {
          "group": "mongodb.com",
          "kind": "MongoDB",
          "plural": "mongodb",
          "version": "v1"
        }
      ],
      "provider": "MongoDB, Inc",
      "related_images": [
        {
          "digest": "sha256:735d9e1cb2366a1ac6d93ff0450085cea214967f594fe8a1e10130499a85c0bb",
          "image": "registry.connect.redhat.com/mongodb/enterprise-operator@sha256:735d9e1cb2366a1ac6d93ff0450085cea214967f594fe8a1e10130499a85c0bb",
          "name": "mongodb-enterprise-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.16.1",
      "version_original": "1.16.1"
    },
    {
      "_id": "628e67750e22c91983733220",
      "alm_examples": [
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDB",
          "metadata": {
            "name": "my-replica-set"
          },
          "spec": {
            "credentials": "my-credentials",
            "members": 3,
            "opsManager": {
              "configMapRef": {
                "name": "my-project"
              }
            },
            "persistent": true,
            "type": "ReplicaSet",
            "version": "4.4.0-ent"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDB",
          "metadata": {
            "name": "sample-sharded-cluster"
          },
          "spec": {
            "configServerCount": 3,
            "credentials": "my-credentials",
            "mongodsPerShardCount": 3,
            "mongosCount": 2,
            "opsManager": {
              "configMapRef": {
                "name": "my-project"
              }
            },
            "persistent": true,
            "shardCount": 1,
            "type": "ShardedCluster",
            "version": "4.4.0-ent"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDBMulti",
          "metadata": {
            "name": "multi-replica-set"
          },
          "spec": {
            "clusterSpecList": {
              "clusterSpecs": [
                {
                  "clusterName": "e2e.cluster1.mongokubernetes.com",
                  "members": 2
                },
                {
                  "clusterName": "e2e.cluster2.mongokubernetes.com",
                  "members": 1
                },
                {
                  "clusterName": "e2e.cluster3.mongokubernetes.com",
                  "members": 2
                }
              ]
            },
            "credentials": "my-credentials",
            "duplicateServiceObjects": false,
            "opsManager": {
              "configMapRef": {
                "name": "my-project"
              }
            },
            "persistent": false,
            "type": "ReplicaSet",
            "version": "4.4.0-ent"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDBOpsManager",
          "metadata": {
            "name": "ops-manager"
          },
          "spec": {
            "adminCredentials": "ops-manager-admin",
            "applicationDatabase": {
              "members": 3,
              "persistent": true,
              "podSpec": {
                "cpu": 1
              }
            },
            "configuration": {
              "mms.fromEmailAddr": "admin@thecompany.com"
            },
            "externalConnectivity": {
              "type": "LoadBalancer"
            },
            "version": "4.4.1"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDBUser",
          "metadata": {
            "name": "my-replica-set-x509-user"
          },
          "spec": {
            "db": "$external",
            "mongodbResourceRef": {
              "name": "my-replica-set"
            },
            "roles": [
              {
                "db": "admin",
                "name": "dbOwner"
              }
            ],
            "username": "CN=my-replica-set-x509-user,OU=cloud,O=MongoDB,L=New York,ST=New York,C=US"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/mongodb/enterprise-operator-bundle@sha256:d75a22a01799c23ff0093ee0458e9807116817141c645cc7e67633d133185cab",
      "bundle_path_digest": "sha256:d75a22a01799c23ff0093ee0458e9807116817141c645cc7e67633d133185cab",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-25T17:29:25.208000+00:00",
      "csv_description": "The MongoDB Enterprise Kubernetes Operator enables easy deploys of MongoDB\ninto Kubernetes clusters, using our management, monitoring and backup\nplatforms, Ops Manager and Cloud Manager.\n\n## Before You Start\n\nTo start using the operator you''ll need an account in MongoDB Cloud Manager or\na MongoDB Ops Manager deployment.\n\n* [Create a Secret with your OpsManager API key](https://docs.mongodb.com/kubernetes-operator/stable/tutorial/create-operator-credentials/#procedure)\n\n* [Create a ConfigMap with your OpsManager project ID and URL](https://docs.mongodb.com/kubernetes-operator/stable/tutorial/create-project-using-configmap/)\n\nBy installing this integration, you will be able to deploy MongoDB instances\nwith a single simple command.\n\n## Required Parameters\n\n* `opsManager` or `cloudManager` - Enter the name of the ConfigMap containing project information\n* `credentials` - Enter the name of the Secret containing your OpsManager credentials\n* `type` - Enter MongoDB Deployment Types (\"Standalone\", \"ReplicaSet\", \"ShardedCluster\"\n\n## Supported MongoDB Deployment Types ##\n\n* Standalone: An instance of mongod that is running as a single server and\nnot as part of a replica set, this is, it does not do any kind of\nreplication.\n\n* Replica Set: A replica set in MongoDB is a group of mongod processes that\nmaintain the same data set. Replica sets provide redundancy and high\navailability, and are the basis for all production deployments. This section\nintroduces replication in MongoDB as well as the components and architecture\nof replica sets. The section also provides tutorials for common tasks\nrelated to replica sets.\n\n* Sharded Cluster: The set of nodes comprising a sharded MongoDB deployment.\nA sharded cluster consists of config servers, shards, and one or more mongos\nrouting processes. Sharding is a A database architecture that partitions\ndata by key ranges and distributes the data among two or more database\ninstances. Sharding enables horizontal scaling.\n\n## Requirements for deploying MongoDB OpsManager\n\n* In order to deploy resources of type MongoDB OpsManager, you will need to\ncreate a secret containing the [credentials](https://docs.mongodb.com/kubernetes-operator/stable/tutorial/plan-om-resource/#om-rsrc-prereqs)\nfor the Global Onwer user\n\n## Security ##\n\nThe operator can enable TLS for all traffic between servers and also between\nclients and servers. Before enabling `security.tls.enabled` to `true` you\nshould create your certificates.  or you can leave the operator to create all\nthe certificates for you. The operator ability to create certs is been\ndepricted due to Kuberentes API changes.\n\nFor more information, please read the official MongoDB\nKubernetes Operator  [docs](https://docs.mongodb.com/kubernetes-operator/stable/).\n",
      "csv_display_name": "MongoDB Enterprise Operator",
      "csv_metadata_description": "The MongoDB Enterprise Kubernetes Operator enables easy deploys of MongoDB into Kubernetes clusters, using our management, monitoring and backup platforms, Ops Manager and Cloud Manager.",
      "csv_name": "mongodb-enterprise.v1.16.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:15:42+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "mongodb-enterprise",
      "provided_apis": [
        {
          "group": "mongodb.com",
          "kind": "MongoDB",
          "plural": "mongodb",
          "version": "v1"
        },
        {
          "group": "mongodb.com",
          "kind": "MongoDBMulti",
          "plural": "mongodbmulti",
          "version": "v1"
        },
        {
          "group": "mongodb.com",
          "kind": "MongoDBUser",
          "plural": "mongodbusers",
          "version": "v1"
        },
        {
          "group": "mongodb.com",
          "kind": "MongoDBOpsManager",
          "plural": "opsmanagers",
          "version": "v1"
        }
      ],
      "provider": "MongoDB, Inc",
      "related_images": [
        {
          "digest": "sha256:735d9e1cb2366a1ac6d93ff0450085cea214967f594fe8a1e10130499a85c0bb",
          "image": "registry.connect.redhat.com/mongodb/enterprise-operator@sha256:735d9e1cb2366a1ac6d93ff0450085cea214967f594fe8a1e10130499a85c0bb",
          "name": "mongodb-enterprise-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "1.16.1",
      "version_original": "1.16.1"
    },
    {
      "_id": "628e68bbe07ae03809e4f7c0",
      "alm_examples": [
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDB",
          "metadata": {
            "name": "my-replica-set"
          },
          "spec": {
            "credentials": "my-credentials",
            "members": 3,
            "opsManager": {
              "configMapRef": {
                "name": "my-project"
              }
            },
            "persistent": true,
            "type": "ReplicaSet",
            "version": "4.4.0-ent"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDB",
          "metadata": {
            "name": "sample-sharded-cluster"
          },
          "spec": {
            "configServerCount": 3,
            "credentials": "my-credentials",
            "mongodsPerShardCount": 3,
            "mongosCount": 2,
            "opsManager": {
              "configMapRef": {
                "name": "my-project"
              }
            },
            "persistent": true,
            "shardCount": 1,
            "type": "ShardedCluster",
            "version": "4.4.0-ent"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDBMulti",
          "metadata": {
            "name": "multi-replica-set"
          },
          "spec": {
            "clusterSpecList": {
              "clusterSpecs": [
                {
                  "clusterName": "e2e.cluster1.mongokubernetes.com",
                  "members": 2
                },
                {
                  "clusterName": "e2e.cluster2.mongokubernetes.com",
                  "members": 1
                },
                {
                  "clusterName": "e2e.cluster3.mongokubernetes.com",
                  "members": 2
                }
              ]
            },
            "credentials": "my-credentials",
            "duplicateServiceObjects": false,
            "opsManager": {
              "configMapRef": {
                "name": "my-project"
              }
            },
            "persistent": false,
            "type": "ReplicaSet",
            "version": "4.4.0-ent"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDBOpsManager",
          "metadata": {
            "name": "ops-manager"
          },
          "spec": {
            "adminCredentials": "ops-manager-admin",
            "applicationDatabase": {
              "members": 3,
              "persistent": true,
              "podSpec": {
                "cpu": 1
              }
            },
            "configuration": {
              "mms.fromEmailAddr": "admin@thecompany.com"
            },
            "externalConnectivity": {
              "type": "LoadBalancer"
            },
            "version": "4.4.1"
          }
        },
        {
          "api_version": "mongodb.com/v1",
          "kind": "MongoDBUser",
          "metadata": {
            "name": "my-replica-set-x509-user"
          },
          "spec": {
            "db": "$external",
            "mongodbResourceRef": {
              "name": "my-replica-set"
            },
            "roles": [
              {
                "db": "admin",
                "name": "dbOwner"
              }
            ],
            "username": "CN=my-replica-set-x509-user,OU=cloud,O=MongoDB,L=New York,ST=New York,C=US"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/mongodb/enterprise-operator-bundle@sha256:d75a22a01799c23ff0093ee0458e9807116817141c645cc7e67633d133185cab",
      "bundle_path_digest": "sha256:d75a22a01799c23ff0093ee0458e9807116817141c645cc7e67633d133185cab",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-25T17:34:51.246000+00:00",
      "csv_description": "The MongoDB Enterprise Kubernetes Operator enables easy deploys of MongoDB\ninto Kubernetes clusters, using our management, monitoring and backup\nplatforms, Ops Manager and Cloud Manager.\n\n## Before You Start\n\nTo start using the operator you''ll need an account in MongoDB Cloud Manager or\na MongoDB Ops Manager deployment.\n\n* [Create a Secret with your OpsManager API key](https://docs.mongodb.com/kubernetes-operator/stable/tutorial/create-operator-credentials/#procedure)\n\n* [Create a ConfigMap with your OpsManager project ID and URL](https://docs.mongodb.com/kubernetes-operator/stable/tutorial/create-project-using-configmap/)\n\nBy installing this integration, you will be able to deploy MongoDB instances\nwith a single simple command.\n\n## Required Parameters\n\n* `opsManager` or `cloudManager` - Enter the name of the ConfigMap containing project information\n* `credentials` - Enter the name of the Secret containing your OpsManager credentials\n* `type` - Enter MongoDB Deployment Types (\"Standalone\", \"ReplicaSet\", \"ShardedCluster\"\n\n## Supported MongoDB Deployment Types ##\n\n* Standalone: An instance of mongod that is running as a single server and\nnot as part of a replica set, this is, it does not do any kind of\nreplication.\n\n* Replica Set: A replica set in MongoDB is a group of mongod processes that\nmaintain the same data set. Replica sets provide redundancy and high\navailability, and are the basis for all production deployments. This section\nintroduces replication in MongoDB as well as the components and architecture\nof replica sets. The section also provides tutorials for common tasks\nrelated to replica sets.\n\n* Sharded Cluster: The set of nodes comprising a sharded MongoDB deployment.\nA sharded cluster consists of config servers, shards, and one or more mongos\nrouting processes. Sharding is a A database architecture that partitions\ndata by key ranges and distributes the data among two or more database\ninstances. Sharding enables horizontal scaling.\n\n## Requirements for deploying MongoDB OpsManager\n\n* In order to deploy resources of type MongoDB OpsManager, you will need to\ncreate a secret containing the [credentials](https://docs.mongodb.com/kubernetes-operator/stable/tutorial/plan-om-resource/#om-rsrc-prereqs)\nfor the Global Onwer user\n\n## Security ##\n\nThe operator can enable TLS for all traffic between servers and also between\nclients and servers. Before enabling `security.tls.enabled` to `true` you\nshould create your certificates.  or you can leave the operator to create all\nthe certificates for you. The operator ability to create certs is been\ndepricted due to Kuberentes API changes.\n\nFor more information, please read the official MongoDB\nKubernetes Operator  [docs](https://docs.mongodb.com/kubernetes-operator/stable/).\n",
      "csv_display_name": "MongoDB Enterprise Operator",
      "csv_metadata_description": "The MongoDB Enterprise Kubernetes Operator enables easy deploys of MongoDB into Kubernetes clusters, using our management, monitoring and backup platforms, Ops Manager and Cloud Manager.",
      "csv_name": "mongodb-enterprise.v1.16.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:00:52.089000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "mongodb-enterprise",
      "provided_apis": [
        {
          "group": "mongodb.com",
          "kind": "MongoDB",
          "plural": "mongodb",
          "version": "v1"
        },
        {
          "group": "mongodb.com",
          "kind": "MongoDBMulti",
          "plural": "mongodbmulti",
          "version": "v1"
        },
        {
          "group": "mongodb.com",
          "kind": "MongoDBUser",
          "plural": "mongodbusers",
          "version": "v1"
        },
        {
          "group": "mongodb.com",
          "kind": "MongoDBOpsManager",
          "plural": "opsmanagers",
          "version": "v1"
        }
      ],
      "provider": "MongoDB, Inc",
      "related_images": [
        {
          "digest": "sha256:735d9e1cb2366a1ac6d93ff0450085cea214967f594fe8a1e10130499a85c0bb",
          "image": "registry.connect.redhat.com/mongodb/enterprise-operator@sha256:735d9e1cb2366a1ac6d93ff0450085cea214967f594fe8a1e10130499a85c0bb",
          "name": "mongodb-enterprise-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "1.16.1",
      "version_original": "1.16.1"
    },
    {
      "_id": "628f8d31256da2c054d060dd",
      "alm_examples": [
        {
          "api_version": "tenantoperator.stakater.com/v1beta1",
          "kind": "Tenant",
          "metadata": {
            "name": "bluesky"
          },
          "spec": {
            "editors": {
              "groups": [
                "alpha"
              ],
              "users": [
                "john@aurora.org"
              ]
            },
            "namespaces": [
              "dev",
              "build",
              "prod"
            ],
            "owners": {
              "users": [
                "anna@aurora.org",
                "anthony@aurora.org"
              ]
            },
            "quota": "small"
          }
        },
        {
          "api_version": "tenantoperator.stakater.com/v1alpha1",
          "kind": "IntegrationConfig",
          "metadata": {
            "name": "tenant-operator-config",
            "namespace": "stakater-tenant-operator"
          },
          "spec": {
            "argocd": {
              "clusterResourceWhitelist": [
                {
                  "group": "tronador.stakater.com",
                  "kind": "EnvironmentProvisioner"
                }
              ],
              "namespace": "openshift-operators",
              "namespaceResourceBlacklist": [
                {
                  "group": "",
                  "kind": "ResourceQuota"
                }
              ]
            },
            "openshift": {
              "clusterAdminGroups": [
                "cluster-admins"
              ],
              "group": {
                "labels": {
                  "role": "customer-reader"
                }
              },
              "namespaceAccessPolicy": {
                "deny": {
                  "privilegedNamespaces": {
                    "groups": [
                      "cluster-admins"
                    ],
                    "users": [
                      "system:serviceaccount:openshift-argocd:argocd-application-controller",
                      "adam@stakater.com"
                    ]
                  }
                }
              },
              "privilegedNamespaces": [
                "default",
                "^openshift-*",
                "^kube-*"
              ],
              "privilegedServiceAccounts": [
                "^system:serviceaccount:openshift-*",
                "^system:serviceaccount:kube-*"
              ],
              "project": {
                "annotations": {
                  "openshift.io/node-selector": "node-role.kubernetes.io/worker="
                },
                "labels": {
                  "stakater.com/workload-monitoring": "true"
                }
              },
              "sandbox": {
                "labels": {
                  "stakater.com/kind": "sandbox"
                }
              }
            },
            "rhsso": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "auth-secrets",
                  "namespace": "openshift-auth"
                },
                "url": "https://iam-keycloak-auth.apps.prod.abcdefghi.kubeapp.cloud/"
              }
            },
            "vault": {
              "enabled": true,
              "endpoint": {
                "secretReference": {
                  "name": "vault-root-token",
                  "namespace": "vault"
                },
                "url": "https://vault.apps.prod.abcdefghi.kubeapp.cloud/"
              },
              "sso": {
                "accessorID": "<ACCESSOR_ID_TOKEN>",
                "clientName": "vault"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/stakater/tenant-operator-0@sha256:aa9a994b83e11741c35fa0c5b6bce10efbfec3cb1bf4ec308fe5167eb99a1bfc",
      "bundle_path_digest": "sha256:aa9a994b83e11741c35fa0c5b6bce10efbfec3cb1bf4ec308fe5167eb99a1bfc",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-05-26T14:22:41.956000+00:00",
      "csv_description": "tenant operator",
      "csv_display_name": "tenant-operator",
      "csv_metadata_description": "",
      "csv_name": "tenant-operator.v0.3.33",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T12:54:43.276000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "tenant-operator",
      "provided_apis": [
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateGroupInstance",
          "plural": "templategroupinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "IntegrationConfig",
          "plural": "integrationconfigs",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Quota",
          "plural": "quotas",
          "version": "v1beta1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Tenant",
          "plural": "tenants",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Quota",
          "plural": "quotas",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "TemplateInstance",
          "plural": "templateinstances",
          "version": "v1alpha1"
        },
        {
          "group": "tenantoperator.stakater.com",
          "kind": "Template",
          "plural": "templates",
          "version": "v1alpha1"
        }
      ],
      "provider": "stakater",
      "related_images": [
        {
          "digest": "sha256:665540a140c30a7f8a31a1ca5fe519a1f0e91dddc597d7a9108926dc174f3b89",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:665540a140c30a7f8a31a1ca5fe519a1f0e91dddc597d7a9108926dc174f3b89",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:b2d9424d5ba70ba370c73b5fcf85fa5e5a1265a5f046c50969500a21dca97aaa",
          "image": "registry.connect.redhat.com/stakater/tenant-operator@sha256:b2d9424d5ba70ba370c73b5fcf85fa5e5a1265a5f046c50969500a21dca97aaa",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "0.3.33",
      "version_original": "0.3.33"
    },
    {
      "_id": "628f9061e4e749aa39c4ad29",
      "alm_examples": [
        {
          "api_version": "mellanox.com/v1alpha1",
          "kind": "HostDeviceNetwork",
          "metadata": {
            "name": "example-hostdevice-network"
          },
          "spec": {
            "ipam": "{\n  \"type\": \"whereabouts\",\n  \"range\": \"192.168.3.225/28\",\n  \"exclude\": [\n   \"192.168.3.229/30\",\n   \"192.168.3.236/32\"\n  ]\n}\n",
            "networkNamespace": "default",
            "resourceName": "hostdev"
          }
        },
        {
          "api_version": "mellanox.com/v1alpha1",
          "kind": "MacvlanNetwork",
          "metadata": {
            "name": "example-macvlannetwork"
          },
          "spec": {
            "ipam": "{\n  \"type\": \"whereabouts\",\n  \"range\": \"192.168.2.225/24\",\n  \"exclude\": [\n   \"192.168.2.229/30\",\n   \"192.168.2.236/32\"\n  ]\n}\n",
            "master": "ens2f0",
            "mode": "bridge",
            "mtu": 1500,
            "networkNamespace": "default"
          }
        },
        {
          "api_version": "mellanox.com/v1alpha1",
          "kind": "NicClusterPolicy",
          "metadata": {
            "name": "nic-cluster-policy"
          },
          "spec": {
            "ofedDriver": {
              "image": "mofed",
              "livenessProbe": {
                "initialDelaySeconds": 30,
                "periodSeconds": 30
              },
              "readinessProbe": {
                "initialDelaySeconds": 10,
                "periodSeconds": 30
              },
              "repository": "mellanox",
              "startupProbe": {
                "initialDelaySeconds": 10,
                "periodSeconds": 20
              },
              "version": "5.5-1.0.3.2"
            },
            "rdmaSharedDevicePlugin": {
              "config": "{\n  \"configList\": [\n    {\n      \"resourceName\": \"rdma_shared_device_a\",\n      \"rdmaHcaMax\": 1000,\n      \"selectors\": {\n        \"ifNames\": [\"ens2f0\"]\n      }\n    }\n  ]\n}\n",
              "image": "k8s-rdma-shared-dev-plugin",
              "repository": "nvcr.io/nvidia/cloud-native",
              "version": "v1.2.1-ubi"
            },
            "sriovDevicePlugin": {
              "config": "{\n  \"resourceList\": [\n      {\n          \"resourcePrefix\": \"nvidia.com\",\n          \"resourceName\": \"hostdev\",\n          \"selectors\": {\n              \"vendors\": [\"15b3\"],\n              \"isRdma\": true\n          }\n      }\n  ]\n}\n",
              "image": "sriov-device-plugin",
              "repository": "docker.io/nfvpe",
              "version": "v3.3"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/nvidia-network-operator/nvidia-network-operator@sha256:5d0554c40fd2ad6d901b0a6384f48bacb478ba22345706448fd66258b4439c3d",
      "bundle_path_digest": "sha256:5d0554c40fd2ad6d901b0a6384f48bacb478ba22345706448fd66258b4439c3d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "1.2.0",
      "creation_date": "2022-05-26T14:36:17.783000+00:00",
      "csv_description": "## NVIDIA Network Operator\nThe NVIDIA Network Operator simplifies the provisioning and management of NVIDIA networking resources  in a Kubernetes cluster. The operator automatically installs the required host networking software - bringing together all the needed components to provide high-speed network connectivity. These components include the NVIDIA networking driver, Kubernetes device plugin, CNI plugins, IP address management (IPAM) plugin and others.\nThe NVIDIA Network Operator works in conjunction with the NVIDIA GPU Operator to deliver high-throughput, low-latency networking for scale-out, GPU computing clusters.\n\nThe Network Operator uses Node Feature Discovery (NFD) labels in order to properly schedule resources.\nNodes can be labelled manually or using the NFD Operator. An example of `NodeFeatureDiscovery`\nconfiguration is available in the documentation.\nThe following NFD labels are used:\n`feature.node.kubernetes.io/pci-15b3.present` for nodes containing NVIDIA Networking hardware.\n`feature.node.kubernetes.io/pci-10de.present` for nodes containing NVIDIA GPU hardware.\n\nThe Network Operator is open-source. For more information on contributions and release artifacts, see the [GitHub repo](https://github.com/Mellanox/network-operator/)\n",
      "csv_display_name": "NVIDIA Network Operator",
      "csv_metadata_description": "Deploy and manage NVIDIA networking resources in Kubernetes",
      "csv_name": "nvidia-network-operator.v1.2.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-05-26T14:36:17.783000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "nvidia-network-operator",
      "provided_apis": [
        {
          "group": "mellanox.com",
          "kind": "HostDeviceNetwork",
          "plural": "hostdevicenetworks",
          "version": "v1alpha1"
        },
        {
          "group": "mellanox.com",
          "kind": "MacvlanNetwork",
          "plural": "macvlannetworks",
          "version": "v1alpha1"
        },
        {
          "group": "mellanox.com",
          "kind": "NicClusterPolicy",
          "plural": "nicclusterpolicies",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:0a5108443c64fc013984be500e7db3d89c04418446f0bbc3241ed6e1c449b773",
          "image": "nvcr.io/nvidia/mellanox/mofed-5.6-1.0.3.3@sha256:0a5108443c64fc013984be500e7db3d89c04418446f0bbc3241ed6e1c449b773",
          "name": "mofed"
        },
        {
          "digest": "sha256:16a53286fecdb1e587d3c4c042078974674c3e86c9e98d7dae282f6eb4ee2d8c",
          "image": "ghcr.io/k8snetworkplumbingwg/sriov-network-device-plugin@sha256:16a53286fecdb1e587d3c4c042078974674c3e86c9e98d7dae282f6eb4ee2d8c",
          "name": "sriov-network-device-plugin"
        },
        {
          "digest": "sha256:941ad9ff5013e9e7ad5abeb0ea9f79d45379cfae88a628d923f87d2259bdd132",
          "image": "nvcr.io/nvidia/cloud-native/k8s-rdma-shared-dev-plugin@sha256:941ad9ff5013e9e7ad5abeb0ea9f79d45379cfae88a628d923f87d2259bdd132",
          "name": "rdma-shared-device-plugin"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:90bd3c4d2620a7f1005afc7c1d101d31a64d2239b0bf33a701c4426a54e4e381",
          "image": "nvcr.io/nvidia/cloud-native/network-operator@sha256:90bd3c4d2620a7f1005afc7c1d101d31a64d2239b0bf33a701c4426a54e4e381",
          "name": "manager"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.2.0",
      "version_original": "1.2.0"
    },
    {
      "_id": "628fa6b4256da2c054d06a66",
      "alm_examples": [
        {
          "api_version": "infoscale.veritas.com/v1",
          "kind": "InfoScaleCluster",
          "metadata": {
            "name": "infoscalecluster-dev"
          },
          "spec": {
            "clusterInfo": [
              {},
              {}
            ],
            "version": "8.0.30"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/veritas-technologies/infoscale-operator-bundle@sha256:b4c0c14990302bce27404b1659575fd3c507fb514fc546d2d141e48337d39072",
      "bundle_path_digest": "sha256:b4c0c14990302bce27404b1659575fd3c507fb514fc546d2d141e48337d39072",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-26T16:11:32.751000+00:00",
      "csv_description": "# InfoScale\u2122 SDS Operator\n\nInfoScale\u2122 SDS Operator manages the lifecycle of the InfoScale\u2122 cluster\n\n## Overview\n\n- Veritas InfoScale\u2122 delivers Infrastructure resiliency and persistent storage for your critical containerized applications for OpenShift\u00ae and Kubernetes Native deployments\n- Engineered to support stateful workloads generated for mission-critical containerized applications.\n\n---\n\n## Data Services & Benefits\n\n**1. Software-Defined Persistent Storage Volumes:** Enables customers to support multiple container application requirements leveraging existing SAN or DAS storage\n\n**2. CSI API Driver:** Facilitates static and dynamic provisioning for applications with RWX, RWO and ROX access modes\n\n**3. Life Cycle Management:** Enables automated deployment, configuration and upgrades of InfoScale Software-defined container images. Certified and Integrated with Red Hat OpenShift for a single-click deployment\n\n**4. Availability:** Provides scaling, mounting and/or movement of InfoScale persistent storage volumes on cluster nodes with minimal disruption\n\n**5. Data Integrity:** Prevents data corruption by allowing only the active cluster nodes to write to the volume. The I/O fencing feature recovers from cluster disruptions quickly by ensuring that application pods are moved to another node to continue normal operations\n\n**6. Point-in-Time Data Copies:** Create snapshots of Persistent Volumes for backup products, data analytics or forensic discovery and analysis\n\n**7. Disaster Recovery (DR) Tech Preview:** This DR feature provides the ability to test and validate disaster recovery capabilities by migrating Kubernetes cluster metadata and application components to peer cluster in case of a local or remote disaster\n\n---\n\n## Pre-requisites\n\n- [Please refer to pre-requisite section from official documentation](https://www.veritas.com/support/en_US/doc/151215298-151215302-0)\n\n\n## InfoScale Cluster custom resource\n\n```\nkind: InfoScaleCluster\nmetadata:\n  name:  < Infoscale Cluster Name >\n\nspec:\n  version: \"8.0.30\"\n\n  clusterInfo:\n  - nodeName: <Name of the first node>\n  ip:\n  - <Optional - First IP address of the first node >\n  - <Optional - Second IP address of the first node>\n  excludeDevice:\n  - <Optional - Device path of the disk on the node that you want to exclude from Infoscale disk group.>\n\n  - nodeName: <Name of the second node>\n  ip:\n  - <Optional - First IP address of the second node >\n  - <Optional - Second IP address of the second node>\n  excludeDevice:\n  - <Optional - Device path of the disk on the node that you want to exclude from Infoscale disk group.>\n\n  # You can add up to 16 nodes.\n\n  licenseServer: < Optional - License server name/IP address >\n  licensePort: < Optional - License port number >\n\n  customImageRegistry: < Optional \u2013 Registry for Infoscale Container images>\n\n```\n\n#### Note\n\nYou can specify up to 16 worker nodes in CR. Although cluster configuration is allowed even with one Network Interface Card,\nVeritas recommends a minimum of two physical links for performance and High Availability (HA). Number of links for each network link must be same on all\nnodes. Optionally, you can enter node level IP addresses. If IP addresses are not provided, IP addresses of OpenShift cluster nodes are used.\n",
      "csv_display_name": "InfoScale\u2122 SDS Operator",
      "csv_metadata_description": "InfoScale\u2122 SDS Operator manages the lifecycle of the InfoScale\u2122 cluster",
      "csv_name": "infoscale-operator.v8.0.32",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:01:08.004000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "infoscale-operator",
      "provided_apis": [
        {
          "group": "infoscale.veritas.com",
          "kind": "InfoScaleCluster",
          "plural": "infoscaleclusters",
          "version": "v1"
        }
      ],
      "provider": "Veritas Technologies LLC",
      "related_images": [
        {
          "digest": "sha256:5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16",
          "image": "registry.connect.redhat.com/veritas-technologies/infoscale-operator@sha256:5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16",
          "name": "manager"
        },
        {
          "digest": "sha256:5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16",
          "image": "registry.connect.redhat.com/veritas-technologies/infoscale-operator@sha256:5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16",
          "name": "pre-manager"
        },
        {
          "digest": "sha256:5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16",
          "image": "registry.connect.redhat.com/veritas-technologies/infoscale-operator@sha256:5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16",
          "name": "infoscale-operator-5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "8.0.32",
      "version_original": "8.0.32"
    },
    {
      "_id": "628fa6cb89e0a10bc8120089",
      "alm_examples": [
        {
          "api_version": "infoscale.veritas.com/v1",
          "kind": "InfoScaleCluster",
          "metadata": {
            "name": "infoscalecluster-dev"
          },
          "spec": {
            "clusterInfo": [
              {},
              {}
            ],
            "version": "8.0.30"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/veritas-technologies/infoscale-operator-bundle@sha256:b4c0c14990302bce27404b1659575fd3c507fb514fc546d2d141e48337d39072",
      "bundle_path_digest": "sha256:b4c0c14990302bce27404b1659575fd3c507fb514fc546d2d141e48337d39072",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-26T16:11:55.509000+00:00",
      "csv_description": "# InfoScale\u2122 SDS Operator\n\nInfoScale\u2122 SDS Operator manages the lifecycle of the InfoScale\u2122 cluster\n\n## Overview\n\n- Veritas InfoScale\u2122 delivers Infrastructure resiliency and persistent storage for your critical containerized applications for OpenShift\u00ae and Kubernetes Native deployments\n- Engineered to support stateful workloads generated for mission-critical containerized applications.\n\n---\n\n## Data Services & Benefits\n\n**1. Software-Defined Persistent Storage Volumes:** Enables customers to support multiple container application requirements leveraging existing SAN or DAS storage\n\n**2. CSI API Driver:** Facilitates static and dynamic provisioning for applications with RWX, RWO and ROX access modes\n\n**3. Life Cycle Management:** Enables automated deployment, configuration and upgrades of InfoScale Software-defined container images. Certified and Integrated with Red Hat OpenShift for a single-click deployment\n\n**4. Availability:** Provides scaling, mounting and/or movement of InfoScale persistent storage volumes on cluster nodes with minimal disruption\n\n**5. Data Integrity:** Prevents data corruption by allowing only the active cluster nodes to write to the volume. The I/O fencing feature recovers from cluster disruptions quickly by ensuring that application pods are moved to another node to continue normal operations\n\n**6. Point-in-Time Data Copies:** Create snapshots of Persistent Volumes for backup products, data analytics or forensic discovery and analysis\n\n**7. Disaster Recovery (DR) Tech Preview:** This DR feature provides the ability to test and validate disaster recovery capabilities by migrating Kubernetes cluster metadata and application components to peer cluster in case of a local or remote disaster\n\n---\n\n## Pre-requisites\n\n- [Please refer to pre-requisite section from official documentation](https://www.veritas.com/support/en_US/doc/151215298-151215302-0)\n\n\n## InfoScale Cluster custom resource\n\n```\nkind: InfoScaleCluster\nmetadata:\n  name:  < Infoscale Cluster Name >\n\nspec:\n  version: \"8.0.30\"\n\n  clusterInfo:\n  - nodeName: <Name of the first node>\n  ip:\n  - <Optional - First IP address of the first node >\n  - <Optional - Second IP address of the first node>\n  excludeDevice:\n  - <Optional - Device path of the disk on the node that you want to exclude from Infoscale disk group.>\n\n  - nodeName: <Name of the second node>\n  ip:\n  - <Optional - First IP address of the second node >\n  - <Optional - Second IP address of the second node>\n  excludeDevice:\n  - <Optional - Device path of the disk on the node that you want to exclude from Infoscale disk group.>\n\n  # You can add up to 16 nodes.\n\n  licenseServer: < Optional - License server name/IP address >\n  licensePort: < Optional - License port number >\n\n  customImageRegistry: < Optional \u2013 Registry for Infoscale Container images>\n\n```\n\n#### Note\n\nYou can specify up to 16 worker nodes in CR. Although cluster configuration is allowed even with one Network Interface Card,\nVeritas recommends a minimum of two physical links for performance and High Availability (HA). Number of links for each network link must be same on all\nnodes. Optionally, you can enter node level IP addresses. If IP addresses are not provided, IP addresses of OpenShift cluster nodes are used.\n",
      "csv_display_name": "InfoScale\u2122 SDS Operator",
      "csv_metadata_description": "InfoScale\u2122 SDS Operator manages the lifecycle of the InfoScale\u2122 cluster",
      "csv_name": "infoscale-operator.v8.0.32",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T12:59:11.256000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "infoscale-operator",
      "provided_apis": [
        {
          "group": "infoscale.veritas.com",
          "kind": "InfoScaleCluster",
          "plural": "infoscaleclusters",
          "version": "v1"
        }
      ],
      "provider": "Veritas Technologies LLC",
      "related_images": [
        {
          "digest": "sha256:5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16",
          "image": "registry.connect.redhat.com/veritas-technologies/infoscale-operator@sha256:5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16",
          "name": "manager"
        },
        {
          "digest": "sha256:5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16",
          "image": "registry.connect.redhat.com/veritas-technologies/infoscale-operator@sha256:5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16",
          "name": "pre-manager"
        },
        {
          "digest": "sha256:5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16",
          "image": "registry.connect.redhat.com/veritas-technologies/infoscale-operator@sha256:5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16",
          "name": "infoscale-operator-5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "8.0.32",
      "version_original": "8.0.32"
    },
    {
      "_id": "628faa4b89e0a10bc812018a",
      "alm_examples": [
        {
          "api_version": "infoscale.veritas.com/v1",
          "kind": "InfoScaleCluster",
          "metadata": {
            "name": "infoscalecluster-dev"
          },
          "spec": {
            "clusterInfo": [
              {},
              {}
            ],
            "version": "8.0.30"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/veritas-technologies/infoscale-operator-bundle@sha256:b4c0c14990302bce27404b1659575fd3c507fb514fc546d2d141e48337d39072",
      "bundle_path_digest": "sha256:b4c0c14990302bce27404b1659575fd3c507fb514fc546d2d141e48337d39072",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-26T16:26:51.856000+00:00",
      "csv_description": "# InfoScale\u2122 SDS Operator\n\nInfoScale\u2122 SDS Operator manages the lifecycle of the InfoScale\u2122 cluster\n\n## Overview\n\n- Veritas InfoScale\u2122 delivers Infrastructure resiliency and persistent storage for your critical containerized applications for OpenShift\u00ae and Kubernetes Native deployments\n- Engineered to support stateful workloads generated for mission-critical containerized applications.\n\n---\n\n## Data Services & Benefits\n\n**1. Software-Defined Persistent Storage Volumes:** Enables customers to support multiple container application requirements leveraging existing SAN or DAS storage\n\n**2. CSI API Driver:** Facilitates static and dynamic provisioning for applications with RWX, RWO and ROX access modes\n\n**3. Life Cycle Management:** Enables automated deployment, configuration and upgrades of InfoScale Software-defined container images. Certified and Integrated with Red Hat OpenShift for a single-click deployment\n\n**4. Availability:** Provides scaling, mounting and/or movement of InfoScale persistent storage volumes on cluster nodes with minimal disruption\n\n**5. Data Integrity:** Prevents data corruption by allowing only the active cluster nodes to write to the volume. The I/O fencing feature recovers from cluster disruptions quickly by ensuring that application pods are moved to another node to continue normal operations\n\n**6. Point-in-Time Data Copies:** Create snapshots of Persistent Volumes for backup products, data analytics or forensic discovery and analysis\n\n**7. Disaster Recovery (DR) Tech Preview:** This DR feature provides the ability to test and validate disaster recovery capabilities by migrating Kubernetes cluster metadata and application components to peer cluster in case of a local or remote disaster\n\n---\n\n## Pre-requisites\n\n- [Please refer to pre-requisite section from official documentation](https://www.veritas.com/support/en_US/doc/151215298-151215302-0)\n\n\n## InfoScale Cluster custom resource\n\n```\nkind: InfoScaleCluster\nmetadata:\n  name:  < Infoscale Cluster Name >\n\nspec:\n  version: \"8.0.30\"\n\n  clusterInfo:\n  - nodeName: <Name of the first node>\n  ip:\n  - <Optional - First IP address of the first node >\n  - <Optional - Second IP address of the first node>\n  excludeDevice:\n  - <Optional - Device path of the disk on the node that you want to exclude from Infoscale disk group.>\n\n  - nodeName: <Name of the second node>\n  ip:\n  - <Optional - First IP address of the second node >\n  - <Optional - Second IP address of the second node>\n  excludeDevice:\n  - <Optional - Device path of the disk on the node that you want to exclude from Infoscale disk group.>\n\n  # You can add up to 16 nodes.\n\n  licenseServer: < Optional - License server name/IP address >\n  licensePort: < Optional - License port number >\n\n  customImageRegistry: < Optional \u2013 Registry for Infoscale Container images>\n\n```\n\n#### Note\n\nYou can specify up to 16 worker nodes in CR. Although cluster configuration is allowed even with one Network Interface Card,\nVeritas recommends a minimum of two physical links for performance and High Availability (HA). Number of links for each network link must be same on all\nnodes. Optionally, you can enter node level IP addresses. If IP addresses are not provided, IP addresses of OpenShift cluster nodes are used.\n",
      "csv_display_name": "InfoScale\u2122 SDS Operator",
      "csv_metadata_description": "InfoScale\u2122 SDS Operator manages the lifecycle of the InfoScale\u2122 cluster",
      "csv_name": "infoscale-operator.v8.0.32",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:42:53.690000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "infoscale-operator",
      "provided_apis": [
        {
          "group": "infoscale.veritas.com",
          "kind": "InfoScaleCluster",
          "version": "v1"
        }
      ],
      "provider": "Veritas Technologies LLC",
      "related_images": [
        {
          "digest": "sha256:5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16",
          "image": "registry.connect.redhat.com/veritas-technologies/infoscale-operator@sha256:5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16",
          "name": "manager"
        },
        {
          "digest": "sha256:5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16",
          "image": "registry.connect.redhat.com/veritas-technologies/infoscale-operator@sha256:5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16",
          "name": "pre-manager"
        },
        {
          "digest": "sha256:5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16",
          "image": "registry.connect.redhat.com/veritas-technologies/infoscale-operator@sha256:5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16",
          "name": "infoscale-operator-5d2b00432d31159577cd3f423a40bc3cc79d033447032fe51905074ccf961c16-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "8.0.32",
      "version_original": "8.0.32"
    },
    {
      "_id": "6292f9e9301a731de19f1ee5",
      "alm_examples": [
        {
          "api_version": "apps.ibmz.com/v1alpha1",
          "kind": "MongoDB",
          "metadata": {
            "name": "mongodb-sample"
          },
          "spec": {
            "affinity": {},
            "autoscaling": {
              "enabled": false,
              "maxReplicas": 100,
              "minReplicas": 1,
              "targetCPUUtilizationPercentage": 80
            },
            "database": {
              "adminpassword": "snowball123",
              "adminuser": "adminuser",
              "name_database": "mydb"
            },
            "fullnameOverride": "",
            "global": {
              "license": true,
              "persistence": {
                "claims": {
                  "accessMode": "ReadWriteMany",
                  "capacity": 10,
                  "capacityUnit": "Gi",
                  "mountPath": "/data/db/",
                  "name": "mongo-pv-claim",
                  "storageClassName": "managed-nfs-storage"
                },
                "securityContext": {
                  "fsGroup": 0,
                  "supplementalGroup": 0
                }
              }
            },
            "image": {
              "pullPolicy": "Always",
              "repository": "quay.io/ibm/ibmz-mongodb-enterprise-database@sha256:6ddfec49c1682283b031168fa9a2e09c5746bb1288b6fc4b6f72feb49db35195"
            },
            "imagePullSecretRef": "registry-pull-secret",
            "imagePullSecrets": [
              {
                "name": "registry-pull-secret"
              }
            ],
            "ingress": {
              "annotations": {},
              "controller": "nginx",
              "tls": []
            },
            "name": "mongodb",
            "nameOverride": "",
            "namespaceList": [],
            "namespaced": true,
            "nodeSelector": {},
            "podSecurity": {
              "enabled": true,
              "securityContext": {
                "fsGroup": 1000650000,
                "runAsNonRoot": true,
                "runAsUser": 1000650000
              }
            },
            "replicaCount": 1,
            "resources": {
              "limits": {
                "cpu": "200m",
                "memory": "1Gi"
              },
              "requests": {
                "cpu": "200m",
                "memory": "1Gi"
              }
            },
            "service": {
              "port": 27017,
              "type": "ClusterIP"
            },
            "serviceAccount": {
              "annotations": {},
              "create": true,
              "name": "mongod"
            },
            "tolerations": []
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [
        "s390x"
      ],
      "bundle_path": "registry.connect.redhat.com/tonyfieit/ibmz-mongodb-operator-bundle@sha256:436d0ba532b631d78d9148ab2f2856beebae91a6ed605afcf8c3a69fe93948d0",
      "bundle_path_digest": "sha256:436d0ba532b631d78d9148ab2f2856beebae91a6ed605afcf8c3a69fe93948d0",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-05-29T04:43:21.035000+00:00",
      "csv_description": "IBM Operator to deploy MongoDB Enterprise on OpenShift Container",
      "csv_display_name": "ibmz-mongodb-enterprise-operator",
      "csv_metadata_description": "Run IBMz Mongodb Enterprise Edition on OpenShift on LinuxONE.",
      "csv_name": "ibmz-mongodb-enterprise-operator.v4.4.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:00:43.543000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "ibmz-mongodb-enterprise-operator",
      "provided_apis": [
        {
          "group": "apps.ibmz.com",
          "kind": "MongoDB",
          "plural": "mongodbs",
          "version": "v1alpha1"
        }
      ],
      "provider": "IBMz",
      "related_images": [
        {
          "digest": "sha256:7b40fc146e6e7fc55cf3fe3e7637b2f6202ec124cbb2c9d875064eb2d4d4f220",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-operator@sha256:7b40fc146e6e7fc55cf3fe3e7637b2f6202ec124cbb2c9d875064eb2d4d4f220",
          "name": "mongodb-enterprise-operator"
        },
        {
          "digest": "sha256:7d51abdae2740d73a05cb3f60bbc047cbe332f29f559b6233b8d15d41f168966",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-database@sha256:7d51abdae2740d73a05cb3f60bbc047cbe332f29f559b6233b8d15d41f168966",
          "name": "mongo-enterprise-database"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-operator@sha256:331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01",
          "name": "ibmz-mongodb-enterprise-operator-331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01-annotation"
        },
        {
          "digest": "sha256:331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-operator@sha256:331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01",
          "name": "manager"
        },
        {
          "digest": "sha256:6ddfec49c1682283b031168fa9a2e09c5746bb1288b6fc4b6f72feb49db35195",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-database@sha256:6ddfec49c1682283b031168fa9a2e09c5746bb1288b6fc4b6f72feb49db35195",
          "name": "ibmz-mongodb-enterprise-database-6ddfec49c1682283b031168fa9a2e09c5746bb1288b6fc4b6f72feb49db35195-annotation"
        }
      ],
      "replaces": null,
      "skip_range": ">=4.4.0 <4.4.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "4.4.2",
      "version_original": "4.4.2"
    },
    {
      "_id": "6292feb24ad695bac574fe6a",
      "alm_examples": [
        {
          "api_version": "apps.ibmz.com/v1alpha1",
          "kind": "MongoDB",
          "metadata": {
            "name": "mongodb-sample"
          },
          "spec": {
            "affinity": {},
            "autoscaling": {
              "enabled": false,
              "maxReplicas": 100,
              "minReplicas": 1,
              "targetCPUUtilizationPercentage": 80
            },
            "database": {
              "adminpassword": "snowball123",
              "adminuser": "adminuser",
              "name_database": "mydb"
            },
            "fullnameOverride": "",
            "global": {
              "license": true,
              "persistence": {
                "claims": {
                  "accessMode": "ReadWriteMany",
                  "capacity": 10,
                  "capacityUnit": "Gi",
                  "mountPath": "/data/db/",
                  "name": "mongo-pv-claim",
                  "storageClassName": "managed-nfs-storage"
                },
                "securityContext": {
                  "fsGroup": 0,
                  "supplementalGroup": 0
                }
              }
            },
            "image": {
              "pullPolicy": "Always",
              "repository": "quay.io/ibm/ibmz-mongodb-enterprise-database@sha256:6ddfec49c1682283b031168fa9a2e09c5746bb1288b6fc4b6f72feb49db35195"
            },
            "imagePullSecretRef": "registry-pull-secret",
            "imagePullSecrets": [
              {
                "name": "registry-pull-secret"
              }
            ],
            "ingress": {
              "annotations": {},
              "controller": "nginx",
              "tls": []
            },
            "name": "mongodb",
            "nameOverride": "",
            "namespaceList": [],
            "namespaced": true,
            "nodeSelector": {},
            "podSecurity": {
              "enabled": true,
              "securityContext": {
                "fsGroup": 1000650000,
                "runAsNonRoot": true,
                "runAsUser": 1000650000
              }
            },
            "replicaCount": 1,
            "resources": {
              "limits": {
                "cpu": "200m",
                "memory": "1Gi"
              },
              "requests": {
                "cpu": "200m",
                "memory": "1Gi"
              }
            },
            "service": {
              "port": 27017,
              "type": "ClusterIP"
            },
            "serviceAccount": {
              "annotations": {},
              "create": true,
              "name": "mongod"
            },
            "tolerations": []
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [
        "s390x"
      ],
      "bundle_path": "registry.connect.redhat.com/tonyfieit/ibmz-mongodb-operator-bundle@sha256:436d0ba532b631d78d9148ab2f2856beebae91a6ed605afcf8c3a69fe93948d0",
      "bundle_path_digest": "sha256:436d0ba532b631d78d9148ab2f2856beebae91a6ed605afcf8c3a69fe93948d0",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-05-29T05:03:46.060000+00:00",
      "csv_description": "IBM Operator to deploy MongoDB Enterprise on OpenShift Container",
      "csv_display_name": "ibmz-mongodb-enterprise-operator",
      "csv_metadata_description": "Run IBMz Mongodb Enterprise Edition on OpenShift on LinuxONE.",
      "csv_name": "ibmz-mongodb-enterprise-operator.v4.4.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T12:56:29.974000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "ibmz-mongodb-enterprise-operator",
      "provided_apis": [
        {
          "group": "apps.ibmz.com",
          "kind": "MongoDB",
          "plural": "mongodbs",
          "version": "v1alpha1"
        }
      ],
      "provider": "IBMz",
      "related_images": [
        {
          "digest": "sha256:7b40fc146e6e7fc55cf3fe3e7637b2f6202ec124cbb2c9d875064eb2d4d4f220",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-operator@sha256:7b40fc146e6e7fc55cf3fe3e7637b2f6202ec124cbb2c9d875064eb2d4d4f220",
          "name": "mongodb-enterprise-operator"
        },
        {
          "digest": "sha256:7d51abdae2740d73a05cb3f60bbc047cbe332f29f559b6233b8d15d41f168966",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-database@sha256:7d51abdae2740d73a05cb3f60bbc047cbe332f29f559b6233b8d15d41f168966",
          "name": "mongo-enterprise-database"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-operator@sha256:331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01",
          "name": "ibmz-mongodb-enterprise-operator-331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01-annotation"
        },
        {
          "digest": "sha256:331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-operator@sha256:331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01",
          "name": "manager"
        },
        {
          "digest": "sha256:6ddfec49c1682283b031168fa9a2e09c5746bb1288b6fc4b6f72feb49db35195",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-database@sha256:6ddfec49c1682283b031168fa9a2e09c5746bb1288b6fc4b6f72feb49db35195",
          "name": "ibmz-mongodb-enterprise-database-6ddfec49c1682283b031168fa9a2e09c5746bb1288b6fc4b6f72feb49db35195-annotation"
        }
      ],
      "replaces": null,
      "skip_range": ">=4.4.0 <4.4.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "4.4.2",
      "version_original": "4.4.2"
    },
    {
      "_id": "6292fec04ad695bac574fe6c",
      "alm_examples": [
        {
          "api_version": "apps.ibmz.com/v1alpha1",
          "kind": "MongoDB",
          "metadata": {
            "name": "mongodb-sample"
          },
          "spec": {
            "affinity": {},
            "autoscaling": {
              "enabled": false,
              "maxReplicas": 100,
              "minReplicas": 1,
              "targetCPUUtilizationPercentage": 80
            },
            "database": {
              "adminpassword": "snowball123",
              "adminuser": "adminuser",
              "name_database": "mydb"
            },
            "fullnameOverride": "",
            "global": {
              "license": true,
              "persistence": {
                "claims": {
                  "accessMode": "ReadWriteMany",
                  "capacity": 10,
                  "capacityUnit": "Gi",
                  "mountPath": "/data/db/",
                  "name": "mongo-pv-claim",
                  "storageClassName": "managed-nfs-storage"
                },
                "securityContext": {
                  "fsGroup": 0,
                  "supplementalGroup": 0
                }
              }
            },
            "image": {
              "pullPolicy": "Always",
              "repository": "quay.io/ibm/ibmz-mongodb-enterprise-database@sha256:6ddfec49c1682283b031168fa9a2e09c5746bb1288b6fc4b6f72feb49db35195"
            },
            "imagePullSecretRef": "registry-pull-secret",
            "imagePullSecrets": [
              {
                "name": "registry-pull-secret"
              }
            ],
            "ingress": {
              "annotations": {},
              "controller": "nginx",
              "tls": []
            },
            "name": "mongodb",
            "nameOverride": "",
            "namespaceList": [],
            "namespaced": true,
            "nodeSelector": {},
            "podSecurity": {
              "enabled": true,
              "securityContext": {
                "fsGroup": 1000650000,
                "runAsNonRoot": true,
                "runAsUser": 1000650000
              }
            },
            "replicaCount": 1,
            "resources": {
              "limits": {
                "cpu": "200m",
                "memory": "1Gi"
              },
              "requests": {
                "cpu": "200m",
                "memory": "1Gi"
              }
            },
            "service": {
              "port": 27017,
              "type": "ClusterIP"
            },
            "serviceAccount": {
              "annotations": {},
              "create": true,
              "name": "mongod"
            },
            "tolerations": []
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [
        "s390x"
      ],
      "bundle_path": "registry.connect.redhat.com/tonyfieit/ibmz-mongodb-operator-bundle@sha256:436d0ba532b631d78d9148ab2f2856beebae91a6ed605afcf8c3a69fe93948d0",
      "bundle_path_digest": "sha256:436d0ba532b631d78d9148ab2f2856beebae91a6ed605afcf8c3a69fe93948d0",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-05-29T05:04:00.750000+00:00",
      "csv_description": "IBM Operator to deploy MongoDB Enterprise on OpenShift Container",
      "csv_display_name": "ibmz-mongodb-enterprise-operator",
      "csv_metadata_description": "Run IBMz Mongodb Enterprise Edition on OpenShift on LinuxONE.",
      "csv_name": "ibmz-mongodb-enterprise-operator.v4.4.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:41:33.447000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "ibmz-mongodb-enterprise-operator",
      "provided_apis": [
        {
          "group": "apps.ibmz.com",
          "kind": "MongoDB",
          "plural": "mongodbs",
          "version": "v1alpha1"
        }
      ],
      "provider": "IBMz",
      "related_images": [
        {
          "digest": "sha256:7b40fc146e6e7fc55cf3fe3e7637b2f6202ec124cbb2c9d875064eb2d4d4f220",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-operator@sha256:7b40fc146e6e7fc55cf3fe3e7637b2f6202ec124cbb2c9d875064eb2d4d4f220",
          "name": "mongodb-enterprise-operator"
        },
        {
          "digest": "sha256:7d51abdae2740d73a05cb3f60bbc047cbe332f29f559b6233b8d15d41f168966",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-database@sha256:7d51abdae2740d73a05cb3f60bbc047cbe332f29f559b6233b8d15d41f168966",
          "name": "mongo-enterprise-database"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-operator@sha256:331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01",
          "name": "ibmz-mongodb-enterprise-operator-331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01-annotation"
        },
        {
          "digest": "sha256:331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-operator@sha256:331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01",
          "name": "manager"
        },
        {
          "digest": "sha256:6ddfec49c1682283b031168fa9a2e09c5746bb1288b6fc4b6f72feb49db35195",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-database@sha256:6ddfec49c1682283b031168fa9a2e09c5746bb1288b6fc4b6f72feb49db35195",
          "name": "ibmz-mongodb-enterprise-database-6ddfec49c1682283b031168fa9a2e09c5746bb1288b6fc4b6f72feb49db35195-annotation"
        }
      ],
      "replaces": null,
      "skip_range": ">=4.4.0 <4.4.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "4.4.2",
      "version_original": "4.4.2"
    },
    {
      "_id": "6292ff28bf1369b7ed5b07fe",
      "alm_examples": [
        {
          "api_version": "apps.ibmz.com/v1alpha1",
          "kind": "MongoDB",
          "metadata": {
            "name": "mongodb-sample"
          },
          "spec": {
            "affinity": {},
            "autoscaling": {
              "enabled": false,
              "maxReplicas": 100,
              "minReplicas": 1,
              "targetCPUUtilizationPercentage": 80
            },
            "database": {
              "adminpassword": "snowball123",
              "adminuser": "adminuser",
              "name_database": "mydb"
            },
            "fullnameOverride": "",
            "global": {
              "license": true,
              "persistence": {
                "claims": {
                  "accessMode": "ReadWriteMany",
                  "capacity": 10,
                  "capacityUnit": "Gi",
                  "mountPath": "/data/db/",
                  "name": "mongo-pv-claim",
                  "storageClassName": "managed-nfs-storage"
                },
                "securityContext": {
                  "fsGroup": 0,
                  "supplementalGroup": 0
                }
              }
            },
            "image": {
              "pullPolicy": "Always",
              "repository": "quay.io/ibm/ibmz-mongodb-enterprise-database@sha256:6ddfec49c1682283b031168fa9a2e09c5746bb1288b6fc4b6f72feb49db35195"
            },
            "imagePullSecretRef": "registry-pull-secret",
            "imagePullSecrets": [
              {
                "name": "registry-pull-secret"
              }
            ],
            "ingress": {
              "annotations": {},
              "controller": "nginx",
              "tls": []
            },
            "name": "mongodb",
            "nameOverride": "",
            "namespaceList": [],
            "namespaced": true,
            "nodeSelector": {},
            "podSecurity": {
              "enabled": true,
              "securityContext": {
                "fsGroup": 1000650000,
                "runAsNonRoot": true,
                "runAsUser": 1000650000
              }
            },
            "replicaCount": 1,
            "resources": {
              "limits": {
                "cpu": "200m",
                "memory": "1Gi"
              },
              "requests": {
                "cpu": "200m",
                "memory": "1Gi"
              }
            },
            "service": {
              "port": 27017,
              "type": "ClusterIP"
            },
            "serviceAccount": {
              "annotations": {},
              "create": true,
              "name": "mongod"
            },
            "tolerations": []
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [
        "s390x"
      ],
      "bundle_path": "registry.connect.redhat.com/tonyfieit/ibmz-mongodb-operator-bundle@sha256:436d0ba532b631d78d9148ab2f2856beebae91a6ed605afcf8c3a69fe93948d0",
      "bundle_path_digest": "sha256:436d0ba532b631d78d9148ab2f2856beebae91a6ed605afcf8c3a69fe93948d0",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-05-29T05:05:44.919000+00:00",
      "csv_description": "IBM Operator to deploy MongoDB Enterprise on OpenShift Container",
      "csv_display_name": "ibmz-mongodb-enterprise-operator",
      "csv_metadata_description": "Run IBMz Mongodb Enterprise Edition on OpenShift on LinuxONE.",
      "csv_name": "ibmz-mongodb-enterprise-operator.v4.4.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T12:58:44.240000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "ibmz-mongodb-enterprise-operator",
      "provided_apis": [
        {
          "group": "apps.ibmz.com",
          "kind": "MongoDB",
          "plural": "mongodbs",
          "version": "v1alpha1"
        }
      ],
      "provider": "IBMz",
      "related_images": [
        {
          "digest": "sha256:7b40fc146e6e7fc55cf3fe3e7637b2f6202ec124cbb2c9d875064eb2d4d4f220",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-operator@sha256:7b40fc146e6e7fc55cf3fe3e7637b2f6202ec124cbb2c9d875064eb2d4d4f220",
          "name": "mongodb-enterprise-operator"
        },
        {
          "digest": "sha256:7d51abdae2740d73a05cb3f60bbc047cbe332f29f559b6233b8d15d41f168966",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-database@sha256:7d51abdae2740d73a05cb3f60bbc047cbe332f29f559b6233b8d15d41f168966",
          "name": "mongo-enterprise-database"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-operator@sha256:331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01",
          "name": "ibmz-mongodb-enterprise-operator-331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01-annotation"
        },
        {
          "digest": "sha256:331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-operator@sha256:331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01",
          "name": "manager"
        },
        {
          "digest": "sha256:6ddfec49c1682283b031168fa9a2e09c5746bb1288b6fc4b6f72feb49db35195",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-database@sha256:6ddfec49c1682283b031168fa9a2e09c5746bb1288b6fc4b6f72feb49db35195",
          "name": "ibmz-mongodb-enterprise-database-6ddfec49c1682283b031168fa9a2e09c5746bb1288b6fc4b6f72feb49db35195-annotation"
        }
      ],
      "replaces": null,
      "skip_range": ">=4.4.0 <4.4.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "4.4.2",
      "version_original": "4.4.2"
    },
    {
      "_id": "6292ff9b301a731de19f1f24",
      "alm_examples": [
        {
          "api_version": "apps.ibmz.com/v1alpha1",
          "kind": "MongoDB",
          "metadata": {
            "name": "mongodb-sample"
          },
          "spec": {
            "affinity": {},
            "autoscaling": {
              "enabled": false,
              "maxReplicas": 100,
              "minReplicas": 1,
              "targetCPUUtilizationPercentage": 80
            },
            "database": {
              "adminpassword": "snowball123",
              "adminuser": "adminuser",
              "name_database": "mydb"
            },
            "fullnameOverride": "",
            "global": {
              "license": true,
              "persistence": {
                "claims": {
                  "accessMode": "ReadWriteMany",
                  "capacity": 10,
                  "capacityUnit": "Gi",
                  "mountPath": "/data/db/",
                  "name": "mongo-pv-claim",
                  "storageClassName": "managed-nfs-storage"
                },
                "securityContext": {
                  "fsGroup": 0,
                  "supplementalGroup": 0
                }
              }
            },
            "image": {
              "pullPolicy": "Always",
              "repository": "quay.io/ibm/ibmz-mongodb-enterprise-database@sha256:6ddfec49c1682283b031168fa9a2e09c5746bb1288b6fc4b6f72feb49db35195"
            },
            "imagePullSecretRef": "registry-pull-secret",
            "imagePullSecrets": [
              {
                "name": "registry-pull-secret"
              }
            ],
            "ingress": {
              "annotations": {},
              "controller": "nginx",
              "tls": []
            },
            "name": "mongodb",
            "nameOverride": "",
            "namespaceList": [],
            "namespaced": true,
            "nodeSelector": {},
            "podSecurity": {
              "enabled": true,
              "securityContext": {
                "fsGroup": 1000650000,
                "runAsNonRoot": true,
                "runAsUser": 1000650000
              }
            },
            "replicaCount": 1,
            "resources": {
              "limits": {
                "cpu": "200m",
                "memory": "1Gi"
              },
              "requests": {
                "cpu": "200m",
                "memory": "1Gi"
              }
            },
            "service": {
              "port": 27017,
              "type": "ClusterIP"
            },
            "serviceAccount": {
              "annotations": {},
              "create": true,
              "name": "mongod"
            },
            "tolerations": []
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [
        "s390x"
      ],
      "bundle_path": "registry.connect.redhat.com/tonyfieit/ibmz-mongodb-operator-bundle@sha256:436d0ba532b631d78d9148ab2f2856beebae91a6ed605afcf8c3a69fe93948d0",
      "bundle_path_digest": "sha256:436d0ba532b631d78d9148ab2f2856beebae91a6ed605afcf8c3a69fe93948d0",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-05-29T05:07:39.045000+00:00",
      "csv_description": "IBM Operator to deploy MongoDB Enterprise on OpenShift Container",
      "csv_display_name": "ibmz-mongodb-enterprise-operator",
      "csv_metadata_description": "Run IBMz Mongodb Enterprise Edition on OpenShift on LinuxONE.",
      "csv_name": "ibmz-mongodb-enterprise-operator.v4.4.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:27:06.364000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "ibmz-mongodb-enterprise-operator",
      "provided_apis": [
        {
          "group": "apps.ibmz.com",
          "kind": "MongoDB",
          "plural": "mongodbs",
          "version": "v1alpha1"
        }
      ],
      "provider": "IBMz",
      "related_images": [
        {
          "digest": "sha256:7b40fc146e6e7fc55cf3fe3e7637b2f6202ec124cbb2c9d875064eb2d4d4f220",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-operator@sha256:7b40fc146e6e7fc55cf3fe3e7637b2f6202ec124cbb2c9d875064eb2d4d4f220",
          "name": "mongodb-enterprise-operator"
        },
        {
          "digest": "sha256:7d51abdae2740d73a05cb3f60bbc047cbe332f29f559b6233b8d15d41f168966",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-database@sha256:7d51abdae2740d73a05cb3f60bbc047cbe332f29f559b6233b8d15d41f168966",
          "name": "mongo-enterprise-database"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-operator@sha256:331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01",
          "name": "ibmz-mongodb-enterprise-operator-331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01-annotation"
        },
        {
          "digest": "sha256:331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-operator@sha256:331564d2061b566baf0d4d77008b08e7f7dfdeea6069f12a6df082988e5c3c01",
          "name": "manager"
        },
        {
          "digest": "sha256:6ddfec49c1682283b031168fa9a2e09c5746bb1288b6fc4b6f72feb49db35195",
          "image": "quay.io/ibm/ibmz-mongodb-enterprise-database@sha256:6ddfec49c1682283b031168fa9a2e09c5746bb1288b6fc4b6f72feb49db35195",
          "name": "ibmz-mongodb-enterprise-database-6ddfec49c1682283b031168fa9a2e09c5746bb1288b6fc4b6f72feb49db35195-annotation"
        }
      ],
      "replaces": null,
      "skip_range": ">=4.4.0 <4.4.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "4.4.2",
      "version_original": "4.4.2"
    },
    {
      "_id": "629660ec0de577781eb829d6",
      "alm_examples": [
        {
          "api_version": "apps.gitlab.com/v1beta2",
          "kind": "Runner",
          "metadata": {
            "name": "example"
          },
          "spec": {
            "gitlabUrl": "https://gitlab.com",
            "imagePullPolicy": "Always",
            "tags": "openshift, test",
            "token": "gitlab-dev-runner-secret"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [
        "amd64",
        "ppc64le"
      ],
      "bundle_path": "registry.connect.redhat.com/gitlab/gitlab-runner-operator-bundle@sha256:0ceab16ea7872acc13ebcd287233cff0ed9f88d82b248710d4cc64c563cc6271",
      "bundle_path_digest": "sha256:0ceab16ea7872acc13ebcd287233cff0ed9f88d82b248710d4cc64c563cc6271",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-31T18:39:40.991000+00:00",
      "csv_description": "GitLab Runner is the lightweight, highly-scalable agent that runs your build jobs and sends the results back to a GitLab instance. GitLab Runner works in conjunction with GitLab CI/CD, the open-source continuous integration service included with GitLab.\n\nThe GitLab Runner operator manages the lifecycle of GitLab Runner in Kubernetes or Openshift clusters. The operator aims to automate the tasks needed to run your CI/CD jobs in your container orchestration platform.\n\n## Prerequisites\n\n  Install cert-manager:\n\n  ```shell\n  kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.7.1/cert-manager.yaml\n  ```\n\n## GitLab Runner version\n\nThis version of **GitLab Runner Operator** ships with **GitLab Runner v15.0.0**.\n\nTo use a different version of **GitLab Runner** change the [`runnerImage` and `helperImage` properties](https://docs.gitlab.com/runner/configuration/configuring_runner_operator.html#operator-properties).\n\n## Usage\n\n To link a GitLab Runner instance to a self-hosted GitLab instance or the hosted [GitLab](https://gitlab.com), you first need to:\n\n 1. Create a secret containing the `runner-registration-token` from your GitLab project.\n\n   ```\n  cat > gitlab-runner-secret.yml << EOF\n  apiVersion: v1\n  kind: Secret\n  metadata:\n    name: gitlab-runner-secret\n  type: Opaque\n  stringData:\n    runner-registration-token: REPLACE_ME # your project runner secret\n  EOF\n  ```\n\n  ```\n  oc apply -f gitlab-runner-secret.yml\n  ```\n\n 2. Create the Custom Resource Definition (CRD) file and include the following information. The tags value must be openshift for the job to run.\n\n   ```\n   cat > gitlab-runner.yml << EOF\n   apiVersion: apps.gitlab.com/v1beta2\n   kind: Runner\n   metadata:\n     name: gitlab-runner\n   spec:\n     gitlabUrl: https://gitlab.example.com\n     buildImage: alpine\n     token: gitlab-runner-secret\n     tags: openshift\n   EOF\n   ```\n\n  ```\n  oc apply -f gitlab-runner.yml\n  ```\n\n## Full documentation\n\nVisit [Install GitLab Runner Operator](https://docs.gitlab.com/runner/install/operator.html)\n",
      "csv_display_name": "GitLab Runner",
      "csv_metadata_description": "GitLab Runner operator manages lifecycle of GitLab Runner instances",
      "csv_name": "gitlab-runner-operator.v1.9.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T12:58:46.298000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "gitlab-runner-operator",
      "provided_apis": [
        {
          "group": "apps.gitlab.com",
          "kind": "Runner",
          "version": "v1beta2"
        }
      ],
      "provider": "GitLab, Inc.",
      "related_images": [
        {
          "digest": "sha256:101d0e79200344df095eb055dcda5401e2315f5d10aa3b73d80199f8baca5f2b",
          "image": "registry.gitlab.com/gitlab-org/ci-cd/gitlab-runner-ubi-images/gitlab-runner-ocp@sha256:101d0e79200344df095eb055dcda5401e2315f5d10aa3b73d80199f8baca5f2b",
          "name": "gitlab-runner"
        },
        {
          "digest": "sha256:c8fd9317cdd464bdc948b3f7674821d2a55165e41fba31b80ee2736847e9aa09",
          "image": "registry.gitlab.com/gitlab-org/ci-cd/gitlab-runner-ubi-images/gitlab-runner-helper-ocp@sha256:c8fd9317cdd464bdc948b3f7674821d2a55165e41fba31b80ee2736847e9aa09",
          "name": "gitlab-runner-helper"
        },
        {
          "digest": "sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "name": "gitlab-runner-operator"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "name": "gl-openshift/gitlab-runner-operator/gitlab-runner-operator-ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b-annotation"
        },
        {
          "digest": "sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.9.0",
      "version_original": "1.9.0"
    },
    {
      "_id": "629661594b05ff1d1a1d32c7",
      "alm_examples": [
        {
          "api_version": "apps.gitlab.com/v1beta2",
          "kind": "Runner",
          "metadata": {
            "name": "example"
          },
          "spec": {
            "gitlabUrl": "https://gitlab.com",
            "imagePullPolicy": "Always",
            "tags": "openshift, test",
            "token": "gitlab-dev-runner-secret"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [
        "amd64",
        "ppc64le"
      ],
      "bundle_path": "registry.connect.redhat.com/gitlab/gitlab-runner-operator-bundle@sha256:0ceab16ea7872acc13ebcd287233cff0ed9f88d82b248710d4cc64c563cc6271",
      "bundle_path_digest": "sha256:0ceab16ea7872acc13ebcd287233cff0ed9f88d82b248710d4cc64c563cc6271",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-31T18:41:29.423000+00:00",
      "csv_description": "GitLab Runner is the lightweight, highly-scalable agent that runs your build jobs and sends the results back to a GitLab instance. GitLab Runner works in conjunction with GitLab CI/CD, the open-source continuous integration service included with GitLab.\n\nThe GitLab Runner operator manages the lifecycle of GitLab Runner in Kubernetes or Openshift clusters. The operator aims to automate the tasks needed to run your CI/CD jobs in your container orchestration platform.\n\n## Prerequisites\n\n  Install cert-manager:\n\n  ```shell\n  kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.7.1/cert-manager.yaml\n  ```\n\n## GitLab Runner version\n\nThis version of **GitLab Runner Operator** ships with **GitLab Runner v15.0.0**.\n\nTo use a different version of **GitLab Runner** change the [`runnerImage` and `helperImage` properties](https://docs.gitlab.com/runner/configuration/configuring_runner_operator.html#operator-properties).\n\n## Usage\n\n To link a GitLab Runner instance to a self-hosted GitLab instance or the hosted [GitLab](https://gitlab.com), you first need to:\n\n 1. Create a secret containing the `runner-registration-token` from your GitLab project.\n\n   ```\n  cat > gitlab-runner-secret.yml << EOF\n  apiVersion: v1\n  kind: Secret\n  metadata:\n    name: gitlab-runner-secret\n  type: Opaque\n  stringData:\n    runner-registration-token: REPLACE_ME # your project runner secret\n  EOF\n  ```\n\n  ```\n  oc apply -f gitlab-runner-secret.yml\n  ```\n\n 2. Create the Custom Resource Definition (CRD) file and include the following information. The tags value must be openshift for the job to run.\n\n   ```\n   cat > gitlab-runner.yml << EOF\n   apiVersion: apps.gitlab.com/v1beta2\n   kind: Runner\n   metadata:\n     name: gitlab-runner\n   spec:\n     gitlabUrl: https://gitlab.example.com\n     buildImage: alpine\n     token: gitlab-runner-secret\n     tags: openshift\n   EOF\n   ```\n\n  ```\n  oc apply -f gitlab-runner.yml\n  ```\n\n## Full documentation\n\nVisit [Install GitLab Runner Operator](https://docs.gitlab.com/runner/install/operator.html)\n",
      "csv_display_name": "GitLab Runner",
      "csv_metadata_description": "GitLab Runner operator manages lifecycle of GitLab Runner instances",
      "csv_name": "gitlab-runner-operator.v1.9.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T12:55:54.174000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "gitlab-runner-operator",
      "provided_apis": [
        {
          "group": "apps.gitlab.com",
          "kind": "Runner",
          "version": "v1beta2"
        }
      ],
      "provider": "GitLab, Inc.",
      "related_images": [
        {
          "digest": "sha256:101d0e79200344df095eb055dcda5401e2315f5d10aa3b73d80199f8baca5f2b",
          "image": "registry.gitlab.com/gitlab-org/ci-cd/gitlab-runner-ubi-images/gitlab-runner-ocp@sha256:101d0e79200344df095eb055dcda5401e2315f5d10aa3b73d80199f8baca5f2b",
          "name": "gitlab-runner"
        },
        {
          "digest": "sha256:c8fd9317cdd464bdc948b3f7674821d2a55165e41fba31b80ee2736847e9aa09",
          "image": "registry.gitlab.com/gitlab-org/ci-cd/gitlab-runner-ubi-images/gitlab-runner-helper-ocp@sha256:c8fd9317cdd464bdc948b3f7674821d2a55165e41fba31b80ee2736847e9aa09",
          "name": "gitlab-runner-helper"
        },
        {
          "digest": "sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "name": "gitlab-runner-operator"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "name": "gl-openshift/gitlab-runner-operator/gitlab-runner-operator-ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b-annotation"
        },
        {
          "digest": "sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.9.0",
      "version_original": "1.9.0"
    },
    {
      "_id": "6296638d0de577781eb82b1e",
      "alm_examples": [
        {
          "api_version": "apps.gitlab.com/v1beta2",
          "kind": "Runner",
          "metadata": {
            "name": "example"
          },
          "spec": {
            "gitlabUrl": "https://gitlab.com",
            "imagePullPolicy": "Always",
            "tags": "openshift, test",
            "token": "gitlab-dev-runner-secret"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [
        "amd64",
        "ppc64le"
      ],
      "bundle_path": "registry.connect.redhat.com/gitlab/gitlab-runner-operator-bundle@sha256:0ceab16ea7872acc13ebcd287233cff0ed9f88d82b248710d4cc64c563cc6271",
      "bundle_path_digest": "sha256:0ceab16ea7872acc13ebcd287233cff0ed9f88d82b248710d4cc64c563cc6271",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-31T18:50:53.491000+00:00",
      "csv_description": "GitLab Runner is the lightweight, highly-scalable agent that runs your build jobs and sends the results back to a GitLab instance. GitLab Runner works in conjunction with GitLab CI/CD, the open-source continuous integration service included with GitLab.\n\nThe GitLab Runner operator manages the lifecycle of GitLab Runner in Kubernetes or Openshift clusters. The operator aims to automate the tasks needed to run your CI/CD jobs in your container orchestration platform.\n\n## Prerequisites\n\n  Install cert-manager:\n\n  ```shell\n  kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.7.1/cert-manager.yaml\n  ```\n\n## GitLab Runner version\n\nThis version of **GitLab Runner Operator** ships with **GitLab Runner v15.0.0**.\n\nTo use a different version of **GitLab Runner** change the [`runnerImage` and `helperImage` properties](https://docs.gitlab.com/runner/configuration/configuring_runner_operator.html#operator-properties).\n\n## Usage\n\n To link a GitLab Runner instance to a self-hosted GitLab instance or the hosted [GitLab](https://gitlab.com), you first need to:\n\n 1. Create a secret containing the `runner-registration-token` from your GitLab project.\n\n   ```\n  cat > gitlab-runner-secret.yml << EOF\n  apiVersion: v1\n  kind: Secret\n  metadata:\n    name: gitlab-runner-secret\n  type: Opaque\n  stringData:\n    runner-registration-token: REPLACE_ME # your project runner secret\n  EOF\n  ```\n\n  ```\n  oc apply -f gitlab-runner-secret.yml\n  ```\n\n 2. Create the Custom Resource Definition (CRD) file and include the following information. The tags value must be openshift for the job to run.\n\n   ```\n   cat > gitlab-runner.yml << EOF\n   apiVersion: apps.gitlab.com/v1beta2\n   kind: Runner\n   metadata:\n     name: gitlab-runner\n   spec:\n     gitlabUrl: https://gitlab.example.com\n     buildImage: alpine\n     token: gitlab-runner-secret\n     tags: openshift\n   EOF\n   ```\n\n  ```\n  oc apply -f gitlab-runner.yml\n  ```\n\n## Full documentation\n\nVisit [Install GitLab Runner Operator](https://docs.gitlab.com/runner/install/operator.html)\n",
      "csv_display_name": "GitLab Runner",
      "csv_metadata_description": "GitLab Runner operator manages lifecycle of GitLab Runner instances",
      "csv_name": "gitlab-runner-operator.v1.9.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T12:51:52.010000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "gitlab-runner-operator",
      "provided_apis": [
        {
          "group": "apps.gitlab.com",
          "kind": "Runner",
          "version": "v1beta2"
        }
      ],
      "provider": "GitLab, Inc.",
      "related_images": [
        {
          "digest": "sha256:101d0e79200344df095eb055dcda5401e2315f5d10aa3b73d80199f8baca5f2b",
          "image": "registry.gitlab.com/gitlab-org/ci-cd/gitlab-runner-ubi-images/gitlab-runner-ocp@sha256:101d0e79200344df095eb055dcda5401e2315f5d10aa3b73d80199f8baca5f2b",
          "name": "gitlab-runner"
        },
        {
          "digest": "sha256:c8fd9317cdd464bdc948b3f7674821d2a55165e41fba31b80ee2736847e9aa09",
          "image": "registry.gitlab.com/gitlab-org/ci-cd/gitlab-runner-ubi-images/gitlab-runner-helper-ocp@sha256:c8fd9317cdd464bdc948b3f7674821d2a55165e41fba31b80ee2736847e9aa09",
          "name": "gitlab-runner-helper"
        },
        {
          "digest": "sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "name": "gitlab-runner-operator"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "name": "gl-openshift/gitlab-runner-operator/gitlab-runner-operator-ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b-annotation"
        },
        {
          "digest": "sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "1.9.0",
      "version_original": "1.9.0"
    },
    {
      "_id": "62966472bef2511b09bb56af",
      "alm_examples": [
        {
          "api_version": "apps.gitlab.com/v1beta2",
          "kind": "Runner",
          "metadata": {
            "name": "example"
          },
          "spec": {
            "gitlabUrl": "https://gitlab.com",
            "imagePullPolicy": "Always",
            "tags": "openshift, test",
            "token": "gitlab-dev-runner-secret"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [
        "amd64",
        "ppc64le"
      ],
      "bundle_path": "registry.connect.redhat.com/gitlab/gitlab-runner-operator-bundle@sha256:0ceab16ea7872acc13ebcd287233cff0ed9f88d82b248710d4cc64c563cc6271",
      "bundle_path_digest": "sha256:0ceab16ea7872acc13ebcd287233cff0ed9f88d82b248710d4cc64c563cc6271",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-31T18:54:42.806000+00:00",
      "csv_description": "GitLab Runner is the lightweight, highly-scalable agent that runs your build jobs and sends the results back to a GitLab instance. GitLab Runner works in conjunction with GitLab CI/CD, the open-source continuous integration service included with GitLab.\n\nThe GitLab Runner operator manages the lifecycle of GitLab Runner in Kubernetes or Openshift clusters. The operator aims to automate the tasks needed to run your CI/CD jobs in your container orchestration platform.\n\n## Prerequisites\n\n  Install cert-manager:\n\n  ```shell\n  kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.7.1/cert-manager.yaml\n  ```\n\n## GitLab Runner version\n\nThis version of **GitLab Runner Operator** ships with **GitLab Runner v15.0.0**.\n\nTo use a different version of **GitLab Runner** change the [`runnerImage` and `helperImage` properties](https://docs.gitlab.com/runner/configuration/configuring_runner_operator.html#operator-properties).\n\n## Usage\n\n To link a GitLab Runner instance to a self-hosted GitLab instance or the hosted [GitLab](https://gitlab.com), you first need to:\n\n 1. Create a secret containing the `runner-registration-token` from your GitLab project.\n\n   ```\n  cat > gitlab-runner-secret.yml << EOF\n  apiVersion: v1\n  kind: Secret\n  metadata:\n    name: gitlab-runner-secret\n  type: Opaque\n  stringData:\n    runner-registration-token: REPLACE_ME # your project runner secret\n  EOF\n  ```\n\n  ```\n  oc apply -f gitlab-runner-secret.yml\n  ```\n\n 2. Create the Custom Resource Definition (CRD) file and include the following information. The tags value must be openshift for the job to run.\n\n   ```\n   cat > gitlab-runner.yml << EOF\n   apiVersion: apps.gitlab.com/v1beta2\n   kind: Runner\n   metadata:\n     name: gitlab-runner\n   spec:\n     gitlabUrl: https://gitlab.example.com\n     buildImage: alpine\n     token: gitlab-runner-secret\n     tags: openshift\n   EOF\n   ```\n\n  ```\n  oc apply -f gitlab-runner.yml\n  ```\n\n## Full documentation\n\nVisit [Install GitLab Runner Operator](https://docs.gitlab.com/runner/install/operator.html)\n",
      "csv_display_name": "GitLab Runner",
      "csv_metadata_description": "GitLab Runner operator manages lifecycle of GitLab Runner instances",
      "csv_name": "gitlab-runner-operator.v1.9.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:37:34.976000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "gitlab-runner-operator",
      "provided_apis": [
        {
          "group": "apps.gitlab.com",
          "kind": "Runner",
          "version": "v1beta2"
        }
      ],
      "provider": "GitLab, Inc.",
      "related_images": [
        {
          "digest": "sha256:101d0e79200344df095eb055dcda5401e2315f5d10aa3b73d80199f8baca5f2b",
          "image": "registry.gitlab.com/gitlab-org/ci-cd/gitlab-runner-ubi-images/gitlab-runner-ocp@sha256:101d0e79200344df095eb055dcda5401e2315f5d10aa3b73d80199f8baca5f2b",
          "name": "gitlab-runner"
        },
        {
          "digest": "sha256:c8fd9317cdd464bdc948b3f7674821d2a55165e41fba31b80ee2736847e9aa09",
          "image": "registry.gitlab.com/gitlab-org/ci-cd/gitlab-runner-ubi-images/gitlab-runner-helper-ocp@sha256:c8fd9317cdd464bdc948b3f7674821d2a55165e41fba31b80ee2736847e9aa09",
          "name": "gitlab-runner-helper"
        },
        {
          "digest": "sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "name": "gitlab-runner-operator"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "name": "gl-openshift/gitlab-runner-operator/gitlab-runner-operator-ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b-annotation"
        },
        {
          "digest": "sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.9.0",
      "version_original": "1.9.0"
    },
    {
      "_id": "62966821bef2511b09bb5767",
      "alm_examples": [
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Backup",
          "metadata": {
            "name": "backup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Cluster",
          "metadata": {
            "name": "cluster-sample"
          },
          "spec": {
            "instances": 3,
            "logLevel": "info",
            "primaryUpdateStrategy": "unsupervised",
            "storage": {
              "size": "1Gi"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Pooler",
          "metadata": {
            "name": "pooler-sample-rw"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "instances": 1,
            "pgbouncer": {
              "poolMode": "session"
            },
            "type": "rw"
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "ScheduledBackup",
          "metadata": {
            "name": "scheduledbackup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "schedule": "0 0 0 * * *"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [
        "amd64",
        "ppc64le",
        "s390x"
      ],
      "bundle_path": "registry.connect.redhat.com/enterprisedb/cloud-native-postgresql@sha256:9dd5f6ec499dd5d084b39d6bf43f07c80dbe82490a230be4581cebd5225d7ae8",
      "bundle_path_digest": "sha256:9dd5f6ec499dd5d084b39d6bf43f07c80dbe82490a230be4581cebd5225d7ae8",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-31T19:10:25.415000+00:00",
      "csv_description": "EDB Postgres for Kubernetes is an operator designed, developed, and supported by EDB that covers the full \nlifecycle of a highly available Postgres database clusters with a primary/standby architecture, using native\nstreaming replication. It is based on the open source CloudNativePG operator, and provides additional value\nsuch as compatibility with Oracle using EDB Postgres Advanced Server and additional supported platforms such\nas IBM Power and OpenShift.\n\nKey features available include:\n\n* Kubernetes API integration for high availability\n* Self-healing through failover and automated recreation of replicas\n* Capacity management with scale up/down capabilities\n* Planned switchovers for scheduled maintenance\n* Read-only and read-write Kubernetes services definitions\n* Rolling updates for Postgres minor versions and operator upgrades\n* Continuous backup and point-in-time recovery\n* Connection Pooling with PgBouncer\n* Integrated metrics exporter out of the box\n* PostgreSQL replication across multiple Kubernetes clusters\n* Red Hat certified operator for OpenShift\n\nThe operator has been renamed from Cloud Native PostgreSQL. Existing users of Cloud Native PostgreSQL will not\nexperience any change, as the underlying components and resources have not changed.\n",
      "csv_display_name": "EDB Postgres for Kubernetes",
      "csv_metadata_description": "Operator to manage Postgres high availability clusters with a primary/standby architecture.",
      "csv_name": "cloud-native-postgresql.v1.15.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-08-15T12:55:41.166000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "cloud-native-postgresql",
      "provided_apis": [
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "ScheduledBackup",
          "plural": "scheduledbackups",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Backup",
          "plural": "backups",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Cluster",
          "plural": "clusters",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Pooler",
          "plural": "poolers",
          "version": "v1"
        }
      ],
      "provider": "EnterpriseDB Corporation",
      "related_images": [
        {
          "digest": "sha256:01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4",
          "name": "cloud-native-postgresql-01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4-annotation"
        },
        {
          "digest": "sha256:01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": ">=0.6.0 < 1.15.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.15.1",
      "version_original": "1.15.1"
    },
    {
      "_id": "62966a514b05ff1d1a1d3569",
      "alm_examples": [
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Backup",
          "metadata": {
            "name": "backup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Cluster",
          "metadata": {
            "name": "cluster-sample"
          },
          "spec": {
            "instances": 3,
            "logLevel": "info",
            "primaryUpdateStrategy": "unsupervised",
            "storage": {
              "size": "1Gi"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Pooler",
          "metadata": {
            "name": "pooler-sample-rw"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "instances": 1,
            "pgbouncer": {
              "poolMode": "session"
            },
            "type": "rw"
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "ScheduledBackup",
          "metadata": {
            "name": "scheduledbackup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "schedule": "0 0 0 * * *"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [
        "amd64",
        "ppc64le",
        "s390x"
      ],
      "bundle_path": "registry.connect.redhat.com/enterprisedb/cloud-native-postgresql@sha256:9dd5f6ec499dd5d084b39d6bf43f07c80dbe82490a230be4581cebd5225d7ae8",
      "bundle_path_digest": "sha256:9dd5f6ec499dd5d084b39d6bf43f07c80dbe82490a230be4581cebd5225d7ae8",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-31T19:19:45.423000+00:00",
      "csv_description": "EDB Postgres for Kubernetes is an operator designed, developed, and supported by EDB that covers the full \nlifecycle of a highly available Postgres database clusters with a primary/standby architecture, using native\nstreaming replication. It is based on the open source CloudNativePG operator, and provides additional value\nsuch as compatibility with Oracle using EDB Postgres Advanced Server and additional supported platforms such\nas IBM Power and OpenShift.\n\nKey features available include:\n\n* Kubernetes API integration for high availability\n* Self-healing through failover and automated recreation of replicas\n* Capacity management with scale up/down capabilities\n* Planned switchovers for scheduled maintenance\n* Read-only and read-write Kubernetes services definitions\n* Rolling updates for Postgres minor versions and operator upgrades\n* Continuous backup and point-in-time recovery\n* Connection Pooling with PgBouncer\n* Integrated metrics exporter out of the box\n* PostgreSQL replication across multiple Kubernetes clusters\n* Red Hat certified operator for OpenShift\n\nThe operator has been renamed from Cloud Native PostgreSQL. Existing users of Cloud Native PostgreSQL will not\nexperience any change, as the underlying components and resources have not changed.\n",
      "csv_display_name": "EDB Postgres for Kubernetes",
      "csv_metadata_description": "Operator to manage Postgres high availability clusters with a primary/standby architecture.",
      "csv_name": "cloud-native-postgresql.v1.15.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-08-15T13:35:20.444000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "cloud-native-postgresql",
      "provided_apis": [
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "ScheduledBackup",
          "plural": "scheduledbackups",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Backup",
          "plural": "backups",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Cluster",
          "plural": "clusters",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Pooler",
          "plural": "poolers",
          "version": "v1"
        }
      ],
      "provider": "EnterpriseDB Corporation",
      "related_images": [
        {
          "digest": "sha256:01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4",
          "name": "cloud-native-postgresql-01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4-annotation"
        },
        {
          "digest": "sha256:01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": ">=0.6.0 < 1.15.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.15.1",
      "version_original": "1.15.1"
    },
    {
      "_id": "62966bde4b05ff1d1a1d365d",
      "alm_examples": [
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Backup",
          "metadata": {
            "name": "backup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Cluster",
          "metadata": {
            "name": "cluster-sample"
          },
          "spec": {
            "instances": 3,
            "logLevel": "info",
            "primaryUpdateStrategy": "unsupervised",
            "storage": {
              "size": "1Gi"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Pooler",
          "metadata": {
            "name": "pooler-sample-rw"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "instances": 1,
            "pgbouncer": {
              "poolMode": "session"
            },
            "type": "rw"
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "ScheduledBackup",
          "metadata": {
            "name": "scheduledbackup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "schedule": "0 0 0 * * *"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [
        "amd64",
        "ppc64le",
        "s390x"
      ],
      "bundle_path": "registry.connect.redhat.com/enterprisedb/cloud-native-postgresql@sha256:9dd5f6ec499dd5d084b39d6bf43f07c80dbe82490a230be4581cebd5225d7ae8",
      "bundle_path_digest": "sha256:9dd5f6ec499dd5d084b39d6bf43f07c80dbe82490a230be4581cebd5225d7ae8",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-31T19:26:22.506000+00:00",
      "csv_description": "EDB Postgres for Kubernetes is an operator designed, developed, and supported by EDB that covers the full \nlifecycle of a highly available Postgres database clusters with a primary/standby architecture, using native\nstreaming replication. It is based on the open source CloudNativePG operator, and provides additional value\nsuch as compatibility with Oracle using EDB Postgres Advanced Server and additional supported platforms such\nas IBM Power and OpenShift.\n\nKey features available include:\n\n* Kubernetes API integration for high availability\n* Self-healing through failover and automated recreation of replicas\n* Capacity management with scale up/down capabilities\n* Planned switchovers for scheduled maintenance\n* Read-only and read-write Kubernetes services definitions\n* Rolling updates for Postgres minor versions and operator upgrades\n* Continuous backup and point-in-time recovery\n* Connection Pooling with PgBouncer\n* Integrated metrics exporter out of the box\n* PostgreSQL replication across multiple Kubernetes clusters\n* Red Hat certified operator for OpenShift\n\nThe operator has been renamed from Cloud Native PostgreSQL. Existing users of Cloud Native PostgreSQL will not\nexperience any change, as the underlying components and resources have not changed.\n",
      "csv_display_name": "EDB Postgres for Kubernetes",
      "csv_metadata_description": "Operator to manage Postgres high availability clusters with a primary/standby architecture.",
      "csv_name": "cloud-native-postgresql.v1.15.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-08-15T12:52:08.087000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "cloud-native-postgresql",
      "provided_apis": [
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Pooler",
          "plural": "poolers",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "ScheduledBackup",
          "plural": "scheduledbackups",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Backup",
          "plural": "backups",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Cluster",
          "plural": "clusters",
          "version": "v1"
        }
      ],
      "provider": "EnterpriseDB Corporation",
      "related_images": [
        {
          "digest": "sha256:01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4",
          "name": "cloud-native-postgresql-01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4-annotation"
        },
        {
          "digest": "sha256:01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": ">=0.6.0 < 1.15.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.15.1",
      "version_original": "1.15.1"
    },
    {
      "_id": "62966ce8bef2511b09bb5957",
      "alm_examples": [
        {
          "api_version": "apps.gitlab.com/v1beta2",
          "kind": "Runner",
          "metadata": {
            "name": "example"
          },
          "spec": {
            "gitlabUrl": "https://gitlab.com",
            "imagePullPolicy": "Always",
            "tags": "openshift, test",
            "token": "gitlab-dev-runner-secret"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [
        "amd64",
        "ppc64le"
      ],
      "bundle_path": "registry.connect.redhat.com/gitlab/gitlab-runner-operator-bundle@sha256:0ceab16ea7872acc13ebcd287233cff0ed9f88d82b248710d4cc64c563cc6271",
      "bundle_path_digest": "sha256:0ceab16ea7872acc13ebcd287233cff0ed9f88d82b248710d4cc64c563cc6271",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-31T19:30:48.373000+00:00",
      "csv_description": "GitLab Runner is the lightweight, highly-scalable agent that runs your build jobs and sends the results back to a GitLab instance. GitLab Runner works in conjunction with GitLab CI/CD, the open-source continuous integration service included with GitLab.\n\nThe GitLab Runner operator manages the lifecycle of GitLab Runner in Kubernetes or Openshift clusters. The operator aims to automate the tasks needed to run your CI/CD jobs in your container orchestration platform.\n\n## Prerequisites\n\n  Install cert-manager:\n\n  ```shell\n  kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.7.1/cert-manager.yaml\n  ```\n\n## GitLab Runner version\n\nThis version of **GitLab Runner Operator** ships with **GitLab Runner v15.0.0**.\n\nTo use a different version of **GitLab Runner** change the [`runnerImage` and `helperImage` properties](https://docs.gitlab.com/runner/configuration/configuring_runner_operator.html#operator-properties).\n\n## Usage\n\n To link a GitLab Runner instance to a self-hosted GitLab instance or the hosted [GitLab](https://gitlab.com), you first need to:\n\n 1. Create a secret containing the `runner-registration-token` from your GitLab project.\n\n   ```\n  cat > gitlab-runner-secret.yml << EOF\n  apiVersion: v1\n  kind: Secret\n  metadata:\n    name: gitlab-runner-secret\n  type: Opaque\n  stringData:\n    runner-registration-token: REPLACE_ME # your project runner secret\n  EOF\n  ```\n\n  ```\n  oc apply -f gitlab-runner-secret.yml\n  ```\n\n 2. Create the Custom Resource Definition (CRD) file and include the following information. The tags value must be openshift for the job to run.\n\n   ```\n   cat > gitlab-runner.yml << EOF\n   apiVersion: apps.gitlab.com/v1beta2\n   kind: Runner\n   metadata:\n     name: gitlab-runner\n   spec:\n     gitlabUrl: https://gitlab.example.com\n     buildImage: alpine\n     token: gitlab-runner-secret\n     tags: openshift\n   EOF\n   ```\n\n  ```\n  oc apply -f gitlab-runner.yml\n  ```\n\n## Full documentation\n\nVisit [Install GitLab Runner Operator](https://docs.gitlab.com/runner/install/operator.html)\n",
      "csv_display_name": "GitLab Runner",
      "csv_metadata_description": "GitLab Runner operator manages lifecycle of GitLab Runner instances",
      "csv_name": "gitlab-runner-operator.v1.9.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:18:41.064000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "gitlab-runner-operator",
      "provided_apis": [
        {
          "group": "apps.gitlab.com",
          "kind": "Runner",
          "version": "v1beta2"
        }
      ],
      "provider": "GitLab, Inc.",
      "related_images": [
        {
          "digest": "sha256:101d0e79200344df095eb055dcda5401e2315f5d10aa3b73d80199f8baca5f2b",
          "image": "registry.gitlab.com/gitlab-org/ci-cd/gitlab-runner-ubi-images/gitlab-runner-ocp@sha256:101d0e79200344df095eb055dcda5401e2315f5d10aa3b73d80199f8baca5f2b",
          "name": "gitlab-runner"
        },
        {
          "digest": "sha256:c8fd9317cdd464bdc948b3f7674821d2a55165e41fba31b80ee2736847e9aa09",
          "image": "registry.gitlab.com/gitlab-org/ci-cd/gitlab-runner-ubi-images/gitlab-runner-helper-ocp@sha256:c8fd9317cdd464bdc948b3f7674821d2a55165e41fba31b80ee2736847e9aa09",
          "name": "gitlab-runner-helper"
        },
        {
          "digest": "sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "name": "gitlab-runner-operator"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "name": "gl-openshift/gitlab-runner-operator/gitlab-runner-operator-ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b-annotation"
        },
        {
          "digest": "sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "image": "registry.gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator/gitlab-runner-operator@sha256:ead726da6f75d80ff7b389dac853096d8680b9910cd5079d3aaf77a31846bf7b",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "1.9.0",
      "version_original": "1.9.0"
    },
    {
      "_id": "62966ceabef2511b09bb595a",
      "alm_examples": [
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Backup",
          "metadata": {
            "name": "backup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Cluster",
          "metadata": {
            "name": "cluster-sample"
          },
          "spec": {
            "instances": 3,
            "logLevel": "info",
            "primaryUpdateStrategy": "unsupervised",
            "storage": {
              "size": "1Gi"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Pooler",
          "metadata": {
            "name": "pooler-sample-rw"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "instances": 1,
            "pgbouncer": {
              "poolMode": "session"
            },
            "type": "rw"
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "ScheduledBackup",
          "metadata": {
            "name": "scheduledbackup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "schedule": "0 0 0 * * *"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [
        "amd64",
        "ppc64le",
        "s390x"
      ],
      "bundle_path": "registry.connect.redhat.com/enterprisedb/cloud-native-postgresql@sha256:9dd5f6ec499dd5d084b39d6bf43f07c80dbe82490a230be4581cebd5225d7ae8",
      "bundle_path_digest": "sha256:9dd5f6ec499dd5d084b39d6bf43f07c80dbe82490a230be4581cebd5225d7ae8",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-31T19:30:50.021000+00:00",
      "csv_description": "EDB Postgres for Kubernetes is an operator designed, developed, and supported by EDB that covers the full \nlifecycle of a highly available Postgres database clusters with a primary/standby architecture, using native\nstreaming replication. It is based on the open source CloudNativePG operator, and provides additional value\nsuch as compatibility with Oracle using EDB Postgres Advanced Server and additional supported platforms such\nas IBM Power and OpenShift.\n\nKey features available include:\n\n* Kubernetes API integration for high availability\n* Self-healing through failover and automated recreation of replicas\n* Capacity management with scale up/down capabilities\n* Planned switchovers for scheduled maintenance\n* Read-only and read-write Kubernetes services definitions\n* Rolling updates for Postgres minor versions and operator upgrades\n* Continuous backup and point-in-time recovery\n* Connection Pooling with PgBouncer\n* Integrated metrics exporter out of the box\n* PostgreSQL replication across multiple Kubernetes clusters\n* Red Hat certified operator for OpenShift\n\nThe operator has been renamed from Cloud Native PostgreSQL. Existing users of Cloud Native PostgreSQL will not\nexperience any change, as the underlying components and resources have not changed.\n",
      "csv_display_name": "EDB Postgres for Kubernetes",
      "csv_metadata_description": "Operator to manage Postgres high availability clusters with a primary/standby architecture.",
      "csv_name": "cloud-native-postgresql.v1.15.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-08-15T13:25:37.361000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "cloud-native-postgresql",
      "provided_apis": [
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "ScheduledBackup",
          "plural": "scheduledbackups",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Backup",
          "plural": "backups",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Cluster",
          "plural": "clusters",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Pooler",
          "plural": "poolers",
          "version": "v1"
        }
      ],
      "provider": "EnterpriseDB Corporation",
      "related_images": [
        {
          "digest": "sha256:01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4",
          "name": "cloud-native-postgresql-01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4-annotation"
        },
        {
          "digest": "sha256:01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": ">=0.6.0 < 1.15.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "1.15.1",
      "version_original": "1.15.1"
    },
    {
      "_id": "62966d4250b5ca24ee5f4d8b",
      "alm_examples": [
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Backup",
          "metadata": {
            "name": "backup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Cluster",
          "metadata": {
            "name": "cluster-sample"
          },
          "spec": {
            "instances": 3,
            "logLevel": "info",
            "primaryUpdateStrategy": "unsupervised",
            "storage": {
              "size": "1Gi"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Pooler",
          "metadata": {
            "name": "pooler-sample-rw"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "instances": 1,
            "pgbouncer": {
              "poolMode": "session"
            },
            "type": "rw"
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "ScheduledBackup",
          "metadata": {
            "name": "scheduledbackup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "schedule": "0 0 0 * * *"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [
        "amd64",
        "ppc64le",
        "s390x"
      ],
      "bundle_path": "registry.connect.redhat.com/enterprisedb/cloud-native-postgresql@sha256:9dd5f6ec499dd5d084b39d6bf43f07c80dbe82490a230be4581cebd5225d7ae8",
      "bundle_path_digest": "sha256:9dd5f6ec499dd5d084b39d6bf43f07c80dbe82490a230be4581cebd5225d7ae8",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-05-31T19:32:18.776000+00:00",
      "csv_description": "EDB Postgres for Kubernetes is an operator designed, developed, and supported by EDB that covers the full \nlifecycle of a highly available Postgres database clusters with a primary/standby architecture, using native\nstreaming replication. It is based on the open source CloudNativePG operator, and provides additional value\nsuch as compatibility with Oracle using EDB Postgres Advanced Server and additional supported platforms such\nas IBM Power and OpenShift.\n\nKey features available include:\n\n* Kubernetes API integration for high availability\n* Self-healing through failover and automated recreation of replicas\n* Capacity management with scale up/down capabilities\n* Planned switchovers for scheduled maintenance\n* Read-only and read-write Kubernetes services definitions\n* Rolling updates for Postgres minor versions and operator upgrades\n* Continuous backup and point-in-time recovery\n* Connection Pooling with PgBouncer\n* Integrated metrics exporter out of the box\n* PostgreSQL replication across multiple Kubernetes clusters\n* Red Hat certified operator for OpenShift\n\nThe operator has been renamed from Cloud Native PostgreSQL. Existing users of Cloud Native PostgreSQL will not\nexperience any change, as the underlying components and resources have not changed.\n",
      "csv_display_name": "EDB Postgres for Kubernetes",
      "csv_metadata_description": "Operator to manage Postgres high availability clusters with a primary/standby architecture.",
      "csv_name": "cloud-native-postgresql.v1.15.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-08-15T13:27:19.982000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "cloud-native-postgresql",
      "provided_apis": [
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Backup",
          "plural": "backups",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Cluster",
          "plural": "clusters",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Pooler",
          "plural": "poolers",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "ScheduledBackup",
          "plural": "scheduledbackups",
          "version": "v1"
        }
      ],
      "provider": "EnterpriseDB Corporation",
      "related_images": [
        {
          "digest": "sha256:01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4",
          "name": "cloud-native-postgresql-01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4-annotation"
        },
        {
          "digest": "sha256:01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:01bfdf40764c47db948c68dab2364b22c586f16a0300dac315c0e0e9af86fea4",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": ">=0.6.0 < 1.15.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "1.15.1",
      "version_original": "1.15.1"
    },
    {
      "_id": "6297b2af8c1a626fc9ae708d",
      "alm_examples": [
        {
          "api_version": "appdirector.randoli.ca/v1beta1",
          "kind": "ClusterWideGuvnor",
          "metadata": {
            "name": "guvnor"
          },
          "spec": {
            "guvnorCertsSecretName": "guvnor-certs",
            "guvnorSecretName": "guvnor-secret",
            "namespace": "app-director-example-app"
          }
        },
        {
          "api_version": "appdirector.randoli.ca/v1beta1",
          "kind": "Guvnor",
          "metadata": {
            "name": "guvnor",
            "namespace": "app-director-example-app"
          },
          "spec": {
            "guvnorCertsSecretName": "guvnor-certs",
            "guvnorSecretName": "guvnor-secret"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/randoli/app-director-operator@sha256:e5d637b0d40a59dce96880c80d61bf8454c4b43ba83e22345da9b1cfeb526633",
      "bundle_path_digest": "sha256:e5d637b0d40a59dce96880c80d61bf8454c4b43ba83e22345da9b1cfeb526633",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "0.0.3",
      "creation_date": "2022-06-01T18:40:47.174000+00:00",
      "csv_description": "App Director\u00ae Operator manages the Guvnor agent that connects with the App Director\u00ae Platform to receive deployments and send back events. The agent can be scoped to a namespace or cluster-wide. More information can be found at https://www.randoli.ca/app-director-overview. Tekton Pipelines are a pre-requisite for this operator to work. If not already installed, the operator will install the correct version on initial start-up.",
      "csv_display_name": "App-Director",
      "csv_metadata_description": "",
      "csv_name": "app-director-operator.v0.0.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-08-15T13:29:28.553000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "app-director-operator",
      "provided_apis": [
        {
          "group": "appdirector.randoli.ca",
          "kind": "ClusterWideGuvnor",
          "plural": "clusterwideguvnors",
          "version": "v1beta1"
        },
        {
          "group": "appdirector.randoli.ca",
          "kind": "Guvnor",
          "plural": "guvnors",
          "version": "v1beta1"
        }
      ],
      "provider": "Randoli",
      "related_images": [
        {
          "digest": "sha256:cb9cb3bdea785e41b7b0da8a5357aaa0cb6c4e6b5d1e87db4a53798e25a56112",
          "image": "docker.io/randoli/app-director-operator:0.0.3@sha256:cb9cb3bdea785e41b7b0da8a5357aaa0cb6c4e6b5d1e87db4a53798e25a56112",
          "name": "app-director-operator:0.0.3-cb9cb3bdea785e41b7b0da8a5357aaa0cb6c4e6b5d1e87db4a53798e25a56112-annotation"
        },
        {
          "digest": "sha256:e10d1d982dd653db74ca87a1d1ad017bc5ef1aeb651bdea089debf16485b080b",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy:v0.5.0@sha256:e10d1d982dd653db74ca87a1d1ad017bc5ef1aeb651bdea089debf16485b080b",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:cb9cb3bdea785e41b7b0da8a5357aaa0cb6c4e6b5d1e87db4a53798e25a56112",
          "image": "docker.io/randoli/app-director-operator:0.0.3@sha256:cb9cb3bdea785e41b7b0da8a5357aaa0cb6c4e6b5d1e87db4a53798e25a56112",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "0.0.3",
      "version_original": "0.0.3"
    },
    {
      "_id": "6297b2eb8c1a626fc9ae70bd",
      "alm_examples": [
        {
          "api_version": "appdirector.randoli.ca/v1beta1",
          "kind": "ClusterWideGuvnor",
          "metadata": {
            "name": "guvnor"
          },
          "spec": {
            "guvnorCertsSecretName": "guvnor-certs",
            "guvnorSecretName": "guvnor-secret",
            "namespace": "app-director-example-app"
          }
        },
        {
          "api_version": "appdirector.randoli.ca/v1beta1",
          "kind": "Guvnor",
          "metadata": {
            "name": "guvnor",
            "namespace": "app-director-example-app"
          },
          "spec": {
            "guvnorCertsSecretName": "guvnor-certs",
            "guvnorSecretName": "guvnor-secret"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/randoli/app-director-operator@sha256:e5d637b0d40a59dce96880c80d61bf8454c4b43ba83e22345da9b1cfeb526633",
      "bundle_path_digest": "sha256:e5d637b0d40a59dce96880c80d61bf8454c4b43ba83e22345da9b1cfeb526633",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "0.0.3",
      "creation_date": "2022-06-01T18:41:47.492000+00:00",
      "csv_description": "App Director\u00ae Operator manages the Guvnor agent that connects with the App Director\u00ae Platform to receive deployments and send back events. The agent can be scoped to a namespace or cluster-wide. More information can be found at https://www.randoli.ca/app-director-overview. Tekton Pipelines are a pre-requisite for this operator to work. If not already installed, the operator will install the correct version on initial start-up.",
      "csv_display_name": "App-Director",
      "csv_metadata_description": "",
      "csv_name": "app-director-operator.v0.0.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-08-15T13:07:31.389000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "app-director-operator",
      "provided_apis": [
        {
          "group": "appdirector.randoli.ca",
          "kind": "ClusterWideGuvnor",
          "plural": "clusterwideguvnors",
          "version": "v1beta1"
        },
        {
          "group": "appdirector.randoli.ca",
          "kind": "Guvnor",
          "plural": "guvnors",
          "version": "v1beta1"
        }
      ],
      "provider": "Randoli",
      "related_images": [
        {
          "digest": "sha256:cb9cb3bdea785e41b7b0da8a5357aaa0cb6c4e6b5d1e87db4a53798e25a56112",
          "image": "docker.io/randoli/app-director-operator:0.0.3@sha256:cb9cb3bdea785e41b7b0da8a5357aaa0cb6c4e6b5d1e87db4a53798e25a56112",
          "name": "app-director-operator:0.0.3-cb9cb3bdea785e41b7b0da8a5357aaa0cb6c4e6b5d1e87db4a53798e25a56112-annotation"
        },
        {
          "digest": "sha256:e10d1d982dd653db74ca87a1d1ad017bc5ef1aeb651bdea089debf16485b080b",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy:v0.5.0@sha256:e10d1d982dd653db74ca87a1d1ad017bc5ef1aeb651bdea089debf16485b080b",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:cb9cb3bdea785e41b7b0da8a5357aaa0cb6c4e6b5d1e87db4a53798e25a56112",
          "image": "docker.io/randoli/app-director-operator:0.0.3@sha256:cb9cb3bdea785e41b7b0da8a5357aaa0cb6c4e6b5d1e87db4a53798e25a56112",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "0.0.3",
      "version_original": "0.0.3"
    },
    {
      "_id": "6297b34eefe144fd5e92f2f1",
      "alm_examples": [
        {
          "api_version": "appdirector.randoli.ca/v1beta1",
          "kind": "ClusterWideGuvnor",
          "metadata": {
            "name": "guvnor"
          },
          "spec": {
            "guvnorCertsSecretName": "guvnor-certs",
            "guvnorSecretName": "guvnor-secret",
            "namespace": "app-director-example-app"
          }
        },
        {
          "api_version": "appdirector.randoli.ca/v1beta1",
          "kind": "Guvnor",
          "metadata": {
            "name": "guvnor",
            "namespace": "app-director-example-app"
          },
          "spec": {
            "guvnorCertsSecretName": "guvnor-certs",
            "guvnorSecretName": "guvnor-secret"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/randoli/app-director-operator@sha256:e5d637b0d40a59dce96880c80d61bf8454c4b43ba83e22345da9b1cfeb526633",
      "bundle_path_digest": "sha256:e5d637b0d40a59dce96880c80d61bf8454c4b43ba83e22345da9b1cfeb526633",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "0.0.3",
      "creation_date": "2022-06-01T18:43:26.683000+00:00",
      "csv_description": "App Director\u00ae Operator manages the Guvnor agent that connects with the App Director\u00ae Platform to receive deployments and send back events. The agent can be scoped to a namespace or cluster-wide. More information can be found at https://www.randoli.ca/app-director-overview. Tekton Pipelines are a pre-requisite for this operator to work. If not already installed, the operator will install the correct version on initial start-up.",
      "csv_display_name": "App-Director",
      "csv_metadata_description": "",
      "csv_name": "app-director-operator.v0.0.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-08-15T13:19:15.494000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "app-director-operator",
      "provided_apis": [
        {
          "group": "appdirector.randoli.ca",
          "kind": "ClusterWideGuvnor",
          "plural": "clusterwideguvnors",
          "version": "v1beta1"
        },
        {
          "group": "appdirector.randoli.ca",
          "kind": "Guvnor",
          "plural": "guvnors",
          "version": "v1beta1"
        }
      ],
      "provider": "Randoli",
      "related_images": [
        {
          "digest": "sha256:cb9cb3bdea785e41b7b0da8a5357aaa0cb6c4e6b5d1e87db4a53798e25a56112",
          "image": "docker.io/randoli/app-director-operator:0.0.3@sha256:cb9cb3bdea785e41b7b0da8a5357aaa0cb6c4e6b5d1e87db4a53798e25a56112",
          "name": "app-director-operator:0.0.3-cb9cb3bdea785e41b7b0da8a5357aaa0cb6c4e6b5d1e87db4a53798e25a56112-annotation"
        },
        {
          "digest": "sha256:e10d1d982dd653db74ca87a1d1ad017bc5ef1aeb651bdea089debf16485b080b",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy:v0.5.0@sha256:e10d1d982dd653db74ca87a1d1ad017bc5ef1aeb651bdea089debf16485b080b",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:cb9cb3bdea785e41b7b0da8a5357aaa0cb6c4e6b5d1e87db4a53798e25a56112",
          "image": "docker.io/randoli/app-director-operator:0.0.3@sha256:cb9cb3bdea785e41b7b0da8a5357aaa0cb6c4e6b5d1e87db4a53798e25a56112",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "0.0.3",
      "version_original": "0.0.3"
    },
    {
      "_id": "6297bc41554afbde4c9b7000",
      "alm_examples": [
        {
          "api_version": "platform.confluent.io/v1beta1",
          "kind": "Zookeeper",
          "metadata": {
            "name": "zookeeper"
          },
          "spec": {
            "dataVolumeCapacity": "10Gi",
            "image": {
              "application": "confluentinc/cp-zookeeper@sha256:f80df50ad358773df08657bace7980dd89c97cfc518141ed1ebffe88ce610ef4",
              "init": "confluentinc/confluent-init-container@sha256:35c19bd2fd4300899a47bd06e66dc43569cba02e95286f9b9548a764de0e1001"
            },
            "logVolumeCapacity": "10Gi",
            "replicas": 3
          }
        },
        {
          "api_version": "platform.confluent.io/v1beta1",
          "kind": "Kafka",
          "metadata": {
            "name": "kafka"
          },
          "spec": {
            "dataVolumeCapacity": "10Gi",
            "image": {
              "application": "confluentinc/cp-server@sha256:bbc1493e52991094cde2c94ad334d6fbbf413e87fa5f203e942f6bcc0d488ffd",
              "init": "confluentinc/confluent-init-container@sha256:35c19bd2fd4300899a47bd06e66dc43569cba02e95286f9b9548a764de0e1001"
            },
            "metricReporter": {
              "enabled": true
            },
            "replicas": 3
          }
        },
        {
          "api_version": "platform.confluent.io/v1beta1",
          "kind": "KafkaRestProxy",
          "metadata": {
            "name": "kafkarestproxy"
          },
          "spec": {
            "image": {
              "application": "confluentinc/cp-kafka-rest@sha256:d380a9e0dbb456f95e70b7d6c56cca02d4734b1d0fde8fbe2a053c3e6d44e16d ",
              "init": "confluentinc/confluent-init-container@sha256:35c19bd2fd4300899a47bd06e66dc43569cba02e95286f9b9548a764de0e1001"
            },
            "metricReporter": {
              "enabled": true
            },
            "replicas": 3
          }
        },
        {
          "api_version": "platform.confluent.io/v1beta1",
          "kind": "Connect",
          "metadata": {
            "name": "connect"
          },
          "spec": {
            "dependencies": {
              "kafka": {
                "bootstrapEndpoint": "kafka:9071"
              }
            },
            "image": {
              "application": "confluentinc/cp-server-connect@sha256:7da14f9d34b48bed11cb307a4a080d2055a18d5acc95f5bcc31b7feac0e0395e",
              "init": "confluentinc/confluent-init-container@sha256:35c19bd2fd4300899a47bd06e66dc43569cba02e95286f9b9548a764de0e1001"
            },
            "replicas": 1
          }
        },
        {
          "api_version": "platform.confluent.io/v1beta1",
          "kind": "KsqlDB",
          "metadata": {
            "name": "ksqldb"
          },
          "spec": {
            "dataVolumeCapacity": "10Gi",
            "image": {
              "application": "confluentinc/cp-ksqldb-server@sha256:951af16f6249a3bc3909420bf0abe78a7d5d853f4aa4eaf66665e1a6b2676af2",
              "init": "confluentinc/confluent-init-container@sha256:35c19bd2fd4300899a47bd06e66dc43569cba02e95286f9b9548a764de0e1001"
            },
            "replicas": 1
          }
        },
        {
          "api_version": "platform.confluent.io/v1beta1",
          "kind": "ControlCenter",
          "metadata": {
            "name": "controlcenter"
          },
          "spec": {
            "dataVolumeCapacity": "10Gi",
            "dependencies": {
              "connect": [
                {
                  "name": "connect",
                  "url": "http://connect.confluent.svc.cluster.local:8083"
                }
              ],
              "ksqldb": [
                {
                  "name": "ksqldb",
                  "url": "http://ksqldb.confluent.svc.cluster.local:8088"
                }
              ],
              "schemaRegistry": {
                "url": "http://schemaregistry.confluent.svc.cluster.local:8081"
              }
            },
            "image": {
              "application": "confluentinc/cp-enterprise-control-center@sha256:ef89f3bc2656c215a80dd202958bbfd1f843297574dff5a537590d1733aaf38a",
              "init": "confluentinc/confluent-init-container@sha256:35c19bd2fd4300899a47bd06e66dc43569cba02e95286f9b9548a764de0e1001"
            },
            "replicas": 1
          }
        },
        {
          "api_version": "platform.confluent.io/v1beta1",
          "kind": "SchemaRegistry",
          "metadata": {
            "name": "schemaregistry"
          },
          "spec": {
            "image": {
              "application": "confluentinc/cp-schema-registry@sha256:dabf016b86abb9ca7ab7f800ccdc0c18fdd80975da2195d90672e3e488ba0797",
              "init": "confluentinc/confluent-init-container@sha256:35c19bd2fd4300899a47bd06e66dc43569cba02e95286f9b9548a764de0e1001"
            },
            "replicas": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "disconnected"
        ],
        "valid_subscription": [
          "Confluent Platform License"
        ]
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/confluentinc/confluent-for-kubernetes-v2@sha256:aaaa7c9077f0d2f844c7b2943b50e880ef7ed501dacae91d68cd14e30902eb02",
      "bundle_path_digest": "sha256:aaaa7c9077f0d2f844c7b2943b50e880ef7ed501dacae91d68cd14e30902eb02",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "2.3",
      "creation_date": "2022-06-01T19:21:37.986000+00:00",
      "csv_description": "Confluent for Kubernetes (CFK) is a cloud-native control plane for deploying and managing Confluent in your private cloud environment. It provides standard and simple interface to customize, deploy, and manage Confluent Platform through declarative API.\nConfluent for Kubernetes runs on Kubernetes, the runtime for private cloud architectures.",
      "csv_display_name": "Confluent for Kubernetes",
      "csv_metadata_description": "",
      "csv_name": "confluent-for-kubernetes.v2.3.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-01T19:21:37.986000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "confluent-for-kubernetes",
      "provided_apis": [
        {
          "group": "platform.confluent.io",
          "kind": "Kafka",
          "plural": "kafkas",
          "version": "v1beta1"
        },
        {
          "group": "platform.confluent.io",
          "kind": "Connect",
          "plural": "connects",
          "version": "v1beta1"
        },
        {
          "group": "platform.confluent.io",
          "kind": "KafkaRestClass",
          "plural": "kafkarestclasses",
          "version": "v1beta1"
        },
        {
          "group": "platform.confluent.io",
          "kind": "Zookeeper",
          "plural": "zookeepers",
          "version": "v1beta1"
        },
        {
          "group": "platform.confluent.io",
          "kind": "SchemaRegistry",
          "plural": "schemaregistries",
          "version": "v1beta1"
        },
        {
          "group": "platform.confluent.io",
          "kind": "KafkaRestProxy",
          "plural": "kafkarestproxies",
          "version": "v1beta1"
        },
        {
          "group": "platform.confluent.io",
          "kind": "ConfluentRolebinding",
          "plural": "confluentrolebindings",
          "version": "v1beta1"
        },
        {
          "group": "platform.confluent.io",
          "kind": "ControlCenter",
          "plural": "controlcenters",
          "version": "v1beta1"
        },
        {
          "group": "platform.confluent.io",
          "kind": "KafkaTopic",
          "plural": "kafkatopics",
          "version": "v1beta1"
        },
        {
          "group": "platform.confluent.io",
          "kind": "MigrationJob",
          "plural": "migrationjobs",
          "version": "v1beta1"
        },
        {
          "group": "platform.confluent.io",
          "kind": "KsqlDB",
          "plural": "ksqldbs",
          "version": "v1beta1"
        },
        {
          "group": "platform.confluent.io",
          "kind": "Connector",
          "plural": "connectors",
          "version": "v1beta1"
        },
        {
          "group": "platform.confluent.io",
          "kind": "Schema",
          "plural": "schemas",
          "version": "v1beta1"
        },
        {
          "group": "platform.confluent.io",
          "kind": "ClusterLink",
          "plural": "clusterlinks",
          "version": "v1beta1"
        },
        {
          "group": "platform.confluent.io",
          "kind": "SchemaExporter",
          "plural": "schemaexporters",
          "version": "v1beta1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:236c01102003982ac70b8f7b101f73de1a049f1900c266fd2986d4f6d4c47ec5",
          "image": "docker.io/confluentinc/confluent-operator@sha256:236c01102003982ac70b8f7b101f73de1a049f1900c266fd2986d4f6d4c47ec5",
          "name": "confluent-operator"
        },
        {
          "digest": "sha256:35c19bd2fd4300899a47bd06e66dc43569cba02e95286f9b9548a764de0e1001",
          "image": "docker.io/confluentinc/confluent-init-container@sha256:35c19bd2fd4300899a47bd06e66dc43569cba02e95286f9b9548a764de0e1001",
          "name": "confluent-init-container"
        },
        {
          "digest": "sha256:f80df50ad358773df08657bace7980dd89c97cfc518141ed1ebffe88ce610ef4",
          "image": "docker.io/confluentinc/cp-zookeeper@sha256:f80df50ad358773df08657bace7980dd89c97cfc518141ed1ebffe88ce610ef4",
          "name": "cp-zookeeper"
        },
        {
          "digest": "sha256:bbc1493e52991094cde2c94ad334d6fbbf413e87fa5f203e942f6bcc0d488ffd",
          "image": "docker.io/confluentinc/cp-server@sha256:bbc1493e52991094cde2c94ad334d6fbbf413e87fa5f203e942f6bcc0d488ffd",
          "name": "cp-server"
        },
        {
          "digest": "sha256:d380a9e0dbb456f95e70b7d6c56cca02d4734b1d0fde8fbe2a053c3e6d44e16d",
          "image": "docker.io/confluentinc/cp-kafka-rest@sha256:d380a9e0dbb456f95e70b7d6c56cca02d4734b1d0fde8fbe2a053c3e6d44e16d",
          "name": "cp-kafka-rest"
        },
        {
          "digest": "sha256:951af16f6249a3bc3909420bf0abe78a7d5d853f4aa4eaf66665e1a6b2676af2",
          "image": "docker.io/confluentinc/cp-ksqldb-server@sha256:951af16f6249a3bc3909420bf0abe78a7d5d853f4aa4eaf66665e1a6b2676af2",
          "name": "cp-ksqldb-server"
        },
        {
          "digest": "sha256:dabf016b86abb9ca7ab7f800ccdc0c18fdd80975da2195d90672e3e488ba0797",
          "image": "docker.io/confluentinc/cp-schema-registry@sha256:dabf016b86abb9ca7ab7f800ccdc0c18fdd80975da2195d90672e3e488ba0797",
          "name": "cp-schema-registry"
        },
        {
          "digest": "sha256:7da14f9d34b48bed11cb307a4a080d2055a18d5acc95f5bcc31b7feac0e0395e",
          "image": "docker.io/confluentinc/cp-server-connect@sha256:7da14f9d34b48bed11cb307a4a080d2055a18d5acc95f5bcc31b7feac0e0395e",
          "name": "cp-server-connect"
        },
        {
          "digest": "sha256:ef89f3bc2656c215a80dd202958bbfd1f843297574dff5a537590d1733aaf38a",
          "image": "docker.io/confluentinc/cp-enterprise-control-center@sha256:ef89f3bc2656c215a80dd202958bbfd1f843297574dff5a537590d1733aaf38a",
          "name": "cp-enterprise-control-center"
        },
        {
          "digest": "sha256:236c01102003982ac70b8f7b101f73de1a049f1900c266fd2986d4f6d4c47ec5",
          "image": "docker.io/confluentinc/confluent-operator@sha256:236c01102003982ac70b8f7b101f73de1a049f1900c266fd2986d4f6d4c47ec5",
          "name": "confluent-operator-236c01102003982ac70b8f7b101f73de1a049f1900c266fd2986d4f6d4c47ec5-annotation"
        }
      ],
      "replaces": "",
      "skip_range": ">=2.2.0 <2.3.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "2.3.0",
      "version_original": "2.3.0"
    },
    {
      "_id": "6297e3edefe144fd5e93017b",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.5.3"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:de272015802808cfe5784f1d1326ccce008179d35f39793bb4a6b92d914bf72f",
      "bundle_path_digest": "sha256:de272015802808cfe5784f1d1326ccce008179d35f39793bb4a6b92d914bf72f",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-01T22:10:53.695000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.10.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:12:05.117000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "name": "t8c-operator-5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6-annotation"
        },
        {
          "digest": "sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "name": "t8c-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "42.10.0",
      "version_original": "42.10.0"
    },
    {
      "_id": "6297e468e0c0938179ef28a9",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.5.3"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:de272015802808cfe5784f1d1326ccce008179d35f39793bb4a6b92d914bf72f",
      "bundle_path_digest": "sha256:de272015802808cfe5784f1d1326ccce008179d35f39793bb4a6b92d914bf72f",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-01T22:12:56.533000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.10.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:11:49.953000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "name": "t8c-operator-5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6-annotation"
        },
        {
          "digest": "sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "name": "t8c-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "42.10.0",
      "version_original": "42.10.0"
    },
    {
      "_id": "6297e70e554afbde4c9b7c23",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.5.3"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:de272015802808cfe5784f1d1326ccce008179d35f39793bb4a6b92d914bf72f",
      "bundle_path_digest": "sha256:de272015802808cfe5784f1d1326ccce008179d35f39793bb4a6b92d914bf72f",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-01T22:24:14.370000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.10.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:31:34.976000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "name": "t8c-operator-5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6-annotation"
        },
        {
          "digest": "sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "name": "t8c-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "42.10.0",
      "version_original": "42.10.0"
    },
    {
      "_id": "6297e72f554afbde4c9b7c29",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.5.3"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:de272015802808cfe5784f1d1326ccce008179d35f39793bb4a6b92d914bf72f",
      "bundle_path_digest": "sha256:de272015802808cfe5784f1d1326ccce008179d35f39793bb4a6b92d914bf72f",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-01T22:24:47.082000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.10.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T12:55:32.358000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "name": "t8c-operator-5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6-annotation"
        },
        {
          "digest": "sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "name": "t8c-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "42.10.0",
      "version_original": "42.10.0"
    },
    {
      "_id": "6297eb11554afbde4c9b7d77",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.5.3"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:de272015802808cfe5784f1d1326ccce008179d35f39793bb4a6b92d914bf72f",
      "bundle_path_digest": "sha256:de272015802808cfe5784f1d1326ccce008179d35f39793bb4a6b92d914bf72f",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-01T22:41:21.457000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.10.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:36:19.181000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "name": "t8c-operator-5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6-annotation"
        },
        {
          "digest": "sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "name": "t8c-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "42.10.0",
      "version_original": "42.10.0"
    },
    {
      "_id": "62982cc9554afbde4c9b931f",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:5884d075419f55d2df891c5efaf1613daf29a7998838deb916c5b599af4170c2",
      "bundle_path_digest": "sha256:5884d075419f55d2df891c5efaf1613daf29a7998838deb916c5b599af4170c2",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-02T03:21:45.111000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.5.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:18:39.941000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator-e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47-annotation"
        },
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:ef6e5f17c31eb5828b29751591778650c397d89b8de1960b215b34cd2e41810a",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:ef6e5f17c31eb5828b29751591778650c397d89b8de1960b215b34cd2e41810a",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "8.5.4",
      "version_original": "8.5.4"
    },
    {
      "_id": "62982cca8c1a626fc9ae9740",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.5.3"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:de272015802808cfe5784f1d1326ccce008179d35f39793bb4a6b92d914bf72f",
      "bundle_path_digest": "sha256:de272015802808cfe5784f1d1326ccce008179d35f39793bb4a6b92d914bf72f",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-02T03:21:46.005000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.10.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:24:22.986000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "name": "t8c-operator-5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6-annotation"
        },
        {
          "digest": "sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "name": "t8c-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "42.10.0",
      "version_original": "42.10.0"
    },
    {
      "_id": "62982cd48c1a626fc9ae9749",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:5884d075419f55d2df891c5efaf1613daf29a7998838deb916c5b599af4170c2",
      "bundle_path_digest": "sha256:5884d075419f55d2df891c5efaf1613daf29a7998838deb916c5b599af4170c2",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-02T03:21:56.485000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.5.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:03:42.609000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator-e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47-annotation"
        },
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:ef6e5f17c31eb5828b29751591778650c397d89b8de1960b215b34cd2e41810a",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:ef6e5f17c31eb5828b29751591778650c397d89b8de1960b215b34cd2e41810a",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "8.5.4",
      "version_original": "8.5.4"
    },
    {
      "_id": "62982d74554afbde4c9b9388",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:5884d075419f55d2df891c5efaf1613daf29a7998838deb916c5b599af4170c2",
      "bundle_path_digest": "sha256:5884d075419f55d2df891c5efaf1613daf29a7998838deb916c5b599af4170c2",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-02T03:24:36.584000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.5.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:02:02.462000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator-e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47-annotation"
        },
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:ef6e5f17c31eb5828b29751591778650c397d89b8de1960b215b34cd2e41810a",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:ef6e5f17c31eb5828b29751591778650c397d89b8de1960b215b34cd2e41810a",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "8.5.4",
      "version_original": "8.5.4"
    },
    {
      "_id": "62982d9d8c1a626fc9ae97b9",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:5884d075419f55d2df891c5efaf1613daf29a7998838deb916c5b599af4170c2",
      "bundle_path_digest": "sha256:5884d075419f55d2df891c5efaf1613daf29a7998838deb916c5b599af4170c2",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-02T03:25:17.647000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.5.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:05:31.996000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator-e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47-annotation"
        },
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:ef6e5f17c31eb5828b29751591778650c397d89b8de1960b215b34cd2e41810a",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:ef6e5f17c31eb5828b29751591778650c397d89b8de1960b215b34cd2e41810a",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "8.5.4",
      "version_original": "8.5.4"
    },
    {
      "_id": "62982db58c1a626fc9ae97c6",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:5884d075419f55d2df891c5efaf1613daf29a7998838deb916c5b599af4170c2",
      "bundle_path_digest": "sha256:5884d075419f55d2df891c5efaf1613daf29a7998838deb916c5b599af4170c2",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-02T03:25:41.377000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.5.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T12:57:27.837000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator-e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47-annotation"
        },
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:ef6e5f17c31eb5828b29751591778650c397d89b8de1960b215b34cd2e41810a",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:ef6e5f17c31eb5828b29751591778650c397d89b8de1960b215b34cd2e41810a",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "8.5.4",
      "version_original": "8.5.4"
    },
    {
      "_id": "629830e0e0c0938179ef42a9",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:5884d075419f55d2df891c5efaf1613daf29a7998838deb916c5b599af4170c2",
      "bundle_path_digest": "sha256:5884d075419f55d2df891c5efaf1613daf29a7998838deb916c5b599af4170c2",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-02T03:39:12.098000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.5.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T12:55:42.794000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator-e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47-annotation"
        },
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:ef6e5f17c31eb5828b29751591778650c397d89b8de1960b215b34cd2e41810a",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:ef6e5f17c31eb5828b29751591778650c397d89b8de1960b215b34cd2e41810a",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "8.5.4",
      "version_original": "8.5.4"
    },
    {
      "_id": "629852008c1a626fc9aea927",
      "alm_examples": [
        {
          "api_version": "ibm.com/v1",
          "kind": "IBMSecurityVerify",
          "metadata": {
            "name": "ibmsecurityverify-sample"
          },
          "spec": {
            "clientSecret": "--secret--",
            "sessionLifetime": 3600,
            "ssoPath": "/verify-sso"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/verify-operator-bundle@sha256:0deef311d65c60bedc0af39fb6dfde09b0b1a60825eaa37188b21b5a692397e9",
      "bundle_path_digest": "sha256:0deef311d65c60bedc0af39fb6dfde09b0b1a60825eaa37188b21b5a692397e9",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-02T06:00:32.638000+00:00",
      "csv_description": "[IBM Security Verify](https://www.ibm.com/products/verify-saas) is an Identity-as-a-Service platform that allows IT, security and business leaders to protect their digital users, assets and data in a hybrid, multi-cloud world by enabling technical agility and operational efficiency. IBM Security Verify SaaS provides single sign-on (SSO), multi-factor authentication (MFA), AI-powered context for risk-based authentication for adaptive access decisions, user management, access recertification campaigns and identity analytics.\n\nAs part of using Red Hat OpenShift, you are entitled to Verify SaaS SSO for unlimited apps and users.  If you do not already have a Verify SaaS SSO tenant a new one can be [created](https://www.ibm.com/account/reg/us-en/signup?formid=urx-51255).\n\nFor a detailed description of IBM Security Verify refer to the [Official documentation](https://www.ibm.com/docs/en/security-verify).\n\nThe IBM Security Verify operator can consistently enforce policy-driven security by using the Ingress networking capability of OpenShift in conjunction with the [Nginx Ingress operator](https://www.nginx.com/blog/getting-started-nginx-ingress-operator-red-hat-openshift/). With this approach, you can enforce authentication and authorization policies for all of the applications in your cluster at the same time, without ever changing your application code. You can also dynamically register your application to start protecting them centrally from the cloud via Verify SaaS. \n\nSee the project [Readme](https://github.com/IBM-Security/verify-operator/blob/master/README.md) for further information and details.\n\n",
      "csv_display_name": "IBM Security Verify Operator",
      "csv_metadata_description": "The IBM Security Verify operator can consistently enforce policy-driven security, including authentication and authorization, using the Ingress networking capability of OpenShift.",
      "csv_name": "ibm-security-verify-operator.v22.6.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:12:20.158000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "ibm-security-verify-operator",
      "provided_apis": [
        {
          "group": "ibm.com",
          "kind": "IBMSecurityVerify",
          "version": "v1"
        }
      ],
      "provider": "IBM",
      "related_images": [
        {
          "digest": "sha256:3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a",
          "image": "ibmcom/verify-operator@sha256:3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a",
          "name": "verify-operator-3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a-annotation"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a",
          "image": "ibmcom/verify-operator@sha256:3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "22.6.0",
      "version_original": "22.6.0"
    },
    {
      "_id": "62985302e0c0938179ef5250",
      "alm_examples": [
        {
          "api_version": "ibm.com/v1",
          "kind": "IBMSecurityVerify",
          "metadata": {
            "name": "ibmsecurityverify-sample"
          },
          "spec": {
            "clientSecret": "--secret--",
            "sessionLifetime": 3600,
            "ssoPath": "/verify-sso"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/verify-operator-bundle@sha256:0deef311d65c60bedc0af39fb6dfde09b0b1a60825eaa37188b21b5a692397e9",
      "bundle_path_digest": "sha256:0deef311d65c60bedc0af39fb6dfde09b0b1a60825eaa37188b21b5a692397e9",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-02T06:04:50.609000+00:00",
      "csv_description": "[IBM Security Verify](https://www.ibm.com/products/verify-saas) is an Identity-as-a-Service platform that allows IT, security and business leaders to protect their digital users, assets and data in a hybrid, multi-cloud world by enabling technical agility and operational efficiency. IBM Security Verify SaaS provides single sign-on (SSO), multi-factor authentication (MFA), AI-powered context for risk-based authentication for adaptive access decisions, user management, access recertification campaigns and identity analytics.\n\nAs part of using Red Hat OpenShift, you are entitled to Verify SaaS SSO for unlimited apps and users.  If you do not already have a Verify SaaS SSO tenant a new one can be [created](https://www.ibm.com/account/reg/us-en/signup?formid=urx-51255).\n\nFor a detailed description of IBM Security Verify refer to the [Official documentation](https://www.ibm.com/docs/en/security-verify).\n\nThe IBM Security Verify operator can consistently enforce policy-driven security by using the Ingress networking capability of OpenShift in conjunction with the [Nginx Ingress operator](https://www.nginx.com/blog/getting-started-nginx-ingress-operator-red-hat-openshift/). With this approach, you can enforce authentication and authorization policies for all of the applications in your cluster at the same time, without ever changing your application code. You can also dynamically register your application to start protecting them centrally from the cloud via Verify SaaS. \n\nSee the project [Readme](https://github.com/IBM-Security/verify-operator/blob/master/README.md) for further information and details.\n\n",
      "csv_display_name": "IBM Security Verify Operator",
      "csv_metadata_description": "The IBM Security Verify operator can consistently enforce policy-driven security, including authentication and authorization, using the Ingress networking capability of OpenShift.",
      "csv_name": "ibm-security-verify-operator.v22.6.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:05:18.696000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "ibm-security-verify-operator",
      "provided_apis": [
        {
          "group": "ibm.com",
          "kind": "IBMSecurityVerify",
          "plural": "ibmsecurityverifies",
          "version": "v1"
        }
      ],
      "provider": "IBM",
      "related_images": [
        {
          "digest": "sha256:3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a",
          "image": "ibmcom/verify-operator@sha256:3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a",
          "name": "verify-operator-3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a-annotation"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a",
          "image": "ibmcom/verify-operator@sha256:3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "22.6.0",
      "version_original": "22.6.0"
    },
    {
      "_id": "629853798c1a626fc9aea9ca",
      "alm_examples": [
        {
          "api_version": "ibm.com/v1",
          "kind": "IBMSecurityVerify",
          "metadata": {
            "name": "ibmsecurityverify-sample"
          },
          "spec": {
            "clientSecret": "--secret--",
            "sessionLifetime": 3600,
            "ssoPath": "/verify-sso"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/verify-operator-bundle@sha256:0deef311d65c60bedc0af39fb6dfde09b0b1a60825eaa37188b21b5a692397e9",
      "bundle_path_digest": "sha256:0deef311d65c60bedc0af39fb6dfde09b0b1a60825eaa37188b21b5a692397e9",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-02T06:06:49.849000+00:00",
      "csv_description": "[IBM Security Verify](https://www.ibm.com/products/verify-saas) is an Identity-as-a-Service platform that allows IT, security and business leaders to protect their digital users, assets and data in a hybrid, multi-cloud world by enabling technical agility and operational efficiency. IBM Security Verify SaaS provides single sign-on (SSO), multi-factor authentication (MFA), AI-powered context for risk-based authentication for adaptive access decisions, user management, access recertification campaigns and identity analytics.\n\nAs part of using Red Hat OpenShift, you are entitled to Verify SaaS SSO for unlimited apps and users.  If you do not already have a Verify SaaS SSO tenant a new one can be [created](https://www.ibm.com/account/reg/us-en/signup?formid=urx-51255).\n\nFor a detailed description of IBM Security Verify refer to the [Official documentation](https://www.ibm.com/docs/en/security-verify).\n\nThe IBM Security Verify operator can consistently enforce policy-driven security by using the Ingress networking capability of OpenShift in conjunction with the [Nginx Ingress operator](https://www.nginx.com/blog/getting-started-nginx-ingress-operator-red-hat-openshift/). With this approach, you can enforce authentication and authorization policies for all of the applications in your cluster at the same time, without ever changing your application code. You can also dynamically register your application to start protecting them centrally from the cloud via Verify SaaS. \n\nSee the project [Readme](https://github.com/IBM-Security/verify-operator/blob/master/README.md) for further information and details.\n\n",
      "csv_display_name": "IBM Security Verify Operator",
      "csv_metadata_description": "The IBM Security Verify operator can consistently enforce policy-driven security, including authentication and authorization, using the Ingress networking capability of OpenShift.",
      "csv_name": "ibm-security-verify-operator.v22.6.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:00:26.762000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "ibm-security-verify-operator",
      "provided_apis": [
        {
          "group": "ibm.com",
          "kind": "IBMSecurityVerify",
          "plural": "ibmsecurityverifies",
          "version": "v1"
        }
      ],
      "provider": "IBM",
      "related_images": [
        {
          "digest": "sha256:3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a",
          "image": "ibmcom/verify-operator@sha256:3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a",
          "name": "verify-operator-3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a-annotation"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a",
          "image": "ibmcom/verify-operator@sha256:3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "22.6.0",
      "version_original": "22.6.0"
    },
    {
      "_id": "629853978c1a626fc9aea9e3",
      "alm_examples": [
        {
          "api_version": "ibm.com/v1",
          "kind": "IBMSecurityVerify",
          "metadata": {
            "name": "ibmsecurityverify-sample"
          },
          "spec": {
            "clientSecret": "--secret--",
            "sessionLifetime": 3600,
            "ssoPath": "/verify-sso"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/verify-operator-bundle@sha256:0deef311d65c60bedc0af39fb6dfde09b0b1a60825eaa37188b21b5a692397e9",
      "bundle_path_digest": "sha256:0deef311d65c60bedc0af39fb6dfde09b0b1a60825eaa37188b21b5a692397e9",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-02T06:07:19.578000+00:00",
      "csv_description": "[IBM Security Verify](https://www.ibm.com/products/verify-saas) is an Identity-as-a-Service platform that allows IT, security and business leaders to protect their digital users, assets and data in a hybrid, multi-cloud world by enabling technical agility and operational efficiency. IBM Security Verify SaaS provides single sign-on (SSO), multi-factor authentication (MFA), AI-powered context for risk-based authentication for adaptive access decisions, user management, access recertification campaigns and identity analytics.\n\nAs part of using Red Hat OpenShift, you are entitled to Verify SaaS SSO for unlimited apps and users.  If you do not already have a Verify SaaS SSO tenant a new one can be [created](https://www.ibm.com/account/reg/us-en/signup?formid=urx-51255).\n\nFor a detailed description of IBM Security Verify refer to the [Official documentation](https://www.ibm.com/docs/en/security-verify).\n\nThe IBM Security Verify operator can consistently enforce policy-driven security by using the Ingress networking capability of OpenShift in conjunction with the [Nginx Ingress operator](https://www.nginx.com/blog/getting-started-nginx-ingress-operator-red-hat-openshift/). With this approach, you can enforce authentication and authorization policies for all of the applications in your cluster at the same time, without ever changing your application code. You can also dynamically register your application to start protecting them centrally from the cloud via Verify SaaS. \n\nSee the project [Readme](https://github.com/IBM-Security/verify-operator/blob/master/README.md) for further information and details.\n\n",
      "csv_display_name": "IBM Security Verify Operator",
      "csv_metadata_description": "The IBM Security Verify operator can consistently enforce policy-driven security, including authentication and authorization, using the Ingress networking capability of OpenShift.",
      "csv_name": "ibm-security-verify-operator.v22.6.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T12:58:23.781000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "ibm-security-verify-operator",
      "provided_apis": [
        {
          "group": "ibm.com",
          "kind": "IBMSecurityVerify",
          "plural": "ibmsecurityverifies",
          "version": "v1"
        }
      ],
      "provider": "IBM",
      "related_images": [
        {
          "digest": "sha256:3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a",
          "image": "ibmcom/verify-operator@sha256:3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a",
          "name": "verify-operator-3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a-annotation"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a",
          "image": "ibmcom/verify-operator@sha256:3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "22.6.0",
      "version_original": "22.6.0"
    },
    {
      "_id": "62987f20554afbde4c9bb236",
      "alm_examples": [
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupPolicy",
          "metadata": {
            "name": "atlasbackuppolicy-sample"
          },
          "spec": {
            "id": "1",
            "items": [
              {
                "frequencyInterval": 6,
                "frequencyType": "WEEKLY",
                "id": "2",
                "retentionUnit": "DAYS",
                "retentionValue": 6
              }
            ]
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupSchedule",
          "metadata": {
            "name": "atlasbackupschedule-sample"
          },
          "spec": {
            "autoExportEnabled": true,
            "policies": [
              {
                "name": "atlas-default-backuppolicy",
                "namespace": "mongodb-atlas-system"
              },
              {
                "name": "atlas-default-backuppolicy2",
                "namespace": "mongodb-atlas-system"
              }
            ],
            "referenceHourOfDay": 10,
            "referenceMinuteOfHour": 10,
            "restoreWindowDays": 2
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDatabaseUser",
          "metadata": {
            "name": "my-database-user"
          },
          "spec": {
            "databaseName": "admin",
            "passwordSecretRef": {
              "name": "my-database-user-password"
            },
            "projectRef": {
              "name": "my-project"
            },
            "roles": [
              {
                "databaseName": "admin",
                "roleName": "readWriteAnyDatabase"
              }
            ],
            "username": "david"
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDeployment",
          "metadata": {
            "name": "my-atlas-cluster"
          },
          "spec": {
            "deploymentSpec": {
              "name": "test-cluster",
              "providerSettings": {
                "instanceSizeName": "M10",
                "providerName": "AWS",
                "regionName": "US_EAST_1"
              }
            },
            "projectRef": {
              "name": "my-project"
            }
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasProject",
          "metadata": {
            "name": "my-project"
          },
          "spec": {
            "name": "Test Atlas Operator Project",
            "projectIpAccessList": [
              {
                "comment": "IP address for Application Server A",
                "ipAddress": "192.0.2.15"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator-bundle@sha256:2338eaab863304250b3b1d267e9f2261c48eef1f97c280b7fa0af0ebc3ba208b",
      "bundle_path_digest": "sha256:2338eaab863304250b3b1d267e9f2261c48eef1f97c280b7fa0af0ebc3ba208b",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-06-02T09:13:04.328000+00:00",
      "csv_description": "The MongoDB Atlas Operator provides a native integration between the Kubernetes orchestration platform and MongoDB Atlas \u2014\nthe only multi-cloud document database service that gives you the versatility you need to build sophisticated and resilient applications that can adapt to changing customer demands and market trends.\n\n> Current Status: *Beta*. The Operator gives users the ability to provision\n> Atlas projects, clusters and database users using Kubernetes Specifications and bind connection information\n> into applications deployed to Kubernetes.\n\n## Quick Start guide\n### Step 1. Deploy Kubernetes operator by clicking Install button.\n\n### Step 2. Create Atlas Cluster\n\n**1.** Create an Atlas API Key Secret\nIn order to work with the Atlas Operator you need to provide [authentication information](https://docs.atlas.mongodb.com/configure-api-access)\n to allow the Atlas Operator to communicate with Atlas API. Once you have generated a Public and Private key in Atlas, you can create a Kuberentes Secret with:\n```\nkubectl create secret generic mongodb-atlas-operator-api-key \\\n         --from-literal=\"orgId=<the_atlas_organization_id>\" \\\n         --from-literal=\"publicApiKey=<the_atlas_api_public_key>\" \\\n         --from-literal=\"privateApiKey=<the_atlas_api_private_key>\" \\\n         -n openshift-operators\n```\n(Note, that you should use the namespace where the Operator was installed - it's `openshift-operators` by default)\n\n**2.** Create an `AtlasProject` Custom Resource\n\nThe `AtlasProject` CustomResource represents Atlas Projects in our Kubernetes cluster. You need to specify\n`projectIpAccessList` with the IP addresses or CIDR blocks of any hosts that will connect to the Atlas Cluster.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\nspec:\n  name: Test Atlas Operator Project\n  projectIpAccessList:\n    - ipAddress: \"192.0.2.15\"\n      comment: \"IP address for Application Server A\"\n    - ipAddress: \"203.0.113.0/24\"\n      comment: \"CIDR block for Application Server B - D\"\n```\n**3.** Create an `AtlasDeployment` Custom Resource.\nThe example below is a minimal configuration to create an M10 Atlas cluster in the AWS US East region. For a full list of properties, check\n`atlasclusters.atlas.mongodb.com` [CRD specification](config/crd/bases/atlas.mongodb.com_atlasclusters.yaml)):\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: my-atlas-cluster\nspec:\n  name: \"Test-cluster\"\n  projectRef:\n    name: my-project\n  providerSettings:\n    instanceSizeName: M10\n    providerName: AWS\n    regionName: US_EAST_1\n```\n\n**4.** Create a database user password Kubernetes Secret\nThe Secret must be created in the same namespace as the `AtlasDeployment` and `AtlasProject` were created.\n```\nkubectl create secret generic the-user-password --from-literal=\"password=P@@sword%\"\n```\n\n**5.** Create an `AtlasDatabaseUser` Custom Resource\n\nIn order to connect to an Atlas Cluster the database user needs to be created. `AtlasDatabaseUser` resource should reference\nthe password Kubernetes Secret created in the previous step.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDatabaseUser\nmetadata:\n  name: my-database-user\nspec:\n  roles:\n    - roleName: \"readWriteAnyDatabase\"\n      databaseName: \"admin\"\n  projectRef:\n    name: my-project\n  username: theuser\n  passwordSecretRef:\n    name: the-user-password\n```\n**6.** Wait for the `AtlasDatabaseUser` Custom Resource to be ready\n\nWait until the AtlasDatabaseUser resource gets to \"ready\" status (it will wait until the cluster is created that may take around 10 minutes):\n```\nkubectl get atlasdatabaseusers my-database-user -o=jsonpath='{.status.conditions[?(@.type==\"Ready\")].status}'\nTrue\n```\n### Step 3. Connect your application to the Atlas Cluster\n\nThe Atlas Operator will create a Kubernetes Secret with the information necessary to connect to the Atlas Cluster created\nin the previous step. An application in the same Kubernetes Cluster can mount and use the Secret:\n\n```\n...\ncontainers:\n      - name: test-app\n        env:\n         - name: \"CONNECTION_STRING\"\n           valueFrom:\n             secretKeyRef:\n               name: test-atlas-operator-project-test-cluster-theuser\n               key: connectionStringStandardSrv\n\n```\n",
      "csv_display_name": "MongoDB Atlas Operator",
      "csv_metadata_description": "The MongoDB Atlas Kubernetes Operator enables easy management of Clusters in MongoDB Atlas",
      "csv_name": "mongodb-atlas-kubernetes.v1.0.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:27:21.001000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "mongodb-atlas-kubernetes",
      "provided_apis": [
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupPolicy",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupSchedule",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDatabaseUser",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDeployment",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasProject",
          "version": "v1"
        }
      ],
      "provider": "MongoDB, Inc",
      "related_images": [
        {
          "digest": "sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "name": "mongodb-atlas-kubernetes-operator-3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3-annotation"
        },
        {
          "digest": "sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.0.0",
      "version_original": "1.0.0"
    },
    {
      "_id": "629881448c1a626fc9aeb790",
      "alm_examples": [
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupPolicy",
          "metadata": {
            "name": "atlasbackuppolicy-sample"
          },
          "spec": {
            "id": "1",
            "items": [
              {
                "frequencyInterval": 6,
                "frequencyType": "WEEKLY",
                "id": "2",
                "retentionUnit": "DAYS",
                "retentionValue": 6
              }
            ]
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupSchedule",
          "metadata": {
            "name": "atlasbackupschedule-sample"
          },
          "spec": {
            "autoExportEnabled": true,
            "policies": [
              {
                "name": "atlas-default-backuppolicy",
                "namespace": "mongodb-atlas-system"
              },
              {
                "name": "atlas-default-backuppolicy2",
                "namespace": "mongodb-atlas-system"
              }
            ],
            "referenceHourOfDay": 10,
            "referenceMinuteOfHour": 10,
            "restoreWindowDays": 2
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDatabaseUser",
          "metadata": {
            "name": "my-database-user"
          },
          "spec": {
            "databaseName": "admin",
            "passwordSecretRef": {
              "name": "my-database-user-password"
            },
            "projectRef": {
              "name": "my-project"
            },
            "roles": [
              {
                "databaseName": "admin",
                "roleName": "readWriteAnyDatabase"
              }
            ],
            "username": "david"
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDeployment",
          "metadata": {
            "name": "my-atlas-cluster"
          },
          "spec": {
            "deploymentSpec": {
              "name": "test-cluster",
              "providerSettings": {
                "instanceSizeName": "M10",
                "providerName": "AWS",
                "regionName": "US_EAST_1"
              }
            },
            "projectRef": {
              "name": "my-project"
            }
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasProject",
          "metadata": {
            "name": "my-project"
          },
          "spec": {
            "name": "Test Atlas Operator Project",
            "projectIpAccessList": [
              {
                "comment": "IP address for Application Server A",
                "ipAddress": "192.0.2.15"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator-bundle@sha256:2338eaab863304250b3b1d267e9f2261c48eef1f97c280b7fa0af0ebc3ba208b",
      "bundle_path_digest": "sha256:2338eaab863304250b3b1d267e9f2261c48eef1f97c280b7fa0af0ebc3ba208b",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-06-02T09:22:12.298000+00:00",
      "csv_description": "The MongoDB Atlas Operator provides a native integration between the Kubernetes orchestration platform and MongoDB Atlas \u2014\nthe only multi-cloud document database service that gives you the versatility you need to build sophisticated and resilient applications that can adapt to changing customer demands and market trends.\n\n> Current Status: *Beta*. The Operator gives users the ability to provision\n> Atlas projects, clusters and database users using Kubernetes Specifications and bind connection information\n> into applications deployed to Kubernetes.\n\n## Quick Start guide\n### Step 1. Deploy Kubernetes operator by clicking Install button.\n\n### Step 2. Create Atlas Cluster\n\n**1.** Create an Atlas API Key Secret\nIn order to work with the Atlas Operator you need to provide [authentication information](https://docs.atlas.mongodb.com/configure-api-access)\n to allow the Atlas Operator to communicate with Atlas API. Once you have generated a Public and Private key in Atlas, you can create a Kuberentes Secret with:\n```\nkubectl create secret generic mongodb-atlas-operator-api-key \\\n         --from-literal=\"orgId=<the_atlas_organization_id>\" \\\n         --from-literal=\"publicApiKey=<the_atlas_api_public_key>\" \\\n         --from-literal=\"privateApiKey=<the_atlas_api_private_key>\" \\\n         -n openshift-operators\n```\n(Note, that you should use the namespace where the Operator was installed - it's `openshift-operators` by default)\n\n**2.** Create an `AtlasProject` Custom Resource\n\nThe `AtlasProject` CustomResource represents Atlas Projects in our Kubernetes cluster. You need to specify\n`projectIpAccessList` with the IP addresses or CIDR blocks of any hosts that will connect to the Atlas Cluster.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\nspec:\n  name: Test Atlas Operator Project\n  projectIpAccessList:\n    - ipAddress: \"192.0.2.15\"\n      comment: \"IP address for Application Server A\"\n    - ipAddress: \"203.0.113.0/24\"\n      comment: \"CIDR block for Application Server B - D\"\n```\n**3.** Create an `AtlasDeployment` Custom Resource.\nThe example below is a minimal configuration to create an M10 Atlas cluster in the AWS US East region. For a full list of properties, check\n`atlasclusters.atlas.mongodb.com` [CRD specification](config/crd/bases/atlas.mongodb.com_atlasclusters.yaml)):\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: my-atlas-cluster\nspec:\n  name: \"Test-cluster\"\n  projectRef:\n    name: my-project\n  providerSettings:\n    instanceSizeName: M10\n    providerName: AWS\n    regionName: US_EAST_1\n```\n\n**4.** Create a database user password Kubernetes Secret\nThe Secret must be created in the same namespace as the `AtlasDeployment` and `AtlasProject` were created.\n```\nkubectl create secret generic the-user-password --from-literal=\"password=P@@sword%\"\n```\n\n**5.** Create an `AtlasDatabaseUser` Custom Resource\n\nIn order to connect to an Atlas Cluster the database user needs to be created. `AtlasDatabaseUser` resource should reference\nthe password Kubernetes Secret created in the previous step.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDatabaseUser\nmetadata:\n  name: my-database-user\nspec:\n  roles:\n    - roleName: \"readWriteAnyDatabase\"\n      databaseName: \"admin\"\n  projectRef:\n    name: my-project\n  username: theuser\n  passwordSecretRef:\n    name: the-user-password\n```\n**6.** Wait for the `AtlasDatabaseUser` Custom Resource to be ready\n\nWait until the AtlasDatabaseUser resource gets to \"ready\" status (it will wait until the cluster is created that may take around 10 minutes):\n```\nkubectl get atlasdatabaseusers my-database-user -o=jsonpath='{.status.conditions[?(@.type==\"Ready\")].status}'\nTrue\n```\n### Step 3. Connect your application to the Atlas Cluster\n\nThe Atlas Operator will create a Kubernetes Secret with the information necessary to connect to the Atlas Cluster created\nin the previous step. An application in the same Kubernetes Cluster can mount and use the Secret:\n\n```\n...\ncontainers:\n      - name: test-app\n        env:\n         - name: \"CONNECTION_STRING\"\n           valueFrom:\n             secretKeyRef:\n               name: test-atlas-operator-project-test-cluster-theuser\n               key: connectionStringStandardSrv\n\n```\n",
      "csv_display_name": "MongoDB Atlas Operator",
      "csv_metadata_description": "The MongoDB Atlas Kubernetes Operator enables easy management of Clusters in MongoDB Atlas",
      "csv_name": "mongodb-atlas-kubernetes.v1.0.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:03:07.063000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "mongodb-atlas-kubernetes",
      "provided_apis": [
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDatabaseUser",
          "plural": "atlasdatabaseusers",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDeployment",
          "plural": "atlasdeployments",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasProject",
          "plural": "atlasprojects",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupPolicy",
          "plural": "atlasbackuppolicies",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupSchedule",
          "plural": "atlasbackupschedules",
          "version": "v1"
        }
      ],
      "provider": "MongoDB, Inc",
      "related_images": [
        {
          "digest": "sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "name": "mongodb-atlas-kubernetes-operator-3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3-annotation"
        },
        {
          "digest": "sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.0.0",
      "version_original": "1.0.0"
    },
    {
      "_id": "6298820e554afbde4c9bb2f5",
      "alm_examples": [
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupPolicy",
          "metadata": {
            "name": "atlasbackuppolicy-sample"
          },
          "spec": {
            "id": "1",
            "items": [
              {
                "frequencyInterval": 6,
                "frequencyType": "WEEKLY",
                "id": "2",
                "retentionUnit": "DAYS",
                "retentionValue": 6
              }
            ]
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupSchedule",
          "metadata": {
            "name": "atlasbackupschedule-sample"
          },
          "spec": {
            "autoExportEnabled": true,
            "policies": [
              {
                "name": "atlas-default-backuppolicy",
                "namespace": "mongodb-atlas-system"
              },
              {
                "name": "atlas-default-backuppolicy2",
                "namespace": "mongodb-atlas-system"
              }
            ],
            "referenceHourOfDay": 10,
            "referenceMinuteOfHour": 10,
            "restoreWindowDays": 2
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDatabaseUser",
          "metadata": {
            "name": "my-database-user"
          },
          "spec": {
            "databaseName": "admin",
            "passwordSecretRef": {
              "name": "my-database-user-password"
            },
            "projectRef": {
              "name": "my-project"
            },
            "roles": [
              {
                "databaseName": "admin",
                "roleName": "readWriteAnyDatabase"
              }
            ],
            "username": "david"
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDeployment",
          "metadata": {
            "name": "my-atlas-cluster"
          },
          "spec": {
            "deploymentSpec": {
              "name": "test-cluster",
              "providerSettings": {
                "instanceSizeName": "M10",
                "providerName": "AWS",
                "regionName": "US_EAST_1"
              }
            },
            "projectRef": {
              "name": "my-project"
            }
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasProject",
          "metadata": {
            "name": "my-project"
          },
          "spec": {
            "name": "Test Atlas Operator Project",
            "projectIpAccessList": [
              {
                "comment": "IP address for Application Server A",
                "ipAddress": "192.0.2.15"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator-bundle@sha256:2338eaab863304250b3b1d267e9f2261c48eef1f97c280b7fa0af0ebc3ba208b",
      "bundle_path_digest": "sha256:2338eaab863304250b3b1d267e9f2261c48eef1f97c280b7fa0af0ebc3ba208b",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-06-02T09:25:34.292000+00:00",
      "csv_description": "The MongoDB Atlas Operator provides a native integration between the Kubernetes orchestration platform and MongoDB Atlas \u2014\nthe only multi-cloud document database service that gives you the versatility you need to build sophisticated and resilient applications that can adapt to changing customer demands and market trends.\n\n> Current Status: *Beta*. The Operator gives users the ability to provision\n> Atlas projects, clusters and database users using Kubernetes Specifications and bind connection information\n> into applications deployed to Kubernetes.\n\n## Quick Start guide\n### Step 1. Deploy Kubernetes operator by clicking Install button.\n\n### Step 2. Create Atlas Cluster\n\n**1.** Create an Atlas API Key Secret\nIn order to work with the Atlas Operator you need to provide [authentication information](https://docs.atlas.mongodb.com/configure-api-access)\n to allow the Atlas Operator to communicate with Atlas API. Once you have generated a Public and Private key in Atlas, you can create a Kuberentes Secret with:\n```\nkubectl create secret generic mongodb-atlas-operator-api-key \\\n         --from-literal=\"orgId=<the_atlas_organization_id>\" \\\n         --from-literal=\"publicApiKey=<the_atlas_api_public_key>\" \\\n         --from-literal=\"privateApiKey=<the_atlas_api_private_key>\" \\\n         -n openshift-operators\n```\n(Note, that you should use the namespace where the Operator was installed - it's `openshift-operators` by default)\n\n**2.** Create an `AtlasProject` Custom Resource\n\nThe `AtlasProject` CustomResource represents Atlas Projects in our Kubernetes cluster. You need to specify\n`projectIpAccessList` with the IP addresses or CIDR blocks of any hosts that will connect to the Atlas Cluster.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\nspec:\n  name: Test Atlas Operator Project\n  projectIpAccessList:\n    - ipAddress: \"192.0.2.15\"\n      comment: \"IP address for Application Server A\"\n    - ipAddress: \"203.0.113.0/24\"\n      comment: \"CIDR block for Application Server B - D\"\n```\n**3.** Create an `AtlasDeployment` Custom Resource.\nThe example below is a minimal configuration to create an M10 Atlas cluster in the AWS US East region. For a full list of properties, check\n`atlasclusters.atlas.mongodb.com` [CRD specification](config/crd/bases/atlas.mongodb.com_atlasclusters.yaml)):\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: my-atlas-cluster\nspec:\n  name: \"Test-cluster\"\n  projectRef:\n    name: my-project\n  providerSettings:\n    instanceSizeName: M10\n    providerName: AWS\n    regionName: US_EAST_1\n```\n\n**4.** Create a database user password Kubernetes Secret\nThe Secret must be created in the same namespace as the `AtlasDeployment` and `AtlasProject` were created.\n```\nkubectl create secret generic the-user-password --from-literal=\"password=P@@sword%\"\n```\n\n**5.** Create an `AtlasDatabaseUser` Custom Resource\n\nIn order to connect to an Atlas Cluster the database user needs to be created. `AtlasDatabaseUser` resource should reference\nthe password Kubernetes Secret created in the previous step.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDatabaseUser\nmetadata:\n  name: my-database-user\nspec:\n  roles:\n    - roleName: \"readWriteAnyDatabase\"\n      databaseName: \"admin\"\n  projectRef:\n    name: my-project\n  username: theuser\n  passwordSecretRef:\n    name: the-user-password\n```\n**6.** Wait for the `AtlasDatabaseUser` Custom Resource to be ready\n\nWait until the AtlasDatabaseUser resource gets to \"ready\" status (it will wait until the cluster is created that may take around 10 minutes):\n```\nkubectl get atlasdatabaseusers my-database-user -o=jsonpath='{.status.conditions[?(@.type==\"Ready\")].status}'\nTrue\n```\n### Step 3. Connect your application to the Atlas Cluster\n\nThe Atlas Operator will create a Kubernetes Secret with the information necessary to connect to the Atlas Cluster created\nin the previous step. An application in the same Kubernetes Cluster can mount and use the Secret:\n\n```\n...\ncontainers:\n      - name: test-app\n        env:\n         - name: \"CONNECTION_STRING\"\n           valueFrom:\n             secretKeyRef:\n               name: test-atlas-operator-project-test-cluster-theuser\n               key: connectionStringStandardSrv\n\n```\n",
      "csv_display_name": "MongoDB Atlas Operator",
      "csv_metadata_description": "The MongoDB Atlas Kubernetes Operator enables easy management of Clusters in MongoDB Atlas",
      "csv_name": "mongodb-atlas-kubernetes.v1.0.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:04:36.669000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "mongodb-atlas-kubernetes",
      "provided_apis": [
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupPolicy",
          "plural": "atlasbackuppolicies",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupSchedule",
          "plural": "atlasbackupschedules",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDatabaseUser",
          "plural": "atlasdatabaseusers",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDeployment",
          "plural": "atlasdeployments",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasProject",
          "plural": "atlasprojects",
          "version": "v1"
        }
      ],
      "provider": "MongoDB, Inc",
      "related_images": [
        {
          "digest": "sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "name": "mongodb-atlas-kubernetes-operator-3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3-annotation"
        },
        {
          "digest": "sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.0.0",
      "version_original": "1.0.0"
    },
    {
      "_id": "62988266efe144fd5e93396e",
      "alm_examples": [
        {
          "api_version": "ibm.com/v1",
          "kind": "IBMSecurityVerify",
          "metadata": {
            "name": "ibmsecurityverify-sample"
          },
          "spec": {
            "clientSecret": "--secret--",
            "sessionLifetime": 3600,
            "ssoPath": "/verify-sso"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/verify-operator-bundle@sha256:0deef311d65c60bedc0af39fb6dfde09b0b1a60825eaa37188b21b5a692397e9",
      "bundle_path_digest": "sha256:0deef311d65c60bedc0af39fb6dfde09b0b1a60825eaa37188b21b5a692397e9",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-02T09:27:02.754000+00:00",
      "csv_description": "[IBM Security Verify](https://www.ibm.com/products/verify-saas) is an Identity-as-a-Service platform that allows IT, security and business leaders to protect their digital users, assets and data in a hybrid, multi-cloud world by enabling technical agility and operational efficiency. IBM Security Verify SaaS provides single sign-on (SSO), multi-factor authentication (MFA), AI-powered context for risk-based authentication for adaptive access decisions, user management, access recertification campaigns and identity analytics.\n\nAs part of using Red Hat OpenShift, you are entitled to Verify SaaS SSO for unlimited apps and users.  If you do not already have a Verify SaaS SSO tenant a new one can be [created](https://www.ibm.com/account/reg/us-en/signup?formid=urx-51255).\n\nFor a detailed description of IBM Security Verify refer to the [Official documentation](https://www.ibm.com/docs/en/security-verify).\n\nThe IBM Security Verify operator can consistently enforce policy-driven security by using the Ingress networking capability of OpenShift in conjunction with the [Nginx Ingress operator](https://www.nginx.com/blog/getting-started-nginx-ingress-operator-red-hat-openshift/). With this approach, you can enforce authentication and authorization policies for all of the applications in your cluster at the same time, without ever changing your application code. You can also dynamically register your application to start protecting them centrally from the cloud via Verify SaaS. \n\nSee the project [Readme](https://github.com/IBM-Security/verify-operator/blob/master/README.md) for further information and details.\n\n",
      "csv_display_name": "IBM Security Verify Operator",
      "csv_metadata_description": "The IBM Security Verify operator can consistently enforce policy-driven security, including authentication and authorization, using the Ingress networking capability of OpenShift.",
      "csv_name": "ibm-security-verify-operator.v22.6.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:36:23.707000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "ibm-security-verify-operator",
      "provided_apis": [
        {
          "group": "ibm.com",
          "kind": "IBMSecurityVerify",
          "plural": "ibmsecurityverifies",
          "version": "v1"
        }
      ],
      "provider": "IBM",
      "related_images": [
        {
          "digest": "sha256:3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a",
          "image": "ibmcom/verify-operator@sha256:3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a",
          "name": "verify-operator-3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a-annotation"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a",
          "image": "ibmcom/verify-operator@sha256:3c8add266bdabd7e19ec60c097e9048e5837d7b81c225dcaeec33df9f515b21a",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "22.6.0",
      "version_original": "22.6.0"
    },
    {
      "_id": "62988267e0c0938179ef6058",
      "alm_examples": [
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupPolicy",
          "metadata": {
            "name": "atlasbackuppolicy-sample"
          },
          "spec": {
            "id": "1",
            "items": [
              {
                "frequencyInterval": 6,
                "frequencyType": "WEEKLY",
                "id": "2",
                "retentionUnit": "DAYS",
                "retentionValue": 6
              }
            ]
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupSchedule",
          "metadata": {
            "name": "atlasbackupschedule-sample"
          },
          "spec": {
            "autoExportEnabled": true,
            "policies": [
              {
                "name": "atlas-default-backuppolicy",
                "namespace": "mongodb-atlas-system"
              },
              {
                "name": "atlas-default-backuppolicy2",
                "namespace": "mongodb-atlas-system"
              }
            ],
            "referenceHourOfDay": 10,
            "referenceMinuteOfHour": 10,
            "restoreWindowDays": 2
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDatabaseUser",
          "metadata": {
            "name": "my-database-user"
          },
          "spec": {
            "databaseName": "admin",
            "passwordSecretRef": {
              "name": "my-database-user-password"
            },
            "projectRef": {
              "name": "my-project"
            },
            "roles": [
              {
                "databaseName": "admin",
                "roleName": "readWriteAnyDatabase"
              }
            ],
            "username": "david"
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDeployment",
          "metadata": {
            "name": "my-atlas-cluster"
          },
          "spec": {
            "deploymentSpec": {
              "name": "test-cluster",
              "providerSettings": {
                "instanceSizeName": "M10",
                "providerName": "AWS",
                "regionName": "US_EAST_1"
              }
            },
            "projectRef": {
              "name": "my-project"
            }
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasProject",
          "metadata": {
            "name": "my-project"
          },
          "spec": {
            "name": "Test Atlas Operator Project",
            "projectIpAccessList": [
              {
                "comment": "IP address for Application Server A",
                "ipAddress": "192.0.2.15"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator-bundle@sha256:2338eaab863304250b3b1d267e9f2261c48eef1f97c280b7fa0af0ebc3ba208b",
      "bundle_path_digest": "sha256:2338eaab863304250b3b1d267e9f2261c48eef1f97c280b7fa0af0ebc3ba208b",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-06-02T09:27:03.274000+00:00",
      "csv_description": "The MongoDB Atlas Operator provides a native integration between the Kubernetes orchestration platform and MongoDB Atlas \u2014\nthe only multi-cloud document database service that gives you the versatility you need to build sophisticated and resilient applications that can adapt to changing customer demands and market trends.\n\n> Current Status: *Beta*. The Operator gives users the ability to provision\n> Atlas projects, clusters and database users using Kubernetes Specifications and bind connection information\n> into applications deployed to Kubernetes.\n\n## Quick Start guide\n### Step 1. Deploy Kubernetes operator by clicking Install button.\n\n### Step 2. Create Atlas Cluster\n\n**1.** Create an Atlas API Key Secret\nIn order to work with the Atlas Operator you need to provide [authentication information](https://docs.atlas.mongodb.com/configure-api-access)\n to allow the Atlas Operator to communicate with Atlas API. Once you have generated a Public and Private key in Atlas, you can create a Kuberentes Secret with:\n```\nkubectl create secret generic mongodb-atlas-operator-api-key \\\n         --from-literal=\"orgId=<the_atlas_organization_id>\" \\\n         --from-literal=\"publicApiKey=<the_atlas_api_public_key>\" \\\n         --from-literal=\"privateApiKey=<the_atlas_api_private_key>\" \\\n         -n openshift-operators\n```\n(Note, that you should use the namespace where the Operator was installed - it's `openshift-operators` by default)\n\n**2.** Create an `AtlasProject` Custom Resource\n\nThe `AtlasProject` CustomResource represents Atlas Projects in our Kubernetes cluster. You need to specify\n`projectIpAccessList` with the IP addresses or CIDR blocks of any hosts that will connect to the Atlas Cluster.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\nspec:\n  name: Test Atlas Operator Project\n  projectIpAccessList:\n    - ipAddress: \"192.0.2.15\"\n      comment: \"IP address for Application Server A\"\n    - ipAddress: \"203.0.113.0/24\"\n      comment: \"CIDR block for Application Server B - D\"\n```\n**3.** Create an `AtlasDeployment` Custom Resource.\nThe example below is a minimal configuration to create an M10 Atlas cluster in the AWS US East region. For a full list of properties, check\n`atlasclusters.atlas.mongodb.com` [CRD specification](config/crd/bases/atlas.mongodb.com_atlasclusters.yaml)):\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: my-atlas-cluster\nspec:\n  name: \"Test-cluster\"\n  projectRef:\n    name: my-project\n  providerSettings:\n    instanceSizeName: M10\n    providerName: AWS\n    regionName: US_EAST_1\n```\n\n**4.** Create a database user password Kubernetes Secret\nThe Secret must be created in the same namespace as the `AtlasDeployment` and `AtlasProject` were created.\n```\nkubectl create secret generic the-user-password --from-literal=\"password=P@@sword%\"\n```\n\n**5.** Create an `AtlasDatabaseUser` Custom Resource\n\nIn order to connect to an Atlas Cluster the database user needs to be created. `AtlasDatabaseUser` resource should reference\nthe password Kubernetes Secret created in the previous step.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDatabaseUser\nmetadata:\n  name: my-database-user\nspec:\n  roles:\n    - roleName: \"readWriteAnyDatabase\"\n      databaseName: \"admin\"\n  projectRef:\n    name: my-project\n  username: theuser\n  passwordSecretRef:\n    name: the-user-password\n```\n**6.** Wait for the `AtlasDatabaseUser` Custom Resource to be ready\n\nWait until the AtlasDatabaseUser resource gets to \"ready\" status (it will wait until the cluster is created that may take around 10 minutes):\n```\nkubectl get atlasdatabaseusers my-database-user -o=jsonpath='{.status.conditions[?(@.type==\"Ready\")].status}'\nTrue\n```\n### Step 3. Connect your application to the Atlas Cluster\n\nThe Atlas Operator will create a Kubernetes Secret with the information necessary to connect to the Atlas Cluster created\nin the previous step. An application in the same Kubernetes Cluster can mount and use the Secret:\n\n```\n...\ncontainers:\n      - name: test-app\n        env:\n         - name: \"CONNECTION_STRING\"\n           valueFrom:\n             secretKeyRef:\n               name: test-atlas-operator-project-test-cluster-theuser\n               key: connectionStringStandardSrv\n\n```\n",
      "csv_display_name": "MongoDB Atlas Operator",
      "csv_metadata_description": "The MongoDB Atlas Kubernetes Operator enables easy management of Clusters in MongoDB Atlas",
      "csv_name": "mongodb-atlas-kubernetes.v1.0.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:05:39.005000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "mongodb-atlas-kubernetes",
      "provided_apis": [
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupPolicy",
          "plural": "atlasbackuppolicies",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupSchedule",
          "plural": "atlasbackupschedules",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDatabaseUser",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDeployment",
          "plural": "atlasdeployments",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasProject",
          "version": "v1"
        }
      ],
      "provider": "MongoDB, Inc",
      "related_images": [
        {
          "digest": "sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "name": "mongodb-atlas-kubernetes-operator-3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3-annotation"
        },
        {
          "digest": "sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "1.0.0",
      "version_original": "1.0.0"
    },
    {
      "_id": "62988486554afbde4c9bb401",
      "alm_examples": [
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupPolicy",
          "metadata": {
            "name": "atlasbackuppolicy-sample"
          },
          "spec": {
            "id": "1",
            "items": [
              {
                "frequencyInterval": 6,
                "frequencyType": "WEEKLY",
                "id": "2",
                "retentionUnit": "DAYS",
                "retentionValue": 6
              }
            ]
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupSchedule",
          "metadata": {
            "name": "atlasbackupschedule-sample"
          },
          "spec": {
            "autoExportEnabled": true,
            "policies": [
              {
                "name": "atlas-default-backuppolicy",
                "namespace": "mongodb-atlas-system"
              },
              {
                "name": "atlas-default-backuppolicy2",
                "namespace": "mongodb-atlas-system"
              }
            ],
            "referenceHourOfDay": 10,
            "referenceMinuteOfHour": 10,
            "restoreWindowDays": 2
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDatabaseUser",
          "metadata": {
            "name": "my-database-user"
          },
          "spec": {
            "databaseName": "admin",
            "passwordSecretRef": {
              "name": "my-database-user-password"
            },
            "projectRef": {
              "name": "my-project"
            },
            "roles": [
              {
                "databaseName": "admin",
                "roleName": "readWriteAnyDatabase"
              }
            ],
            "username": "david"
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDeployment",
          "metadata": {
            "name": "my-atlas-cluster"
          },
          "spec": {
            "deploymentSpec": {
              "name": "test-cluster",
              "providerSettings": {
                "instanceSizeName": "M10",
                "providerName": "AWS",
                "regionName": "US_EAST_1"
              }
            },
            "projectRef": {
              "name": "my-project"
            }
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasProject",
          "metadata": {
            "name": "my-project"
          },
          "spec": {
            "name": "Test Atlas Operator Project",
            "projectIpAccessList": [
              {
                "comment": "IP address for Application Server A",
                "ipAddress": "192.0.2.15"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator-bundle@sha256:2338eaab863304250b3b1d267e9f2261c48eef1f97c280b7fa0af0ebc3ba208b",
      "bundle_path_digest": "sha256:2338eaab863304250b3b1d267e9f2261c48eef1f97c280b7fa0af0ebc3ba208b",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-06-02T09:36:06.357000+00:00",
      "csv_description": "The MongoDB Atlas Operator provides a native integration between the Kubernetes orchestration platform and MongoDB Atlas \u2014\nthe only multi-cloud document database service that gives you the versatility you need to build sophisticated and resilient applications that can adapt to changing customer demands and market trends.\n\n> Current Status: *Beta*. The Operator gives users the ability to provision\n> Atlas projects, clusters and database users using Kubernetes Specifications and bind connection information\n> into applications deployed to Kubernetes.\n\n## Quick Start guide\n### Step 1. Deploy Kubernetes operator by clicking Install button.\n\n### Step 2. Create Atlas Cluster\n\n**1.** Create an Atlas API Key Secret\nIn order to work with the Atlas Operator you need to provide [authentication information](https://docs.atlas.mongodb.com/configure-api-access)\n to allow the Atlas Operator to communicate with Atlas API. Once you have generated a Public and Private key in Atlas, you can create a Kuberentes Secret with:\n```\nkubectl create secret generic mongodb-atlas-operator-api-key \\\n         --from-literal=\"orgId=<the_atlas_organization_id>\" \\\n         --from-literal=\"publicApiKey=<the_atlas_api_public_key>\" \\\n         --from-literal=\"privateApiKey=<the_atlas_api_private_key>\" \\\n         -n openshift-operators\n```\n(Note, that you should use the namespace where the Operator was installed - it's `openshift-operators` by default)\n\n**2.** Create an `AtlasProject` Custom Resource\n\nThe `AtlasProject` CustomResource represents Atlas Projects in our Kubernetes cluster. You need to specify\n`projectIpAccessList` with the IP addresses or CIDR blocks of any hosts that will connect to the Atlas Cluster.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\nspec:\n  name: Test Atlas Operator Project\n  projectIpAccessList:\n    - ipAddress: \"192.0.2.15\"\n      comment: \"IP address for Application Server A\"\n    - ipAddress: \"203.0.113.0/24\"\n      comment: \"CIDR block for Application Server B - D\"\n```\n**3.** Create an `AtlasDeployment` Custom Resource.\nThe example below is a minimal configuration to create an M10 Atlas cluster in the AWS US East region. For a full list of properties, check\n`atlasclusters.atlas.mongodb.com` [CRD specification](config/crd/bases/atlas.mongodb.com_atlasclusters.yaml)):\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: my-atlas-cluster\nspec:\n  name: \"Test-cluster\"\n  projectRef:\n    name: my-project\n  providerSettings:\n    instanceSizeName: M10\n    providerName: AWS\n    regionName: US_EAST_1\n```\n\n**4.** Create a database user password Kubernetes Secret\nThe Secret must be created in the same namespace as the `AtlasDeployment` and `AtlasProject` were created.\n```\nkubectl create secret generic the-user-password --from-literal=\"password=P@@sword%\"\n```\n\n**5.** Create an `AtlasDatabaseUser` Custom Resource\n\nIn order to connect to an Atlas Cluster the database user needs to be created. `AtlasDatabaseUser` resource should reference\nthe password Kubernetes Secret created in the previous step.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDatabaseUser\nmetadata:\n  name: my-database-user\nspec:\n  roles:\n    - roleName: \"readWriteAnyDatabase\"\n      databaseName: \"admin\"\n  projectRef:\n    name: my-project\n  username: theuser\n  passwordSecretRef:\n    name: the-user-password\n```\n**6.** Wait for the `AtlasDatabaseUser` Custom Resource to be ready\n\nWait until the AtlasDatabaseUser resource gets to \"ready\" status (it will wait until the cluster is created that may take around 10 minutes):\n```\nkubectl get atlasdatabaseusers my-database-user -o=jsonpath='{.status.conditions[?(@.type==\"Ready\")].status}'\nTrue\n```\n### Step 3. Connect your application to the Atlas Cluster\n\nThe Atlas Operator will create a Kubernetes Secret with the information necessary to connect to the Atlas Cluster created\nin the previous step. An application in the same Kubernetes Cluster can mount and use the Secret:\n\n```\n...\ncontainers:\n      - name: test-app\n        env:\n         - name: \"CONNECTION_STRING\"\n           valueFrom:\n             secretKeyRef:\n               name: test-atlas-operator-project-test-cluster-theuser\n               key: connectionStringStandardSrv\n\n```\n",
      "csv_display_name": "MongoDB Atlas Operator",
      "csv_metadata_description": "The MongoDB Atlas Kubernetes Operator enables easy management of Clusters in MongoDB Atlas",
      "csv_name": "mongodb-atlas-kubernetes.v1.0.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T12:58:22.623000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "mongodb-atlas-kubernetes",
      "provided_apis": [
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasProject",
          "plural": "atlasprojects",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupPolicy",
          "plural": "atlasbackuppolicies",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupSchedule",
          "plural": "atlasbackupschedules",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDatabaseUser",
          "plural": "atlasdatabaseusers",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDeployment",
          "plural": "atlasdeployments",
          "version": "v1"
        }
      ],
      "provider": "MongoDB, Inc",
      "related_images": [
        {
          "digest": "sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "name": "mongodb-atlas-kubernetes-operator-3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3-annotation"
        },
        {
          "digest": "sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.0.0",
      "version_original": "1.0.0"
    },
    {
      "_id": "6298856be0c0938179ef6195",
      "alm_examples": [
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupPolicy",
          "metadata": {
            "name": "atlasbackuppolicy-sample"
          },
          "spec": {
            "id": "1",
            "items": [
              {
                "frequencyInterval": 6,
                "frequencyType": "WEEKLY",
                "id": "2",
                "retentionUnit": "DAYS",
                "retentionValue": 6
              }
            ]
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupSchedule",
          "metadata": {
            "name": "atlasbackupschedule-sample"
          },
          "spec": {
            "autoExportEnabled": true,
            "policies": [
              {
                "name": "atlas-default-backuppolicy",
                "namespace": "mongodb-atlas-system"
              },
              {
                "name": "atlas-default-backuppolicy2",
                "namespace": "mongodb-atlas-system"
              }
            ],
            "referenceHourOfDay": 10,
            "referenceMinuteOfHour": 10,
            "restoreWindowDays": 2
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDatabaseUser",
          "metadata": {
            "name": "my-database-user"
          },
          "spec": {
            "databaseName": "admin",
            "passwordSecretRef": {
              "name": "my-database-user-password"
            },
            "projectRef": {
              "name": "my-project"
            },
            "roles": [
              {
                "databaseName": "admin",
                "roleName": "readWriteAnyDatabase"
              }
            ],
            "username": "david"
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDeployment",
          "metadata": {
            "name": "my-atlas-cluster"
          },
          "spec": {
            "deploymentSpec": {
              "name": "test-cluster",
              "providerSettings": {
                "instanceSizeName": "M10",
                "providerName": "AWS",
                "regionName": "US_EAST_1"
              }
            },
            "projectRef": {
              "name": "my-project"
            }
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasProject",
          "metadata": {
            "name": "my-project"
          },
          "spec": {
            "name": "Test Atlas Operator Project",
            "projectIpAccessList": [
              {
                "comment": "IP address for Application Server A",
                "ipAddress": "192.0.2.15"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator-bundle@sha256:2338eaab863304250b3b1d267e9f2261c48eef1f97c280b7fa0af0ebc3ba208b",
      "bundle_path_digest": "sha256:2338eaab863304250b3b1d267e9f2261c48eef1f97c280b7fa0af0ebc3ba208b",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-06-02T09:39:55.202000+00:00",
      "csv_description": "The MongoDB Atlas Operator provides a native integration between the Kubernetes orchestration platform and MongoDB Atlas \u2014\nthe only multi-cloud document database service that gives you the versatility you need to build sophisticated and resilient applications that can adapt to changing customer demands and market trends.\n\n> Current Status: *Beta*. The Operator gives users the ability to provision\n> Atlas projects, clusters and database users using Kubernetes Specifications and bind connection information\n> into applications deployed to Kubernetes.\n\n## Quick Start guide\n### Step 1. Deploy Kubernetes operator by clicking Install button.\n\n### Step 2. Create Atlas Cluster\n\n**1.** Create an Atlas API Key Secret\nIn order to work with the Atlas Operator you need to provide [authentication information](https://docs.atlas.mongodb.com/configure-api-access)\n to allow the Atlas Operator to communicate with Atlas API. Once you have generated a Public and Private key in Atlas, you can create a Kuberentes Secret with:\n```\nkubectl create secret generic mongodb-atlas-operator-api-key \\\n         --from-literal=\"orgId=<the_atlas_organization_id>\" \\\n         --from-literal=\"publicApiKey=<the_atlas_api_public_key>\" \\\n         --from-literal=\"privateApiKey=<the_atlas_api_private_key>\" \\\n         -n openshift-operators\n```\n(Note, that you should use the namespace where the Operator was installed - it's `openshift-operators` by default)\n\n**2.** Create an `AtlasProject` Custom Resource\n\nThe `AtlasProject` CustomResource represents Atlas Projects in our Kubernetes cluster. You need to specify\n`projectIpAccessList` with the IP addresses or CIDR blocks of any hosts that will connect to the Atlas Cluster.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\nspec:\n  name: Test Atlas Operator Project\n  projectIpAccessList:\n    - ipAddress: \"192.0.2.15\"\n      comment: \"IP address for Application Server A\"\n    - ipAddress: \"203.0.113.0/24\"\n      comment: \"CIDR block for Application Server B - D\"\n```\n**3.** Create an `AtlasDeployment` Custom Resource.\nThe example below is a minimal configuration to create an M10 Atlas cluster in the AWS US East region. For a full list of properties, check\n`atlasclusters.atlas.mongodb.com` [CRD specification](config/crd/bases/atlas.mongodb.com_atlasclusters.yaml)):\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: my-atlas-cluster\nspec:\n  name: \"Test-cluster\"\n  projectRef:\n    name: my-project\n  providerSettings:\n    instanceSizeName: M10\n    providerName: AWS\n    regionName: US_EAST_1\n```\n\n**4.** Create a database user password Kubernetes Secret\nThe Secret must be created in the same namespace as the `AtlasDeployment` and `AtlasProject` were created.\n```\nkubectl create secret generic the-user-password --from-literal=\"password=P@@sword%\"\n```\n\n**5.** Create an `AtlasDatabaseUser` Custom Resource\n\nIn order to connect to an Atlas Cluster the database user needs to be created. `AtlasDatabaseUser` resource should reference\nthe password Kubernetes Secret created in the previous step.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDatabaseUser\nmetadata:\n  name: my-database-user\nspec:\n  roles:\n    - roleName: \"readWriteAnyDatabase\"\n      databaseName: \"admin\"\n  projectRef:\n    name: my-project\n  username: theuser\n  passwordSecretRef:\n    name: the-user-password\n```\n**6.** Wait for the `AtlasDatabaseUser` Custom Resource to be ready\n\nWait until the AtlasDatabaseUser resource gets to \"ready\" status (it will wait until the cluster is created that may take around 10 minutes):\n```\nkubectl get atlasdatabaseusers my-database-user -o=jsonpath='{.status.conditions[?(@.type==\"Ready\")].status}'\nTrue\n```\n### Step 3. Connect your application to the Atlas Cluster\n\nThe Atlas Operator will create a Kubernetes Secret with the information necessary to connect to the Atlas Cluster created\nin the previous step. An application in the same Kubernetes Cluster can mount and use the Secret:\n\n```\n...\ncontainers:\n      - name: test-app\n        env:\n         - name: \"CONNECTION_STRING\"\n           valueFrom:\n             secretKeyRef:\n               name: test-atlas-operator-project-test-cluster-theuser\n               key: connectionStringStandardSrv\n\n```\n",
      "csv_display_name": "MongoDB Atlas Operator",
      "csv_metadata_description": "The MongoDB Atlas Kubernetes Operator enables easy management of Clusters in MongoDB Atlas",
      "csv_name": "mongodb-atlas-kubernetes.v1.0.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T12:47:26.379000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "mongodb-atlas-kubernetes",
      "provided_apis": [
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupSchedule",
          "plural": "atlasbackupschedules",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDatabaseUser",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDeployment",
          "plural": "atlasdeployments",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasProject",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupPolicy",
          "plural": "atlasbackuppolicies",
          "version": "v1"
        }
      ],
      "provider": "MongoDB, Inc",
      "related_images": [
        {
          "digest": "sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "name": "mongodb-atlas-kubernetes-operator-3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3-annotation"
        },
        {
          "digest": "sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:3cfbd700e4771c2c7e75c2c41cf6de57c9ef71ecd286e96a21d2567e43424bc3",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "1.0.0",
      "version_original": "1.0.0"
    },
    {
      "_id": "6299f1d4c18e5a3b8335a9c2",
      "alm_examples": [
        {
          "api_version": "csi.nec.com/v1",
          "kind": "NSPC",
          "metadata": {
            "name": "nspc",
            "namespace": "kube-system"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/nec/nspc-operator-bundle@sha256:ae54f0df026b854a1d67b1e0b866a7ea4241d2b2330ad474e7ffccf511264030",
      "bundle_path_digest": "sha256:ae54f0df026b854a1d67b1e0b866a7ea4241d2b2330ad474e7ffccf511264030",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-03T11:34:44.729000+00:00",
      "csv_description": "## About\nNEC Storage Plug-in for Containers (NSPC) is a plugin that integrates NEC Storage V Series into Kubernetes based clusters.\nNSPC provides dynamic persistent volume provisioning capabilities from NEC Storage V Series arrays.\n\nFor full documentation, refer to the reference guide.\n\n## Requirements\n\n### Supported Driver Version\n\n* NSPC v3.9.0\n\n### Supported Platforms\n\n* OpenShift v4.7, v4.8, v4.9\n\n### Supported Operating Systems\n\n* RHEL 7.x\n* RHEL 8.x",
      "csv_display_name": "NEC Storage Plug-in for Containers",
      "csv_metadata_description": "An operator for managing NEC Storage Plug-in for Containers CSI driver",
      "csv_name": "nspc-operator.v1.9.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:04:21.155000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "nspc-operator",
      "provided_apis": [
        {
          "group": "csi.nec.com",
          "kind": "NSPC",
          "plural": "nspcs",
          "version": "v1"
        }
      ],
      "provider": "NEC",
      "related_images": [
        {
          "digest": "sha256:4a4330567d3e540bcfe144df8aec069315f51661e47357e858593283eaf66d0b",
          "image": "registry.connect.redhat.com/nec/nspc-csi-driver@sha256:4a4330567d3e540bcfe144df8aec069315f51661e47357e858593283eaf66d0b",
          "name": "nspc-csi-driver"
        },
        {
          "digest": "sha256:1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2",
          "image": "registry.connect.redhat.com/nec/nspc-operator@sha256:1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2",
          "name": "nspc-operator"
        },
        {
          "digest": "sha256:e4ce5adf0abe5add640b166bc9f658d069ca4783ed37fcd8774f20da89a7cad1",
          "image": "registry.redhat.io/openshift4/ose-csi-external-attacher@sha256:e4ce5adf0abe5add640b166bc9f658d069ca4783ed37fcd8774f20da89a7cad1",
          "name": "ose-csi-external-attacher-v4.7"
        },
        {
          "digest": "sha256:d99597158ef4baf204e0fe7ed24c1dbc7b0218305077cdaf22c3899a1b3988c7",
          "image": "registry.redhat.io/openshift4/ose-csi-external-provisioner@sha256:d99597158ef4baf204e0fe7ed24c1dbc7b0218305077cdaf22c3899a1b3988c7",
          "name": "ose-csi-external-provisioner-v4.7"
        },
        {
          "digest": "sha256:2c7bb13d648a5048584530fddc62deb4b2e47bb7d389b77992e1077b920867e8",
          "image": "registry.redhat.io/openshift4/ose-csi-node-driver-registrar-rhel8@sha256:2c7bb13d648a5048584530fddc62deb4b2e47bb7d389b77992e1077b920867e8",
          "name": "ose-csi-node-driver-registrar-v4.7"
        },
        {
          "digest": "sha256:221cda173d5ad2be44655dd8ab697a80bd94149358183b3375b09280ba025f92",
          "image": "registry.redhat.io/openshift4/ose-csi-livenessprobe@sha256:221cda173d5ad2be44655dd8ab697a80bd94149358183b3375b09280ba025f92",
          "name": "ose-csi-livenessprobe-v4.7"
        },
        {
          "digest": "sha256:890729e261e87ad12bf7c523f9c2c39a20fb07e18aa269cd015f86ed23ac22b7",
          "image": "registry.redhat.io/openshift4/ose-csi-external-resizer-rhel8@sha256:890729e261e87ad12bf7c523f9c2c39a20fb07e18aa269cd015f86ed23ac22b7",
          "name": "ose-csi-external-resizer-rhel8-v4.7"
        },
        {
          "digest": "sha256:727b6317ef2575c905cd87c9d6d14b7c45886c4f20f0d75904641c55bb1e1814",
          "image": "registry.redhat.io/openshift4/ose-csi-external-snapshotter-rhel8@sha256:727b6317ef2575c905cd87c9d6d14b7c45886c4f20f0d75904641c55bb1e1814",
          "name": "ose-csi-external-snapshotter-rhel8-v4.7"
        },
        {
          "digest": "sha256:89e05898626e7689113d46ffb98c98e95a2a49b71c6a8b32409699eab8f32ea4",
          "image": "registry.redhat.io/openshift4/ose-csi-external-attacher@sha256:89e05898626e7689113d46ffb98c98e95a2a49b71c6a8b32409699eab8f32ea4",
          "name": "ose-csi-external-attacher-v4.8"
        },
        {
          "digest": "sha256:f91ba2c92c97f9b4c4afe789040250c9a6cb675fbe24cbae3ad381e58bc3b83a",
          "image": "registry.redhat.io/openshift4/ose-csi-external-provisioner@sha256:f91ba2c92c97f9b4c4afe789040250c9a6cb675fbe24cbae3ad381e58bc3b83a",
          "name": "ose-csi-external-provisioner-v4.8"
        },
        {
          "digest": "sha256:2e01a77235d1b692b87ec7e3e842dab52762032fbf3988f258960e2cece04225",
          "image": "registry.redhat.io/openshift4/ose-csi-node-driver-registrar-rhel8@sha256:2e01a77235d1b692b87ec7e3e842dab52762032fbf3988f258960e2cece04225",
          "name": "ose-csi-node-driver-registrar-v4.8"
        },
        {
          "digest": "sha256:2f0c069bd085951f864c268ebbb28d5044e912327cf1de13cb40e082a2aaf4db",
          "image": "registry.redhat.io/openshift4/ose-csi-livenessprobe@sha256:2f0c069bd085951f864c268ebbb28d5044e912327cf1de13cb40e082a2aaf4db",
          "name": "ose-csi-livenessprobe-v4.8"
        },
        {
          "digest": "sha256:e55efd04b15565bfcfcb8bd64b4da3a58461d8a6e2cfbbf1b1ac4bc537cf307b",
          "image": "registry.redhat.io/openshift4/ose-csi-external-resizer-rhel8@sha256:e55efd04b15565bfcfcb8bd64b4da3a58461d8a6e2cfbbf1b1ac4bc537cf307b",
          "name": "ose-csi-external-resizer-rhel8-v4.8"
        },
        {
          "digest": "sha256:bca38e3c695cf2bbb338b4933982f6892782b7fec14a1c835cb5a08c1cc7a14c",
          "image": "registry.redhat.io/openshift4/ose-csi-external-snapshotter-rhel8@sha256:bca38e3c695cf2bbb338b4933982f6892782b7fec14a1c835cb5a08c1cc7a14c",
          "name": "ose-csi-external-snapshotter-rhel8-v4.8"
        },
        {
          "digest": "sha256:9ffed943cdc9597803faedfac8891b963e08ec86f4cb21a59ae7c37adc5ce349",
          "image": "registry.redhat.io/openshift4/ose-csi-external-attacher@sha256:9ffed943cdc9597803faedfac8891b963e08ec86f4cb21a59ae7c37adc5ce349",
          "name": "ose-csi-external-attacher-v4.9"
        },
        {
          "digest": "sha256:ea0797b04595d1bf46ca5d3b205cead25c70e8c252e844551944079000a3fbe1",
          "image": "registry.redhat.io/openshift4/ose-csi-external-provisioner@sha256:ea0797b04595d1bf46ca5d3b205cead25c70e8c252e844551944079000a3fbe1",
          "name": "ose-csi-external-provisioner-v4.9"
        },
        {
          "digest": "sha256:4ca6d4d2f88eb0435084e1e0703330181e69e9c5c205ce21071d30fce864efde",
          "image": "registry.redhat.io/openshift4/ose-csi-node-driver-registrar-rhel8@sha256:4ca6d4d2f88eb0435084e1e0703330181e69e9c5c205ce21071d30fce864efde",
          "name": "ose-csi-node-driver-registrar-v4.9"
        },
        {
          "digest": "sha256:7c9816e9265dcc83af534a61175814e174ec10c1b411e71baf5d379ceeca1ecd",
          "image": "registry.redhat.io/openshift4/ose-csi-livenessprobe@sha256:7c9816e9265dcc83af534a61175814e174ec10c1b411e71baf5d379ceeca1ecd",
          "name": "ose-csi-livenessprobe-v4.9"
        },
        {
          "digest": "sha256:49ed3001a156015c3acbe5ef058f9acbb471b456535e7d56f6baec742527de74",
          "image": "registry.redhat.io/openshift4/ose-csi-external-resizer-rhel8@sha256:49ed3001a156015c3acbe5ef058f9acbb471b456535e7d56f6baec742527de74",
          "name": "ose-csi-external-resizer-rhel8-v4.9"
        },
        {
          "digest": "sha256:3ce747b7e19c5d0fa095fdeb29db3c9133575d24d941bad8ef6e71130c3f3883",
          "image": "registry.redhat.io/openshift4/ose-csi-external-snapshotter-rhel8@sha256:3ce747b7e19c5d0fa095fdeb29db3c9133575d24d941bad8ef6e71130c3f3883",
          "name": "ose-csi-external-snapshotter-rhel8-v4.9"
        },
        {
          "digest": "sha256:1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2",
          "image": "registry.connect.redhat.com/nec/nspc-operator@sha256:1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2",
          "name": "nspc-operator-1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2-annotation"
        },
        {
          "digest": "sha256:1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2",
          "image": "registry.connect.redhat.com/nec/nspc-operator@sha256:1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.9.0",
      "version_original": "1.9.0"
    },
    {
      "_id": "6299f257706b4bf5cee5af9b",
      "alm_examples": [
        {
          "api_version": "csi.nec.com/v1",
          "kind": "NSPC",
          "metadata": {
            "name": "nspc",
            "namespace": "kube-system"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/nec/nspc-operator-bundle@sha256:ae54f0df026b854a1d67b1e0b866a7ea4241d2b2330ad474e7ffccf511264030",
      "bundle_path_digest": "sha256:ae54f0df026b854a1d67b1e0b866a7ea4241d2b2330ad474e7ffccf511264030",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-03T11:36:55.786000+00:00",
      "csv_description": "## About\nNEC Storage Plug-in for Containers (NSPC) is a plugin that integrates NEC Storage V Series into Kubernetes based clusters.\nNSPC provides dynamic persistent volume provisioning capabilities from NEC Storage V Series arrays.\n\nFor full documentation, refer to the reference guide.\n\n## Requirements\n\n### Supported Driver Version\n\n* NSPC v3.9.0\n\n### Supported Platforms\n\n* OpenShift v4.7, v4.8, v4.9\n\n### Supported Operating Systems\n\n* RHEL 7.x\n* RHEL 8.x",
      "csv_display_name": "NEC Storage Plug-in for Containers",
      "csv_metadata_description": "An operator for managing NEC Storage Plug-in for Containers CSI driver",
      "csv_name": "nspc-operator.v1.9.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:31:30.564000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "nspc-operator",
      "provided_apis": [
        {
          "group": "csi.nec.com",
          "kind": "NSPC",
          "plural": "nspcs",
          "version": "v1"
        }
      ],
      "provider": "NEC",
      "related_images": [
        {
          "digest": "sha256:4a4330567d3e540bcfe144df8aec069315f51661e47357e858593283eaf66d0b",
          "image": "registry.connect.redhat.com/nec/nspc-csi-driver@sha256:4a4330567d3e540bcfe144df8aec069315f51661e47357e858593283eaf66d0b",
          "name": "nspc-csi-driver"
        },
        {
          "digest": "sha256:1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2",
          "image": "registry.connect.redhat.com/nec/nspc-operator@sha256:1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2",
          "name": "nspc-operator"
        },
        {
          "digest": "sha256:e4ce5adf0abe5add640b166bc9f658d069ca4783ed37fcd8774f20da89a7cad1",
          "image": "registry.redhat.io/openshift4/ose-csi-external-attacher@sha256:e4ce5adf0abe5add640b166bc9f658d069ca4783ed37fcd8774f20da89a7cad1",
          "name": "ose-csi-external-attacher-v4.7"
        },
        {
          "digest": "sha256:d99597158ef4baf204e0fe7ed24c1dbc7b0218305077cdaf22c3899a1b3988c7",
          "image": "registry.redhat.io/openshift4/ose-csi-external-provisioner@sha256:d99597158ef4baf204e0fe7ed24c1dbc7b0218305077cdaf22c3899a1b3988c7",
          "name": "ose-csi-external-provisioner-v4.7"
        },
        {
          "digest": "sha256:2c7bb13d648a5048584530fddc62deb4b2e47bb7d389b77992e1077b920867e8",
          "image": "registry.redhat.io/openshift4/ose-csi-node-driver-registrar-rhel8@sha256:2c7bb13d648a5048584530fddc62deb4b2e47bb7d389b77992e1077b920867e8",
          "name": "ose-csi-node-driver-registrar-v4.7"
        },
        {
          "digest": "sha256:221cda173d5ad2be44655dd8ab697a80bd94149358183b3375b09280ba025f92",
          "image": "registry.redhat.io/openshift4/ose-csi-livenessprobe@sha256:221cda173d5ad2be44655dd8ab697a80bd94149358183b3375b09280ba025f92",
          "name": "ose-csi-livenessprobe-v4.7"
        },
        {
          "digest": "sha256:890729e261e87ad12bf7c523f9c2c39a20fb07e18aa269cd015f86ed23ac22b7",
          "image": "registry.redhat.io/openshift4/ose-csi-external-resizer-rhel8@sha256:890729e261e87ad12bf7c523f9c2c39a20fb07e18aa269cd015f86ed23ac22b7",
          "name": "ose-csi-external-resizer-rhel8-v4.7"
        },
        {
          "digest": "sha256:727b6317ef2575c905cd87c9d6d14b7c45886c4f20f0d75904641c55bb1e1814",
          "image": "registry.redhat.io/openshift4/ose-csi-external-snapshotter-rhel8@sha256:727b6317ef2575c905cd87c9d6d14b7c45886c4f20f0d75904641c55bb1e1814",
          "name": "ose-csi-external-snapshotter-rhel8-v4.7"
        },
        {
          "digest": "sha256:89e05898626e7689113d46ffb98c98e95a2a49b71c6a8b32409699eab8f32ea4",
          "image": "registry.redhat.io/openshift4/ose-csi-external-attacher@sha256:89e05898626e7689113d46ffb98c98e95a2a49b71c6a8b32409699eab8f32ea4",
          "name": "ose-csi-external-attacher-v4.8"
        },
        {
          "digest": "sha256:f91ba2c92c97f9b4c4afe789040250c9a6cb675fbe24cbae3ad381e58bc3b83a",
          "image": "registry.redhat.io/openshift4/ose-csi-external-provisioner@sha256:f91ba2c92c97f9b4c4afe789040250c9a6cb675fbe24cbae3ad381e58bc3b83a",
          "name": "ose-csi-external-provisioner-v4.8"
        },
        {
          "digest": "sha256:2e01a77235d1b692b87ec7e3e842dab52762032fbf3988f258960e2cece04225",
          "image": "registry.redhat.io/openshift4/ose-csi-node-driver-registrar-rhel8@sha256:2e01a77235d1b692b87ec7e3e842dab52762032fbf3988f258960e2cece04225",
          "name": "ose-csi-node-driver-registrar-v4.8"
        },
        {
          "digest": "sha256:2f0c069bd085951f864c268ebbb28d5044e912327cf1de13cb40e082a2aaf4db",
          "image": "registry.redhat.io/openshift4/ose-csi-livenessprobe@sha256:2f0c069bd085951f864c268ebbb28d5044e912327cf1de13cb40e082a2aaf4db",
          "name": "ose-csi-livenessprobe-v4.8"
        },
        {
          "digest": "sha256:e55efd04b15565bfcfcb8bd64b4da3a58461d8a6e2cfbbf1b1ac4bc537cf307b",
          "image": "registry.redhat.io/openshift4/ose-csi-external-resizer-rhel8@sha256:e55efd04b15565bfcfcb8bd64b4da3a58461d8a6e2cfbbf1b1ac4bc537cf307b",
          "name": "ose-csi-external-resizer-rhel8-v4.8"
        },
        {
          "digest": "sha256:bca38e3c695cf2bbb338b4933982f6892782b7fec14a1c835cb5a08c1cc7a14c",
          "image": "registry.redhat.io/openshift4/ose-csi-external-snapshotter-rhel8@sha256:bca38e3c695cf2bbb338b4933982f6892782b7fec14a1c835cb5a08c1cc7a14c",
          "name": "ose-csi-external-snapshotter-rhel8-v4.8"
        },
        {
          "digest": "sha256:9ffed943cdc9597803faedfac8891b963e08ec86f4cb21a59ae7c37adc5ce349",
          "image": "registry.redhat.io/openshift4/ose-csi-external-attacher@sha256:9ffed943cdc9597803faedfac8891b963e08ec86f4cb21a59ae7c37adc5ce349",
          "name": "ose-csi-external-attacher-v4.9"
        },
        {
          "digest": "sha256:ea0797b04595d1bf46ca5d3b205cead25c70e8c252e844551944079000a3fbe1",
          "image": "registry.redhat.io/openshift4/ose-csi-external-provisioner@sha256:ea0797b04595d1bf46ca5d3b205cead25c70e8c252e844551944079000a3fbe1",
          "name": "ose-csi-external-provisioner-v4.9"
        },
        {
          "digest": "sha256:4ca6d4d2f88eb0435084e1e0703330181e69e9c5c205ce21071d30fce864efde",
          "image": "registry.redhat.io/openshift4/ose-csi-node-driver-registrar-rhel8@sha256:4ca6d4d2f88eb0435084e1e0703330181e69e9c5c205ce21071d30fce864efde",
          "name": "ose-csi-node-driver-registrar-v4.9"
        },
        {
          "digest": "sha256:7c9816e9265dcc83af534a61175814e174ec10c1b411e71baf5d379ceeca1ecd",
          "image": "registry.redhat.io/openshift4/ose-csi-livenessprobe@sha256:7c9816e9265dcc83af534a61175814e174ec10c1b411e71baf5d379ceeca1ecd",
          "name": "ose-csi-livenessprobe-v4.9"
        },
        {
          "digest": "sha256:49ed3001a156015c3acbe5ef058f9acbb471b456535e7d56f6baec742527de74",
          "image": "registry.redhat.io/openshift4/ose-csi-external-resizer-rhel8@sha256:49ed3001a156015c3acbe5ef058f9acbb471b456535e7d56f6baec742527de74",
          "name": "ose-csi-external-resizer-rhel8-v4.9"
        },
        {
          "digest": "sha256:3ce747b7e19c5d0fa095fdeb29db3c9133575d24d941bad8ef6e71130c3f3883",
          "image": "registry.redhat.io/openshift4/ose-csi-external-snapshotter-rhel8@sha256:3ce747b7e19c5d0fa095fdeb29db3c9133575d24d941bad8ef6e71130c3f3883",
          "name": "ose-csi-external-snapshotter-rhel8-v4.9"
        },
        {
          "digest": "sha256:1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2",
          "image": "registry.connect.redhat.com/nec/nspc-operator@sha256:1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2",
          "name": "nspc-operator-1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2-annotation"
        },
        {
          "digest": "sha256:1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2",
          "image": "registry.connect.redhat.com/nec/nspc-operator@sha256:1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.9.0",
      "version_original": "1.9.0"
    },
    {
      "_id": "6299f3a1665978f21d29a116",
      "alm_examples": [
        {
          "api_version": "csi.nec.com/v1",
          "kind": "NSPC",
          "metadata": {
            "name": "nspc",
            "namespace": "kube-system"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/nec/nspc-operator-bundle@sha256:ae54f0df026b854a1d67b1e0b866a7ea4241d2b2330ad474e7ffccf511264030",
      "bundle_path_digest": "sha256:ae54f0df026b854a1d67b1e0b866a7ea4241d2b2330ad474e7ffccf511264030",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-03T11:42:25.326000+00:00",
      "csv_description": "## About\nNEC Storage Plug-in for Containers (NSPC) is a plugin that integrates NEC Storage V Series into Kubernetes based clusters.\nNSPC provides dynamic persistent volume provisioning capabilities from NEC Storage V Series arrays.\n\nFor full documentation, refer to the reference guide.\n\n## Requirements\n\n### Supported Driver Version\n\n* NSPC v3.9.0\n\n### Supported Platforms\n\n* OpenShift v4.7, v4.8, v4.9\n\n### Supported Operating Systems\n\n* RHEL 7.x\n* RHEL 8.x",
      "csv_display_name": "NEC Storage Plug-in for Containers",
      "csv_metadata_description": "An operator for managing NEC Storage Plug-in for Containers CSI driver",
      "csv_name": "nspc-operator.v1.9.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:03:06.922000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "nspc-operator",
      "provided_apis": [
        {
          "group": "csi.nec.com",
          "kind": "NSPC",
          "version": "v1"
        }
      ],
      "provider": "NEC",
      "related_images": [
        {
          "digest": "sha256:4a4330567d3e540bcfe144df8aec069315f51661e47357e858593283eaf66d0b",
          "image": "registry.connect.redhat.com/nec/nspc-csi-driver@sha256:4a4330567d3e540bcfe144df8aec069315f51661e47357e858593283eaf66d0b",
          "name": "nspc-csi-driver"
        },
        {
          "digest": "sha256:1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2",
          "image": "registry.connect.redhat.com/nec/nspc-operator@sha256:1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2",
          "name": "nspc-operator"
        },
        {
          "digest": "sha256:e4ce5adf0abe5add640b166bc9f658d069ca4783ed37fcd8774f20da89a7cad1",
          "image": "registry.redhat.io/openshift4/ose-csi-external-attacher@sha256:e4ce5adf0abe5add640b166bc9f658d069ca4783ed37fcd8774f20da89a7cad1",
          "name": "ose-csi-external-attacher-v4.7"
        },
        {
          "digest": "sha256:d99597158ef4baf204e0fe7ed24c1dbc7b0218305077cdaf22c3899a1b3988c7",
          "image": "registry.redhat.io/openshift4/ose-csi-external-provisioner@sha256:d99597158ef4baf204e0fe7ed24c1dbc7b0218305077cdaf22c3899a1b3988c7",
          "name": "ose-csi-external-provisioner-v4.7"
        },
        {
          "digest": "sha256:2c7bb13d648a5048584530fddc62deb4b2e47bb7d389b77992e1077b920867e8",
          "image": "registry.redhat.io/openshift4/ose-csi-node-driver-registrar-rhel8@sha256:2c7bb13d648a5048584530fddc62deb4b2e47bb7d389b77992e1077b920867e8",
          "name": "ose-csi-node-driver-registrar-v4.7"
        },
        {
          "digest": "sha256:221cda173d5ad2be44655dd8ab697a80bd94149358183b3375b09280ba025f92",
          "image": "registry.redhat.io/openshift4/ose-csi-livenessprobe@sha256:221cda173d5ad2be44655dd8ab697a80bd94149358183b3375b09280ba025f92",
          "name": "ose-csi-livenessprobe-v4.7"
        },
        {
          "digest": "sha256:890729e261e87ad12bf7c523f9c2c39a20fb07e18aa269cd015f86ed23ac22b7",
          "image": "registry.redhat.io/openshift4/ose-csi-external-resizer-rhel8@sha256:890729e261e87ad12bf7c523f9c2c39a20fb07e18aa269cd015f86ed23ac22b7",
          "name": "ose-csi-external-resizer-rhel8-v4.7"
        },
        {
          "digest": "sha256:727b6317ef2575c905cd87c9d6d14b7c45886c4f20f0d75904641c55bb1e1814",
          "image": "registry.redhat.io/openshift4/ose-csi-external-snapshotter-rhel8@sha256:727b6317ef2575c905cd87c9d6d14b7c45886c4f20f0d75904641c55bb1e1814",
          "name": "ose-csi-external-snapshotter-rhel8-v4.7"
        },
        {
          "digest": "sha256:89e05898626e7689113d46ffb98c98e95a2a49b71c6a8b32409699eab8f32ea4",
          "image": "registry.redhat.io/openshift4/ose-csi-external-attacher@sha256:89e05898626e7689113d46ffb98c98e95a2a49b71c6a8b32409699eab8f32ea4",
          "name": "ose-csi-external-attacher-v4.8"
        },
        {
          "digest": "sha256:f91ba2c92c97f9b4c4afe789040250c9a6cb675fbe24cbae3ad381e58bc3b83a",
          "image": "registry.redhat.io/openshift4/ose-csi-external-provisioner@sha256:f91ba2c92c97f9b4c4afe789040250c9a6cb675fbe24cbae3ad381e58bc3b83a",
          "name": "ose-csi-external-provisioner-v4.8"
        },
        {
          "digest": "sha256:2e01a77235d1b692b87ec7e3e842dab52762032fbf3988f258960e2cece04225",
          "image": "registry.redhat.io/openshift4/ose-csi-node-driver-registrar-rhel8@sha256:2e01a77235d1b692b87ec7e3e842dab52762032fbf3988f258960e2cece04225",
          "name": "ose-csi-node-driver-registrar-v4.8"
        },
        {
          "digest": "sha256:2f0c069bd085951f864c268ebbb28d5044e912327cf1de13cb40e082a2aaf4db",
          "image": "registry.redhat.io/openshift4/ose-csi-livenessprobe@sha256:2f0c069bd085951f864c268ebbb28d5044e912327cf1de13cb40e082a2aaf4db",
          "name": "ose-csi-livenessprobe-v4.8"
        },
        {
          "digest": "sha256:e55efd04b15565bfcfcb8bd64b4da3a58461d8a6e2cfbbf1b1ac4bc537cf307b",
          "image": "registry.redhat.io/openshift4/ose-csi-external-resizer-rhel8@sha256:e55efd04b15565bfcfcb8bd64b4da3a58461d8a6e2cfbbf1b1ac4bc537cf307b",
          "name": "ose-csi-external-resizer-rhel8-v4.8"
        },
        {
          "digest": "sha256:bca38e3c695cf2bbb338b4933982f6892782b7fec14a1c835cb5a08c1cc7a14c",
          "image": "registry.redhat.io/openshift4/ose-csi-external-snapshotter-rhel8@sha256:bca38e3c695cf2bbb338b4933982f6892782b7fec14a1c835cb5a08c1cc7a14c",
          "name": "ose-csi-external-snapshotter-rhel8-v4.8"
        },
        {
          "digest": "sha256:9ffed943cdc9597803faedfac8891b963e08ec86f4cb21a59ae7c37adc5ce349",
          "image": "registry.redhat.io/openshift4/ose-csi-external-attacher@sha256:9ffed943cdc9597803faedfac8891b963e08ec86f4cb21a59ae7c37adc5ce349",
          "name": "ose-csi-external-attacher-v4.9"
        },
        {
          "digest": "sha256:ea0797b04595d1bf46ca5d3b205cead25c70e8c252e844551944079000a3fbe1",
          "image": "registry.redhat.io/openshift4/ose-csi-external-provisioner@sha256:ea0797b04595d1bf46ca5d3b205cead25c70e8c252e844551944079000a3fbe1",
          "name": "ose-csi-external-provisioner-v4.9"
        },
        {
          "digest": "sha256:4ca6d4d2f88eb0435084e1e0703330181e69e9c5c205ce21071d30fce864efde",
          "image": "registry.redhat.io/openshift4/ose-csi-node-driver-registrar-rhel8@sha256:4ca6d4d2f88eb0435084e1e0703330181e69e9c5c205ce21071d30fce864efde",
          "name": "ose-csi-node-driver-registrar-v4.9"
        },
        {
          "digest": "sha256:7c9816e9265dcc83af534a61175814e174ec10c1b411e71baf5d379ceeca1ecd",
          "image": "registry.redhat.io/openshift4/ose-csi-livenessprobe@sha256:7c9816e9265dcc83af534a61175814e174ec10c1b411e71baf5d379ceeca1ecd",
          "name": "ose-csi-livenessprobe-v4.9"
        },
        {
          "digest": "sha256:49ed3001a156015c3acbe5ef058f9acbb471b456535e7d56f6baec742527de74",
          "image": "registry.redhat.io/openshift4/ose-csi-external-resizer-rhel8@sha256:49ed3001a156015c3acbe5ef058f9acbb471b456535e7d56f6baec742527de74",
          "name": "ose-csi-external-resizer-rhel8-v4.9"
        },
        {
          "digest": "sha256:3ce747b7e19c5d0fa095fdeb29db3c9133575d24d941bad8ef6e71130c3f3883",
          "image": "registry.redhat.io/openshift4/ose-csi-external-snapshotter-rhel8@sha256:3ce747b7e19c5d0fa095fdeb29db3c9133575d24d941bad8ef6e71130c3f3883",
          "name": "ose-csi-external-snapshotter-rhel8-v4.9"
        },
        {
          "digest": "sha256:1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2",
          "image": "registry.connect.redhat.com/nec/nspc-operator@sha256:1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2",
          "name": "nspc-operator-1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2-annotation"
        },
        {
          "digest": "sha256:1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2",
          "image": "registry.connect.redhat.com/nec/nspc-operator@sha256:1ccfd3a8b7e730e2fb83480399385f4f68d6f9cbb8e55caf9c4a6307f916fbd2",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "1.9.0",
      "version_original": "1.9.0"
    },
    {
      "_id": "629e455c706b4bf5cee71131",
      "alm_examples": [
        {
          "api_version": "crunchydata.com/v1",
          "kind": "Pgcluster",
          "metadata": {
            "annotations": {
              "current-primary": "hippo"
            },
            "labels": {
              "crunchy-pgha-scope": "hippo",
              "deployment-name": "hippo",
              "name": "hippo",
              "namespace": "pgo",
              "pg-cluster": "hippo",
              "pgo-version": "4.7.5"
            },
            "name": "hippo"
          },
          "spec": {
            "BackrestStorage": {
              "accessmode": "ReadWriteMany",
              "matchLabels": "",
              "name": "",
              "size": "5Gi",
              "storageclass": "",
              "storagetype": "dynamic",
              "supplementalgroups": ""
            },
            "PrimaryStorage": {
              "accessmode": "ReadWriteMany",
              "matchLabels": "",
              "name": "hippo",
              "size": "5Gi",
              "storageclass": "",
              "storagetype": "dynamic",
              "supplementalgroups": ""
            },
            "ReplicaStorage": {
              "accessmode": "ReadWriteMany",
              "matchLabels": "",
              "name": "",
              "size": "5Gi",
              "storageclass": "",
              "storagetype": "dynamic",
              "supplementalgroups": ""
            },
            "ccpimage": "crunchy-postgres-ha",
            "ccpimagetag": "ubi8-13.6-4.7.5",
            "clustername": "hippo",
            "database": "hippo",
            "exporterport": "9187",
            "name": "hippo",
            "namespace": "pgo",
            "pgbadgerport": "10000",
            "podAntiAffinity": {
              "default": "preferred"
            },
            "port": "5432",
            "user": "hippo",
            "userlabels": {
              "pgo-version": "4.7.5"
            }
          }
        },
        {
          "api_version": "crunchydata.com/v1",
          "kind": "Pgreplica",
          "metadata": {
            "name": "example"
          },
          "spec": {}
        },
        {
          "api_version": "crunchydata.com/v1",
          "kind": "Pgpolicy",
          "metadata": {
            "name": "example"
          },
          "spec": {}
        },
        {
          "api_version": "crunchydata.com/v1",
          "kind": "Pgtask",
          "metadata": {
            "name": "example"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/crunchydata/postgres-operator-bundle@sha256:8ae562b0c37aeffd811263713d8577df0ce88dfc57aef83fb081cf957fbe2d1b",
      "bundle_path_digest": "sha256:8ae562b0c37aeffd811263713d8577df0ce88dfc57aef83fb081cf957fbe2d1b",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-06T18:20:12.633000+00:00",
      "csv_description": "Crunchy PostgreSQL for OpenShift lets you run your own production-grade PostgreSQL-as-a-Service on OpenShift!\n\nPowered by the Crunchy [PostgreSQL Operator](https://github.com/CrunchyData/postgres-operator), Crunchy PostgreSQL\nfor OpenShift automates and simplifies deploying and managing open source PostgreSQL clusters on OpenShift by\nproviding the essential features you need to keep your PostgreSQL clusters up and running, including:\n\n- **PostgreSQL Cluster Provisioning**: [Create, Scale, & Delete PostgreSQL clusters with ease][provisioning],\n  while fully customizing your Pods and PostgreSQL configuration!\n- **High-Availability**: Safe, automated failover backed by a [distributed consensus based high-availability solution][high-availability].\n  Uses [Pod Anti-Affinity][k8s-anti-affinity] to help resiliency; you can configure how aggressive this can be!\n  Failed primaries automatically heal, allowing for faster recovery time. You can even create regularly scheduled\n  backups as well and set your backup retention policy\n- **Disaster Recovery**: Backups and restores leverage the open source [pgBackRest][] utility\n  and [includes support for full, incremental, and differential backups as well as efficient delta restores][disaster-recovery].\n  Set how long you want your backups retained for. Works great with very large databases!\n- **Monitoring**: Track the health of your PostgreSQL clusters using the open source [pgMonitor][] library.\n- **Clone**: Create new clusters from your existing clusters or backups with a single [`pgo create cluster --restore-from`][pgo-create-cluster] command.\n- **TLS**: Secure communication between your applications and data servers by [enabling TLS for your PostgreSQL servers][pgo-task-tls], including the ability to enforce that all of your connections to use TLS.\n- **Connection Pooling**: Use [pgBouncer][] for connection pooling\n- **Affinity and Tolerations**: Have your PostgreSQL clusters deployed to [Kubernetes Nodes][k8s-nodes] of your preference with [node affinity][high-availability-node-affinity], or designate which nodes Kubernetes can schedule PostgreSQL instances to with Kubernetes [tolerations][high-availability-tolerations].\n- **Full Customizability**: Crunchy PostgreSQL for OpenShift makes it easy to get your own PostgreSQL-as-a-Service up and running on\n  and lets make further enhancements to customize your deployments, including:\n    - Selecting different storage classes for your primary, replica, and backup storage\n    - Select your own container resources class for each PostgreSQL cluster deployment; differentiate between resources applied for primary and replica clusters!\n    - Use your own container image repository, including support `imagePullSecrets` and private repositories\n    - Bring your own trusted certificate authority (CA) for use with the Operator API server\n    - Override your PostgreSQL configuration for each cluster\n\nand much more!\n\n[disaster-recovery]: https://access.crunchydata.com/documentation/postgres-operator/latest/architecture/disaster-recovery/\n[high-availability]: https://access.crunchydata.com/documentation/postgres-operator/latest/architecture/high-availability/\n[high-availability-node-affinity]: https://access.crunchydata.com/documentation/postgres-operator/latest/architecture/high-availability/#node-affinity\n[high-availability-tolerations]: https://access.crunchydata.com/documentation/postgres-operator/latest/architecture/high-availability/#tolerations\n[pgo-create-cluster]: https://access.crunchydata.com/documentation/postgres-operator/latest/pgo-client/reference/pgo_create_cluster/\n[pgo-task-tls]: https://access.crunchydata.com/documentation/postgres-operator/latest/tutorial/tls/\n[provisioning]: https://access.crunchydata.com/documentation/postgres-operator/latest/architecture/provisioning/\n\n[k8s-anti-affinity]: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n[k8s-nodes]: https://kubernetes.io/docs/concepts/architecture/nodes/\n\n[pgBackRest]: https://www.pgbackrest.org\n[pgBouncer]: https://access.crunchydata.com/documentation/postgres-operator/latest/tutorial/pgbouncer/\n[pgMonitor]: https://github.com/CrunchyData/pgmonitor\n\n## Pre-Installation\n\nThere are a few manual steps that the cluster administrator must perform prior to installing the PostgreSQL Operator.\nAt the very least, it must be provided with an initial configuration.\n\nFirst, select a namespace in which to install the PostgreSQL Operator. PostgreSQL clusters will also be deployed here.\nIf it does not exist, create it now.\n\n```\nexport PGO_OPERATOR_NAMESPACE=pgo\noc create namespace \"$PGO_OPERATOR_NAMESPACE\"\n```\n\n### Security\n\nFor the PostgreSQL Operator and PostgreSQL clusters to run in the recommended `restricted` [Security Context Constraint][],\nedit `conf/postgres-operator/pgo.yaml` and set `DisableFSGroup` to `true`.\n\n[Security Context Constraint]: https://docs.openshift.com/container-platform/latest/authentication/managing-security-context-constraints.html\n\n### Secrets (optional)\n\nIf you plan to use AWS S3 to store backups, you can configure your environment to automatically provide your AWS S3 credentials to all newly created PostgreSQL clusters:\n\n```\noc -n \"$PGO_OPERATOR_NAMESPACE\" create secret generic pgo-backrest-repo-config \\\n  --from-literal=aws-s3-key=\"<your-aws-s3-key>\" \\\n  --from-literal=aws-s3-key-secret=\"<your-aws-s3-key-secret>\"\noc -n \"$PGO_OPERATOR_NAMESPACE\" label secret pgo-backrest-repo-config vendor=crunchydata\n```\n\n### Certificates (optional)\n\nThe PostgreSQL Operator has an API that uses TLS to communicate securely with clients. If one is not provided, the API will automatically generated one for you.\n\nIf you have a certificate bundle validated by your organization, you can install it now.\n\n```\noc -n \"$PGO_OPERATOR_NAMESPACE\" create secret tls pgo.tls \\\n  --cert=/path/to/server.crt \\\n  --key=/path/to/server.key\n```\n\nOnce these resources are in place, the PostgreSQL Operator can be installed into the cluster.\n\n## Installation\n\nYou can now go ahead and install the PostgreSQL Operator from OperatorHub.\n\n### Security\n\nFor the PostgreSQL Operator and PostgreSQL clusters to run in the recommended `restricted` [Security Context Constraint][],\nedit the ConfigMap `pgo-config`, find the `pgo.yaml` entry, and set `DisableFSGroup` to `true`.\n\n[Security Context Constraint]: https://docs.openshift.com/container-platform/latest/authentication/managing-security-context-constraints.html\n\nYou will have to scale the `postgres-operator` Deployment down and up for the above change to take effect:\n\n```\noc -n pgo scale --replicas 0 deployment/postgres-operator\noc -n pgo scale --replicas 1 deployment/postgres-operator\n```\n\n## Post-Installation\n\n### Tutorial\n\nFor a guide on how to perform many of the daily functions of the PostgreSQL Operator, we recommend that you read the [Postgres Operator tutorial][pgo-tutorial]\n\n[pgo-tutorial]: https://access.crunchydata.com/documentation/postgres-operator/latest/tutorial/create-cluster/\n\nHowever, the below guide will show you how to create a Postgres cluster from a custom resource or from using the `pgo-client`.\n\n### Create a PostgreSQL Cluster from a Custom Resource\n\nThe fundamental workflow for interfacing with a PostgreSQL Operator Custom\nResource Definition is for creating a PostgreSQL cluster. There are several\nthat a PostgreSQL cluster requires to be deployed, including:\n\n- Secrets\n  - Information for setting up a pgBackRest repository\n  - PostgreSQL superuser bootstrap credentials\n  - PostgreSQL replication user bootstrap credentials\n  - PostgresQL standard user bootstrap credentials\n\nAdditionally, if you want to add some of the other sidecars, you may need to\ncreate additional secrets.\n\nThe good news is that if you do not provide these objects, the PostgreSQL\nOperator will create them for you to get your Postgres cluster up and running!\n\nThe following goes through how to create a PostgreSQL cluster called\n`hippo` by creating a new custom resource.\n\n```\n# this variable is the name of the cluster being created\nexport pgo_cluster_name=hippo\n# this variable is the namespace the cluster is being deployed into\nexport cluster_namespace=pgo\n# this variable is set to the location of your image repository\nexport cluster_image_prefix=registry.developers.crunchydata.com/crunchydata\n\ncat <<-EOF > \"${pgo_cluster_name}-pgcluster.yaml\"\napiVersion: crunchydata.com/v1\nkind: Pgcluster\nmetadata:\n  annotations:\n    current-primary: ${pgo_cluster_name}\n  labels:\n    crunchy-pgha-scope: ${pgo_cluster_name}\n    deployment-name: ${pgo_cluster_name}\n    name: ${pgo_cluster_name}\n    pg-cluster: ${pgo_cluster_name}\n    pgo-version: 4.7.5\n    pgouser: admin\n  name: ${pgo_cluster_name}\n  namespace: ${cluster_namespace}\nspec:\n  BackrestStorage:\n    accessmode: ReadWriteMany\n    matchLabels: \"\"\n    name: \"\"\n    size: 1G\n    storageclass: \"\"\n    storagetype: create\n    supplementalgroups: \"\"\n  PrimaryStorage:\n    accessmode: ReadWriteMany\n    matchLabels: \"\"\n    name: ${pgo_cluster_name}\n    size: 1G\n    storageclass: \"\"\n    storagetype: create\n    supplementalgroups: \"\"\n  ReplicaStorage:\n    accessmode: ReadWriteMany\n    matchLabels: \"\"\n    name: \"\"\n    size: 1G\n    storageclass: \"\"\n    storagetype: create\n    supplementalgroups: \"\"\n  annotations: {}\n  ccpimage: crunchy-postgres-ha\n  ccpimageprefix: ${cluster_image_prefix}\n  ccpimagetag: centos8-13.6-4.7.5\n  clustername: ${pgo_cluster_name}\n  database: ${pgo_cluster_name}\n  exporterport: \"9187\"\n  limits: {}\n  name: ${pgo_cluster_name}\n  pgDataSource:\n    restoreFrom: \"\"\n    restoreOpts: \"\"\n  pgbadgerport: \"10000\"\n  pgoimageprefix: ${cluster_image_prefix}\n  podAntiAffinity:\n    default: preferred\n    pgBackRest: preferred\n    pgBouncer: preferred\n  port: \"5432\"\n  tolerations: []\n  user: hippo\n  userlabels:\n    pgo-version: 4.7.5\nEOF\n\noc apply -f \"${pgo_cluster_name}-pgcluster.yaml\"\n```\n\nAnd that's all! The PostgreSQL Operator will go ahead and create the cluster.\n\nIf you have the PostgreSQL client `psql` installed on your host machine, you can\ntest connection to the PostgreSQL cluster using the following command:\n\n```\n# namespace that the cluster is running in\nexport PGO_OPERATOR_NAMESPACE=pgo\n# name of the cluster\nexport pgo_cluster_name=hippo\n# name of the user whose password we want to get\nexport pgo_cluster_username=hippo\n\n# get the password of the user and set it to a recognized psql environmental variable\nexport PGPASSWORD=$(oc -n \"${PGO_OPERATOR_NAMESPACE}\" get secrets \\\n  \"${pgo_cluster_name}-${pgo_cluster_username}-secret\" -o \"jsonpath={.data['password']}\" | base64 -d)\n\n# set up a port-forward either in a new terminal, or in the same terminal in the background:\noc -n pgo port-forward svc/hippo 5432:5432 &\n\npsql -h localhost -U \"${pgo_cluster_username}\" \"${pgo_cluster_name}\"\n```\n\n### Create a PostgreSQL Cluster the `pgo` Client\n\nOnce the PostgreSQL Operator is installed in your OpenShift cluster, you will need to do a few things\nto use the [PostgreSQL Operator Client][pgo-client].\n\n[pgo-client]: https://access.crunchydata.com/documentation/postgres-operator/latest/pgo-client/\n\nInstall the first set of client credentials and download the `pgo` binary and client certificates.\n\n```\ncurl https://raw.githubusercontent.com/CrunchyData/postgres-operator/v4.7.5/deploy/install-bootstrap-creds.sh > install-bootstrap-creds.sh\ncurl https://raw.githubusercontent.com/CrunchyData/postgres-operator/v4.7.5/installers/kubectl/client-setup.sh > client-setup.sh\n\nchmod +x install-bootstrap-creds.sh client-setup.sh\n\nPGO_CMD=oc ./install-bootstrap-creds.sh\nPGO_CMD=oc ./client-setup.sh\n```\n\nThe client needs to be able to reach the PostgreSQL Operator API from outside the OpenShift cluster.\nCreate an external service or forward a port locally.\n\n```\noc -n \"$PGO_OPERATOR_NAMESPACE\" expose deployment postgres-operator\noc -n \"$PGO_OPERATOR_NAMESPACE\" create route passthrough postgres-operator --service=postgres-operator\n\nexport PGO_APISERVER_URL=\"https://$(oc -n \"$PGO_OPERATOR_NAMESPACE\" get route postgres-operator -o jsonpath=\"{.spec.host}\")\"\n```\n_or_\n```\noc -n \"$PGO_OPERATOR_NAMESPACE\" port-forward deployment/postgres-operator 8443\n\nexport PGO_APISERVER_URL=\"https://127.0.0.1:8443\"\n```\n\nVerify connectivity using the `pgo` command.\n\n```\npgo version\n# pgo client version 4.7.5\n# pgo-apiserver version 4.7.5\n```\n\n\nYou can then create a cluster with the `pgo` client as simply as this:\n\n```\npgo create cluster -n pgo hippo\n```\n\nThe cluster may take a few moments to provision. You can verify that the cluster is up and running by using the `pgo test` command:\n\n```\npgo test cluster -n pgo hippo\n```\n\nIf you have the PostgreSQL client `psql` installed on your host machine, you can\ntest connection to the PostgreSQL cluster using the following command:\n\n```\n# namespace that the cluster is running in\nexport PGO_OPERATOR_NAMESPACE=pgo\n# name of the cluster\nexport pgo_cluster_name=hippo\n# name of the user whose password we want to get\nexport pgo_cluster_username=hippo\n\n# get the password of the user and set it to a recognized psql environmental variable\nexport PGPASSWORD=$(kubectl -n \"${PGO_OPERATOR_NAMESPACE}\" get secrets \\\n  \"${pgo_cluster_name}-${pgo_cluster_username}-secret\" -o \"jsonpath={.data['password']}\" | base64 -d)\n\n# set up a port-forward either in a new terminal, or in the same terminal in the background:\nkubectl -n pgo port-forward svc/hippo 5432:5432 &\n\npsql -h localhost -U \"${pgo_cluster_username}\" \"${pgo_cluster_name}\"\n```",
      "csv_display_name": "Crunchy PostgreSQL for OpenShift",
      "csv_metadata_description": "Enterprise open source PostgreSQL-as-a-Service",
      "csv_name": "postgresoperator.v4.7.5",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-08-15T13:07:16.298000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "crunchy-postgres-operator",
      "provided_apis": [
        {
          "group": "crunchydata.com",
          "kind": "Pgcluster",
          "plural": "pgclusters",
          "version": "v1"
        },
        {
          "group": "crunchydata.com",
          "kind": "Pgpolicy",
          "plural": "pgpolicies",
          "version": "v1"
        },
        {
          "group": "crunchydata.com",
          "kind": "Pgreplica",
          "plural": "pgreplicas",
          "version": "v1"
        },
        {
          "group": "crunchydata.com",
          "kind": "Pgtask",
          "plural": "pgtasks",
          "version": "v1"
        }
      ],
      "provider": "Crunchy Data",
      "related_images": [
        {
          "digest": "sha256:d9f91cb300615bcf39e610abd4741ff6be3d13418db4260f9409395a2a5c1ecb",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:d9f91cb300615bcf39e610abd4741ff6be3d13418db4260f9409395a2a5c1ecb",
          "name": "postgres-operator-d9f91cb300615bcf39e610abd4741ff6be3d13418db4260f9409395a2a5c1ecb-annotation"
        },
        {
          "digest": "sha256:86b5b293c263667dfc5016fc587643261438bd8868cc1c523ccb77a7c4e1b85a",
          "image": "registry.connect.redhat.com/crunchydata/pgo-apiserver@sha256:86b5b293c263667dfc5016fc587643261438bd8868cc1c523ccb77a7c4e1b85a",
          "name": "apiserver"
        },
        {
          "digest": "sha256:d9f91cb300615bcf39e610abd4741ff6be3d13418db4260f9409395a2a5c1ecb",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:d9f91cb300615bcf39e610abd4741ff6be3d13418db4260f9409395a2a5c1ecb",
          "name": "operator"
        },
        {
          "digest": "sha256:481c48699d7ba6aefc7ad27b43e4df54b8f8686f3445cf303a45bd43ceec4244",
          "image": "registry.connect.redhat.com/crunchydata/pgo-scheduler@sha256:481c48699d7ba6aefc7ad27b43e4df54b8f8686f3445cf303a45bd43ceec4244",
          "name": "scheduler"
        },
        {
          "digest": "sha256:bcc9f68cfce901352408e4645f7c6aa5d2157af93952b9124c3a20923e4f1288",
          "image": "registry.connect.redhat.com/crunchydata/pgo-event@sha256:bcc9f68cfce901352408e4645f7c6aa5d2157af93952b9124c3a20923e4f1288",
          "name": "event"
        },
        {
          "digest": "sha256:0016bf993af9ed5fdfdbbd56b1e743d1991ed390a4800cf1a04cdf55cafe119a",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbackrest@sha256:0016bf993af9ed5fdfdbbd56b1e743d1991ed390a4800cf1a04cdf55cafe119a",
          "name": "pgo_backrest"
        },
        {
          "digest": "sha256:2991db135d2158fbb496afaabee221c432e13d11767e90130f4b2b5c2912a6b5",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbackrest-repo@sha256:2991db135d2158fbb496afaabee221c432e13d11767e90130f4b2b5c2912a6b5",
          "name": "pgo_backrest_repo"
        },
        {
          "digest": "sha256:dabd59ff8e97a06e5e823c33805da6f66300c43c8b315cfd7ab0315bd92803e1",
          "image": "registry.connect.redhat.com/crunchydata/pgo-client@sha256:dabd59ff8e97a06e5e823c33805da6f66300c43c8b315cfd7ab0315bd92803e1",
          "name": "pgo_client"
        },
        {
          "digest": "sha256:c44507bfc3286017afef0697133595043256b8b595e1e2e470b6ff7598cff575",
          "image": "registry.connect.redhat.com/crunchydata/pgo-rmdata@sha256:c44507bfc3286017afef0697133595043256b8b595e1e2e470b6ff7598cff575",
          "name": "pgo_rmdata"
        },
        {
          "digest": "sha256:79d658ec93a10951cd06950e753f92332ea07ce191197213e14f4dc6042cc9f1",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-exporter@sha256:79d658ec93a10951cd06950e753f92332ea07ce191197213e14f4dc6042cc9f1",
          "name": "crunchy_postgres_exporter"
        },
        {
          "digest": "sha256:77e508924d2358af0f3a8f597f7f59c38f7aecda2af9014ab9438d35f503de9c",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgadmin4@sha256:77e508924d2358af0f3a8f597f7f59c38f7aecda2af9014ab9438d35f503de9c",
          "name": "crunchy_pgadmin"
        },
        {
          "digest": "sha256:8850ac1be18d01b7dee9bb0f61d453c787961985bc84df3bc8c1595962a00fab",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbadger@sha256:8850ac1be18d01b7dee9bb0f61d453c787961985bc84df3bc8c1595962a00fab",
          "name": "crunchy_pgbadger"
        },
        {
          "digest": "sha256:a339798a1712a3a3bcf303e6df8186460edfb47aca0e2ae4cadf9db2207d72d6",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbouncer@sha256:a339798a1712a3a3bcf303e6df8186460edfb47aca0e2ae4cadf9db2207d72d6",
          "name": "crunchy_pgbouncer"
        },
        {
          "digest": "sha256:ea787e002ce3aee1b8c54127816885b07c1f063515fa5b80ce957676f4e0a21b",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-ha@sha256:ea787e002ce3aee1b8c54127816885b07c1f063515fa5b80ce957676f4e0a21b",
          "name": "crunchy_postgres_ha"
        },
        {
          "digest": "sha256:f0d2c8df4adb038af6be43089d96af02afd88b82568a2da342d8d97e1fa4ba8f",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis-ha@sha256:f0d2c8df4adb038af6be43089d96af02afd88b82568a2da342d8d97e1fa4ba8f",
          "name": "crunchy_postgres_gis_ha"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "4.7.5",
      "version_original": "4.7.5"
    },
    {
      "_id": "629e48b75bfb3ed63084b31d",
      "alm_examples": [
        {
          "api_version": "crunchydata.com/v1",
          "kind": "Pgcluster",
          "metadata": {
            "annotations": {
              "current-primary": "hippo"
            },
            "labels": {
              "crunchy-pgha-scope": "hippo",
              "deployment-name": "hippo",
              "name": "hippo",
              "namespace": "pgo",
              "pg-cluster": "hippo",
              "pgo-version": "4.7.5"
            },
            "name": "hippo"
          },
          "spec": {
            "BackrestStorage": {
              "accessmode": "ReadWriteMany",
              "matchLabels": "",
              "name": "",
              "size": "5Gi",
              "storageclass": "",
              "storagetype": "dynamic",
              "supplementalgroups": ""
            },
            "PrimaryStorage": {
              "accessmode": "ReadWriteMany",
              "matchLabels": "",
              "name": "hippo",
              "size": "5Gi",
              "storageclass": "",
              "storagetype": "dynamic",
              "supplementalgroups": ""
            },
            "ReplicaStorage": {
              "accessmode": "ReadWriteMany",
              "matchLabels": "",
              "name": "",
              "size": "5Gi",
              "storageclass": "",
              "storagetype": "dynamic",
              "supplementalgroups": ""
            },
            "ccpimage": "crunchy-postgres-ha",
            "ccpimagetag": "ubi8-13.6-4.7.5",
            "clustername": "hippo",
            "database": "hippo",
            "exporterport": "9187",
            "name": "hippo",
            "namespace": "pgo",
            "pgbadgerport": "10000",
            "podAntiAffinity": {
              "default": "preferred"
            },
            "port": "5432",
            "user": "hippo",
            "userlabels": {
              "pgo-version": "4.7.5"
            }
          }
        },
        {
          "api_version": "crunchydata.com/v1",
          "kind": "Pgreplica",
          "metadata": {
            "name": "example"
          },
          "spec": {}
        },
        {
          "api_version": "crunchydata.com/v1",
          "kind": "Pgpolicy",
          "metadata": {
            "name": "example"
          },
          "spec": {}
        },
        {
          "api_version": "crunchydata.com/v1",
          "kind": "Pgtask",
          "metadata": {
            "name": "example"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/crunchydata/postgres-operator-bundle@sha256:8ae562b0c37aeffd811263713d8577df0ce88dfc57aef83fb081cf957fbe2d1b",
      "bundle_path_digest": "sha256:8ae562b0c37aeffd811263713d8577df0ce88dfc57aef83fb081cf957fbe2d1b",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-06T18:34:31.755000+00:00",
      "csv_description": "Crunchy PostgreSQL for OpenShift lets you run your own production-grade PostgreSQL-as-a-Service on OpenShift!\n\nPowered by the Crunchy [PostgreSQL Operator](https://github.com/CrunchyData/postgres-operator), Crunchy PostgreSQL\nfor OpenShift automates and simplifies deploying and managing open source PostgreSQL clusters on OpenShift by\nproviding the essential features you need to keep your PostgreSQL clusters up and running, including:\n\n- **PostgreSQL Cluster Provisioning**: [Create, Scale, & Delete PostgreSQL clusters with ease][provisioning],\n  while fully customizing your Pods and PostgreSQL configuration!\n- **High-Availability**: Safe, automated failover backed by a [distributed consensus based high-availability solution][high-availability].\n  Uses [Pod Anti-Affinity][k8s-anti-affinity] to help resiliency; you can configure how aggressive this can be!\n  Failed primaries automatically heal, allowing for faster recovery time. You can even create regularly scheduled\n  backups as well and set your backup retention policy\n- **Disaster Recovery**: Backups and restores leverage the open source [pgBackRest][] utility\n  and [includes support for full, incremental, and differential backups as well as efficient delta restores][disaster-recovery].\n  Set how long you want your backups retained for. Works great with very large databases!\n- **Monitoring**: Track the health of your PostgreSQL clusters using the open source [pgMonitor][] library.\n- **Clone**: Create new clusters from your existing clusters or backups with a single [`pgo create cluster --restore-from`][pgo-create-cluster] command.\n- **TLS**: Secure communication between your applications and data servers by [enabling TLS for your PostgreSQL servers][pgo-task-tls], including the ability to enforce that all of your connections to use TLS.\n- **Connection Pooling**: Use [pgBouncer][] for connection pooling\n- **Affinity and Tolerations**: Have your PostgreSQL clusters deployed to [Kubernetes Nodes][k8s-nodes] of your preference with [node affinity][high-availability-node-affinity], or designate which nodes Kubernetes can schedule PostgreSQL instances to with Kubernetes [tolerations][high-availability-tolerations].\n- **Full Customizability**: Crunchy PostgreSQL for OpenShift makes it easy to get your own PostgreSQL-as-a-Service up and running on\n  and lets make further enhancements to customize your deployments, including:\n    - Selecting different storage classes for your primary, replica, and backup storage\n    - Select your own container resources class for each PostgreSQL cluster deployment; differentiate between resources applied for primary and replica clusters!\n    - Use your own container image repository, including support `imagePullSecrets` and private repositories\n    - Bring your own trusted certificate authority (CA) for use with the Operator API server\n    - Override your PostgreSQL configuration for each cluster\n\nand much more!\n\n[disaster-recovery]: https://access.crunchydata.com/documentation/postgres-operator/latest/architecture/disaster-recovery/\n[high-availability]: https://access.crunchydata.com/documentation/postgres-operator/latest/architecture/high-availability/\n[high-availability-node-affinity]: https://access.crunchydata.com/documentation/postgres-operator/latest/architecture/high-availability/#node-affinity\n[high-availability-tolerations]: https://access.crunchydata.com/documentation/postgres-operator/latest/architecture/high-availability/#tolerations\n[pgo-create-cluster]: https://access.crunchydata.com/documentation/postgres-operator/latest/pgo-client/reference/pgo_create_cluster/\n[pgo-task-tls]: https://access.crunchydata.com/documentation/postgres-operator/latest/tutorial/tls/\n[provisioning]: https://access.crunchydata.com/documentation/postgres-operator/latest/architecture/provisioning/\n\n[k8s-anti-affinity]: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n[k8s-nodes]: https://kubernetes.io/docs/concepts/architecture/nodes/\n\n[pgBackRest]: https://www.pgbackrest.org\n[pgBouncer]: https://access.crunchydata.com/documentation/postgres-operator/latest/tutorial/pgbouncer/\n[pgMonitor]: https://github.com/CrunchyData/pgmonitor\n\n## Pre-Installation\n\nThere are a few manual steps that the cluster administrator must perform prior to installing the PostgreSQL Operator.\nAt the very least, it must be provided with an initial configuration.\n\nFirst, select a namespace in which to install the PostgreSQL Operator. PostgreSQL clusters will also be deployed here.\nIf it does not exist, create it now.\n\n```\nexport PGO_OPERATOR_NAMESPACE=pgo\noc create namespace \"$PGO_OPERATOR_NAMESPACE\"\n```\n\n### Security\n\nFor the PostgreSQL Operator and PostgreSQL clusters to run in the recommended `restricted` [Security Context Constraint][],\nedit `conf/postgres-operator/pgo.yaml` and set `DisableFSGroup` to `true`.\n\n[Security Context Constraint]: https://docs.openshift.com/container-platform/latest/authentication/managing-security-context-constraints.html\n\n### Secrets (optional)\n\nIf you plan to use AWS S3 to store backups, you can configure your environment to automatically provide your AWS S3 credentials to all newly created PostgreSQL clusters:\n\n```\noc -n \"$PGO_OPERATOR_NAMESPACE\" create secret generic pgo-backrest-repo-config \\\n  --from-literal=aws-s3-key=\"<your-aws-s3-key>\" \\\n  --from-literal=aws-s3-key-secret=\"<your-aws-s3-key-secret>\"\noc -n \"$PGO_OPERATOR_NAMESPACE\" label secret pgo-backrest-repo-config vendor=crunchydata\n```\n\n### Certificates (optional)\n\nThe PostgreSQL Operator has an API that uses TLS to communicate securely with clients. If one is not provided, the API will automatically generated one for you.\n\nIf you have a certificate bundle validated by your organization, you can install it now.\n\n```\noc -n \"$PGO_OPERATOR_NAMESPACE\" create secret tls pgo.tls \\\n  --cert=/path/to/server.crt \\\n  --key=/path/to/server.key\n```\n\nOnce these resources are in place, the PostgreSQL Operator can be installed into the cluster.\n\n## Installation\n\nYou can now go ahead and install the PostgreSQL Operator from OperatorHub.\n\n### Security\n\nFor the PostgreSQL Operator and PostgreSQL clusters to run in the recommended `restricted` [Security Context Constraint][],\nedit the ConfigMap `pgo-config`, find the `pgo.yaml` entry, and set `DisableFSGroup` to `true`.\n\n[Security Context Constraint]: https://docs.openshift.com/container-platform/latest/authentication/managing-security-context-constraints.html\n\nYou will have to scale the `postgres-operator` Deployment down and up for the above change to take effect:\n\n```\noc -n pgo scale --replicas 0 deployment/postgres-operator\noc -n pgo scale --replicas 1 deployment/postgres-operator\n```\n\n## Post-Installation\n\n### Tutorial\n\nFor a guide on how to perform many of the daily functions of the PostgreSQL Operator, we recommend that you read the [Postgres Operator tutorial][pgo-tutorial]\n\n[pgo-tutorial]: https://access.crunchydata.com/documentation/postgres-operator/latest/tutorial/create-cluster/\n\nHowever, the below guide will show you how to create a Postgres cluster from a custom resource or from using the `pgo-client`.\n\n### Create a PostgreSQL Cluster from a Custom Resource\n\nThe fundamental workflow for interfacing with a PostgreSQL Operator Custom\nResource Definition is for creating a PostgreSQL cluster. There are several\nthat a PostgreSQL cluster requires to be deployed, including:\n\n- Secrets\n  - Information for setting up a pgBackRest repository\n  - PostgreSQL superuser bootstrap credentials\n  - PostgreSQL replication user bootstrap credentials\n  - PostgresQL standard user bootstrap credentials\n\nAdditionally, if you want to add some of the other sidecars, you may need to\ncreate additional secrets.\n\nThe good news is that if you do not provide these objects, the PostgreSQL\nOperator will create them for you to get your Postgres cluster up and running!\n\nThe following goes through how to create a PostgreSQL cluster called\n`hippo` by creating a new custom resource.\n\n```\n# this variable is the name of the cluster being created\nexport pgo_cluster_name=hippo\n# this variable is the namespace the cluster is being deployed into\nexport cluster_namespace=pgo\n# this variable is set to the location of your image repository\nexport cluster_image_prefix=registry.developers.crunchydata.com/crunchydata\n\ncat <<-EOF > \"${pgo_cluster_name}-pgcluster.yaml\"\napiVersion: crunchydata.com/v1\nkind: Pgcluster\nmetadata:\n  annotations:\n    current-primary: ${pgo_cluster_name}\n  labels:\n    crunchy-pgha-scope: ${pgo_cluster_name}\n    deployment-name: ${pgo_cluster_name}\n    name: ${pgo_cluster_name}\n    pg-cluster: ${pgo_cluster_name}\n    pgo-version: 4.7.5\n    pgouser: admin\n  name: ${pgo_cluster_name}\n  namespace: ${cluster_namespace}\nspec:\n  BackrestStorage:\n    accessmode: ReadWriteMany\n    matchLabels: \"\"\n    name: \"\"\n    size: 1G\n    storageclass: \"\"\n    storagetype: create\n    supplementalgroups: \"\"\n  PrimaryStorage:\n    accessmode: ReadWriteMany\n    matchLabels: \"\"\n    name: ${pgo_cluster_name}\n    size: 1G\n    storageclass: \"\"\n    storagetype: create\n    supplementalgroups: \"\"\n  ReplicaStorage:\n    accessmode: ReadWriteMany\n    matchLabels: \"\"\n    name: \"\"\n    size: 1G\n    storageclass: \"\"\n    storagetype: create\n    supplementalgroups: \"\"\n  annotations: {}\n  ccpimage: crunchy-postgres-ha\n  ccpimageprefix: ${cluster_image_prefix}\n  ccpimagetag: centos8-13.6-4.7.5\n  clustername: ${pgo_cluster_name}\n  database: ${pgo_cluster_name}\n  exporterport: \"9187\"\n  limits: {}\n  name: ${pgo_cluster_name}\n  pgDataSource:\n    restoreFrom: \"\"\n    restoreOpts: \"\"\n  pgbadgerport: \"10000\"\n  pgoimageprefix: ${cluster_image_prefix}\n  podAntiAffinity:\n    default: preferred\n    pgBackRest: preferred\n    pgBouncer: preferred\n  port: \"5432\"\n  tolerations: []\n  user: hippo\n  userlabels:\n    pgo-version: 4.7.5\nEOF\n\noc apply -f \"${pgo_cluster_name}-pgcluster.yaml\"\n```\n\nAnd that's all! The PostgreSQL Operator will go ahead and create the cluster.\n\nIf you have the PostgreSQL client `psql` installed on your host machine, you can\ntest connection to the PostgreSQL cluster using the following command:\n\n```\n# namespace that the cluster is running in\nexport PGO_OPERATOR_NAMESPACE=pgo\n# name of the cluster\nexport pgo_cluster_name=hippo\n# name of the user whose password we want to get\nexport pgo_cluster_username=hippo\n\n# get the password of the user and set it to a recognized psql environmental variable\nexport PGPASSWORD=$(oc -n \"${PGO_OPERATOR_NAMESPACE}\" get secrets \\\n  \"${pgo_cluster_name}-${pgo_cluster_username}-secret\" -o \"jsonpath={.data['password']}\" | base64 -d)\n\n# set up a port-forward either in a new terminal, or in the same terminal in the background:\noc -n pgo port-forward svc/hippo 5432:5432 &\n\npsql -h localhost -U \"${pgo_cluster_username}\" \"${pgo_cluster_name}\"\n```\n\n### Create a PostgreSQL Cluster the `pgo` Client\n\nOnce the PostgreSQL Operator is installed in your OpenShift cluster, you will need to do a few things\nto use the [PostgreSQL Operator Client][pgo-client].\n\n[pgo-client]: https://access.crunchydata.com/documentation/postgres-operator/latest/pgo-client/\n\nInstall the first set of client credentials and download the `pgo` binary and client certificates.\n\n```\ncurl https://raw.githubusercontent.com/CrunchyData/postgres-operator/v4.7.5/deploy/install-bootstrap-creds.sh > install-bootstrap-creds.sh\ncurl https://raw.githubusercontent.com/CrunchyData/postgres-operator/v4.7.5/installers/kubectl/client-setup.sh > client-setup.sh\n\nchmod +x install-bootstrap-creds.sh client-setup.sh\n\nPGO_CMD=oc ./install-bootstrap-creds.sh\nPGO_CMD=oc ./client-setup.sh\n```\n\nThe client needs to be able to reach the PostgreSQL Operator API from outside the OpenShift cluster.\nCreate an external service or forward a port locally.\n\n```\noc -n \"$PGO_OPERATOR_NAMESPACE\" expose deployment postgres-operator\noc -n \"$PGO_OPERATOR_NAMESPACE\" create route passthrough postgres-operator --service=postgres-operator\n\nexport PGO_APISERVER_URL=\"https://$(oc -n \"$PGO_OPERATOR_NAMESPACE\" get route postgres-operator -o jsonpath=\"{.spec.host}\")\"\n```\n_or_\n```\noc -n \"$PGO_OPERATOR_NAMESPACE\" port-forward deployment/postgres-operator 8443\n\nexport PGO_APISERVER_URL=\"https://127.0.0.1:8443\"\n```\n\nVerify connectivity using the `pgo` command.\n\n```\npgo version\n# pgo client version 4.7.5\n# pgo-apiserver version 4.7.5\n```\n\n\nYou can then create a cluster with the `pgo` client as simply as this:\n\n```\npgo create cluster -n pgo hippo\n```\n\nThe cluster may take a few moments to provision. You can verify that the cluster is up and running by using the `pgo test` command:\n\n```\npgo test cluster -n pgo hippo\n```\n\nIf you have the PostgreSQL client `psql` installed on your host machine, you can\ntest connection to the PostgreSQL cluster using the following command:\n\n```\n# namespace that the cluster is running in\nexport PGO_OPERATOR_NAMESPACE=pgo\n# name of the cluster\nexport pgo_cluster_name=hippo\n# name of the user whose password we want to get\nexport pgo_cluster_username=hippo\n\n# get the password of the user and set it to a recognized psql environmental variable\nexport PGPASSWORD=$(kubectl -n \"${PGO_OPERATOR_NAMESPACE}\" get secrets \\\n  \"${pgo_cluster_name}-${pgo_cluster_username}-secret\" -o \"jsonpath={.data['password']}\" | base64 -d)\n\n# set up a port-forward either in a new terminal, or in the same terminal in the background:\nkubectl -n pgo port-forward svc/hippo 5432:5432 &\n\npsql -h localhost -U \"${pgo_cluster_username}\" \"${pgo_cluster_name}\"\n```",
      "csv_display_name": "Crunchy PostgreSQL for OpenShift",
      "csv_metadata_description": "Enterprise open source PostgreSQL-as-a-Service",
      "csv_name": "postgresoperator.v4.7.5",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-08-15T13:08:36.266000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "crunchy-postgres-operator",
      "provided_apis": [
        {
          "group": "crunchydata.com",
          "kind": "Pgpolicy",
          "plural": "pgpolicies",
          "version": "v1"
        },
        {
          "group": "crunchydata.com",
          "kind": "Pgreplica",
          "plural": "pgreplicas",
          "version": "v1"
        },
        {
          "group": "crunchydata.com",
          "kind": "Pgtask",
          "plural": "pgtasks",
          "version": "v1"
        },
        {
          "group": "crunchydata.com",
          "kind": "Pgcluster",
          "plural": "pgclusters",
          "version": "v1"
        }
      ],
      "provider": "Crunchy Data",
      "related_images": [
        {
          "digest": "sha256:d9f91cb300615bcf39e610abd4741ff6be3d13418db4260f9409395a2a5c1ecb",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:d9f91cb300615bcf39e610abd4741ff6be3d13418db4260f9409395a2a5c1ecb",
          "name": "postgres-operator-d9f91cb300615bcf39e610abd4741ff6be3d13418db4260f9409395a2a5c1ecb-annotation"
        },
        {
          "digest": "sha256:86b5b293c263667dfc5016fc587643261438bd8868cc1c523ccb77a7c4e1b85a",
          "image": "registry.connect.redhat.com/crunchydata/pgo-apiserver@sha256:86b5b293c263667dfc5016fc587643261438bd8868cc1c523ccb77a7c4e1b85a",
          "name": "apiserver"
        },
        {
          "digest": "sha256:d9f91cb300615bcf39e610abd4741ff6be3d13418db4260f9409395a2a5c1ecb",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:d9f91cb300615bcf39e610abd4741ff6be3d13418db4260f9409395a2a5c1ecb",
          "name": "operator"
        },
        {
          "digest": "sha256:481c48699d7ba6aefc7ad27b43e4df54b8f8686f3445cf303a45bd43ceec4244",
          "image": "registry.connect.redhat.com/crunchydata/pgo-scheduler@sha256:481c48699d7ba6aefc7ad27b43e4df54b8f8686f3445cf303a45bd43ceec4244",
          "name": "scheduler"
        },
        {
          "digest": "sha256:bcc9f68cfce901352408e4645f7c6aa5d2157af93952b9124c3a20923e4f1288",
          "image": "registry.connect.redhat.com/crunchydata/pgo-event@sha256:bcc9f68cfce901352408e4645f7c6aa5d2157af93952b9124c3a20923e4f1288",
          "name": "event"
        },
        {
          "digest": "sha256:0016bf993af9ed5fdfdbbd56b1e743d1991ed390a4800cf1a04cdf55cafe119a",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbackrest@sha256:0016bf993af9ed5fdfdbbd56b1e743d1991ed390a4800cf1a04cdf55cafe119a",
          "name": "pgo_backrest"
        },
        {
          "digest": "sha256:2991db135d2158fbb496afaabee221c432e13d11767e90130f4b2b5c2912a6b5",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbackrest-repo@sha256:2991db135d2158fbb496afaabee221c432e13d11767e90130f4b2b5c2912a6b5",
          "name": "pgo_backrest_repo"
        },
        {
          "digest": "sha256:dabd59ff8e97a06e5e823c33805da6f66300c43c8b315cfd7ab0315bd92803e1",
          "image": "registry.connect.redhat.com/crunchydata/pgo-client@sha256:dabd59ff8e97a06e5e823c33805da6f66300c43c8b315cfd7ab0315bd92803e1",
          "name": "pgo_client"
        },
        {
          "digest": "sha256:c44507bfc3286017afef0697133595043256b8b595e1e2e470b6ff7598cff575",
          "image": "registry.connect.redhat.com/crunchydata/pgo-rmdata@sha256:c44507bfc3286017afef0697133595043256b8b595e1e2e470b6ff7598cff575",
          "name": "pgo_rmdata"
        },
        {
          "digest": "sha256:79d658ec93a10951cd06950e753f92332ea07ce191197213e14f4dc6042cc9f1",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-exporter@sha256:79d658ec93a10951cd06950e753f92332ea07ce191197213e14f4dc6042cc9f1",
          "name": "crunchy_postgres_exporter"
        },
        {
          "digest": "sha256:77e508924d2358af0f3a8f597f7f59c38f7aecda2af9014ab9438d35f503de9c",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgadmin4@sha256:77e508924d2358af0f3a8f597f7f59c38f7aecda2af9014ab9438d35f503de9c",
          "name": "crunchy_pgadmin"
        },
        {
          "digest": "sha256:8850ac1be18d01b7dee9bb0f61d453c787961985bc84df3bc8c1595962a00fab",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbadger@sha256:8850ac1be18d01b7dee9bb0f61d453c787961985bc84df3bc8c1595962a00fab",
          "name": "crunchy_pgbadger"
        },
        {
          "digest": "sha256:a339798a1712a3a3bcf303e6df8186460edfb47aca0e2ae4cadf9db2207d72d6",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbouncer@sha256:a339798a1712a3a3bcf303e6df8186460edfb47aca0e2ae4cadf9db2207d72d6",
          "name": "crunchy_pgbouncer"
        },
        {
          "digest": "sha256:ea787e002ce3aee1b8c54127816885b07c1f063515fa5b80ce957676f4e0a21b",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-ha@sha256:ea787e002ce3aee1b8c54127816885b07c1f063515fa5b80ce957676f4e0a21b",
          "name": "crunchy_postgres_ha"
        },
        {
          "digest": "sha256:f0d2c8df4adb038af6be43089d96af02afd88b82568a2da342d8d97e1fa4ba8f",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis-ha@sha256:f0d2c8df4adb038af6be43089d96af02afd88b82568a2da342d8d97e1fa4ba8f",
          "name": "crunchy_postgres_gis_ha"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "4.7.5",
      "version_original": "4.7.5"
    },
    {
      "_id": "629e4c3e5bfb3ed63084b484",
      "alm_examples": [
        {
          "api_version": "postgres-operator.crunchydata.com/v1beta1",
          "kind": "PostgresCluster",
          "metadata": {
            "name": "example"
          },
          "spec": {
            "instances": [
              {
                "dataVolumeClaimSpec": {
                  "accessModes": [
                    "ReadWriteOnce"
                  ],
                  "resources": {
                    "requests": {
                      "storage": "1Gi"
                    }
                  }
                },
                "replicas": 1
              }
            ],
            "postgresVersion": 13
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/crunchydata/postgres-operator-bundle@sha256:ce40b9bd94ed562963fd298acdad256ef5fe30397aa8ee82e88febfab61f96e4",
      "bundle_path_digest": "sha256:ce40b9bd94ed562963fd298acdad256ef5fe30397aa8ee82e88febfab61f96e4",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "v5",
      "creation_date": "2022-06-06T18:49:34.429000+00:00",
      "csv_description": "[PGO](https://github.com/CrunchyData/postgres-operator), the\n[Postgres Operator](https://github.com/CrunchyData/postgres-operator) from\n[Crunchy Data](https://www.crunchydata.com), gives you a **declarative Postgres** solution that\nautomatically manages your [PostgreSQL](https://www.postgresql.org) clusters.\n\nDesigned for your GitOps workflows, it is [easy to get started](https://access.crunchydata.com/documentation/postgres-operator/v5/quickstart/)\nwith Postgres on Kubernetes with PGO. Within a few moments, you can have a production grade Postgres\ncluster complete with high availability, disaster recovery, and monitoring, all over secure TLS communications.\nEven better, PGO lets you easily customize your Postgres cluster to tailor it to your workload!\n\nWith conveniences like cloning Postgres clusters to using rolling updates to roll out disruptive\nchanges with minimal downtime, PGO is ready to support your Postgres data at every stage of your\nrelease pipeline. Built for resiliency and uptime, PGO will keep your desired Postgres in a desired\nstate so you do not need to worry about it.\n\nPGO is developed with many years of production experience in automating Postgres management on\nKubernetes, providing a seamless cloud native Postgres solution to keep your data always available.\n\n- **PostgreSQL Cluster Provisioning**: [Create, Scale, & Delete PostgreSQL clusters with ease][provisioning],\n  while fully customizing your Pods and PostgreSQL configuration!\n- **High-Availability**: Safe, automated failover backed by a [distributed consensus based high-availability solution][high-availability].\n  Uses [Pod Anti-Affinity][k8s-anti-affinity] to help resiliency; you can configure how aggressive this can be!\n  Failed primaries automatically heal, allowing for faster recovery time. You can even create regularly scheduled\n  backups as well and set your backup retention policy\n- **Disaster Recovery**: [Backups][backups] and [restores][disaster-recovery] leverage the open source [pgBackRest][] utility and\n  [includes support for full, incremental, and differential backups as well as efficient delta restores][backups].\n  Set how long you want your backups retained for. Works great with very large databases!\n- **Monitoring**: [Track the health of your PostgreSQL clusters][monitoring] using the open source [pgMonitor][] library.\n- **Clone**: [Create new clusters from your existing clusters or backups][clone] with efficient data cloning.\n- **TLS**: All connections are over [TLS][tls]. You can also [bring your own TLS infrastructure][tls] if you do not want to use the provided defaults.\n- **Connection Pooling**: Advanced [connection pooling][pool] support using [pgBouncer][].\n- **Affinity and Tolerations**: Have your PostgreSQL clusters deployed to [Kubernetes Nodes][k8s-nodes] of your preference.\n  Set your [pod anti-affinity][k8s-anti-affinity], node affinity, Pod tolerations and more rules to customize your deployment topology!\n- **Full Customizability**: Crunchy PostgreSQL for Kubernetes makes it easy to get your own PostgreSQL-as-a-Service up and running\n  and fully customize your deployments, including:\n    - Choose the resources for your Postgres cluster: [container resources and storage size][resize-cluster]. [Resize at any time][resize-cluster] with minimal disruption.\n    - Use your own container image repository, including support `imagePullSecrets` and private repositories\n    - [Customize your PostgreSQL configuration][customize-cluster]\n\nand much more!\n\n[backups]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/backups/\n[clone]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/disaster-recovery/#clone-a-postgres-cluster\n[customize-cluster]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/customize-cluster/\n[disaster-recovery]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/disaster-recovery/\n[high-availability]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/high-availability/\n[monitoring]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/monitoring/\n[pool]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/connection-pooling/\n[provisioning]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/create-cluster/\n[resize-cluster]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/resize-cluster/\n[tls]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/customize-cluster/#customize-tls\n\n[k8s-anti-affinity]: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n[k8s-nodes]: https://kubernetes.io/docs/concepts/architecture/nodes/\n\n[pgBackRest]: https://www.pgbackrest.org\n[pgBouncer]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/connection-pooling/\n[pgMonitor]: https://github.com/CrunchyData/pgmonitor\n\n\n## Post-Installation\n\n### Tutorial\n\nWant to [learn more about the PostgreSQL Operator][tutorial]? Browse through the [tutorial][] to learn more about what you can do!\n\n[tutorial]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial",
      "csv_display_name": "Crunchy Postgres for Kubernetes",
      "csv_metadata_description": "Production Postgres Made Easy",
      "csv_name": "postgresoperator.v5.0.5",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:08:42.243000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "crunchy-postgres-operator",
      "provided_apis": [
        {
          "group": "postgres-operator.crunchydata.com",
          "kind": "PostgresCluster",
          "plural": "postgresclusters",
          "version": "v1beta1"
        }
      ],
      "provider": "Crunchy Data",
      "related_images": [
        {
          "digest": "sha256:779c528947a218c9a7ca1b2eb59987b20f42c93e75d6606c540e6fa32811b685",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:779c528947a218c9a7ca1b2eb59987b20f42c93e75d6606c540e6fa32811b685",
          "name": "postgres-operator-779c528947a218c9a7ca1b2eb59987b20f42c93e75d6606c540e6fa32811b685-annotation"
        },
        {
          "digest": "sha256:779c528947a218c9a7ca1b2eb59987b20f42c93e75d6606c540e6fa32811b685",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:779c528947a218c9a7ca1b2eb59987b20f42c93e75d6606c540e6fa32811b685",
          "name": "operator"
        },
        {
          "digest": "sha256:42807ed2f6b6594e9f023a843ee1de965b11afd62e12d6d5949fa4aba94a72ff",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbackrest@sha256:42807ed2f6b6594e9f023a843ee1de965b11afd62e12d6d5949fa4aba94a72ff",
          "name": "pgbackrest"
        },
        {
          "digest": "sha256:d97c88c2d0804de1ee93fd99b647918b0b0b7c0ff3091254f315c4474e2623cf",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbouncer@sha256:d97c88c2d0804de1ee93fd99b647918b0b0b7c0ff3091254f315c4474e2623cf",
          "name": "pgbouncer"
        },
        {
          "digest": "sha256:5043f230985d89e2bf1d41f6ca5831ce98a2c33b2e7c0521c0ccdbb5bd045230",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-exporter@sha256:5043f230985d89e2bf1d41f6ca5831ce98a2c33b2e7c0521c0ccdbb5bd045230",
          "name": "pgexporter"
        },
        {
          "digest": "sha256:10f449d290003133c4a37482f575078250b9ab9d0efcb3541291e42140e5b2eb",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:10f449d290003133c4a37482f575078250b9ab9d0efcb3541291e42140e5b2eb",
          "name": "postgres_12"
        },
        {
          "digest": "sha256:56a08b3d6c417bee9d670bf4063b05cfee5e4ab250e791cfd36dc10d8bdf1caa",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:56a08b3d6c417bee9d670bf4063b05cfee5e4ab250e791cfd36dc10d8bdf1caa",
          "name": "postgres_13"
        },
        {
          "digest": "sha256:397ef823ac62b3d0d0f6b5e5d594bfcdb6b1ca1423a4c7ed6a80847a4bc6cb26",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:397ef823ac62b3d0d0f6b5e5d594bfcdb6b1ca1423a4c7ed6a80847a4bc6cb26",
          "name": "postgres_14"
        },
        {
          "digest": "sha256:3ad82d4757699474d647606775ae6eed1527c0deb08690f5486ec993e4339b80",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:3ad82d4757699474d647606775ae6eed1527c0deb08690f5486ec993e4339b80",
          "name": "postgres_12_gis_2.5"
        },
        {
          "digest": "sha256:fd29e3f0f1ff6c81bf5821378cee6ac83954dd7b2f9e3ace00c18111d2bcda49",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:fd29e3f0f1ff6c81bf5821378cee6ac83954dd7b2f9e3ace00c18111d2bcda49",
          "name": "postgres_12_gis_3.0"
        },
        {
          "digest": "sha256:de806714dbf7ab548b18760f2181be67fe2dadacf5939027fd2ac4b2a94912d9",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:de806714dbf7ab548b18760f2181be67fe2dadacf5939027fd2ac4b2a94912d9",
          "name": "postgres_13_gis_3.0"
        },
        {
          "digest": "sha256:8bf4f028e941898a3f1ecfde8caaafab555e8547190df923e80c4cc7d2c13351",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:8bf4f028e941898a3f1ecfde8caaafab555e8547190df923e80c4cc7d2c13351",
          "name": "postgres_13_gis_3.1"
        },
        {
          "digest": "sha256:a35500c19df076b44566ef23c54f2adbe4bdbb6e6b9e01ccd0f30a2b679df776",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:a35500c19df076b44566ef23c54f2adbe4bdbb6e6b9e01ccd0f30a2b679df776",
          "name": "postgres_14_gis_3.1"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "5.0.5",
      "version_original": "5.0.5"
    },
    {
      "_id": "629e4e45665978f21d2b0678",
      "alm_examples": [
        {
          "api_version": "crunchydata.com/v1",
          "kind": "Pgcluster",
          "metadata": {
            "annotations": {
              "current-primary": "hippo"
            },
            "labels": {
              "crunchy-pgha-scope": "hippo",
              "deployment-name": "hippo",
              "name": "hippo",
              "namespace": "pgo",
              "pg-cluster": "hippo",
              "pgo-version": "4.7.5"
            },
            "name": "hippo"
          },
          "spec": {
            "BackrestStorage": {
              "accessmode": "ReadWriteMany",
              "matchLabels": "",
              "name": "",
              "size": "5Gi",
              "storageclass": "",
              "storagetype": "dynamic",
              "supplementalgroups": ""
            },
            "PrimaryStorage": {
              "accessmode": "ReadWriteMany",
              "matchLabels": "",
              "name": "hippo",
              "size": "5Gi",
              "storageclass": "",
              "storagetype": "dynamic",
              "supplementalgroups": ""
            },
            "ReplicaStorage": {
              "accessmode": "ReadWriteMany",
              "matchLabels": "",
              "name": "",
              "size": "5Gi",
              "storageclass": "",
              "storagetype": "dynamic",
              "supplementalgroups": ""
            },
            "ccpimage": "crunchy-postgres-ha",
            "ccpimagetag": "ubi8-13.6-4.7.5",
            "clustername": "hippo",
            "database": "hippo",
            "exporterport": "9187",
            "name": "hippo",
            "namespace": "pgo",
            "pgbadgerport": "10000",
            "podAntiAffinity": {
              "default": "preferred"
            },
            "port": "5432",
            "user": "hippo",
            "userlabels": {
              "pgo-version": "4.7.5"
            }
          }
        },
        {
          "api_version": "crunchydata.com/v1",
          "kind": "Pgreplica",
          "metadata": {
            "name": "example"
          },
          "spec": {}
        },
        {
          "api_version": "crunchydata.com/v1",
          "kind": "Pgpolicy",
          "metadata": {
            "name": "example"
          },
          "spec": {}
        },
        {
          "api_version": "crunchydata.com/v1",
          "kind": "Pgtask",
          "metadata": {
            "name": "example"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/crunchydata/postgres-operator-bundle@sha256:8ae562b0c37aeffd811263713d8577df0ce88dfc57aef83fb081cf957fbe2d1b",
      "bundle_path_digest": "sha256:8ae562b0c37aeffd811263713d8577df0ce88dfc57aef83fb081cf957fbe2d1b",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-06T18:58:13.657000+00:00",
      "csv_description": "Crunchy PostgreSQL for OpenShift lets you run your own production-grade PostgreSQL-as-a-Service on OpenShift!\n\nPowered by the Crunchy [PostgreSQL Operator](https://github.com/CrunchyData/postgres-operator), Crunchy PostgreSQL\nfor OpenShift automates and simplifies deploying and managing open source PostgreSQL clusters on OpenShift by\nproviding the essential features you need to keep your PostgreSQL clusters up and running, including:\n\n- **PostgreSQL Cluster Provisioning**: [Create, Scale, & Delete PostgreSQL clusters with ease][provisioning],\n  while fully customizing your Pods and PostgreSQL configuration!\n- **High-Availability**: Safe, automated failover backed by a [distributed consensus based high-availability solution][high-availability].\n  Uses [Pod Anti-Affinity][k8s-anti-affinity] to help resiliency; you can configure how aggressive this can be!\n  Failed primaries automatically heal, allowing for faster recovery time. You can even create regularly scheduled\n  backups as well and set your backup retention policy\n- **Disaster Recovery**: Backups and restores leverage the open source [pgBackRest][] utility\n  and [includes support for full, incremental, and differential backups as well as efficient delta restores][disaster-recovery].\n  Set how long you want your backups retained for. Works great with very large databases!\n- **Monitoring**: Track the health of your PostgreSQL clusters using the open source [pgMonitor][] library.\n- **Clone**: Create new clusters from your existing clusters or backups with a single [`pgo create cluster --restore-from`][pgo-create-cluster] command.\n- **TLS**: Secure communication between your applications and data servers by [enabling TLS for your PostgreSQL servers][pgo-task-tls], including the ability to enforce that all of your connections to use TLS.\n- **Connection Pooling**: Use [pgBouncer][] for connection pooling\n- **Affinity and Tolerations**: Have your PostgreSQL clusters deployed to [Kubernetes Nodes][k8s-nodes] of your preference with [node affinity][high-availability-node-affinity], or designate which nodes Kubernetes can schedule PostgreSQL instances to with Kubernetes [tolerations][high-availability-tolerations].\n- **Full Customizability**: Crunchy PostgreSQL for OpenShift makes it easy to get your own PostgreSQL-as-a-Service up and running on\n  and lets make further enhancements to customize your deployments, including:\n    - Selecting different storage classes for your primary, replica, and backup storage\n    - Select your own container resources class for each PostgreSQL cluster deployment; differentiate between resources applied for primary and replica clusters!\n    - Use your own container image repository, including support `imagePullSecrets` and private repositories\n    - Bring your own trusted certificate authority (CA) for use with the Operator API server\n    - Override your PostgreSQL configuration for each cluster\n\nand much more!\n\n[disaster-recovery]: https://access.crunchydata.com/documentation/postgres-operator/latest/architecture/disaster-recovery/\n[high-availability]: https://access.crunchydata.com/documentation/postgres-operator/latest/architecture/high-availability/\n[high-availability-node-affinity]: https://access.crunchydata.com/documentation/postgres-operator/latest/architecture/high-availability/#node-affinity\n[high-availability-tolerations]: https://access.crunchydata.com/documentation/postgres-operator/latest/architecture/high-availability/#tolerations\n[pgo-create-cluster]: https://access.crunchydata.com/documentation/postgres-operator/latest/pgo-client/reference/pgo_create_cluster/\n[pgo-task-tls]: https://access.crunchydata.com/documentation/postgres-operator/latest/tutorial/tls/\n[provisioning]: https://access.crunchydata.com/documentation/postgres-operator/latest/architecture/provisioning/\n\n[k8s-anti-affinity]: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n[k8s-nodes]: https://kubernetes.io/docs/concepts/architecture/nodes/\n\n[pgBackRest]: https://www.pgbackrest.org\n[pgBouncer]: https://access.crunchydata.com/documentation/postgres-operator/latest/tutorial/pgbouncer/\n[pgMonitor]: https://github.com/CrunchyData/pgmonitor\n\n## Pre-Installation\n\nThere are a few manual steps that the cluster administrator must perform prior to installing the PostgreSQL Operator.\nAt the very least, it must be provided with an initial configuration.\n\nFirst, select a namespace in which to install the PostgreSQL Operator. PostgreSQL clusters will also be deployed here.\nIf it does not exist, create it now.\n\n```\nexport PGO_OPERATOR_NAMESPACE=pgo\noc create namespace \"$PGO_OPERATOR_NAMESPACE\"\n```\n\n### Security\n\nFor the PostgreSQL Operator and PostgreSQL clusters to run in the recommended `restricted` [Security Context Constraint][],\nedit `conf/postgres-operator/pgo.yaml` and set `DisableFSGroup` to `true`.\n\n[Security Context Constraint]: https://docs.openshift.com/container-platform/latest/authentication/managing-security-context-constraints.html\n\n### Secrets (optional)\n\nIf you plan to use AWS S3 to store backups, you can configure your environment to automatically provide your AWS S3 credentials to all newly created PostgreSQL clusters:\n\n```\noc -n \"$PGO_OPERATOR_NAMESPACE\" create secret generic pgo-backrest-repo-config \\\n  --from-literal=aws-s3-key=\"<your-aws-s3-key>\" \\\n  --from-literal=aws-s3-key-secret=\"<your-aws-s3-key-secret>\"\noc -n \"$PGO_OPERATOR_NAMESPACE\" label secret pgo-backrest-repo-config vendor=crunchydata\n```\n\n### Certificates (optional)\n\nThe PostgreSQL Operator has an API that uses TLS to communicate securely with clients. If one is not provided, the API will automatically generated one for you.\n\nIf you have a certificate bundle validated by your organization, you can install it now.\n\n```\noc -n \"$PGO_OPERATOR_NAMESPACE\" create secret tls pgo.tls \\\n  --cert=/path/to/server.crt \\\n  --key=/path/to/server.key\n```\n\nOnce these resources are in place, the PostgreSQL Operator can be installed into the cluster.\n\n## Installation\n\nYou can now go ahead and install the PostgreSQL Operator from OperatorHub.\n\n### Security\n\nFor the PostgreSQL Operator and PostgreSQL clusters to run in the recommended `restricted` [Security Context Constraint][],\nedit the ConfigMap `pgo-config`, find the `pgo.yaml` entry, and set `DisableFSGroup` to `true`.\n\n[Security Context Constraint]: https://docs.openshift.com/container-platform/latest/authentication/managing-security-context-constraints.html\n\nYou will have to scale the `postgres-operator` Deployment down and up for the above change to take effect:\n\n```\noc -n pgo scale --replicas 0 deployment/postgres-operator\noc -n pgo scale --replicas 1 deployment/postgres-operator\n```\n\n## Post-Installation\n\n### Tutorial\n\nFor a guide on how to perform many of the daily functions of the PostgreSQL Operator, we recommend that you read the [Postgres Operator tutorial][pgo-tutorial]\n\n[pgo-tutorial]: https://access.crunchydata.com/documentation/postgres-operator/latest/tutorial/create-cluster/\n\nHowever, the below guide will show you how to create a Postgres cluster from a custom resource or from using the `pgo-client`.\n\n### Create a PostgreSQL Cluster from a Custom Resource\n\nThe fundamental workflow for interfacing with a PostgreSQL Operator Custom\nResource Definition is for creating a PostgreSQL cluster. There are several\nthat a PostgreSQL cluster requires to be deployed, including:\n\n- Secrets\n  - Information for setting up a pgBackRest repository\n  - PostgreSQL superuser bootstrap credentials\n  - PostgreSQL replication user bootstrap credentials\n  - PostgresQL standard user bootstrap credentials\n\nAdditionally, if you want to add some of the other sidecars, you may need to\ncreate additional secrets.\n\nThe good news is that if you do not provide these objects, the PostgreSQL\nOperator will create them for you to get your Postgres cluster up and running!\n\nThe following goes through how to create a PostgreSQL cluster called\n`hippo` by creating a new custom resource.\n\n```\n# this variable is the name of the cluster being created\nexport pgo_cluster_name=hippo\n# this variable is the namespace the cluster is being deployed into\nexport cluster_namespace=pgo\n# this variable is set to the location of your image repository\nexport cluster_image_prefix=registry.developers.crunchydata.com/crunchydata\n\ncat <<-EOF > \"${pgo_cluster_name}-pgcluster.yaml\"\napiVersion: crunchydata.com/v1\nkind: Pgcluster\nmetadata:\n  annotations:\n    current-primary: ${pgo_cluster_name}\n  labels:\n    crunchy-pgha-scope: ${pgo_cluster_name}\n    deployment-name: ${pgo_cluster_name}\n    name: ${pgo_cluster_name}\n    pg-cluster: ${pgo_cluster_name}\n    pgo-version: 4.7.5\n    pgouser: admin\n  name: ${pgo_cluster_name}\n  namespace: ${cluster_namespace}\nspec:\n  BackrestStorage:\n    accessmode: ReadWriteMany\n    matchLabels: \"\"\n    name: \"\"\n    size: 1G\n    storageclass: \"\"\n    storagetype: create\n    supplementalgroups: \"\"\n  PrimaryStorage:\n    accessmode: ReadWriteMany\n    matchLabels: \"\"\n    name: ${pgo_cluster_name}\n    size: 1G\n    storageclass: \"\"\n    storagetype: create\n    supplementalgroups: \"\"\n  ReplicaStorage:\n    accessmode: ReadWriteMany\n    matchLabels: \"\"\n    name: \"\"\n    size: 1G\n    storageclass: \"\"\n    storagetype: create\n    supplementalgroups: \"\"\n  annotations: {}\n  ccpimage: crunchy-postgres-ha\n  ccpimageprefix: ${cluster_image_prefix}\n  ccpimagetag: centos8-13.6-4.7.5\n  clustername: ${pgo_cluster_name}\n  database: ${pgo_cluster_name}\n  exporterport: \"9187\"\n  limits: {}\n  name: ${pgo_cluster_name}\n  pgDataSource:\n    restoreFrom: \"\"\n    restoreOpts: \"\"\n  pgbadgerport: \"10000\"\n  pgoimageprefix: ${cluster_image_prefix}\n  podAntiAffinity:\n    default: preferred\n    pgBackRest: preferred\n    pgBouncer: preferred\n  port: \"5432\"\n  tolerations: []\n  user: hippo\n  userlabels:\n    pgo-version: 4.7.5\nEOF\n\noc apply -f \"${pgo_cluster_name}-pgcluster.yaml\"\n```\n\nAnd that's all! The PostgreSQL Operator will go ahead and create the cluster.\n\nIf you have the PostgreSQL client `psql` installed on your host machine, you can\ntest connection to the PostgreSQL cluster using the following command:\n\n```\n# namespace that the cluster is running in\nexport PGO_OPERATOR_NAMESPACE=pgo\n# name of the cluster\nexport pgo_cluster_name=hippo\n# name of the user whose password we want to get\nexport pgo_cluster_username=hippo\n\n# get the password of the user and set it to a recognized psql environmental variable\nexport PGPASSWORD=$(oc -n \"${PGO_OPERATOR_NAMESPACE}\" get secrets \\\n  \"${pgo_cluster_name}-${pgo_cluster_username}-secret\" -o \"jsonpath={.data['password']}\" | base64 -d)\n\n# set up a port-forward either in a new terminal, or in the same terminal in the background:\noc -n pgo port-forward svc/hippo 5432:5432 &\n\npsql -h localhost -U \"${pgo_cluster_username}\" \"${pgo_cluster_name}\"\n```\n\n### Create a PostgreSQL Cluster the `pgo` Client\n\nOnce the PostgreSQL Operator is installed in your OpenShift cluster, you will need to do a few things\nto use the [PostgreSQL Operator Client][pgo-client].\n\n[pgo-client]: https://access.crunchydata.com/documentation/postgres-operator/latest/pgo-client/\n\nInstall the first set of client credentials and download the `pgo` binary and client certificates.\n\n```\ncurl https://raw.githubusercontent.com/CrunchyData/postgres-operator/v4.7.5/deploy/install-bootstrap-creds.sh > install-bootstrap-creds.sh\ncurl https://raw.githubusercontent.com/CrunchyData/postgres-operator/v4.7.5/installers/kubectl/client-setup.sh > client-setup.sh\n\nchmod +x install-bootstrap-creds.sh client-setup.sh\n\nPGO_CMD=oc ./install-bootstrap-creds.sh\nPGO_CMD=oc ./client-setup.sh\n```\n\nThe client needs to be able to reach the PostgreSQL Operator API from outside the OpenShift cluster.\nCreate an external service or forward a port locally.\n\n```\noc -n \"$PGO_OPERATOR_NAMESPACE\" expose deployment postgres-operator\noc -n \"$PGO_OPERATOR_NAMESPACE\" create route passthrough postgres-operator --service=postgres-operator\n\nexport PGO_APISERVER_URL=\"https://$(oc -n \"$PGO_OPERATOR_NAMESPACE\" get route postgres-operator -o jsonpath=\"{.spec.host}\")\"\n```\n_or_\n```\noc -n \"$PGO_OPERATOR_NAMESPACE\" port-forward deployment/postgres-operator 8443\n\nexport PGO_APISERVER_URL=\"https://127.0.0.1:8443\"\n```\n\nVerify connectivity using the `pgo` command.\n\n```\npgo version\n# pgo client version 4.7.5\n# pgo-apiserver version 4.7.5\n```\n\n\nYou can then create a cluster with the `pgo` client as simply as this:\n\n```\npgo create cluster -n pgo hippo\n```\n\nThe cluster may take a few moments to provision. You can verify that the cluster is up and running by using the `pgo test` command:\n\n```\npgo test cluster -n pgo hippo\n```\n\nIf you have the PostgreSQL client `psql` installed on your host machine, you can\ntest connection to the PostgreSQL cluster using the following command:\n\n```\n# namespace that the cluster is running in\nexport PGO_OPERATOR_NAMESPACE=pgo\n# name of the cluster\nexport pgo_cluster_name=hippo\n# name of the user whose password we want to get\nexport pgo_cluster_username=hippo\n\n# get the password of the user and set it to a recognized psql environmental variable\nexport PGPASSWORD=$(kubectl -n \"${PGO_OPERATOR_NAMESPACE}\" get secrets \\\n  \"${pgo_cluster_name}-${pgo_cluster_username}-secret\" -o \"jsonpath={.data['password']}\" | base64 -d)\n\n# set up a port-forward either in a new terminal, or in the same terminal in the background:\nkubectl -n pgo port-forward svc/hippo 5432:5432 &\n\npsql -h localhost -U \"${pgo_cluster_username}\" \"${pgo_cluster_name}\"\n```",
      "csv_display_name": "Crunchy PostgreSQL for OpenShift",
      "csv_metadata_description": "Enterprise open source PostgreSQL-as-a-Service",
      "csv_name": "postgresoperator.v4.7.5",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-08-15T13:31:42.437000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "crunchy-postgres-operator",
      "provided_apis": [
        {
          "group": "crunchydata.com",
          "kind": "Pgcluster",
          "version": "v1"
        },
        {
          "group": "crunchydata.com",
          "kind": "Pgpolicy",
          "version": "v1"
        },
        {
          "group": "crunchydata.com",
          "kind": "Pgreplica",
          "version": "v1"
        },
        {
          "group": "crunchydata.com",
          "kind": "Pgtask",
          "version": "v1"
        }
      ],
      "provider": "Crunchy Data",
      "related_images": [
        {
          "digest": "sha256:d9f91cb300615bcf39e610abd4741ff6be3d13418db4260f9409395a2a5c1ecb",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:d9f91cb300615bcf39e610abd4741ff6be3d13418db4260f9409395a2a5c1ecb",
          "name": "postgres-operator-d9f91cb300615bcf39e610abd4741ff6be3d13418db4260f9409395a2a5c1ecb-annotation"
        },
        {
          "digest": "sha256:86b5b293c263667dfc5016fc587643261438bd8868cc1c523ccb77a7c4e1b85a",
          "image": "registry.connect.redhat.com/crunchydata/pgo-apiserver@sha256:86b5b293c263667dfc5016fc587643261438bd8868cc1c523ccb77a7c4e1b85a",
          "name": "apiserver"
        },
        {
          "digest": "sha256:d9f91cb300615bcf39e610abd4741ff6be3d13418db4260f9409395a2a5c1ecb",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:d9f91cb300615bcf39e610abd4741ff6be3d13418db4260f9409395a2a5c1ecb",
          "name": "operator"
        },
        {
          "digest": "sha256:481c48699d7ba6aefc7ad27b43e4df54b8f8686f3445cf303a45bd43ceec4244",
          "image": "registry.connect.redhat.com/crunchydata/pgo-scheduler@sha256:481c48699d7ba6aefc7ad27b43e4df54b8f8686f3445cf303a45bd43ceec4244",
          "name": "scheduler"
        },
        {
          "digest": "sha256:bcc9f68cfce901352408e4645f7c6aa5d2157af93952b9124c3a20923e4f1288",
          "image": "registry.connect.redhat.com/crunchydata/pgo-event@sha256:bcc9f68cfce901352408e4645f7c6aa5d2157af93952b9124c3a20923e4f1288",
          "name": "event"
        },
        {
          "digest": "sha256:0016bf993af9ed5fdfdbbd56b1e743d1991ed390a4800cf1a04cdf55cafe119a",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbackrest@sha256:0016bf993af9ed5fdfdbbd56b1e743d1991ed390a4800cf1a04cdf55cafe119a",
          "name": "pgo_backrest"
        },
        {
          "digest": "sha256:2991db135d2158fbb496afaabee221c432e13d11767e90130f4b2b5c2912a6b5",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbackrest-repo@sha256:2991db135d2158fbb496afaabee221c432e13d11767e90130f4b2b5c2912a6b5",
          "name": "pgo_backrest_repo"
        },
        {
          "digest": "sha256:dabd59ff8e97a06e5e823c33805da6f66300c43c8b315cfd7ab0315bd92803e1",
          "image": "registry.connect.redhat.com/crunchydata/pgo-client@sha256:dabd59ff8e97a06e5e823c33805da6f66300c43c8b315cfd7ab0315bd92803e1",
          "name": "pgo_client"
        },
        {
          "digest": "sha256:c44507bfc3286017afef0697133595043256b8b595e1e2e470b6ff7598cff575",
          "image": "registry.connect.redhat.com/crunchydata/pgo-rmdata@sha256:c44507bfc3286017afef0697133595043256b8b595e1e2e470b6ff7598cff575",
          "name": "pgo_rmdata"
        },
        {
          "digest": "sha256:79d658ec93a10951cd06950e753f92332ea07ce191197213e14f4dc6042cc9f1",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-exporter@sha256:79d658ec93a10951cd06950e753f92332ea07ce191197213e14f4dc6042cc9f1",
          "name": "crunchy_postgres_exporter"
        },
        {
          "digest": "sha256:77e508924d2358af0f3a8f597f7f59c38f7aecda2af9014ab9438d35f503de9c",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgadmin4@sha256:77e508924d2358af0f3a8f597f7f59c38f7aecda2af9014ab9438d35f503de9c",
          "name": "crunchy_pgadmin"
        },
        {
          "digest": "sha256:8850ac1be18d01b7dee9bb0f61d453c787961985bc84df3bc8c1595962a00fab",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbadger@sha256:8850ac1be18d01b7dee9bb0f61d453c787961985bc84df3bc8c1595962a00fab",
          "name": "crunchy_pgbadger"
        },
        {
          "digest": "sha256:a339798a1712a3a3bcf303e6df8186460edfb47aca0e2ae4cadf9db2207d72d6",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbouncer@sha256:a339798a1712a3a3bcf303e6df8186460edfb47aca0e2ae4cadf9db2207d72d6",
          "name": "crunchy_pgbouncer"
        },
        {
          "digest": "sha256:ea787e002ce3aee1b8c54127816885b07c1f063515fa5b80ce957676f4e0a21b",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-ha@sha256:ea787e002ce3aee1b8c54127816885b07c1f063515fa5b80ce957676f4e0a21b",
          "name": "crunchy_postgres_ha"
        },
        {
          "digest": "sha256:f0d2c8df4adb038af6be43089d96af02afd88b82568a2da342d8d97e1fa4ba8f",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis-ha@sha256:f0d2c8df4adb038af6be43089d96af02afd88b82568a2da342d8d97e1fa4ba8f",
          "name": "crunchy_postgres_gis_ha"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "4.7.5",
      "version_original": "4.7.5"
    },
    {
      "_id": "629e4fba665978f21d2b0682",
      "alm_examples": [
        {
          "api_version": "postgres-operator.crunchydata.com/v1beta1",
          "kind": "PostgresCluster",
          "metadata": {
            "name": "example"
          },
          "spec": {
            "instances": [
              {
                "dataVolumeClaimSpec": {
                  "accessModes": [
                    "ReadWriteOnce"
                  ],
                  "resources": {
                    "requests": {
                      "storage": "1Gi"
                    }
                  }
                },
                "replicas": 1
              }
            ],
            "postgresVersion": 13
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/crunchydata/postgres-operator-bundle@sha256:ce40b9bd94ed562963fd298acdad256ef5fe30397aa8ee82e88febfab61f96e4",
      "bundle_path_digest": "sha256:ce40b9bd94ed562963fd298acdad256ef5fe30397aa8ee82e88febfab61f96e4",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "v5",
      "creation_date": "2022-06-06T19:04:25.999000+00:00",
      "csv_description": "[PGO](https://github.com/CrunchyData/postgres-operator), the\n[Postgres Operator](https://github.com/CrunchyData/postgres-operator) from\n[Crunchy Data](https://www.crunchydata.com), gives you a **declarative Postgres** solution that\nautomatically manages your [PostgreSQL](https://www.postgresql.org) clusters.\n\nDesigned for your GitOps workflows, it is [easy to get started](https://access.crunchydata.com/documentation/postgres-operator/v5/quickstart/)\nwith Postgres on Kubernetes with PGO. Within a few moments, you can have a production grade Postgres\ncluster complete with high availability, disaster recovery, and monitoring, all over secure TLS communications.\nEven better, PGO lets you easily customize your Postgres cluster to tailor it to your workload!\n\nWith conveniences like cloning Postgres clusters to using rolling updates to roll out disruptive\nchanges with minimal downtime, PGO is ready to support your Postgres data at every stage of your\nrelease pipeline. Built for resiliency and uptime, PGO will keep your desired Postgres in a desired\nstate so you do not need to worry about it.\n\nPGO is developed with many years of production experience in automating Postgres management on\nKubernetes, providing a seamless cloud native Postgres solution to keep your data always available.\n\n- **PostgreSQL Cluster Provisioning**: [Create, Scale, & Delete PostgreSQL clusters with ease][provisioning],\n  while fully customizing your Pods and PostgreSQL configuration!\n- **High-Availability**: Safe, automated failover backed by a [distributed consensus based high-availability solution][high-availability].\n  Uses [Pod Anti-Affinity][k8s-anti-affinity] to help resiliency; you can configure how aggressive this can be!\n  Failed primaries automatically heal, allowing for faster recovery time. You can even create regularly scheduled\n  backups as well and set your backup retention policy\n- **Disaster Recovery**: [Backups][backups] and [restores][disaster-recovery] leverage the open source [pgBackRest][] utility and\n  [includes support for full, incremental, and differential backups as well as efficient delta restores][backups].\n  Set how long you want your backups retained for. Works great with very large databases!\n- **Monitoring**: [Track the health of your PostgreSQL clusters][monitoring] using the open source [pgMonitor][] library.\n- **Clone**: [Create new clusters from your existing clusters or backups][clone] with efficient data cloning.\n- **TLS**: All connections are over [TLS][tls]. You can also [bring your own TLS infrastructure][tls] if you do not want to use the provided defaults.\n- **Connection Pooling**: Advanced [connection pooling][pool] support using [pgBouncer][].\n- **Affinity and Tolerations**: Have your PostgreSQL clusters deployed to [Kubernetes Nodes][k8s-nodes] of your preference.\n  Set your [pod anti-affinity][k8s-anti-affinity], node affinity, Pod tolerations and more rules to customize your deployment topology!\n- **Full Customizability**: Crunchy PostgreSQL for Kubernetes makes it easy to get your own PostgreSQL-as-a-Service up and running\n  and fully customize your deployments, including:\n    - Choose the resources for your Postgres cluster: [container resources and storage size][resize-cluster]. [Resize at any time][resize-cluster] with minimal disruption.\n    - Use your own container image repository, including support `imagePullSecrets` and private repositories\n    - [Customize your PostgreSQL configuration][customize-cluster]\n\nand much more!\n\n[backups]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/backups/\n[clone]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/disaster-recovery/#clone-a-postgres-cluster\n[customize-cluster]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/customize-cluster/\n[disaster-recovery]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/disaster-recovery/\n[high-availability]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/high-availability/\n[monitoring]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/monitoring/\n[pool]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/connection-pooling/\n[provisioning]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/create-cluster/\n[resize-cluster]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/resize-cluster/\n[tls]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/customize-cluster/#customize-tls\n\n[k8s-anti-affinity]: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n[k8s-nodes]: https://kubernetes.io/docs/concepts/architecture/nodes/\n\n[pgBackRest]: https://www.pgbackrest.org\n[pgBouncer]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial/connection-pooling/\n[pgMonitor]: https://github.com/CrunchyData/pgmonitor\n\n\n## Post-Installation\n\n### Tutorial\n\nWant to [learn more about the PostgreSQL Operator][tutorial]? Browse through the [tutorial][] to learn more about what you can do!\n\n[tutorial]: https://access.crunchydata.com/documentation/postgres-operator/v5/tutorial",
      "csv_display_name": "Crunchy Postgres for Kubernetes",
      "csv_metadata_description": "Production Postgres Made Easy",
      "csv_name": "postgresoperator.v5.0.5",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:31:47.284000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "crunchy-postgres-operator",
      "provided_apis": [
        {
          "group": "postgres-operator.crunchydata.com",
          "kind": "PostgresCluster",
          "version": "v1beta1"
        }
      ],
      "provider": "Crunchy Data",
      "related_images": [
        {
          "digest": "sha256:779c528947a218c9a7ca1b2eb59987b20f42c93e75d6606c540e6fa32811b685",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:779c528947a218c9a7ca1b2eb59987b20f42c93e75d6606c540e6fa32811b685",
          "name": "postgres-operator-779c528947a218c9a7ca1b2eb59987b20f42c93e75d6606c540e6fa32811b685-annotation"
        },
        {
          "digest": "sha256:779c528947a218c9a7ca1b2eb59987b20f42c93e75d6606c540e6fa32811b685",
          "image": "registry.connect.redhat.com/crunchydata/postgres-operator@sha256:779c528947a218c9a7ca1b2eb59987b20f42c93e75d6606c540e6fa32811b685",
          "name": "operator"
        },
        {
          "digest": "sha256:42807ed2f6b6594e9f023a843ee1de965b11afd62e12d6d5949fa4aba94a72ff",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbackrest@sha256:42807ed2f6b6594e9f023a843ee1de965b11afd62e12d6d5949fa4aba94a72ff",
          "name": "pgbackrest"
        },
        {
          "digest": "sha256:d97c88c2d0804de1ee93fd99b647918b0b0b7c0ff3091254f315c4474e2623cf",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-pgbouncer@sha256:d97c88c2d0804de1ee93fd99b647918b0b0b7c0ff3091254f315c4474e2623cf",
          "name": "pgbouncer"
        },
        {
          "digest": "sha256:5043f230985d89e2bf1d41f6ca5831ce98a2c33b2e7c0521c0ccdbb5bd045230",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-exporter@sha256:5043f230985d89e2bf1d41f6ca5831ce98a2c33b2e7c0521c0ccdbb5bd045230",
          "name": "pgexporter"
        },
        {
          "digest": "sha256:10f449d290003133c4a37482f575078250b9ab9d0efcb3541291e42140e5b2eb",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:10f449d290003133c4a37482f575078250b9ab9d0efcb3541291e42140e5b2eb",
          "name": "postgres_12"
        },
        {
          "digest": "sha256:56a08b3d6c417bee9d670bf4063b05cfee5e4ab250e791cfd36dc10d8bdf1caa",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:56a08b3d6c417bee9d670bf4063b05cfee5e4ab250e791cfd36dc10d8bdf1caa",
          "name": "postgres_13"
        },
        {
          "digest": "sha256:397ef823ac62b3d0d0f6b5e5d594bfcdb6b1ca1423a4c7ed6a80847a4bc6cb26",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres@sha256:397ef823ac62b3d0d0f6b5e5d594bfcdb6b1ca1423a4c7ed6a80847a4bc6cb26",
          "name": "postgres_14"
        },
        {
          "digest": "sha256:3ad82d4757699474d647606775ae6eed1527c0deb08690f5486ec993e4339b80",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:3ad82d4757699474d647606775ae6eed1527c0deb08690f5486ec993e4339b80",
          "name": "postgres_12_gis_2.5"
        },
        {
          "digest": "sha256:fd29e3f0f1ff6c81bf5821378cee6ac83954dd7b2f9e3ace00c18111d2bcda49",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:fd29e3f0f1ff6c81bf5821378cee6ac83954dd7b2f9e3ace00c18111d2bcda49",
          "name": "postgres_12_gis_3.0"
        },
        {
          "digest": "sha256:de806714dbf7ab548b18760f2181be67fe2dadacf5939027fd2ac4b2a94912d9",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:de806714dbf7ab548b18760f2181be67fe2dadacf5939027fd2ac4b2a94912d9",
          "name": "postgres_13_gis_3.0"
        },
        {
          "digest": "sha256:8bf4f028e941898a3f1ecfde8caaafab555e8547190df923e80c4cc7d2c13351",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:8bf4f028e941898a3f1ecfde8caaafab555e8547190df923e80c4cc7d2c13351",
          "name": "postgres_13_gis_3.1"
        },
        {
          "digest": "sha256:a35500c19df076b44566ef23c54f2adbe4bdbb6e6b9e01ccd0f30a2b679df776",
          "image": "registry.connect.redhat.com/crunchydata/crunchy-postgres-gis@sha256:a35500c19df076b44566ef23c54f2adbe4bdbb6e6b9e01ccd0f30a2b679df776",
          "name": "postgres_14_gis_3.1"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "5.0.5",
      "version_original": "5.0.5"
    },
    {
      "_id": "62a32228d1667dcf800b9c6a",
      "alm_examples": [
        {
          "api_version": "app.joget.com/v1alpha1",
          "kind": "JogetDX",
          "metadata": {
            "name": "example-joget"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/joget/joget-dx-operator-bundle@sha256:609d7eaba12b325ed9c3d932fc453cd06e2e4545877913a77b0f95ad6e7ea23d",
      "bundle_path_digest": "sha256:609d7eaba12b325ed9c3d932fc453cd06e2e4545877913a77b0f95ad6e7ea23d",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-06-10T10:51:20.581000+00:00",
      "csv_description": "Joget DX is the next generation open source no-code / low-code application platform that combines the best of Rapid Application Development, Business Process Automation and Workflow Management. \nJoget DX empowers business users, non-coders or coders with a single platform to easily build, deliver, monitor and maintain enterprise applications.\n\nThis operator installs a Joget DX cluster running on JBoss EAP 7.\n\n### Features\n* Build full-fledged apps e.g. CRM, HR, Healthcare, etc\n* Drag and drop forms, lists, UI\n* Add workflow to automate processes\n* Extend via plugins\n* Apps are mobile optimized and cloud ready\n* Download ready-made apps from the Joget Marketplace\n\n### Before You Start\nDeploy a [MySQL](https://docs.openshift.com/online/pro/using_images/db_images/mysql.html) or [MariaDB](https://docs.openshift.com/online/pro/using_images/db_images/mariadb.html) database.\n\n### Post Deployment\nAccess the service URL and complete the one-time [Database Setup](https://dev.joget.org/community/display/DX7/Setting+Up+Database)\n\n### More Information\nMore information about Joget DX on JBoss EAP 7 is available in the [Joget Knowledge Base](https://dev.joget.org/community/display/DX7/Automated+Deployment+on+Red+Hat+OpenShift+with+the+Joget+Operator)\n",
      "csv_display_name": "Joget DX Operator",
      "csv_metadata_description": "No-code/low-code application platform to visually build, run and maintain apps",
      "csv_name": "joget-dx-openshift-operator.v0.0.30",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:13:25.874000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "joget-dx-operator",
      "provided_apis": [
        {
          "group": "app.joget.com",
          "kind": "JogetDX",
          "version": "v1alpha1"
        }
      ],
      "provider": "Joget, Inc",
      "related_images": [
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "joget-dx-operator-79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749-annotation"
        },
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "operator"
        },
        {
          "digest": "sha256:0142dd0852a8d57411836c7b6fd61584b604291870a471c53694b7bd888469a4",
          "image": "registry.connect.redhat.com/joget/joget-dx7-eap7@sha256:0142dd0852a8d57411836c7b6fd61584b604291870a471c53694b7bd888469a4",
          "name": "joget"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "0.0.30",
      "version_original": "0.0.30"
    },
    {
      "_id": "62a32394e5356b6330e2d16c",
      "alm_examples": [
        {
          "api_version": "app.joget.com/v1alpha1",
          "kind": "JogetDX",
          "metadata": {
            "name": "example-joget"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/joget/joget-dx-operator-bundle@sha256:609d7eaba12b325ed9c3d932fc453cd06e2e4545877913a77b0f95ad6e7ea23d",
      "bundle_path_digest": "sha256:609d7eaba12b325ed9c3d932fc453cd06e2e4545877913a77b0f95ad6e7ea23d",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-06-10T10:57:24.314000+00:00",
      "csv_description": "Joget DX is the next generation open source no-code / low-code application platform that combines the best of Rapid Application Development, Business Process Automation and Workflow Management. \nJoget DX empowers business users, non-coders or coders with a single platform to easily build, deliver, monitor and maintain enterprise applications.\n\nThis operator installs a Joget DX cluster running on JBoss EAP 7.\n\n### Features\n* Build full-fledged apps e.g. CRM, HR, Healthcare, etc\n* Drag and drop forms, lists, UI\n* Add workflow to automate processes\n* Extend via plugins\n* Apps are mobile optimized and cloud ready\n* Download ready-made apps from the Joget Marketplace\n\n### Before You Start\nDeploy a [MySQL](https://docs.openshift.com/online/pro/using_images/db_images/mysql.html) or [MariaDB](https://docs.openshift.com/online/pro/using_images/db_images/mariadb.html) database.\n\n### Post Deployment\nAccess the service URL and complete the one-time [Database Setup](https://dev.joget.org/community/display/DX7/Setting+Up+Database)\n\n### More Information\nMore information about Joget DX on JBoss EAP 7 is available in the [Joget Knowledge Base](https://dev.joget.org/community/display/DX7/Automated+Deployment+on+Red+Hat+OpenShift+with+the+Joget+Operator)\n",
      "csv_display_name": "Joget DX Operator",
      "csv_metadata_description": "No-code/low-code application platform to visually build, run and maintain apps",
      "csv_name": "joget-dx-openshift-operator.v0.0.30",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:01:00.097000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "joget-dx-operator",
      "provided_apis": [
        {
          "group": "app.joget.com",
          "kind": "JogetDX",
          "plural": "jogetdx",
          "version": "v1alpha1"
        }
      ],
      "provider": "Joget, Inc",
      "related_images": [
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "joget-dx-operator-79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749-annotation"
        },
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "operator"
        },
        {
          "digest": "sha256:0142dd0852a8d57411836c7b6fd61584b604291870a471c53694b7bd888469a4",
          "image": "registry.connect.redhat.com/joget/joget-dx7-eap7@sha256:0142dd0852a8d57411836c7b6fd61584b604291870a471c53694b7bd888469a4",
          "name": "joget"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "0.0.30",
      "version_original": "0.0.30"
    },
    {
      "_id": "62a3245be5356b6330e2d16f",
      "alm_examples": [
        {
          "api_version": "app.joget.com/v1alpha1",
          "kind": "JogetDX",
          "metadata": {
            "name": "example-joget"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/joget/joget-dx-operator-bundle@sha256:609d7eaba12b325ed9c3d932fc453cd06e2e4545877913a77b0f95ad6e7ea23d",
      "bundle_path_digest": "sha256:609d7eaba12b325ed9c3d932fc453cd06e2e4545877913a77b0f95ad6e7ea23d",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-06-10T11:00:43.401000+00:00",
      "csv_description": "Joget DX is the next generation open source no-code / low-code application platform that combines the best of Rapid Application Development, Business Process Automation and Workflow Management. \nJoget DX empowers business users, non-coders or coders with a single platform to easily build, deliver, monitor and maintain enterprise applications.\n\nThis operator installs a Joget DX cluster running on JBoss EAP 7.\n\n### Features\n* Build full-fledged apps e.g. CRM, HR, Healthcare, etc\n* Drag and drop forms, lists, UI\n* Add workflow to automate processes\n* Extend via plugins\n* Apps are mobile optimized and cloud ready\n* Download ready-made apps from the Joget Marketplace\n\n### Before You Start\nDeploy a [MySQL](https://docs.openshift.com/online/pro/using_images/db_images/mysql.html) or [MariaDB](https://docs.openshift.com/online/pro/using_images/db_images/mariadb.html) database.\n\n### Post Deployment\nAccess the service URL and complete the one-time [Database Setup](https://dev.joget.org/community/display/DX7/Setting+Up+Database)\n\n### More Information\nMore information about Joget DX on JBoss EAP 7 is available in the [Joget Knowledge Base](https://dev.joget.org/community/display/DX7/Automated+Deployment+on+Red+Hat+OpenShift+with+the+Joget+Operator)\n",
      "csv_display_name": "Joget DX Operator",
      "csv_metadata_description": "No-code/low-code application platform to visually build, run and maintain apps",
      "csv_name": "joget-dx-openshift-operator.v0.0.30",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:02:50.288000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "joget-dx-operator",
      "provided_apis": [
        {
          "group": "app.joget.com",
          "kind": "JogetDX",
          "plural": "jogetdx",
          "version": "v1alpha1"
        }
      ],
      "provider": "Joget, Inc",
      "related_images": [
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "joget-dx-operator-79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749-annotation"
        },
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "operator"
        },
        {
          "digest": "sha256:0142dd0852a8d57411836c7b6fd61584b604291870a471c53694b7bd888469a4",
          "image": "registry.connect.redhat.com/joget/joget-dx7-eap7@sha256:0142dd0852a8d57411836c7b6fd61584b604291870a471c53694b7bd888469a4",
          "name": "joget"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "0.0.30",
      "version_original": "0.0.30"
    },
    {
      "_id": "62a326299ec0687ab6e7208a",
      "alm_examples": [
        {
          "api_version": "app.joget.com/v1alpha1",
          "kind": "JogetDX",
          "metadata": {
            "name": "example-joget"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/joget/joget-dx-operator-bundle@sha256:609d7eaba12b325ed9c3d932fc453cd06e2e4545877913a77b0f95ad6e7ea23d",
      "bundle_path_digest": "sha256:609d7eaba12b325ed9c3d932fc453cd06e2e4545877913a77b0f95ad6e7ea23d",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-06-10T11:08:25.015000+00:00",
      "csv_description": "Joget DX is the next generation open source no-code / low-code application platform that combines the best of Rapid Application Development, Business Process Automation and Workflow Management. \nJoget DX empowers business users, non-coders or coders with a single platform to easily build, deliver, monitor and maintain enterprise applications.\n\nThis operator installs a Joget DX cluster running on JBoss EAP 7.\n\n### Features\n* Build full-fledged apps e.g. CRM, HR, Healthcare, etc\n* Drag and drop forms, lists, UI\n* Add workflow to automate processes\n* Extend via plugins\n* Apps are mobile optimized and cloud ready\n* Download ready-made apps from the Joget Marketplace\n\n### Before You Start\nDeploy a [MySQL](https://docs.openshift.com/online/pro/using_images/db_images/mysql.html) or [MariaDB](https://docs.openshift.com/online/pro/using_images/db_images/mariadb.html) database.\n\n### Post Deployment\nAccess the service URL and complete the one-time [Database Setup](https://dev.joget.org/community/display/DX7/Setting+Up+Database)\n\n### More Information\nMore information about Joget DX on JBoss EAP 7 is available in the [Joget Knowledge Base](https://dev.joget.org/community/display/DX7/Automated+Deployment+on+Red+Hat+OpenShift+with+the+Joget+Operator)\n",
      "csv_display_name": "Joget DX Operator",
      "csv_metadata_description": "No-code/low-code application platform to visually build, run and maintain apps",
      "csv_name": "joget-dx-openshift-operator.v0.0.30",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T12:55:35.700000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "joget-dx-operator",
      "provided_apis": [
        {
          "group": "app.joget.com",
          "kind": "JogetDX",
          "plural": "jogetdx",
          "version": "v1alpha1"
        }
      ],
      "provider": "Joget, Inc",
      "related_images": [
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "joget-dx-operator-79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749-annotation"
        },
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "operator"
        },
        {
          "digest": "sha256:0142dd0852a8d57411836c7b6fd61584b604291870a471c53694b7bd888469a4",
          "image": "registry.connect.redhat.com/joget/joget-dx7-eap7@sha256:0142dd0852a8d57411836c7b6fd61584b604291870a471c53694b7bd888469a4",
          "name": "joget"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "0.0.30",
      "version_original": "0.0.30"
    },
    {
      "_id": "62a326364ceb377f81ad7d10",
      "alm_examples": [
        {
          "api_version": "app.joget.com/v1alpha1",
          "kind": "JogetDX",
          "metadata": {
            "name": "example-joget"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/joget/joget-dx-operator-bundle@sha256:609d7eaba12b325ed9c3d932fc453cd06e2e4545877913a77b0f95ad6e7ea23d",
      "bundle_path_digest": "sha256:609d7eaba12b325ed9c3d932fc453cd06e2e4545877913a77b0f95ad6e7ea23d",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-06-10T11:08:38.925000+00:00",
      "csv_description": "Joget DX is the next generation open source no-code / low-code application platform that combines the best of Rapid Application Development, Business Process Automation and Workflow Management. \nJoget DX empowers business users, non-coders or coders with a single platform to easily build, deliver, monitor and maintain enterprise applications.\n\nThis operator installs a Joget DX cluster running on JBoss EAP 7.\n\n### Features\n* Build full-fledged apps e.g. CRM, HR, Healthcare, etc\n* Drag and drop forms, lists, UI\n* Add workflow to automate processes\n* Extend via plugins\n* Apps are mobile optimized and cloud ready\n* Download ready-made apps from the Joget Marketplace\n\n### Before You Start\nDeploy a [MySQL](https://docs.openshift.com/online/pro/using_images/db_images/mysql.html) or [MariaDB](https://docs.openshift.com/online/pro/using_images/db_images/mariadb.html) database.\n\n### Post Deployment\nAccess the service URL and complete the one-time [Database Setup](https://dev.joget.org/community/display/DX7/Setting+Up+Database)\n\n### More Information\nMore information about Joget DX on JBoss EAP 7 is available in the [Joget Knowledge Base](https://dev.joget.org/community/display/DX7/Automated+Deployment+on+Red+Hat+OpenShift+with+the+Joget+Operator)\n",
      "csv_display_name": "Joget DX Operator",
      "csv_metadata_description": "No-code/low-code application platform to visually build, run and maintain apps",
      "csv_name": "joget-dx-openshift-operator.v0.0.30",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T12:59:16.794000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "joget-dx-operator",
      "provided_apis": [
        {
          "group": "app.joget.com",
          "kind": "JogetDX",
          "plural": "jogetdx",
          "version": "v1alpha1"
        }
      ],
      "provider": "Joget, Inc",
      "related_images": [
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "joget-dx-operator-79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749-annotation"
        },
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "operator"
        },
        {
          "digest": "sha256:0142dd0852a8d57411836c7b6fd61584b604291870a471c53694b7bd888469a4",
          "image": "registry.connect.redhat.com/joget/joget-dx7-eap7@sha256:0142dd0852a8d57411836c7b6fd61584b604291870a471c53694b7bd888469a4",
          "name": "joget"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "0.0.30",
      "version_original": "0.0.30"
    },
    {
      "_id": "62a83733be1fd3a96e03d724",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "agentManager": {
              "credential": "",
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "daemonset": {
              "apmia": {
                "epagent": {
                  "port": 8889
                }
              },
              "privileged": true
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                }
              },
              "container": {
                "dockerstats": {
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "maxMemory": "",
                  "minMemory": "",
                  "port": 8085
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "bundle_path_digest": "sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-06-14T07:22:27.428000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for Kubernetes (UMA for Kubernetes) acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for Kubernetes discovers and monitors all the containers on a host. This capability allows to monitor both the Kubernetes Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   # The agent and Enterprise Manager connection details.\n   agentManager:\n     url: localhost:5001\n     # Agent/EM login credentials.\n     credential:\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n\n   clusterName: DevelopmentCluster\n   # type should be Kubernetes or Openshift depending on the environment\n   type: Openshift\n   role: common\n   monitor:\n     application:\n       # autoattach properties\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         # java autoattach properties\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         # dotnet autoattach properties\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: true\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         minMemory:\n         maxMemory:\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             # Defines the URL endpoint of the Prometheus backend.\n             url:\n             # Username (if any) for connecting to the Prometheus backend URL.\n             username:\n             password:\n             # Token (if any) for connecting to the Prometheus backend URL.\n             token:\n             configFiles:\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name:\n             value:\n           custom:\n             promqlConfigMap: custom-promql-config\n\n       dockerstats:\n         enabled: true\n     clusterPerformance:\n       enabled: true\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n       dataReporter:\n          vertex:\n            ttl: 720\n            refreshInterval: 360\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n         # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n         # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n\n   # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n   daemonset:\n     privileged: true\n     apmia:\n       epagent:\n         port: 8889\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey:\n       secretKey:\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList:\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.6.0-6",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-08-15T13:13:15.663000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator-a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d-annotation"
        },
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.6.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "2022.6.0-6",
      "version_original": "2022.6.0-6"
    },
    {
      "_id": "62a83733240dc134424ab48e",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "agentManager": {
              "credential": "",
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "daemonset": {
              "apmia": {
                "epagent": {
                  "port": 8889
                }
              },
              "privileged": true
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                }
              },
              "container": {
                "dockerstats": {
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "maxMemory": "",
                  "minMemory": "",
                  "port": 8085
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "bundle_path_digest": "sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "beta",
      "creation_date": "2022-06-14T07:22:27.817000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for Kubernetes (UMA for Kubernetes) acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for Kubernetes discovers and monitors all the containers on a host. This capability allows to monitor both the Kubernetes Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   # The agent and Enterprise Manager connection details.\n   agentManager:\n     url: localhost:5001\n     # Agent/EM login credentials.\n     credential:\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n\n   clusterName: DevelopmentCluster\n   # type should be Kubernetes or Openshift depending on the environment\n   type: Openshift\n   role: common\n   monitor:\n     application:\n       # autoattach properties\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         # java autoattach properties\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         # dotnet autoattach properties\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: true\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         minMemory:\n         maxMemory:\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             # Defines the URL endpoint of the Prometheus backend.\n             url:\n             # Username (if any) for connecting to the Prometheus backend URL.\n             username:\n             password:\n             # Token (if any) for connecting to the Prometheus backend URL.\n             token:\n             configFiles:\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name:\n             value:\n           custom:\n             promqlConfigMap: custom-promql-config\n\n       dockerstats:\n         enabled: true\n     clusterPerformance:\n       enabled: true\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n       dataReporter:\n          vertex:\n            ttl: 720\n            refreshInterval: 360\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n         # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n         # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n\n   # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n   daemonset:\n     privileged: true\n     apmia:\n       epagent:\n         port: 8889\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey:\n       secretKey:\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList:\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.6.0-6",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-08-15T13:13:20.703000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator-a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d-annotation"
        },
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.6.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "2022.6.0-6",
      "version_original": "2022.6.0-6"
    },
    {
      "_id": "62a83734240dc134424ab490",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "agentManager": {
              "credential": "",
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "daemonset": {
              "apmia": {
                "epagent": {
                  "port": 8889
                }
              },
              "privileged": true
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                }
              },
              "container": {
                "dockerstats": {
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "maxMemory": "",
                  "minMemory": "",
                  "port": 8085
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "bundle_path_digest": "sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-14T07:22:28.227000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for Kubernetes (UMA for Kubernetes) acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for Kubernetes discovers and monitors all the containers on a host. This capability allows to monitor both the Kubernetes Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   # The agent and Enterprise Manager connection details.\n   agentManager:\n     url: localhost:5001\n     # Agent/EM login credentials.\n     credential:\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n\n   clusterName: DevelopmentCluster\n   # type should be Kubernetes or Openshift depending on the environment\n   type: Openshift\n   role: common\n   monitor:\n     application:\n       # autoattach properties\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         # java autoattach properties\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         # dotnet autoattach properties\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: true\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         minMemory:\n         maxMemory:\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             # Defines the URL endpoint of the Prometheus backend.\n             url:\n             # Username (if any) for connecting to the Prometheus backend URL.\n             username:\n             password:\n             # Token (if any) for connecting to the Prometheus backend URL.\n             token:\n             configFiles:\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name:\n             value:\n           custom:\n             promqlConfigMap: custom-promql-config\n\n       dockerstats:\n         enabled: true\n     clusterPerformance:\n       enabled: true\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n       dataReporter:\n          vertex:\n            ttl: 720\n            refreshInterval: 360\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n         # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n         # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n\n   # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n   daemonset:\n     privileged: true\n     apmia:\n       epagent:\n         port: 8889\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey:\n       secretKey:\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList:\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.6.0-6",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:13:26.665000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator-a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d-annotation"
        },
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.6.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "2022.6.0-6",
      "version_original": "2022.6.0-6"
    },
    {
      "_id": "62a83b4dbe1fd3a96e03d73d",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "agentManager": {
              "credential": "",
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "daemonset": {
              "apmia": {
                "epagent": {
                  "port": 8889
                }
              },
              "privileged": true
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                }
              },
              "container": {
                "dockerstats": {
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "maxMemory": "",
                  "minMemory": "",
                  "port": 8085
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "bundle_path_digest": "sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-06-14T07:39:57.403000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for Kubernetes (UMA for Kubernetes) acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for Kubernetes discovers and monitors all the containers on a host. This capability allows to monitor both the Kubernetes Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   # The agent and Enterprise Manager connection details.\n   agentManager:\n     url: localhost:5001\n     # Agent/EM login credentials.\n     credential:\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n\n   clusterName: DevelopmentCluster\n   # type should be Kubernetes or Openshift depending on the environment\n   type: Openshift\n   role: common\n   monitor:\n     application:\n       # autoattach properties\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         # java autoattach properties\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         # dotnet autoattach properties\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: true\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         minMemory:\n         maxMemory:\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             # Defines the URL endpoint of the Prometheus backend.\n             url:\n             # Username (if any) for connecting to the Prometheus backend URL.\n             username:\n             password:\n             # Token (if any) for connecting to the Prometheus backend URL.\n             token:\n             configFiles:\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name:\n             value:\n           custom:\n             promqlConfigMap: custom-promql-config\n\n       dockerstats:\n         enabled: true\n     clusterPerformance:\n       enabled: true\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n       dataReporter:\n          vertex:\n            ttl: 720\n            refreshInterval: 360\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n         # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n         # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n\n   # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n   daemonset:\n     privileged: true\n     apmia:\n       epagent:\n         port: 8889\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey:\n       secretKey:\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList:\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.6.0-6",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-08-15T13:13:43.180000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator-a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d-annotation"
        },
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.6.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2022.6.0-6",
      "version_original": "2022.6.0-6"
    },
    {
      "_id": "62a83b4dbe1fd3a96e03d73f",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "agentManager": {
              "credential": "",
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "daemonset": {
              "apmia": {
                "epagent": {
                  "port": 8889
                }
              },
              "privileged": true
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                }
              },
              "container": {
                "dockerstats": {
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "maxMemory": "",
                  "minMemory": "",
                  "port": 8085
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "bundle_path_digest": "sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "beta",
      "creation_date": "2022-06-14T07:39:57.850000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for Kubernetes (UMA for Kubernetes) acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for Kubernetes discovers and monitors all the containers on a host. This capability allows to monitor both the Kubernetes Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   # The agent and Enterprise Manager connection details.\n   agentManager:\n     url: localhost:5001\n     # Agent/EM login credentials.\n     credential:\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n\n   clusterName: DevelopmentCluster\n   # type should be Kubernetes or Openshift depending on the environment\n   type: Openshift\n   role: common\n   monitor:\n     application:\n       # autoattach properties\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         # java autoattach properties\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         # dotnet autoattach properties\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: true\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         minMemory:\n         maxMemory:\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             # Defines the URL endpoint of the Prometheus backend.\n             url:\n             # Username (if any) for connecting to the Prometheus backend URL.\n             username:\n             password:\n             # Token (if any) for connecting to the Prometheus backend URL.\n             token:\n             configFiles:\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name:\n             value:\n           custom:\n             promqlConfigMap: custom-promql-config\n\n       dockerstats:\n         enabled: true\n     clusterPerformance:\n       enabled: true\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n       dataReporter:\n          vertex:\n            ttl: 720\n            refreshInterval: 360\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n         # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n         # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n\n   # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n   daemonset:\n     privileged: true\n     apmia:\n       epagent:\n         port: 8889\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey:\n       secretKey:\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList:\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.6.0-6",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-08-15T13:13:48.227000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator-a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d-annotation"
        },
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.6.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2022.6.0-6",
      "version_original": "2022.6.0-6"
    },
    {
      "_id": "62a83b4edd92c1f1f128e22c",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "agentManager": {
              "credential": "",
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "daemonset": {
              "apmia": {
                "epagent": {
                  "port": 8889
                }
              },
              "privileged": true
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                }
              },
              "container": {
                "dockerstats": {
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "maxMemory": "",
                  "minMemory": "",
                  "port": 8085
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "bundle_path_digest": "sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-14T07:39:58.255000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for Kubernetes (UMA for Kubernetes) acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for Kubernetes discovers and monitors all the containers on a host. This capability allows to monitor both the Kubernetes Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   # The agent and Enterprise Manager connection details.\n   agentManager:\n     url: localhost:5001\n     # Agent/EM login credentials.\n     credential:\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n\n   clusterName: DevelopmentCluster\n   # type should be Kubernetes or Openshift depending on the environment\n   type: Openshift\n   role: common\n   monitor:\n     application:\n       # autoattach properties\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         # java autoattach properties\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         # dotnet autoattach properties\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: true\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         minMemory:\n         maxMemory:\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             # Defines the URL endpoint of the Prometheus backend.\n             url:\n             # Username (if any) for connecting to the Prometheus backend URL.\n             username:\n             password:\n             # Token (if any) for connecting to the Prometheus backend URL.\n             token:\n             configFiles:\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name:\n             value:\n           custom:\n             promqlConfigMap: custom-promql-config\n\n       dockerstats:\n         enabled: true\n     clusterPerformance:\n       enabled: true\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n       dataReporter:\n          vertex:\n            ttl: 720\n            refreshInterval: 360\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n         # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n         # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n\n   # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n   daemonset:\n     privileged: true\n     apmia:\n       epagent:\n         port: 8889\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey:\n       secretKey:\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList:\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.6.0-6",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:13:52.873000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator-a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d-annotation"
        },
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.6.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2022.6.0-6",
      "version_original": "2022.6.0-6"
    },
    {
      "_id": "62a83c3c150d8182de8d12ef",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "agentManager": {
              "credential": "",
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "daemonset": {
              "apmia": {
                "epagent": {
                  "port": 8889
                }
              },
              "privileged": true
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                }
              },
              "container": {
                "dockerstats": {
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "maxMemory": "",
                  "minMemory": "",
                  "port": 8085
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "bundle_path_digest": "sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "beta",
      "creation_date": "2022-06-14T07:43:56.118000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for Kubernetes (UMA for Kubernetes) acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for Kubernetes discovers and monitors all the containers on a host. This capability allows to monitor both the Kubernetes Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   # The agent and Enterprise Manager connection details.\n   agentManager:\n     url: localhost:5001\n     # Agent/EM login credentials.\n     credential:\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n\n   clusterName: DevelopmentCluster\n   # type should be Kubernetes or Openshift depending on the environment\n   type: Openshift\n   role: common\n   monitor:\n     application:\n       # autoattach properties\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         # java autoattach properties\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         # dotnet autoattach properties\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: true\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         minMemory:\n         maxMemory:\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             # Defines the URL endpoint of the Prometheus backend.\n             url:\n             # Username (if any) for connecting to the Prometheus backend URL.\n             username:\n             password:\n             # Token (if any) for connecting to the Prometheus backend URL.\n             token:\n             configFiles:\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name:\n             value:\n           custom:\n             promqlConfigMap: custom-promql-config\n\n       dockerstats:\n         enabled: true\n     clusterPerformance:\n       enabled: true\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n       dataReporter:\n          vertex:\n            ttl: 720\n            refreshInterval: 360\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n         # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n         # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n\n   # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n   daemonset:\n     privileged: true\n     apmia:\n       epagent:\n         port: 8889\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey:\n       secretKey:\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList:\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.6.0-6",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-08-15T13:33:06.466000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "plural": "universalmonitoringagents",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator-a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d-annotation"
        },
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.6.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2022.6.0-6",
      "version_original": "2022.6.0-6"
    },
    {
      "_id": "62a83c3dbe1fd3a96e03d749",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "agentManager": {
              "credential": "",
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "daemonset": {
              "apmia": {
                "epagent": {
                  "port": 8889
                }
              },
              "privileged": true
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                }
              },
              "container": {
                "dockerstats": {
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "maxMemory": "",
                  "minMemory": "",
                  "port": 8085
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "bundle_path_digest": "sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-14T07:43:57.078000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for Kubernetes (UMA for Kubernetes) acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for Kubernetes discovers and monitors all the containers on a host. This capability allows to monitor both the Kubernetes Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   # The agent and Enterprise Manager connection details.\n   agentManager:\n     url: localhost:5001\n     # Agent/EM login credentials.\n     credential:\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n\n   clusterName: DevelopmentCluster\n   # type should be Kubernetes or Openshift depending on the environment\n   type: Openshift\n   role: common\n   monitor:\n     application:\n       # autoattach properties\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         # java autoattach properties\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         # dotnet autoattach properties\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: true\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         minMemory:\n         maxMemory:\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             # Defines the URL endpoint of the Prometheus backend.\n             url:\n             # Username (if any) for connecting to the Prometheus backend URL.\n             username:\n             password:\n             # Token (if any) for connecting to the Prometheus backend URL.\n             token:\n             configFiles:\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name:\n             value:\n           custom:\n             promqlConfigMap: custom-promql-config\n\n       dockerstats:\n         enabled: true\n     clusterPerformance:\n       enabled: true\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n       dataReporter:\n          vertex:\n            ttl: 720\n            refreshInterval: 360\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n         # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n         # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n\n   # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n   daemonset:\n     privileged: true\n     apmia:\n       epagent:\n         port: 8889\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey:\n       secretKey:\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList:\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.6.0-6",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:41:07.880000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "plural": "universalmonitoringagents",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator-a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d-annotation"
        },
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.6.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2022.6.0-6",
      "version_original": "2022.6.0-6"
    },
    {
      "_id": "62a83c3edd92c1f1f128e236",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "agentManager": {
              "credential": "",
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "daemonset": {
              "apmia": {
                "epagent": {
                  "port": 8889
                }
              },
              "privileged": true
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                }
              },
              "container": {
                "dockerstats": {
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "maxMemory": "",
                  "minMemory": "",
                  "port": 8085
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "bundle_path_digest": "sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-06-14T07:43:58.071000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for Kubernetes (UMA for Kubernetes) acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for Kubernetes discovers and monitors all the containers on a host. This capability allows to monitor both the Kubernetes Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   # The agent and Enterprise Manager connection details.\n   agentManager:\n     url: localhost:5001\n     # Agent/EM login credentials.\n     credential:\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n\n   clusterName: DevelopmentCluster\n   # type should be Kubernetes or Openshift depending on the environment\n   type: Openshift\n   role: common\n   monitor:\n     application:\n       # autoattach properties\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         # java autoattach properties\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         # dotnet autoattach properties\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: true\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         minMemory:\n         maxMemory:\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             # Defines the URL endpoint of the Prometheus backend.\n             url:\n             # Username (if any) for connecting to the Prometheus backend URL.\n             username:\n             password:\n             # Token (if any) for connecting to the Prometheus backend URL.\n             token:\n             configFiles:\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name:\n             value:\n           custom:\n             promqlConfigMap: custom-promql-config\n\n       dockerstats:\n         enabled: true\n     clusterPerformance:\n       enabled: true\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n       dataReporter:\n          vertex:\n            ttl: 720\n            refreshInterval: 360\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n         # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n         # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n\n   # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n   daemonset:\n     privileged: true\n     apmia:\n       epagent:\n         port: 8889\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey:\n       secretKey:\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList:\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.6.0-6",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-08-15T13:29:19.199000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "plural": "universalmonitoringagents",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator-a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d-annotation"
        },
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.6.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2022.6.0-6",
      "version_original": "2022.6.0-6"
    },
    {
      "_id": "62a83c48dd92c1f1f128e23b",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "agentManager": {
              "credential": "",
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "daemonset": {
              "apmia": {
                "epagent": {
                  "port": 8889
                }
              },
              "privileged": true
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                }
              },
              "container": {
                "dockerstats": {
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "maxMemory": "",
                  "minMemory": "",
                  "port": 8085
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "bundle_path_digest": "sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-06-14T07:44:08.454000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for Kubernetes (UMA for Kubernetes) acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for Kubernetes discovers and monitors all the containers on a host. This capability allows to monitor both the Kubernetes Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   # The agent and Enterprise Manager connection details.\n   agentManager:\n     url: localhost:5001\n     # Agent/EM login credentials.\n     credential:\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n\n   clusterName: DevelopmentCluster\n   # type should be Kubernetes or Openshift depending on the environment\n   type: Openshift\n   role: common\n   monitor:\n     application:\n       # autoattach properties\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         # java autoattach properties\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         # dotnet autoattach properties\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: true\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         minMemory:\n         maxMemory:\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             # Defines the URL endpoint of the Prometheus backend.\n             url:\n             # Username (if any) for connecting to the Prometheus backend URL.\n             username:\n             password:\n             # Token (if any) for connecting to the Prometheus backend URL.\n             token:\n             configFiles:\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name:\n             value:\n           custom:\n             promqlConfigMap: custom-promql-config\n\n       dockerstats:\n         enabled: true\n     clusterPerformance:\n       enabled: true\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n       dataReporter:\n          vertex:\n            ttl: 720\n            refreshInterval: 360\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n         # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n         # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n\n   # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n   daemonset:\n     privileged: true\n     apmia:\n       epagent:\n         port: 8889\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey:\n       secretKey:\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList:\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.6.0-6",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-08-15T13:24:44.037000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "plural": "universalmonitoringagents",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator-a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d-annotation"
        },
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.6.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "2022.6.0-6",
      "version_original": "2022.6.0-6"
    },
    {
      "_id": "62a83c49240dc134424ab4ae",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "agentManager": {
              "credential": "",
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "daemonset": {
              "apmia": {
                "epagent": {
                  "port": 8889
                }
              },
              "privileged": true
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                }
              },
              "container": {
                "dockerstats": {
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "maxMemory": "",
                  "minMemory": "",
                  "port": 8085
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "bundle_path_digest": "sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "beta",
      "creation_date": "2022-06-14T07:44:09.020000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for Kubernetes (UMA for Kubernetes) acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for Kubernetes discovers and monitors all the containers on a host. This capability allows to monitor both the Kubernetes Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   # The agent and Enterprise Manager connection details.\n   agentManager:\n     url: localhost:5001\n     # Agent/EM login credentials.\n     credential:\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n\n   clusterName: DevelopmentCluster\n   # type should be Kubernetes or Openshift depending on the environment\n   type: Openshift\n   role: common\n   monitor:\n     application:\n       # autoattach properties\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         # java autoattach properties\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         # dotnet autoattach properties\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: true\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         minMemory:\n         maxMemory:\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             # Defines the URL endpoint of the Prometheus backend.\n             url:\n             # Username (if any) for connecting to the Prometheus backend URL.\n             username:\n             password:\n             # Token (if any) for connecting to the Prometheus backend URL.\n             token:\n             configFiles:\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name:\n             value:\n           custom:\n             promqlConfigMap: custom-promql-config\n\n       dockerstats:\n         enabled: true\n     clusterPerformance:\n       enabled: true\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n       dataReporter:\n          vertex:\n            ttl: 720\n            refreshInterval: 360\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n         # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n         # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n\n   # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n   daemonset:\n     privileged: true\n     apmia:\n       epagent:\n         port: 8889\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey:\n       secretKey:\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList:\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.6.0-6",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-08-15T12:55:06+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "plural": "universalmonitoringagents",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator-a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d-annotation"
        },
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.6.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "2022.6.0-6",
      "version_original": "2022.6.0-6"
    },
    {
      "_id": "62a83c49dd92c1f1f128e23d",
      "alm_examples": [
        {
          "api_version": "ca.broadcom.com/v1alpha1",
          "kind": "UniversalMonitoringAgent",
          "metadata": {
            "name": "uma-monitor"
          },
          "spec": {
            "agentManager": {
              "credential": "",
              "tenantID": "",
              "url": "localhost:5001"
            },
            "cloudmonitoring": {
              "aws": {
                "accessKey": "",
                "enabled": false,
                "secretKey": "",
                "servicesList": ""
              }
            },
            "clusterName": "DevelopmentCluster",
            "daemonset": {
              "apmia": {
                "epagent": {
                  "port": 8889
                }
              },
              "privileged": true
            },
            "monitor": {
              "application": {
                "autoattach": {
                  "dotnet": {
                    "enabled": true
                  },
                  "dynamicPropertyResolution": {
                    "agentName": "",
                    "hostName": "{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost"
                  },
                  "filterType": "whitelist",
                  "java": {
                    "customJdkTools": {
                      "enabled": false,
                      "imageName": ""
                    },
                    "enabled": true
                  },
                  "probe": {
                    "enabled": true
                  }
                },
                "jmx": {
                  "enabled": true
                },
                "opentracing": {
                  "correlation": {
                    "enabled": false
                  },
                  "enabled": true,
                  "grpc": {
                    "hostport": ""
                  }
                },
                "zipkinTracing": {
                  "enabled": true,
                  "zipkinServer": {}
                }
              },
              "clusterPerformance": {
                "dataReporter": {
                  "vertex": {
                    "refreshInterval": 360,
                    "ttl": 720
                  }
                },
                "enabled": true,
                "node": {
                  "noscheduleTaint": {
                    "allowed": {
                      "tolerations": ""
                    },
                    "skipMetricAggregation": {
                      "enabled": true
                    }
                  }
                }
              },
              "container": {
                "dockerstats": {
                  "enabled": true
                },
                "prometheus": {
                  "backend": {
                    "custom": {
                      "promqlConfigMap": "custom-promql-config"
                    },
                    "enabled": false,
                    "endPoint": {
                      "configFiles": "",
                      "metricAlias": "container_name=container,pod_name=pod",
                      "password": "",
                      "token": "",
                      "url": "",
                      "username": ""
                    },
                    "filter": {
                      "name": "",
                      "value": ""
                    }
                  },
                  "exporter": {
                    "enabled": true
                  }
                }
              },
              "events": {
                "clamp": {
                  "perDayLimit": 15000
                },
                "elasticDocTypeId": "itoa_events_apm",
                "elasticDocTypeVersion": 1,
                "elasticProduct": "ao",
                "enabled": false,
                "filter": {
                  "fieldselector": "type!=Normal"
                }
              },
              "httpCollector": {
                "enabled": true,
                "ingress": {
                  "enabled": false,
                  "ssl": {
                    "enabled": false
                  }
                },
                "memoryGrid": {},
                "replicas": 1,
                "server": {
                  "host": "0.0.0.0",
                  "maxMemory": "",
                  "minMemory": "",
                  "port": 8085
                }
              },
              "kafka": {
                "consumergroups": {
                  "filter": "",
                  "metrics": true
                },
                "debug": false,
                "deployAsDaemonSet": false,
                "enabled": false,
                "jmx": {
                  "MBeans": {
                    "exclude": "",
                    "include": ""
                  },
                  "modules": "kafka,jvm,memory"
                },
                "ssl": {
                  "client": {
                    "enabled": false,
                    "endpointIdentificationEnabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystoreKeyPassword": {
                      "value": ""
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  },
                  "jmx": {
                    "enabled": false,
                    "keystoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "keystorePassword": {
                      "value": ""
                    },
                    "truststoreKey": {
                      "value": "",
                      "valueFrom": {
                        "secretKeyRef": {
                          "key": "",
                          "name": ""
                        }
                      }
                    },
                    "truststorePassword": {
                      "value": ""
                    }
                  }
                }
              },
              "node": {
                "enabled": true
              }
            },
            "role": "common",
            "type": "Openshift"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ca/uma-operator-bundle@sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "bundle_path_digest": "sha256:e0e611af7c927055cadd8bc21f02eb03083924a385b3a22ac417e9dbf9ca8b96",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-06-14T07:44:09.519000+00:00",
      "csv_description": "The **DX APM Universal Monitoring Agent** for Kubernetes (UMA for Kubernetes) acts as a single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes. UMA for Kubernetes discovers and monitors all the containers on a host. This capability allows to monitor both the Kubernetes Infrastructure ( like Node, Pods, Containers, Cluster Services etc ) and applications running on this infrastructure & correlate them together which can help the triager to isolate if the the problem is related to the application or infrastructure\n\n**Usage**:\n```\n apiVersion: ca.broadcom.com/v1alpha1\n kind: UniversalMonitoringAgent\n metadata:\n   name: uma-monitor\n spec:\n   # The agent and Enterprise Manager connection details.\n   agentManager:\n     url: localhost:5001\n     # Agent/EM login credentials.\n     credential:\n     # tenantID is Cohort ID of DX SaaS tenant.\n     # After logging into DX SaaS, Cohort ID is available at \"Launch Pad -> Settings -> Connector Parameters\"\n     # tenantID is only required if Kubernetes/OpenShift events monitoring is enabled in UMA.\n     tenantID: \"\"\n\n   clusterName: DevelopmentCluster\n   # type should be Kubernetes or Openshift depending on the environment\n   type: Openshift\n   role: common\n   monitor:\n     application:\n       # autoattach properties\n       autoattach:\n         filterType: whitelist\n         probe:\n           enabled: true\n         # this feature leverages container metadata to resolve agent host name and agent name\n         dynamicPropertyResolution:\n           hostName: \"{k8s_deployment_name},{k8s_daemonset_name},{k8s_deploymentconfig_name},{k8s_pod_name},ContainerHost\"\n           agentName: \"\"\n         # java autoattach properties\n         java:\n           enabled: true\n           propertiesOverride:\n           customJdkTools:\n             enabled: false\n             # Provide your custom created jdk tools jar image name below.\n             imageName: \"\"\n         # dotnet autoattach properties\n         dotnet:\n           enabled: true\n           propertiesOverride:\n       jmx:\n         enabled: true\n       opentracing:\n         enabled: true\n         grpc:\n           hostport: \"\"\n         correlation:\n           enabled: false\n       zipkinTracing:\n         enabled: true\n         zipkinServer:\n           hostport:\n     events:\n       enabled: true\n       filter:\n         # fieldselector property can be used to filter the Kubernetes events based on the value of one or more resource fields.\n         # Here are some examples of field selector queries: metadata.namespace!=default, metadata.name=my-service etc.\n         fieldselector: type!=Normal\n         namespace:\n       clamp:\n         perDayLimit: 15000\n       elasticDocTypeId: itoa_events_apm\n       elasticDocTypeVersion: 1\n       elasticProduct: ao\n     httpCollector:\n       enabled: true\n       replicas: 1\n       server:\n         host: 0.0.0.0\n         port: 8085\n         minMemory:\n         maxMemory:\n       memoryGrid:\n         enabled:\n       # Enable this ingress resource creation if there is Ingress Controller deployed\n       # It requires session affinity using HTTP Headers by LB Ingress Controller\n       ingress:\n         enabled: false\n         host:\n         ssl:\n           enabled: false\n     container:\n       prometheus:\n         exporter:\n           enabled: true\n         backend:\n           enabled: false\n           endPoint:\n             # Defines the URL endpoint of the Prometheus backend.\n             url:\n             # Username (if any) for connecting to the Prometheus backend URL.\n             username:\n             password:\n             # Token (if any) for connecting to the Prometheus backend URL.\n             token:\n             configFiles:\n             metricAlias: container_name=container,pod_name=pod\n           filter:\n             name:\n             value:\n           custom:\n             promqlConfigMap: custom-promql-config\n\n       dockerstats:\n         enabled: true\n     clusterPerformance:\n       enabled: true\n       node:\n         noscheduleTaint:\n           skipMetricAggregation:\n             enabled: true\n           allowed:\n             tolerations: \"\"\n       dataReporter:\n          vertex:\n            ttl: 720\n            refreshInterval: 360\n     node:\n       enabled: true\n     kafka:\n       enabled: false\n       consumergroups:\n         metrics: true\n         filter: \"\"\n       jmx:\n         modules: \"kafka,jvm,memory\"\n         MBeans:\n         # A semi-colon separated list of managed bean object names. JMX metrics will be automatically reported for matching beans.\n           include: \"\"\n         # A semi-colon separated list of managed bean object names. Matching beans will be ignored for Kafka JMX metrics reporting. This property overrides \"include\" configuration.\n           exclude: \"\"\n       deployAsDaemonSet: false\n       debug: false\n       ssl:\n         client:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n           keystoreKeyPassword:\n             value: \"\"\n           endpointIdentificationEnabled: false\n         jmx:\n           enabled: false\n           truststoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           truststorePassword:\n             value: \"\"\n           keystoreKey:\n             value: \"\"\n             valueFrom:\n               secretKeyRef:\n                 name: \"\"\n                 key: \"\"\n           keystorePassword:\n             value: \"\"\n\n   # Default epagent port of the UMA daemonset pod deployment (app-container-monitor)\n   daemonset:\n     privileged: true\n     apmia:\n       epagent:\n         port: 8889\n   cloudmonitoring:\n     aws:\n       enabled: false\n       accessKey:\n       secretKey:\n       # services supported are rds,ec2,ebs,lambda,dynamodb,s3,sns,ecs,sqs,kinesis,clb,nlb,alb,redshift,elasticache,autoScaling,billing,apiGateway\n       # provide comma separated services to monitor\n       servicesList:\n\n```\n",
      "csv_display_name": "DX APM Universal Monitoring Agent",
      "csv_metadata_description": "The Universal Monitoring Agent for Kubernetes (UMA for Kubernetes) acts as single deployment that automatically discovers and monitors cloud and container infrastructures and containerized application processes.",
      "csv_name": "uma-operator.v2022.6.0-6",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-08-15T12:48:54.137000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "uma-operator",
      "provided_apis": [
        {
          "group": "ca.broadcom.com",
          "kind": "UniversalMonitoringAgent",
          "plural": "universalmonitoringagents",
          "version": "v1alpha1"
        }
      ],
      "provider": "Broadcom, Inc.",
      "related_images": [
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator-a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d-annotation"
        },
        {
          "digest": "sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "image": "registry.connect.redhat.com/ca/uma-operator@sha256:a9be2966adeb764edff9f371464d2ebb72f8203ad8bbef5785095c783c5c305d",
          "name": "uma-operator"
        },
        {
          "digest": "sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "image": "registry.connect.redhat.com/ca/universalmonitoragent@sha256:2c37187f89406d5dd00cb5bc113e504835d42f2c3590db5fe13520f75e8c0159",
          "name": "uma"
        }
      ],
      "replaces": null,
      "skip_range": ">=2022.1.0 <2022.6.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "2022.6.0-6",
      "version_original": "2022.6.0-6"
    }
  ],
  "page": 33,
  "page_size": 100,
  "total": 4763
}
