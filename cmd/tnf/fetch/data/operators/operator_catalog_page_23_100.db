{
  "data": [
    {
      "_id": "62345fa7314381d2b0756b31",
      "alm_examples": [
        {
          "api_version": "apps.gitlab.com/v1beta2",
          "kind": "Runner",
          "metadata": {
            "name": "example"
          },
          "spec": {
            "gitlabUrl": "https://gitlab.com",
            "imagePullPolicy": "Always",
            "tags": "openshift, test",
            "token": "gitlab-dev-runner-secret"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/gitlab/gitlab-runner-operator-bundle@sha256:abe1504fedbf38bc1cb45e5393216bae9cca95066ca84fa730c7e8b129930074",
      "bundle_path_digest": "sha256:abe1504fedbf38bc1cb45e5393216bae9cca95066ca84fa730c7e8b129930074",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:32:07.664000+00:00",
      "csv_description": "GitLab Runner is the lightweight, highly-scalable agent that runs your build jobs and sends the results back to a GitLab instance. GitLab Runner works in conjunction with GitLab CI/CD, the open-source continuous integration service included with GitLab.\n\nThe GitLab Runner operator manages the lifecycle of GitLab Runner in Kubernetes or Openshift clusters. The operator aims to automate the tasks needed to run your CI/CD jobs in your container orchestration platform.\n\n## Usage\n\n To link a GitLab Runner instance to a self-hosted GitLab instance or the hosted [GitLab](https://gitlab.com), you first need to:\n\n 1. create a secret containing the `runner-registration-token` from your GitLab project.\n\n   ```\n  cat > gitlab-runner-secret.yml << EOF\n  apiVersion: v1\n  kind: Secret\n  metadata:\n    name: gitlab-runner-secret\n  type: Opaque\n  stringData:\n    runner-registration-token: REPLACE_ME # your project runner secret\n  EOF\n  ```\n\n  ```\n  oc apply -f gitlab-runner-secret.yml\n  ```\n\n 2. Create the Custom Resource Definition (CRD) file and include the following information. The tags value must be openshift for the job to run.\n\n   ```\n   cat > gitlab-runner.yml << EOF\n   apiVersion: apps.gitlab.com/v1beta2\n   kind: Runner\n   metadata:\n     name: gitlab-runner\n   spec:\n     gitlabUrl: https://gitlab.example.com\n     buildImage: alpine\n     token: gitlab-runner-secret\n     tags: openshift\n   EOF\n   ```\n\n  ```\n  oc apply -f gitlab-runner.yml\n  ```\n\n## Full documentation\n\nVisit [Install GitLab Runner on Red Hat OpenShift](https://docs.gitlab.com/runner/install/openshift.html)\n",
      "csv_display_name": "GitLab Runner",
      "csv_metadata_description": "GitLab Runner operator manages lifecycle of GitLab Runner instances",
      "csv_name": "gitlab-runner-operator.v1.2.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:41:25.074000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "gitlab-runner-operator",
      "provided_apis": [
        {
          "group": "apps.gitlab.com",
          "kind": "Runner",
          "version": "v1beta2"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:f48d93d89905284a35a72ec312ad4313bb1a42deaaab662eb181a65d34a89cd9",
          "image": "registry.connect.redhat.com/gitlab/gitlab-runner@sha256:f48d93d89905284a35a72ec312ad4313bb1a42deaaab662eb181a65d34a89cd9",
          "name": "gitlab-runner"
        },
        {
          "digest": "sha256:9148c4c10685871e3bbed037d9c36e85f0603da38e721c5db2a85b9c6defeac9",
          "image": "registry.connect.redhat.com/gitlab/gitlab-runner-helper@sha256:9148c4c10685871e3bbed037d9c36e85f0603da38e721c5db2a85b9c6defeac9",
          "name": "gitlab-runner-helper"
        },
        {
          "digest": "sha256:6ac79da50858f82949e1dae4a016cbe86b75de977fe747a958d28dcd5c8e4080",
          "image": "registry.connect.redhat.com/gitlab/gitlab-runner-operator@sha256:6ac79da50858f82949e1dae4a016cbe86b75de977fe747a958d28dcd5c8e4080",
          "name": "gitlab-runner-operator"
        },
        {
          "digest": "sha256:dc0f91e256c86c3f7cb930d0e4d48eb68576425bc4bd288fb76decb0577c7e9e",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:dc0f91e256c86c3f7cb930d0e4d48eb68576425bc4bd288fb76decb0577c7e9e",
          "name": "kube-rbac-proxy"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.2.0",
      "version_original": "1.2.0"
    },
    {
      "_id": "62345fa95593ce895a7b5355",
      "alm_examples": [
        {
          "api_version": "apps.gitlab.com/v1beta2",
          "kind": "Runner",
          "metadata": {
            "name": "example"
          },
          "spec": {
            "gitlabUrl": "https://gitlab.com",
            "imagePullPolicy": "Always",
            "tags": "openshift, test",
            "token": "gitlab-dev-runner-secret"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/gitlab/gitlab-runner-operator-bundle@sha256:a983d27fdb8e3c63bdbf40efe22a2ab62016c3ca75040c2f1a4b429278d72731",
      "bundle_path_digest": "sha256:a983d27fdb8e3c63bdbf40efe22a2ab62016c3ca75040c2f1a4b429278d72731",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:32:09.415000+00:00",
      "csv_description": "GitLab Runner is the lightweight, highly-scalable agent that runs your build jobs and sends the results back to a GitLab instance. GitLab Runner works in conjunction with GitLab CI/CD, the open-source continuous integration service included with GitLab.\n\nThe GitLab Runner operator manages the lifecycle of GitLab Runner in Kubernetes or Openshift clusters. The operator aims to automate the tasks needed to run your CI/CD jobs in your container orchestration platform.\n\n## Usage\n\n To link a GitLab Runner instance to a self-hosted GitLab instance or the hosted [GitLab](https://gitlab.com), you first need to:\n\n 1. create a secret containing the `runner-registration-token` from your GitLab project.\n\n   ```\n  cat > gitlab-runner-secret.yml << EOF\n  apiVersion: v1\n  kind: Secret\n  metadata:\n    name: gitlab-runner-secret\n  type: Opaque\n  stringData:\n    runner-registration-token: REPLACE_ME # your project runner secret\n  EOF\n  ```\n\n  ```\n  oc apply -f gitlab-runner-secret.yml\n  ```\n\n 2. Create the Custom Resource Definition (CRD) file and include the following information. The tags value must be openshift for the job to run.\n\n   ```\n   cat > gitlab-runner.yml << EOF\n   apiVersion: apps.gitlab.com/v1beta2\n   kind: Runner\n   metadata:\n     name: gitlab-runner\n   spec:\n     gitlabUrl: https://gitlab.example.com\n     buildImage: alpine\n     token: gitlab-runner-secret\n     tags: openshift\n   EOF\n   ```\n\n  ```\n  oc apply -f gitlab-runner.yml\n  ```\n\n## Full documentation\n\nVisit [Install GitLab Runner on Red Hat OpenShift](https://docs.gitlab.com/runner/install/openshift.html)\n",
      "csv_display_name": "GitLab Runner",
      "csv_metadata_description": "GitLab Runner operator manages lifecycle of GitLab Runner instances",
      "csv_name": "gitlab-runner-operator.v1.4.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:41:31.816000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "gitlab-runner-operator",
      "provided_apis": [
        {
          "group": "apps.gitlab.com",
          "kind": "Runner",
          "version": "v1beta2"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:4cd860f02a5c22208cebfdae751fdc27069a4c14442a9020024c576c700f0634",
          "image": "registry.connect.redhat.com/gitlab/gitlab-runner@sha256:4cd860f02a5c22208cebfdae751fdc27069a4c14442a9020024c576c700f0634",
          "name": "gitlab-runner"
        },
        {
          "digest": "sha256:272c50ca9ef77c92deac0ca302df9e0127d5c54609c35230f96cf1d91de5fe97",
          "image": "registry.connect.redhat.com/gitlab/gitlab-runner-helper@sha256:272c50ca9ef77c92deac0ca302df9e0127d5c54609c35230f96cf1d91de5fe97",
          "name": "gitlab-runner-helper"
        },
        {
          "digest": "sha256:c6572cb1c20713f2f582f8b436307e80c23dcac08c1d7bde37833fd266ef9618",
          "image": "registry.connect.redhat.com/gitlab/gitlab-runner-operator@sha256:c6572cb1c20713f2f582f8b436307e80c23dcac08c1d7bde37833fd266ef9618",
          "name": "gitlab-runner-operator"
        },
        {
          "digest": "sha256:dc0f91e256c86c3f7cb930d0e4d48eb68576425bc4bd288fb76decb0577c7e9e",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:dc0f91e256c86c3f7cb930d0e4d48eb68576425bc4bd288fb76decb0577c7e9e",
          "name": "kube-rbac-proxy"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.4.0",
      "version_original": "1.4.0"
    },
    {
      "_id": "62345fad314381d2b0756b33",
      "alm_examples": [
        {
          "api_version": "xcrypt.zettaset.com/v1alpha1",
          "kind": "XCrypt",
          "metadata": {
            "name": "zts-masterset"
          },
          "spec": {
            "status": {
              "podNames": "zts-ca",
              "replicas": "1,"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/zts/xcrypt-operator-1-bundle@sha256:c3913778f986ae4f3a7d94da2a9d0157233dbb676e3c1eecacbdbc02a864685a",
      "bundle_path_digest": "sha256:c3913778f986ae4f3a7d94da2a9d0157233dbb676e3c1eecacbdbc02a864685a",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-03-18T10:32:13.847000+00:00",
      "csv_description": "Zettaset\u2019s RedHat Certified XCrypt Operator allows users to deploy multiple XCrypt components on OpenShift with just a few simple commands. The XCrypt Operator deployment provides software-defined encryption that transparently protects container data throughout your OpenShift environment.\n\n## Core Features\n* **Automated XCrypt provisioning** - Deploying a Zettaset XCrypt has never been easier. Adjust cluster specific configuration and let the Zettaset Operator take care of provisioning XCrypt services and setting up the XCrypt encryption to your exact specification. \n* **CSI Driver deployment**: Zettaset XCrypt Operator automatically deploys Zettaset XCrypt CSI Driver in order to provide automated and transparent data-at-rest  encryption functionality compatible with Openshift and any other container orchestrator. Once the Operator is provisioned, the driver runs fine tuned and ready to work with other XCrypt components.\n* **Multi-node topology**: Encrypt as many nodes and volumes as you need to. XCrypt components can be installed on multiple nodes across the cluster. This is defined by two labels: zts-master and zts-worker. Normally zts-master node is a single node that runs Zettaset XCrypt major services required for the product operation. Multiple nodes can be marked as zts-worker and those are the nodes that can have encrypted volumes.\n* **Seamless Encrypted Volume mount**: Volumes are not only being encrypted, but also are mounted/unmounted to containers with Persistent Volume Claims. This happens as seamlessly as regular volumes provision and mount/unmount.\n* **Robust failover**: A node failure doesn\u2019t affect XCrypt operations on other nodes of the cluster. Encryption on a restarted/recovered node gets back to normal functioning if the node stays healthy and data hasn\u2019t been corrupted during the restart\n\n## About Zettaset XCrypt Kubernetes Encryption for OpenShift\nXCrypt Kubernetes Encryption for OpenShift is a software-only solution that enables encryption of data at rest stored in Red Hat OpenShift container environments without slowing down the DevSecOps process. In addition to providing a transparent and high-performance layer of security that flexibly protects container data across on-premise, in hybrid, and multi-cloud environments, it also helps your organization efficiently transition from DevOps to DevSecOps.  \n\nMore information about Zettaset XCrypt Kubernetes Encryption for OpenShift can be found in the [Deployment and Administration Guide](https://1f2aca073706bb52f501-133f3466c38fdb0417539cdf095d8336.ssl.cf1.rackcdn.com/ZettasetXCryptContainerEncryption.8.5.0.Final.pdf)\n\n## RedHat OpenShift + Zettaset: The next generation of secure enterprise infrastructure for DevSecOps  \nBy combining RedHat\u2019s Container Platform with Zettaset\u2019s certified software-defined encryption, you can create the next generation of secure enterprise infrastructure that DevSecOps requires. Together they create the stable, consistent, and supported base that your organization needs to develop applications faster, simplify updates, drive innovation, and reduce the risk of potential security breaches and data theft.\n### Core Features\n* Software-only for simple and scalable deployments \n* Negligible performance impact\n* Transparent to developers and administrators \n* Works with AWS, Google, and Azure \n* Unique encryption key per container volume \n* Encrypted volumes are only available when in use\n* Direct integration with OpenShift \n* Automated encryption policy management Secure erase of volumes\n* Ability to securely decommission a node\n\n## How does XCrypt Kubernetes Encryption fit into OpenShift? \nXCrypt XCrypt Kubernetes Encryption for OpenShift Encryption makes it incredibly easy to protect container data in your OpenShift environment. \n### Use cases include:\n* Transitioning from DevOps to DevSecOps \n* Ensuring data protection in OpenShift container environments with negligible performance impact \n* Achieving compliance in regulated industries like healthcare and finance\n\n## Other Information\nRole-based access control needs to be configured prior to the Operator installation. Please find details in the [Deployment and Administration Guide](https://1f2aca073706bb52f501-133f3466c38fdb0417539cdf095d8336.ssl.cf1.rackcdn.com/ZettasetXCryptContainerEncryption.8.5.0.Final.pdf)    ",
      "csv_display_name": "Zettaset XCrypt Operator",
      "csv_metadata_description": "XCrypt Operator deploys Zettaset XCrypt Container Encryption  - the only software-defined solution that offers transparent high performance data-at-rest encryption of critical data in container environments.",
      "csv_name": "zts-xcrypt-operator.v0.0.17",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:46:07.441000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "xcrypt-operator",
      "provided_apis": [
        {
          "group": "xcrypt.zettaset.com",
          "kind": "XCrypt",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:7e6316a6c41dd71c4d9025bd958a475929369284eee1a02d9e870e883acfd9ac",
          "image": "registry.connect.redhat.com/zts/xcrypt-operator-1@sha256:7e6316a6c41dd71c4d9025bd958a475929369284eee1a02d9e870e883acfd9ac",
          "name": "xcrypt-operator-1-7e6316a6c41dd71c4d9025bd958a475929369284eee1a02d9e870e883acfd9ac-annotation"
        },
        {
          "digest": "sha256:7e6316a6c41dd71c4d9025bd958a475929369284eee1a02d9e870e883acfd9ac",
          "image": "registry.connect.redhat.com/zts/xcrypt-operator-1@sha256:7e6316a6c41dd71c4d9025bd958a475929369284eee1a02d9e870e883acfd9ac",
          "name": "zts-xcrypt-operator"
        },
        {
          "digest": "sha256:9f1015dfb459b69f5dbf449efa0517452095a6cf4f20826ebae278f9f800ffe7",
          "image": "registry.connect.redhat.com/zts/xcrypt-ca-1@sha256:9f1015dfb459b69f5dbf449efa0517452095a6cf4f20826ebae278f9f800ffe7",
          "name": "ca"
        },
        {
          "digest": "sha256:9af5d21dd748dfbf4e107f27a5f10fa3c0ba928ade9b989a744b620ce34ec757",
          "image": "registry.connect.redhat.com/zts/xcrypt-kmip-server-1@sha256:9af5d21dd748dfbf4e107f27a5f10fa3c0ba928ade9b989a744b620ce34ec757",
          "name": "kmip"
        },
        {
          "digest": "sha256:bc5486892a41e70f5dc4c4e1d82fca8db2149598fb8b5950ba5da1ee2d9d245d",
          "image": "registry.connect.redhat.com/zts/xcrypt-license-server-1@sha256:bc5486892a41e70f5dc4c4e1d82fca8db2149598fb8b5950ba5da1ee2d9d245d",
          "name": "ls"
        },
        {
          "digest": "sha256:9faa4b597eb74df412761dffa057b64fb69dbf9fa016414962eb2099a343e734",
          "image": "registry.connect.redhat.com/zts/xcrypt-host-manager-1@sha256:9faa4b597eb74df412761dffa057b64fb69dbf9fa016414962eb2099a343e734",
          "name": "hm"
        },
        {
          "digest": "sha256:c15fa9a7cc40891103f426206663dcebe1210c8ee3ab6037cbf64e1f86b9c7e5",
          "image": "registry.connect.redhat.com/zts/zts-csi-driver-1@sha256:c15fa9a7cc40891103f426206663dcebe1210c8ee3ab6037cbf64e1f86b9c7e5",
          "name": "csi_driver"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "0.0.17",
      "version_original": "0.0.17"
    },
    {
      "_id": "62345fb0314381d2b0756b34",
      "alm_examples": [
        {
          "api_version": "anzounstructured.clusters.cambridgesemantics.com/v1",
          "kind": "AnzoUnstructured",
          "metadata": {
            "name": "au01"
          },
          "spec": {
            "auWorker": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app": "anzounstructured"
                    }
                  },
                  "serviceName": "au-au01-w",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app": "anzounstructured"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:4db61bdf6dc8b42824a06d2f8d8aeecddde765d123b40a63a7bbf87845719fb2",
                          "name": "w",
                          "resources": {
                            "limits": {
                              "cpu": "2",
                              "memory": "4Gi"
                            },
                            "requests": {
                              "cpu": "2",
                              "memory": "4Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "unstructured-operator"
                    }
                  }
                }
              }
            },
            "msLeader": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app": "anzounstructured"
                    }
                  },
                  "serviceName": "au-au01-ms",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app": "anzounstructured"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-microservices-leader@sha256:0579fd97e81e436eaff3b58c5395f13aa924940a3d51f0bdea5163d327620286",
                          "name": "ms",
                          "resources": {
                            "limits": {
                              "cpu": "2",
                              "memory": "4Gi"
                            },
                            "requests": {
                              "cpu": "2",
                              "memory": "4Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "unstructured-operator"
                    }
                  }
                }
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-operator-bundle@sha256:800c686058a8b80d2c082741019db9d35535b2ba2b59007cbde0c2dffa143e82",
      "bundle_path_digest": "sha256:800c686058a8b80d2c082741019db9d35535b2ba2b59007cbde0c2dffa143e82",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:32:16.545000+00:00",
      "csv_description": "The Anzo Unstructured Operator provides the way to install and configure an anzo unstructured setup on Red Hat K8S environment.\nCurrently, this is possible only through existing Anzo installation.\n\n### Installation\n Refer [installation instructions]( https://github.com/cambridgesemantics/csi-k8s-operator-anzo-unstructured/blob/v2.0.0/README.md )\n\n### Documentation\n\nYou can find our documentation [here.]( https://docs.cambridgesemantics.com/anzo/userdoc/cloud-deployments.htm )\n\n### Support\n\nWe offer Support to our customers through [ Cambridge Semantics Customer Center ]( https://customercenter.cambridgesemantics.com/ ).",
      "csv_display_name": "Anzo Unstructured Operator",
      "csv_metadata_description": "Kubernetes Operator for Anzo Unstructured",
      "csv_name": "anzounstructured-operator.v2.0.101",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:40:21.913000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "anzounstructured-operator",
      "provided_apis": [
        {
          "group": "anzounstructured.clusters.cambridgesemantics.com",
          "kind": "AnzoUnstructured",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:a47af068a7aa55c12be84c80d263feeed5597ecc434986b4f2fff782b568bb04",
          "image": "registry.connect.redhat.com/cambridgesemantics/unstructured-operator@sha256:a47af068a7aa55c12be84c80d263feeed5597ecc434986b4f2fff782b568bb04",
          "name": "unstructured-operator-a47af068a7aa55c12be84c80d263feeed5597ecc434986b4f2fff782b568bb04-annotation"
        },
        {
          "digest": "sha256:a47af068a7aa55c12be84c80d263feeed5597ecc434986b4f2fff782b568bb04",
          "image": "registry.connect.redhat.com/cambridgesemantics/unstructured-operator@sha256:a47af068a7aa55c12be84c80d263feeed5597ecc434986b4f2fff782b568bb04",
          "name": "manager"
        },
        {
          "digest": "sha256:0579fd97e81e436eaff3b58c5395f13aa924940a3d51f0bdea5163d327620286",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-microservices-leader@sha256:0579fd97e81e436eaff3b58c5395f13aa924940a3d51f0bdea5163d327620286",
          "name": "anzo_microservices_leader"
        },
        {
          "digest": "sha256:4db61bdf6dc8b42824a06d2f8d8aeecddde765d123b40a63a7bbf87845719fb2",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:4db61bdf6dc8b42824a06d2f8d8aeecddde765d123b40a63a7bbf87845719fb2",
          "name": "anzo_unstructured_worker"
        },
        {
          "digest": "sha256:0579fd97e81e436eaff3b58c5395f13aa924940a3d51f0bdea5163d327620286",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-microservices-leader@sha256:0579fd97e81e436eaff3b58c5395f13aa924940a3d51f0bdea5163d327620286",
          "name": "anzo-microservices-leader-0579fd97e81e436eaff3b58c5395f13aa924940a3d51f0bdea5163d327620286-annotation"
        },
        {
          "digest": "sha256:4db61bdf6dc8b42824a06d2f8d8aeecddde765d123b40a63a7bbf87845719fb2",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-unstructured-worker@sha256:4db61bdf6dc8b42824a06d2f8d8aeecddde765d123b40a63a7bbf87845719fb2",
          "name": "anzo-unstructured-worker-4db61bdf6dc8b42824a06d2f8d8aeecddde765d123b40a63a7bbf87845719fb2-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2.0.0",
      "version_original": "2.0.0"
    },
    {
      "_id": "62345fb2314381d2b0756b35",
      "alm_examples": [],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/iomesh/iomesh@sha256:27c5d91d62371f3cf0dea4d50044d8a6e0a6015a453c4216a030683ea2474c64",
      "bundle_path_digest": "sha256:27c5d91d62371f3cf0dea4d50044d8a6e0a6015a453c4216a030683ea2474c64",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:32:18.838000+00:00",
      "csv_description": "IOMesh (https://www.iomesh.com/) is a cloud-native storage product specifically designed and developed for Kubernetes. It takes ZBS as its core, a \u201cproduction-ready\u201d distributed storage system developed independently by SmartX, to provide production-level high performance and reliable persistent storage for business-critical applications such as MySQL, Cassandra, MongoDB, etc., contributing to the containerized transformation of stateful applications.      \n## Pre-Requisites\n* According to https://docs.iomesh.com/deploy/prerequisites, make sure that your openshift cluster meets the \"Installation Requirements\" and set up the worker nodes correctly according to the \"Setup Worker Node\" chapter.\n* Run IOMesh Operator pre-installation script in an environment where oc or kubectl can be used to access the openshift cluster, the script will install the dependencies of IOMesh Operator and specific IOMesh settings for the openshift cluster:\n```shell\ncurl -sSL https://iomesh.run/iomesh-operator-pre-install-openshift.sh | sh -\n```\n## Install IOMesh Operator and IOMesh Cluster\n* Click install button on the current web page to install IOMesh Operator\n* On the **Installed Operators** -> **IOMesh Operator** -> **Create instance** -> **YAML view**, fill in an IOMesh Custom Resources according https://iomesh.run/iomesh.yaml, change the `spec.*.dataCIDR` to your own data network CIDR:\n## Post Install\n* Run IOMesh Operator post-installation script in an environment where oc or kubectl can be used to access the openshift cluster, the script will install IOMesh CSI Driver\n```shell\ncurl -sSL https://iomesh.run/iomesh-operator-post-install-openshift.sh | sh -\n```\n## Getting Started\n* Try to quickstart setup and use IOMesh: https://docs.iomesh.com/deploy/setup-iomesh\n",
      "csv_display_name": "IOMesh Operator",
      "csv_metadata_description": "",
      "csv_name": "iomesh-operator.0.10.1-rc4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-16T16:38:20.736000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "iomesh-operator",
      "provided_apis": [
        {
          "group": "iomesh.com",
          "kind": "IOMeshCluster",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:52b8718ce46fa764f802f7709f2ca39ebc78cf25e4af78a4c8011e4c0ff1d8f3",
          "image": "iomesh/operator@sha256:52b8718ce46fa764f802f7709f2ca39ebc78cf25e4af78a4c8011e4c0ff1d8f3",
          "name": "operator-52b8718ce46fa764f802f7709f2ca39ebc78cf25e4af78a4c8011e4c0ff1d8f3-annotation"
        },
        {
          "digest": "sha256:52b8718ce46fa764f802f7709f2ca39ebc78cf25e4af78a4c8011e4c0ff1d8f3",
          "image": "iomesh/operator@sha256:52b8718ce46fa764f802f7709f2ca39ebc78cf25e4af78a4c8011e4c0ff1d8f3",
          "name": "operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "0.10.1-rc4",
      "version_original": "0.10.1-rc4"
    },
    {
      "_id": "62345fb5314381d2b0756b36",
      "alm_examples": [
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyApplication",
          "metadata": {
            "name": "openliberty-app-sample"
          },
          "spec": {
            "applicationImage": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
            "expose": true,
            "replicas": 1
          }
        },
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyDump",
          "metadata": {
            "name": "openliberty-dump-sample"
          },
          "spec": {
            "include": [
              "thread",
              "heap"
            ],
            "podName": "Specify_Pod_Name_Here"
          }
        },
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyTrace",
          "metadata": {
            "name": "openliberty-trace-sample"
          },
          "spec": {
            "maxFileSize": 20,
            "maxFiles": 5,
            "podName": "Specify_Pod_Name_Here",
            "traceSpecification": "*=info:com.ibm.ws.webcontainer*=all"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/open-liberty-operator-bundle@sha256:88ff3cd847c4b606466b1e782cec0dfbdb62fb3dd0e4e1bc8b9c2d1016c74132",
      "bundle_path_digest": "sha256:88ff3cd847c4b606466b1e782cec0dfbdb62fb3dd0e4e1bc8b9c2d1016c74132",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "beta2",
      "creation_date": "2022-03-18T10:32:21.767000+00:00",
      "csv_description": "This advanced Operator can be used to deploy and manage Open Liberty applications with consistent, production-grade QoS. This operator is based on the [Runtime Component Operator](https://github.com/application-stacks/runtime-component-operator) and provides all of its capabilities in addition to Open Liberty specific features such as gathering traces and dumps (Day-2 operations) and easily configuring and managing the single sign-on information for your Open Liberty applications.\n\nOpen Liberty Operator enables enterprise architects to govern the way their applications get deployed & managed in the cluster, while dramatically reducing the learning curve for developers to deploy into Kubernetes - allowing them to focus on writing the code! Here are some key features:\n\n#### Application Lifecyle\nYou can deploy your Open Liberty application container by either pointing to a container image, or an OpenShift ImageStream. When using an ImageStream the Operator will watch for any updates and will re-deploy the modified image.\n\n#### Custom RBAC\nThis Operator is capable of using a custom ServiceAccount from the caller, allowing it to follow RBAC restrictions. By default it creates a ServiceAccount if one is not specified, which can also be bound with specific roles.\n\n#### Environment Configuration\nYou can configure a variety of artifacts with your deployment, such as: labels, annotations, and environment variables from a ConfigMap, a Secret or a value.\n\n#### Routing\nExpose your application to external users via a single toggle to create a Route on OpenShift or an Ingress on other Kubernetes environments. Advanced configuration, such as TLS settings, are also easily enabled. Expiring Route certificates are re-issued.\n\n#### High Availability via Horizontal Pod Autoscaling\nRun multiple instances of your application for high availability. Either specify a static number of replicas or easily configure horizontal auto scaling to create (and delete) instances based on resource consumption.\n\n#### Persistence and advanced storage\nEnable persistence for your application by specifying simple requirements: just tell us the size of the storage and where you would like it to be mounted and We will create and manage that storage for you.\nThis toggles a StatefulSet resource instead of a Deployment resource, so your container can recover transactions and state upon a pod restart.\nWe offer an advanced mode where the user specifies a built-in PersistentVolumeClaim, allowing them to configure many details of the persistent volume, such as its storage class and access mode.\nYou can also easily configure and use a single storage for serviceability related Day-2 operations, such as gatherig server traces and dumps.\n\n#### Service Binding\nYour runtime components can expose services by a simple toggle. We take care of the heavy lifting such as creating kubernetes Secrets with information other services can use to bind. We also keep the bindable information synchronized, so your applications can dynamically reconnect to its required services without any intervention or interruption.\n\n#### Single Sign-On (SSO)\nOpen Liberty provides capabilities to delegate authentication to external providers. Your application users can log in using their existing social media credentials from providers such as Google, Facebook, LinkedIn, Twitter, GitHub, and any OpenID Connect (OIDC) or OAuth 2.0 clients. Open Liberty Operator allows to easily configure and manage the single sign-on information for your applications.\n\n#### Exposing metrics to Prometheus\nThe Open Liberty Operator exposes the runtime container's metrics via the [Prometheus Operator](https://operatorhub.io/operator/prometheus).\nUsers can pick between a basic mode, where they simply specify the label that Prometheus is watching to scrape the metrics from the container, or they can specify the full `ServiceMonitor` spec embedded into the OpenLibertyApplication's `spec.monitoring` key controlling things like the poll internal and security credentials.\n\n#### Easily mount logs and transaction directories\nIf you need to mount the logs and transaction data from your application to an external volume such as NFS (or any storage supported in your cluster), simply add the following (customizing the folder location and size) to your OpenLibertyApplication CR:\n``` storage: size: 2Gi mountPath: \"/logs\" ```\n\n#### Integration with OpenShift Serverless\nDeploy your serverless runtime component using a single toggle.  The Operator will convert all of its generated resources into [Knative](https://knative.dev) resources, allowing your pod to automatically scale to 0 when it is idle.\n\n#### Integration with OpenShift's Topology UI\nWe set the corresponding labels to support OpenShift's Developer Topology UI, which allows you to visualize your entire set of deployments and how they are connected.\n\nSee our [**documentation**](https://github.com/OpenLiberty/open-liberty-operator/tree/main/doc/) for more information.\n",
      "csv_display_name": "Open Liberty",
      "csv_metadata_description": "Deploy and manage applications running on Liberty",
      "csv_name": "open-liberty-operator.v0.8.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:44:15.991000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "open-liberty-certified",
      "provided_apis": [
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyApplication",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyDump",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyTrace",
          "version": "v1beta2"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:43b3f004a19c91c80ba815aedc1b361b87cd12daa28bb215e6775e64ef890af1",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:43b3f004a19c91c80ba815aedc1b361b87cd12daa28bb215e6775e64ef890af1",
          "name": "open-liberty-operator-controller-43b3f004a19c91c80ba815aedc1b361b87cd12daa28bb215e6775e64ef890af1-annotation"
        },
        {
          "digest": "sha256:43b3f004a19c91c80ba815aedc1b361b87cd12daa28bb215e6775e64ef890af1",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:43b3f004a19c91c80ba815aedc1b361b87cd12daa28bb215e6775e64ef890af1",
          "name": "manager"
        },
        {
          "digest": "sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "image": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "name": "open-liberty-samples-8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "<0.8.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "0.8.0",
      "version_original": "0.8.0"
    },
    {
      "_id": "62345fb95593ce895a7b5357",
      "alm_examples": [
        {
          "api_version": "machinelearning.seldon.io/v1",
          "kind": "SeldonDeployment",
          "metadata": {
            "labels": {
              "app": "seldon",
              "app.kubernetes.io/instance": "seldon1",
              "app.kubernetes.io/name": "seldon",
              "app.kubernetes.io/version": "v0.5"
            },
            "name": "seldon-model"
          },
          "spec": {
            "name": "test-deployment",
            "predictors": [
              {
                "componentSpecs": [
                  {
                    "spec": {
                      "containers": [
                        {
                          "image": "seldonio/mock_classifier:1.6.0",
                          "name": "classifier"
                        }
                      ]
                    }
                  }
                ],
                "graph": {
                  "children": [],
                  "name": "classifier",
                  "type": "MODEL"
                },
                "name": "example",
                "replicas": 1
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/seldonio/seldon-core-operator-bundle@sha256:4ff78537117948052d6e7414fec414ff8351601ec09e7a097a804298a831c11d",
      "bundle_path_digest": "sha256:4ff78537117948052d6e7414fec414ff8351601ec09e7a097a804298a831c11d",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:32:25.669000+00:00",
      "csv_description": "The Seldon operator enables for native operation of production machine learning workloads, including monitoring and operations of language-agnostic models with the benefits of real-time metrics and log analysis.\n   \n## Overview\nSeldon Core is an open source platform for deploying machine learning models on a Kubernetes cluster.\n\n* Deploy machine learning models in the cloud or on-premise.\n* Get metrics and ensure proper governance and compliance for your running machine learning models.\n* Create powerful inference graphs made up of multiple components.\n* Provide a consistent serving layer for models built using heterogeneous ML toolkits.\n\nYou can get started by following the guides in our documentation at https://docs.seldon.io/projects/seldon-core/en/latest/workflow/README.html\n",
      "csv_display_name": "Seldon Operator",
      "csv_metadata_description": "The Seldon operator for management, monitoring and operations of machine learning systems through the Seldon Engine. Once installed, the Seldon Operator provides multiple functions which facilitate the productisation, monitoring and maintenance of machine learning systems at scale.",
      "csv_name": "seldon-operator.v1.12.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:38:08.618000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "seldon-operator-certified",
      "provided_apis": [
        {
          "group": "machinelearning.seldon.io",
          "kind": "SeldonDeployment",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:dbea873072acda45863dabc94555d39b9f48670ac04fec3e835c90531f1a2eda",
          "image": "registry.connect.redhat.com/seldonio/seldon-core-operator@sha256:dbea873072acda45863dabc94555d39b9f48670ac04fec3e835c90531f1a2eda",
          "name": "seldon-core-operator-dbea873072acda45863dabc94555d39b9f48670ac04fec3e835c90531f1a2eda-annotation"
        },
        {
          "digest": "sha256:dbea873072acda45863dabc94555d39b9f48670ac04fec3e835c90531f1a2eda",
          "image": "registry.connect.redhat.com/seldonio/seldon-core-operator@sha256:dbea873072acda45863dabc94555d39b9f48670ac04fec3e835c90531f1a2eda",
          "name": "manager"
        },
        {
          "digest": "sha256:4aab0706cef5ae37e3d62ba3cc4f92bc5d0b0e18d0d953143d25d745696ecc54",
          "image": "registry.connect.redhat.com/seldonio/seldon-core-executor@sha256:4aab0706cef5ae37e3d62ba3cc4f92bc5d0b0e18d0d953143d25d745696ecc54",
          "name": "executor"
        },
        {
          "digest": "sha256:0abffc5f882b16a7ffa9ecfb7d1b362d8e8017b47e94b4b72b10dce74daeec65",
          "image": "registry.connect.redhat.com/seldonio/seldon-engine@sha256:0abffc5f882b16a7ffa9ecfb7d1b362d8e8017b47e94b4b72b10dce74daeec65",
          "name": "engine"
        },
        {
          "digest": "sha256:554547229653bf1ebedb88c8eec40e63c8282146e0a0ea14f2d47f000004439f",
          "image": "registry.connect.redhat.com/seldonio/storage-initializer@sha256:554547229653bf1ebedb88c8eec40e63c8282146e0a0ea14f2d47f000004439f",
          "name": "storage_initializer"
        },
        {
          "digest": "sha256:0a68b243b28d2dc273a3278393e9f986b6ed5fc29aea7b9f3f343bf9efc5ac8e",
          "image": "registry.connect.redhat.com/seldonio/sklearnserver@sha256:0a68b243b28d2dc273a3278393e9f986b6ed5fc29aea7b9f3f343bf9efc5ac8e",
          "name": "sklearnserver"
        },
        {
          "digest": "sha256:0ee0001730d21ca636417824655d74d423d4492d7fed28befc74c23caf0cc4c8",
          "image": "registry.connect.redhat.com/seldonio/xgboostserver@sha256:0ee0001730d21ca636417824655d74d423d4492d7fed28befc74c23caf0cc4c8",
          "name": "xgboostserver"
        },
        {
          "digest": "sha256:3381cad85a16434f48cd65afbcfc65f2693bee46a149aa143a4088c9f9d899a2",
          "image": "registry.connect.redhat.com/seldonio/mlflowserver@sha256:3381cad85a16434f48cd65afbcfc65f2693bee46a149aa143a4088c9f9d899a2",
          "name": "mlflowserver"
        },
        {
          "digest": "sha256:407932f2d8e670bb4d3b9f6670a687039fae8d79312269d4da2677b73dc3e301",
          "image": "registry.connect.redhat.com/seldonio/tfproxy@sha256:407932f2d8e670bb4d3b9f6670a687039fae8d79312269d4da2677b73dc3e301",
          "name": "tfproxy"
        },
        {
          "digest": "sha256:04d1eee0208ca0e64ae277197cb1ddff4c0ee143a712a7f7a30faec397239dfc",
          "image": "registry.connect.redhat.com/seldonio/tensorflow-serving@sha256:04d1eee0208ca0e64ae277197cb1ddff4c0ee143a712a7f7a30faec397239dfc",
          "name": "tensorflow"
        },
        {
          "digest": "sha256:6ec697ad5187639712701454198a5f6afa1f662d3c127641c06b4322f391d6dd",
          "image": "registry.connect.redhat.com/seldonio/alibiexplainer@sha256:6ec697ad5187639712701454198a5f6afa1f662d3c127641c06b4322f391d6dd",
          "name": "explainer"
        },
        {
          "digest": "sha256:ea78453871e656b71ec9ce4660623a58938d0492fb8b660cc36a1943c768ce4d",
          "image": "registry.connect.redhat.com/seldonio/mock-classifier@sha256:ea78453871e656b71ec9ce4660623a58938d0492fb8b660cc36a1943c768ce4d",
          "name": "mock_classifier"
        }
      ],
      "replaces": "",
      "skip_range": "<1.12.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.12.0",
      "version_original": "1.12.0"
    },
    {
      "_id": "62345fbc670f4cadbafad2a6",
      "alm_examples": [
        {
          "api_version": "logs.grafana.com/v1alpha1",
          "kind": "GrafanaCloudLogForwarder",
          "metadata": {
            "name": "grafanacloudlogforwarder-sample",
            "namespace": "openshift-logging"
          },
          "spec": {
            "apipassword": "******",
            "url": "******",
            "username": "******"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/grafana/openshift-cloud-log-forwarder-bundle@sha256:8934fe4f13280cbc19868094bd9accb243f3862c104254b23dcf218c7b2a184d",
      "bundle_path_digest": "sha256:8934fe4f13280cbc19868094bd9accb243f3862c104254b23dcf218c7b2a184d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-03-18T10:32:28.205000+00:00",
      "csv_description": "Grafana Cloud is a completeobservability stack for metrics, logs, and traces that's tightly integrated with Grafana.\nLeverage the best open source observability software without the overhead of installing, maintaining, and scaling your observability stack.\n",
      "csv_display_name": "Grafana Cloud Log Forwarder",
      "csv_metadata_description": "",
      "csv_name": "grafana-cloud-log-forwarder-operator.v1.0.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:40:26.425000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "grafana-cloud-log-forwarder-operator",
      "provided_apis": [
        {
          "group": "logs.grafana.com",
          "kind": "GrafanaCloudLogForwarder",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:06b389c049dd4648257abf151f16e03d3c518a625a96fe68a63365ea86678514",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:06b389c049dd4648257abf151f16e03d3c518a625a96fe68a63365ea86678514",
          "name": "ose-kube-rbac-proxy"
        },
        {
          "digest": "sha256:9cb04cb779615c2b42ee37528da7f5abf71dc40c238de0c601035c9cf8fa1bc4",
          "image": "docker.io/grafana/openshift-cloud-log-forwarder@sha256:9cb04cb779615c2b42ee37528da7f5abf71dc40c238de0c601035c9cf8fa1bc4",
          "name": "openshift-cloud-log-forwarder"
        },
        {
          "digest": "sha256:06b389c049dd4648257abf151f16e03d3c518a625a96fe68a63365ea86678514",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:06b389c049dd4648257abf151f16e03d3c518a625a96fe68a63365ea86678514",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:9cb04cb779615c2b42ee37528da7f5abf71dc40c238de0c601035c9cf8fa1bc4",
          "image": "docker.io/grafana/openshift-cloud-log-forwarder@sha256:9cb04cb779615c2b42ee37528da7f5abf71dc40c238de0c601035c9cf8fa1bc4",
          "name": "manager"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.0.2",
      "version_original": "1.0.2"
    },
    {
      "_id": "62345fbe5593ce895a7b5358",
      "alm_examples": [
        {
          "api_version": "apm.neuvector.com/v1alpha1",
          "kind": "Neuvector",
          "metadata": {
            "name": "neuvector"
          },
          "spec": {
            "admissionwebhook": {
              "type": "ClusterIP"
            },
            "bottlerocket": {
              "enabled": false,
              "runtimePath": "/run/dockershim.sock"
            },
            "containerd": {
              "enabled": false,
              "path": "/var/run/containerd/containerd.sock"
            },
            "controller": {
              "apisvc": {
                "annotations": {},
                "route": {
                  "enabled": false,
                  "host": "",
                  "termination": "passthrough"
                },
                "type": ""
              },
              "azureFileShare": {
                "enabled": false,
                "secretName": "",
                "shareName": ""
              },
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "configmap": {
                "data": "",
                "enabled": false
              },
              "disruptionbudget": 0,
              "enabled": true,
              "federation": {
                "managedsvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                },
                "mastersvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                }
              },
              "image": "registry.connect.redhat.com/neuvector/controller",
              "ingress": {
                "annotations": {
                  "ingress.kubernetes.io/protocol": "https"
                },
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "priorityClassName": "",
              "pvc": {
                "accessModes": [
                  "ReadWriteMany"
                ],
                "capacity": "",
                "enabled": false,
                "storageClass": ""
              },
              "replicas": 3,
              "resources": {},
              "strategy": {
                "rollingUpdate": {
                  "maxSurge": 1,
                  "maxUnavailable": 0
                },
                "type": "RollingUpdate"
              }
            },
            "crdwebhook": {
              "enabled": true,
              "type": "ClusterIP"
            },
            "crio": {
              "enabled": true,
              "path": "/var/run/crio/crio.sock"
            },
            "cve": {
              "scanner": {
                "dockerPath": "",
                "enabled": true,
                "image": "registry.connect.redhat.com/neuvector/scanner@sha256:a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06",
                "priorityClassName": "",
                "replicas": 3,
                "resources": {},
                "strategy": {
                  "rollingUpdate": {
                    "maxSurge": 1,
                    "maxUnavailable": 0
                  },
                  "type": "RollingUpdate"
                }
              },
              "updater": {
                "enabled": true,
                "image": "registry.access.redhat.com/ubi8@sha256:091ad37a5a638af2c21d01c2d3f4d489c2368070a6c43371e897013fb0987e49",
                "priorityClassName": "",
                "schedule": "0 0 * * *"
              }
            },
            "docker": {
              "enabled": false,
              "path": "/var/run/docker.sock"
            },
            "enforcer": {
              "enabled": true,
              "image": "registry.connect.redhat.com/neuvector/enforcer",
              "priorityClassName": "",
              "resources": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                }
              ]
            },
            "k3s": {
              "enabled": false,
              "runtimePath": "/run/k3s/containerd/containerd.sock"
            },
            "manager": {
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "enabled": true,
              "env": {
                "ssl": true
              },
              "image": "registry.connect.redhat.com/neuvector/manager",
              "ingress": {
                "annotations": {},
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "priorityClassName": "",
              "resources": {},
              "route": {
                "enabled": true,
                "host": "",
                "termination": "passthrough"
              },
              "svc": {
                "annotations": {},
                "loadBalancerIP": "",
                "type": "NodePort"
              }
            },
            "openshift": true,
            "psp": false,
            "resources": {},
            "serviceAccount": "default"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/neuvector/neuvector-operator-bundle@sha256:6f4ff463c67af42c1c3603e36e512a60dedb95775380a1a6b26c4cded86de5e1",
      "bundle_path_digest": "sha256:6f4ff463c67af42c1c3603e36e512a60dedb95775380a1a6b26c4cded86de5e1",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-03-18T10:32:30.756000+00:00",
      "csv_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.\n\nThe NeuVector Operator runs  in the openshift container platform to deploy and manage the NeuVector Security cluster components. The NeuVector operator contains all necessary information to deploy NeuVector using helm charts. You simply need to install the NeuVector operator from the OpenShift embeded operator hub and create NeuVector instance. You can modify the NeuVector installation configuration by modifying yaml while creating the NeuVector instance such as imagePullSecrets, tag version, etc. Please refer to [github link](https://github.com/neuvector/neuvector-helm/tree/master/charts/core) for the values that can be modifed during installation. To upgrade to a newer version of NeuVector, just reapply the NeuVector instance with desired tag , which in turn pulls the specified NeuVector image tags and upgrades as per upgrade plan configured on the helm chart.  NeuVector Operator versions are tied to NeuVector product versions. Version 1.2.8 of the NeuVector Certified Operator deploys version 4.3.1 of NeuVector.\n\n**Complete below steps to Grant Service Account Access to the Privileged SCC before installation.**\n\nCreate the NeuVector namespace\n\n         oc new-project  neuvector\nLogin as system:admin account\n\n         oc login -u system:admin\n\nGrant Service Account Access to the Privileged SCC\n\n         oc -n neuvector adm policy add-scc-to-user privileged -z default\n\nThe following info will be added in the Privileged SCC users:\n\n         - system:serviceaccount:neuvector:default\n\nIn OpenShift 4.6+ use the following to check:\n\n         oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide\n         NAME                              ROLE                                          AGE     USERS   GROUPS   SERVICEACCOUNTS\n         system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/default\n\n\n**Add NeuVector license from NeuVector WebUI->setting**\n\n\n#Deploying the NeuVector Operator#\n\n\nPlease refer to the instructions [here](https://github.com/neuvector/neuvector-operator/blob/master/README.md)\n\n\n",
      "csv_display_name": "NeuVector Operator",
      "csv_metadata_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.",
      "csv_name": "neuvector-operator.v1.2.8",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:45:48.581000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "neuvector-certified-operator",
      "provided_apis": [
        {
          "group": "apm.neuvector.com",
          "kind": "Neuvector",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:9d8ab5fc5e3122fe1332ccf624e6897277e2e935690f4b07ca1c491599daec72",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:9d8ab5fc5e3122fe1332ccf624e6897277e2e935690f4b07ca1c491599daec72",
          "name": "neuvector-operator-9d8ab5fc5e3122fe1332ccf624e6897277e2e935690f4b07ca1c491599daec72-annotation"
        },
        {
          "digest": "sha256:9d8ab5fc5e3122fe1332ccf624e6897277e2e935690f4b07ca1c491599daec72",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:9d8ab5fc5e3122fe1332ccf624e6897277e2e935690f4b07ca1c491599daec72",
          "name": "neuvector-operator"
        },
        {
          "digest": "sha256:55b3d9873846d0a8670b58e8a8a76c426d3aba74d4e5c4fca43d05c1dd296f10",
          "image": "registry.connect.redhat.com/neuvector/controller@sha256:55b3d9873846d0a8670b58e8a8a76c426d3aba74d4e5c4fca43d05c1dd296f10",
          "name": "controller"
        },
        {
          "digest": "sha256:fdd66288454dd01f4f618c8cf04c7da501d4362773266ec6f448d63e26e3a35c",
          "image": "registry.connect.redhat.com/neuvector/enforcer@sha256:fdd66288454dd01f4f618c8cf04c7da501d4362773266ec6f448d63e26e3a35c",
          "name": "enforcer"
        },
        {
          "digest": "sha256:73445c18ea18f131b6fa630a97623a3043d05758205ef93fc02fa920abbedaa6",
          "image": "registry.connect.redhat.com/neuvector/manager@sha256:73445c18ea18f131b6fa630a97623a3043d05758205ef93fc02fa920abbedaa6",
          "name": "manager"
        },
        {
          "digest": "sha256:a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06",
          "name": "scanner"
        },
        {
          "digest": "sha256:091ad37a5a638af2c21d01c2d3f4d489c2368070a6c43371e897013fb0987e49",
          "image": "registry.access.redhat.com/ubi8@sha256:091ad37a5a638af2c21d01c2d3f4d489c2368070a6c43371e897013fb0987e49",
          "name": "updater"
        },
        {
          "digest": "sha256:a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06",
          "name": "scanner-a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06-annotation"
        },
        {
          "digest": "sha256:091ad37a5a638af2c21d01c2d3f4d489c2368070a6c43371e897013fb0987e49",
          "image": "registry.access.redhat.com/ubi8@sha256:091ad37a5a638af2c21d01c2d3f4d489c2368070a6c43371e897013fb0987e49",
          "name": "ubi8-091ad37a5a638af2c21d01c2d3f4d489c2368070a6c43371e897013fb0987e49-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.2.8",
      "version_original": "1.2.8"
    },
    {
      "_id": "62345fc1314381d2b0756b37",
      "alm_examples": [
        {
          "api_version": "apm.neuvector.com/v1alpha1",
          "kind": "Neuvector",
          "metadata": {
            "name": "neuvector"
          },
          "spec": {
            "admissionwebhook": {
              "type": "ClusterIP"
            },
            "bottlerocket": {
              "enabled": false,
              "runtimePath": "/run/dockershim.sock"
            },
            "containerd": {
              "enabled": false,
              "path": "/var/run/containerd/containerd.sock"
            },
            "controller": {
              "apisvc": {
                "annotations": {},
                "route": {
                  "enabled": false,
                  "host": "",
                  "termination": "passthrough"
                },
                "type": ""
              },
              "azureFileShare": {
                "enabled": false,
                "secretName": "",
                "shareName": ""
              },
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "configmap": {
                "data": "",
                "enabled": false
              },
              "disruptionbudget": 0,
              "enabled": true,
              "federation": {
                "managedsvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                },
                "mastersvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                }
              },
              "image": "registry.connect.redhat.com/neuvector/controller",
              "ingress": {
                "annotations": {
                  "ingress.kubernetes.io/protocol": "https"
                },
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "priorityClassName": "",
              "pvc": {
                "accessModes": [
                  "ReadWriteMany"
                ],
                "capacity": "",
                "enabled": false,
                "storageClass": ""
              },
              "replicas": 3,
              "resources": {},
              "schedulerName": "",
              "strategy": {
                "rollingUpdate": {
                  "maxSurge": 1,
                  "maxUnavailable": 0
                },
                "type": "RollingUpdate"
              }
            },
            "crdwebhook": {
              "enabled": true,
              "type": "ClusterIP"
            },
            "crio": {
              "enabled": true,
              "path": "/var/run/crio/crio.sock"
            },
            "cve": {
              "scanner": {
                "dockerPath": "",
                "enabled": true,
                "image": "registry.connect.redhat.com/neuvector/scanner@sha256:a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06",
                "priorityClassName": "",
                "replicas": 3,
                "resources": {},
                "strategy": {
                  "rollingUpdate": {
                    "maxSurge": 1,
                    "maxUnavailable": 0
                  },
                  "type": "RollingUpdate"
                }
              },
              "updater": {
                "enabled": true,
                "image": "registry.access.redhat.com/ubi8@sha256:910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7",
                "priorityClassName": "",
                "schedule": "0 0 * * *",
                "secure": false
              }
            },
            "docker": {
              "enabled": false,
              "path": "/var/run/docker.sock"
            },
            "enforcer": {
              "enabled": true,
              "image": "registry.connect.redhat.com/neuvector/enforcer",
              "priorityClassName": "",
              "resources": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                }
              ]
            },
            "k3s": {
              "enabled": false,
              "runtimePath": "/run/k3s/containerd/containerd.sock"
            },
            "manager": {
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "enabled": true,
              "env": {
                "ssl": true
              },
              "image": "registry.connect.redhat.com/neuvector/manager",
              "ingress": {
                "annotations": {},
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "priorityClassName": "",
              "resources": {},
              "route": {
                "enabled": true,
                "host": "",
                "termination": "passthrough"
              },
              "svc": {
                "annotations": {},
                "loadBalancerIP": "",
                "type": "NodePort"
              }
            },
            "openshift": true,
            "psp": false,
            "resources": {},
            "serviceAccount": "default"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/neuvector/neuvector-operator-bundle@sha256:29996196f2eba8f7662bdf1efeaac3a0ccf56bdfb2e522b340d9a239f7ca51e4",
      "bundle_path_digest": "sha256:29996196f2eba8f7662bdf1efeaac3a0ccf56bdfb2e522b340d9a239f7ca51e4",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-03-18T10:32:33.444000+00:00",
      "csv_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.\n\nThe NeuVector Operator runs  in the openshift container platform to deploy and manage the NeuVector Security cluster components. The NeuVector operator contains all necessary information to deploy NeuVector using helm charts. You simply need to install the NeuVector operator from the OpenShift embeded operator hub and create NeuVector instance. You can modify the NeuVector installation configuration by modifying yaml while creating the NeuVector instance such as imagePullSecrets, tag version, etc. Please refer to [github link](https://github.com/neuvector/neuvector-helm/tree/master/charts/core) for the values that can be modifed during installation. To upgrade to a newer version of NeuVector, just reapply the NeuVector instance with desired tag , which in turn pulls the specified NeuVector image tags and upgrades as per upgrade plan configured on the helm chart.  NeuVector Operator versions are tied to NeuVector product versions. Version 1.2.9 of the NeuVector Certified Operator deploys version 4.3.1 of NeuVector.\n\n**Complete below steps to Grant Service Account Access to the Privileged SCC before installation.**\n\nCreate the NeuVector namespace\n\n         oc new-project  neuvector\nLogin as system:admin account\n\n         oc login -u system:admin\n\nGrant Service Account Access to the Privileged SCC\n\n         oc -n neuvector adm policy add-scc-to-user privileged -z default\n\nThe following info will be added in the Privileged SCC users:\n\n         - system:serviceaccount:neuvector:default\n\nIn OpenShift 4.6+ use the following to check:\n\n         oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide\n         NAME                              ROLE                                          AGE     USERS   GROUPS   SERVICEACCOUNTS\n         system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/default\n\n\n**Add NeuVector license from NeuVector WebUI->setting**\n\n\n#Deploying the NeuVector Operator#\n\n\nPlease refer to the instructions [here](https://github.com/neuvector/neuvector-operator/blob/master/README.md)\n\n\n",
      "csv_display_name": "NeuVector Operator",
      "csv_metadata_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.",
      "csv_name": "neuvector-operator.v1.2.9",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:45:22.259000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "neuvector-certified-operator",
      "provided_apis": [
        {
          "group": "apm.neuvector.com",
          "kind": "Neuvector",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "name": "neuvector-operator-487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1-annotation"
        },
        {
          "digest": "sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "name": "neuvector-operator"
        },
        {
          "digest": "sha256:55b3d9873846d0a8670b58e8a8a76c426d3aba74d4e5c4fca43d05c1dd296f10",
          "image": "registry.connect.redhat.com/neuvector/controller@sha256:55b3d9873846d0a8670b58e8a8a76c426d3aba74d4e5c4fca43d05c1dd296f10",
          "name": "controller"
        },
        {
          "digest": "sha256:fdd66288454dd01f4f618c8cf04c7da501d4362773266ec6f448d63e26e3a35c",
          "image": "registry.connect.redhat.com/neuvector/enforcer@sha256:fdd66288454dd01f4f618c8cf04c7da501d4362773266ec6f448d63e26e3a35c",
          "name": "enforcer"
        },
        {
          "digest": "sha256:73445c18ea18f131b6fa630a97623a3043d05758205ef93fc02fa920abbedaa6",
          "image": "registry.connect.redhat.com/neuvector/manager@sha256:73445c18ea18f131b6fa630a97623a3043d05758205ef93fc02fa920abbedaa6",
          "name": "manager"
        },
        {
          "digest": "sha256:a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06",
          "name": "scanner"
        },
        {
          "digest": "sha256:910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7",
          "image": "registry.access.redhat.com/ubi8@sha256:910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7",
          "name": "updater"
        },
        {
          "digest": "sha256:a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06",
          "name": "scanner-a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06-annotation"
        },
        {
          "digest": "sha256:910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7",
          "image": "registry.access.redhat.com/ubi8@sha256:910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7",
          "name": "ubi8-910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.2.9",
      "version_original": "1.2.9"
    },
    {
      "_id": "62345fc406c5dada0193e07a",
      "alm_examples": [
        {
          "api_version": "apm.neuvector.com/v1alpha1",
          "kind": "Neuvector",
          "metadata": {
            "name": "neuvector"
          },
          "spec": {
            "admissionwebhook": {
              "type": "ClusterIP"
            },
            "bottlerocket": {
              "enabled": false,
              "runtimePath": "/run/dockershim.sock"
            },
            "containerd": {
              "enabled": false,
              "path": "/var/run/containerd/containerd.sock"
            },
            "controller": {
              "apisvc": {
                "annotations": {},
                "route": {
                  "enabled": false,
                  "host": "",
                  "termination": "passthrough"
                },
                "type": ""
              },
              "azureFileShare": {
                "enabled": false,
                "secretName": "",
                "shareName": ""
              },
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "configmap": {
                "data": "",
                "enabled": false
              },
              "disruptionbudget": 0,
              "enabled": true,
              "federation": {
                "managedsvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                },
                "mastersvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                }
              },
              "image": "registry.connect.redhat.com/neuvector/controller",
              "ingress": {
                "annotations": {
                  "ingress.kubernetes.io/protocol": "https"
                },
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "priorityClassName": "",
              "pvc": {
                "accessModes": [
                  "ReadWriteMany"
                ],
                "capacity": "",
                "enabled": false,
                "storageClass": ""
              },
              "replicas": 3,
              "resources": {},
              "schedulerName": "",
              "strategy": {
                "rollingUpdate": {
                  "maxSurge": 1,
                  "maxUnavailable": 0
                },
                "type": "RollingUpdate"
              }
            },
            "crdwebhook": {
              "enabled": true,
              "type": "ClusterIP"
            },
            "crio": {
              "enabled": true,
              "path": "/var/run/crio/crio.sock"
            },
            "cve": {
              "scanner": {
                "dockerPath": "",
                "enabled": true,
                "image": "registry.connect.redhat.com/neuvector/scanner@sha256:5f2d23d20f9ea5d1d3bc56b758ddc3f3b4f57a9db47c7cc95e74f6d7a4072e00",
                "priorityClassName": "",
                "replicas": 3,
                "resources": {},
                "strategy": {
                  "rollingUpdate": {
                    "maxSurge": 1,
                    "maxUnavailable": 0
                  },
                  "type": "RollingUpdate"
                }
              },
              "updater": {
                "enabled": true,
                "image": "registry.access.redhat.com/ubi8@sha256:910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7",
                "priorityClassName": "",
                "schedule": "0 0 * * *",
                "secure": false
              }
            },
            "docker": {
              "enabled": false,
              "path": "/var/run/docker.sock"
            },
            "enforcer": {
              "enabled": true,
              "image": "registry.connect.redhat.com/neuvector/enforcer",
              "priorityClassName": "",
              "resources": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                }
              ]
            },
            "k3s": {
              "enabled": false,
              "runtimePath": "/run/k3s/containerd/containerd.sock"
            },
            "manager": {
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "enabled": true,
              "env": {
                "ssl": true
              },
              "image": "registry.connect.redhat.com/neuvector/manager",
              "ingress": {
                "annotations": {},
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "priorityClassName": "",
              "resources": {},
              "route": {
                "enabled": true,
                "host": "",
                "termination": "passthrough"
              },
              "svc": {
                "annotations": {},
                "loadBalancerIP": "",
                "type": "NodePort"
              }
            },
            "openshift": true,
            "psp": false,
            "resources": {},
            "serviceAccount": "default"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/neuvector/neuvector-operator-bundle@sha256:38e93c5f551f7ebfc1736a58cf2f07a793974fdd04f59af1c15df20e38e195da",
      "bundle_path_digest": "sha256:38e93c5f551f7ebfc1736a58cf2f07a793974fdd04f59af1c15df20e38e195da",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-03-18T10:32:36.255000+00:00",
      "csv_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.\n\nThe NeuVector Operator runs  in the openshift container platform to deploy and manage the NeuVector Security cluster components. The NeuVector operator contains all necessary information to deploy NeuVector using helm charts. You simply need to install the NeuVector operator from the OpenShift embeded operator hub and create NeuVector instance. You can modify the NeuVector installation configuration by modifying yaml while creating the NeuVector instance such as imagePullSecrets, tag version, etc. Please refer to [github link](https://github.com/neuvector/neuvector-helm/tree/master/charts/core) for the values that can be modifed during installation. To upgrade to a newer version of NeuVector, just reapply the NeuVector instance with desired tag , which in turn pulls the specified NeuVector image tags and upgrades as per upgrade plan configured on the helm chart.  NeuVector Operator versions are tied to NeuVector product versions. Version 1.3.0 of the NeuVector Certified Operator deploys version 4.3.2 of NeuVector.\n\n**Complete below steps to Grant Service Account Access to the Privileged SCC before installation.**\n\nCreate the NeuVector namespace\n\n         oc new-project  neuvector\nLogin as system:admin account\n\n         oc login -u system:admin\n\nGrant Service Account Access to the Privileged SCC\n\n         oc -n neuvector adm policy add-scc-to-user privileged -z default\n\nThe following info will be added in the Privileged SCC users:\n\n         - system:serviceaccount:neuvector:default\n\nIn OpenShift 4.6+ use the following to check:\n\n         oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide\n         system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/default\n\n\n**Add NeuVector license from NeuVector WebUI->setting**\n\n\n#Deploying the NeuVector Operator#\n\n\nPlease refer to the instructions [here](https://github.com/neuvector/neuvector-operator/blob/master/README.md)\n\n\n",
      "csv_display_name": "NeuVector Operator",
      "csv_metadata_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.",
      "csv_name": "neuvector-operator.v1.3.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:45:26.420000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "neuvector-certified-operator",
      "provided_apis": [
        {
          "group": "apm.neuvector.com",
          "kind": "Neuvector",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "name": "neuvector-operator-487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1-annotation"
        },
        {
          "digest": "sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "name": "neuvector-operator"
        },
        {
          "digest": "sha256:a748a22eff64576a89b15a0f70b0d50d781bc0bff809029e78cdcd19c105e6ff",
          "image": "registry.connect.redhat.com/neuvector/controller@sha256:a748a22eff64576a89b15a0f70b0d50d781bc0bff809029e78cdcd19c105e6ff",
          "name": "controller"
        },
        {
          "digest": "sha256:45c5e78ed5a72944dfdd3123623d71376fea8ef329e2980e162c633c58c049f2",
          "image": "registry.connect.redhat.com/neuvector/enforcer@sha256:45c5e78ed5a72944dfdd3123623d71376fea8ef329e2980e162c633c58c049f2",
          "name": "enforcer"
        },
        {
          "digest": "sha256:a7139cddaf9f7e53494cd9ad553331473466973f151489cb92bd6ffee864a56a",
          "image": "registry.connect.redhat.com/neuvector/manager@sha256:a7139cddaf9f7e53494cd9ad553331473466973f151489cb92bd6ffee864a56a",
          "name": "manager"
        },
        {
          "digest": "sha256:5f2d23d20f9ea5d1d3bc56b758ddc3f3b4f57a9db47c7cc95e74f6d7a4072e00",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:5f2d23d20f9ea5d1d3bc56b758ddc3f3b4f57a9db47c7cc95e74f6d7a4072e00",
          "name": "scanner"
        },
        {
          "digest": "sha256:910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7",
          "image": "registry.access.redhat.com/ubi8@sha256:910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7",
          "name": "updater"
        },
        {
          "digest": "sha256:5f2d23d20f9ea5d1d3bc56b758ddc3f3b4f57a9db47c7cc95e74f6d7a4072e00",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:5f2d23d20f9ea5d1d3bc56b758ddc3f3b4f57a9db47c7cc95e74f6d7a4072e00",
          "name": "scanner-5f2d23d20f9ea5d1d3bc56b758ddc3f3b4f57a9db47c7cc95e74f6d7a4072e00-annotation"
        },
        {
          "digest": "sha256:910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7",
          "image": "registry.access.redhat.com/ubi8@sha256:910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7",
          "name": "ubi8-910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.3.0",
      "version_original": "1.3.0"
    },
    {
      "_id": "62345fc5314381d2b0756b38",
      "alm_examples": [
        {
          "api_version": "apm.neuvector.com/v1alpha1",
          "kind": "Neuvector",
          "metadata": {
            "name": "neuvector"
          },
          "spec": {
            "admissionwebhook": {
              "type": "ClusterIP"
            },
            "bottlerocket": {
              "enabled": false,
              "runtimePath": "/run/dockershim.sock"
            },
            "containerd": {
              "enabled": false,
              "path": "/var/run/containerd/containerd.sock"
            },
            "controller": {
              "apisvc": {
                "annotations": {},
                "route": {
                  "enabled": false,
                  "host": "",
                  "termination": "passthrough"
                },
                "type": ""
              },
              "azureFileShare": {
                "enabled": false,
                "secretName": "",
                "shareName": ""
              },
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "configmap": {
                "data": "",
                "enabled": false
              },
              "disruptionbudget": 0,
              "enabled": true,
              "federation": {
                "managedsvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                },
                "mastersvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                }
              },
              "image": "registry.connect.redhat.com/neuvector/controller",
              "ingress": {
                "annotations": {
                  "ingress.kubernetes.io/protocol": "https"
                },
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "priorityClassName": "",
              "pvc": {
                "accessModes": [
                  "ReadWriteMany"
                ],
                "capacity": "",
                "enabled": false,
                "storageClass": ""
              },
              "replicas": 3,
              "resources": {},
              "schedulerName": "",
              "strategy": {
                "rollingUpdate": {
                  "maxSurge": 1,
                  "maxUnavailable": 0
                },
                "type": "RollingUpdate"
              }
            },
            "crdwebhook": {
              "enabled": true,
              "type": "ClusterIP"
            },
            "crio": {
              "enabled": true,
              "path": "/var/run/crio/crio.sock"
            },
            "cve": {
              "scanner": {
                "dockerPath": "",
                "enabled": true,
                "image": "registry.connect.redhat.com/neuvector/scanner@sha256:c0c7095bcb36e93a4c074e5c97d652db5f0133022fd2ab6838a092e8959f2041",
                "priorityClassName": "",
                "replicas": 3,
                "resources": {},
                "strategy": {
                  "rollingUpdate": {
                    "maxSurge": 1,
                    "maxUnavailable": 0
                  },
                  "type": "RollingUpdate"
                }
              },
              "updater": {
                "enabled": true,
                "image": "registry.access.redhat.com/ubi8@sha256:060d7d6827b34949cc0fc58a50f72a5dccf00a4cc594406bdf5982f41dfe6118",
                "priorityClassName": "",
                "schedule": "0 0 * * *",
                "secure": false
              }
            },
            "docker": {
              "enabled": false,
              "path": "/var/run/docker.sock"
            },
            "enforcer": {
              "enabled": true,
              "image": "registry.connect.redhat.com/neuvector/enforcer",
              "priorityClassName": "",
              "resources": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                }
              ]
            },
            "k3s": {
              "enabled": false,
              "runtimePath": "/run/k3s/containerd/containerd.sock"
            },
            "manager": {
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "enabled": true,
              "env": {
                "ssl": true
              },
              "image": "registry.connect.redhat.com/neuvector/manager",
              "ingress": {
                "annotations": {},
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "priorityClassName": "",
              "resources": {},
              "route": {
                "enabled": true,
                "host": "",
                "termination": "passthrough"
              },
              "svc": {
                "annotations": {},
                "loadBalancerIP": "",
                "type": "NodePort"
              }
            },
            "openshift": true,
            "psp": false,
            "resources": {},
            "serviceAccount": "default"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/neuvector/neuvector-operator-bundle@sha256:bd5db9f3403eee933627d3a1ef0c534cac8c7b53eda247589d546c1f6cfed71b",
      "bundle_path_digest": "sha256:bd5db9f3403eee933627d3a1ef0c534cac8c7b53eda247589d546c1f6cfed71b",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-03-18T10:32:37.971000+00:00",
      "csv_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.\n\nThe NeuVector Operator runs  in the openshift container platform to deploy and manage the NeuVector Security cluster components. The NeuVector operator contains all necessary information to deploy NeuVector using helm charts. You simply need to install the NeuVector operator from the OpenShift embeded operator hub and create NeuVector instance. You can modify the NeuVector installation configuration by modifying yaml while creating the NeuVector instance such as imagePullSecrets, tag version, etc. Please refer to [github link](https://github.com/neuvector/neuvector-helm/tree/master/charts/core) for the values that can be modifed during installation. To upgrade to a newer version of NeuVector, just reapply the NeuVector instance with desired tag , which in turn pulls the specified NeuVector image tags and upgrades as per upgrade plan configured on the helm chart.  NeuVector Operator versions are tied to NeuVector product versions. Version 1.3.1 of the NeuVector Certified Operator deploys version 4.3.2-s1 of NeuVector.\n\n**Complete below steps to Grant Service Account Access to the Privileged SCC before installation.**\n\nCreate the NeuVector namespace\n\n         oc new-project  neuvector\nLogin as system:admin account\n\n         oc login -u system:admin\n\nGrant Service Account Access to the Privileged SCC\n\n         oc -n neuvector adm policy add-scc-to-user privileged -z default\n\nThe following info will be added in the Privileged SCC users:\n\n         - system:serviceaccount:neuvector:default\n\nIn OpenShift 4.6+ use the following to check:\n\n         oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide\n         system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/default\n\n\n**Add NeuVector license from NeuVector WebUI->setting**\n\n\n#Deploying the NeuVector Operator#\n\n\nPlease refer to the instructions [here](https://github.com/neuvector/neuvector-operator/blob/master/README.md)\n\n\n",
      "csv_display_name": "NeuVector Operator",
      "csv_metadata_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.",
      "csv_name": "neuvector-operator.v1.3.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:45:29.179000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "neuvector-certified-operator",
      "provided_apis": [
        {
          "group": "apm.neuvector.com",
          "kind": "Neuvector",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "name": "neuvector-operator-487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1-annotation"
        },
        {
          "digest": "sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "name": "neuvector-operator"
        },
        {
          "digest": "sha256:afa454d7a22de6161e6ff6b6f859ce15fa0bfc4e9d4e5e191b61125dfc5cad6b",
          "image": "registry.connect.redhat.com/neuvector/controller@sha256:afa454d7a22de6161e6ff6b6f859ce15fa0bfc4e9d4e5e191b61125dfc5cad6b",
          "name": "controller"
        },
        {
          "digest": "sha256:f9543cdf9bb338161a3f84a81381f26cbf724a23f6363583417c9da682e91cf8",
          "image": "registry.connect.redhat.com/neuvector/enforcer@sha256:f9543cdf9bb338161a3f84a81381f26cbf724a23f6363583417c9da682e91cf8",
          "name": "enforcer"
        },
        {
          "digest": "sha256:085bd24dadcd9d023c6600227ca088ed8d03ab83a70b62401477d10272450952",
          "image": "registry.connect.redhat.com/neuvector/manager@sha256:085bd24dadcd9d023c6600227ca088ed8d03ab83a70b62401477d10272450952",
          "name": "manager"
        },
        {
          "digest": "sha256:c0c7095bcb36e93a4c074e5c97d652db5f0133022fd2ab6838a092e8959f2041",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:c0c7095bcb36e93a4c074e5c97d652db5f0133022fd2ab6838a092e8959f2041",
          "name": "scanner"
        },
        {
          "digest": "sha256:060d7d6827b34949cc0fc58a50f72a5dccf00a4cc594406bdf5982f41dfe6118",
          "image": "registry.access.redhat.com/ubi8@sha256:060d7d6827b34949cc0fc58a50f72a5dccf00a4cc594406bdf5982f41dfe6118",
          "name": "updater"
        },
        {
          "digest": "sha256:c0c7095bcb36e93a4c074e5c97d652db5f0133022fd2ab6838a092e8959f2041",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:c0c7095bcb36e93a4c074e5c97d652db5f0133022fd2ab6838a092e8959f2041",
          "name": "scanner-c0c7095bcb36e93a4c074e5c97d652db5f0133022fd2ab6838a092e8959f2041-annotation"
        },
        {
          "digest": "sha256:060d7d6827b34949cc0fc58a50f72a5dccf00a4cc594406bdf5982f41dfe6118",
          "image": "registry.access.redhat.com/ubi8@sha256:060d7d6827b34949cc0fc58a50f72a5dccf00a4cc594406bdf5982f41dfe6118",
          "name": "ubi8-060d7d6827b34949cc0fc58a50f72a5dccf00a4cc594406bdf5982f41dfe6118-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.3.1",
      "version_original": "1.3.1"
    },
    {
      "_id": "62345fc75593ce895a7b5359",
      "alm_examples": [
        {
          "api_version": "apm.neuvector.com/v1alpha1",
          "kind": "Neuvector",
          "metadata": {
            "name": "neuvector"
          },
          "spec": {
            "admissionwebhook": {
              "type": "ClusterIP"
            },
            "bottlerocket": {
              "enabled": false,
              "runtimePath": "/run/dockershim.sock"
            },
            "containerd": {
              "enabled": false,
              "path": "/var/run/containerd/containerd.sock"
            },
            "controller": {
              "affinity": {
                "podAntiAffinity": {
                  "preferredDuringSchedulingIgnoredDuringExecution": [
                    {
                      "podAffinityTerm": {
                        "labelSelector": {
                          "matchExpressions": [
                            {
                              "key": "app",
                              "operator": "In",
                              "values": [
                                "neuvector-controller-pod"
                              ]
                            }
                          ]
                        },
                        "topologyKey": "kubernetes.io/hostname"
                      },
                      "weight": 100
                    }
                  ]
                }
              },
              "apisvc": {
                "annotations": {},
                "route": {
                  "enabled": false,
                  "host": "",
                  "termination": "passthrough"
                },
                "type": ""
              },
              "azureFileShare": {
                "enabled": false,
                "secretName": "",
                "shareName": ""
              },
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "configmap": {
                "data": "",
                "enabled": false
              },
              "disruptionbudget": 0,
              "enabled": true,
              "env": [],
              "federation": {
                "managedsvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                },
                "mastersvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                }
              },
              "image": "registry.connect.redhat.com/neuvector/controller",
              "ingress": {
                "annotations": {
                  "ingress.kubernetes.io/protocol": "https"
                },
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "pvc": {
                "accessModes": [
                  "ReadWriteMany"
                ],
                "capacity": "",
                "enabled": false,
                "storageClass": ""
              },
              "replicas": 3,
              "resources": {},
              "schedulerName": "",
              "secret": {
                "data": {},
                "enabled": false
              },
              "strategy": {
                "rollingUpdate": {
                  "maxSurge": 1,
                  "maxUnavailable": 0
                },
                "type": "RollingUpdate"
              },
              "tolerations": []
            },
            "crdwebhook": {
              "enabled": true,
              "type": "ClusterIP"
            },
            "crio": {
              "enabled": true,
              "path": "/var/run/crio/crio.sock"
            },
            "cve": {
              "scanner": {
                "affinity": {},
                "dockerPath": "",
                "enabled": true,
                "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
                "nodeSelector": {},
                "priorityClassName": "",
                "replicas": 3,
                "resources": {},
                "strategy": {
                  "rollingUpdate": {
                    "maxSurge": 1,
                    "maxUnavailable": 0
                  },
                  "type": "RollingUpdate"
                },
                "tolerations": []
              },
              "updater": {
                "enabled": true,
                "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
                "priorityClassName": "",
                "schedule": "0 0 * * *",
                "secure": false
              }
            },
            "docker": {
              "enabled": false,
              "path": "/var/run/docker.sock"
            },
            "enforcer": {
              "enabled": true,
              "image": "registry.connect.redhat.com/neuvector/enforcer",
              "priorityClassName": "",
              "resources": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                }
              ]
            },
            "k3s": {
              "enabled": false,
              "runtimePath": "/run/k3s/containerd/containerd.sock"
            },
            "manager": {
              "affinity": {},
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "enabled": true,
              "env": {
                "ssl": true
              },
              "image": "registry.connect.redhat.com/neuvector/manager",
              "ingress": {
                "annotations": {},
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "resources": {},
              "route": {
                "enabled": true,
                "host": "",
                "termination": "passthrough"
              },
              "svc": {
                "annotations": {},
                "loadBalancerIP": "",
                "type": "NodePort"
              },
              "tolerations": []
            },
            "openshift": true,
            "psp": false,
            "resources": {},
            "serviceAccount": "default"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/neuvector/neuvector-operator-bundle@sha256:bb9a141e7420196baf0bfc456ae28d7d150f6b40de987b214d0833207fcc1a3e",
      "bundle_path_digest": "sha256:bb9a141e7420196baf0bfc456ae28d7d150f6b40de987b214d0833207fcc1a3e",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-03-18T10:32:39.444000+00:00",
      "csv_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.\n\nThe NeuVector Operator runs  in the openshift container platform to deploy and manage the NeuVector Security cluster components. The NeuVector operator contains all necessary information to deploy NeuVector using helm charts. You simply need to install the NeuVector operator from the OpenShift embeded operator hub and create NeuVector instance. You can modify the NeuVector installation configuration by modifying yaml while creating the NeuVector instance such as imagePullSecrets, tag version, etc. Please refer to [github link](https://github.com/neuvector/neuvector-helm/tree/master/charts/core) for the values that can be modifed during installation. To upgrade to a newer version of NeuVector, just reapply the NeuVector instance with desired tag , which in turn pulls the specified NeuVector image tags and upgrades as per upgrade plan configured on the helm chart.  NeuVector Operator versions are tied to NeuVector product versions. Version 1.3.2 of the NeuVector Certified Operator deploys version 4.4.2 of NeuVector.\n\n**Complete below steps to Grant Service Account Access to the Privileged SCC before installation.**\n\nCreate the NeuVector namespace\n\n         oc new-project  neuvector\nLogin as system:admin account\n\n         oc login -u system:admin\n\nGrant Service Account Access to the Privileged SCC\n\n         oc -n neuvector adm policy add-scc-to-user privileged -z default\n\nThe following info will be added in the Privileged SCC users:\n\n         - system:serviceaccount:neuvector:default\n\nIn OpenShift 4.6+ use the following to check:\n\n         oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide\n         system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/default\n\n\n**Add NeuVector license from NeuVector WebUI->setting**\n\n\n#Deploying the NeuVector Operator#\n\n\nPlease refer to the instructions [here](https://github.com/neuvector/neuvector-operator/blob/master/README.md)\n\n\n",
      "csv_display_name": "NeuVector Operator",
      "csv_metadata_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.",
      "csv_name": "neuvector-operator.v1.3.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:45:34.174000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "neuvector-certified-operator",
      "provided_apis": [
        {
          "group": "apm.neuvector.com",
          "kind": "Neuvector",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "name": "neuvector-operator-a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0-annotation"
        },
        {
          "digest": "sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "name": "neuvector-operator"
        },
        {
          "digest": "sha256:ecc4814bf9e38d41898ae2354bbafd2f1ed7c6e5602bb30cb40486e67725395c",
          "image": "registry.connect.redhat.com/neuvector/controller@sha256:ecc4814bf9e38d41898ae2354bbafd2f1ed7c6e5602bb30cb40486e67725395c",
          "name": "controller"
        },
        {
          "digest": "sha256:4621d69ca47929eedcab2c9163fc9d73ede09e0cd14f2a14db495e610590f5c2",
          "image": "registry.connect.redhat.com/neuvector/enforcer@sha256:4621d69ca47929eedcab2c9163fc9d73ede09e0cd14f2a14db495e610590f5c2",
          "name": "enforcer"
        },
        {
          "digest": "sha256:b49ba8bba9aaf292603896d5d3b9e5328b23260dfd977c70e7f3e39460564679",
          "image": "registry.connect.redhat.com/neuvector/manager@sha256:b49ba8bba9aaf292603896d5d3b9e5328b23260dfd977c70e7f3e39460564679",
          "name": "manager"
        },
        {
          "digest": "sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "name": "scanner"
        },
        {
          "digest": "sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "name": "updater"
        },
        {
          "digest": "sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "name": "scanner-d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038-annotation"
        },
        {
          "digest": "sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "name": "ubi8-228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.3.2",
      "version_original": "1.3.2"
    },
    {
      "_id": "62345fca5593ce895a7b535a",
      "alm_examples": [
        {
          "api_version": "apm.neuvector.com/v1alpha1",
          "kind": "Neuvector",
          "metadata": {
            "name": "neuvector"
          },
          "spec": {
            "admissionwebhook": {
              "type": "ClusterIP"
            },
            "bottlerocket": {
              "enabled": false,
              "runtimePath": "/run/dockershim.sock"
            },
            "containerd": {
              "enabled": false,
              "path": "/var/run/containerd/containerd.sock"
            },
            "controller": {
              "affinity": {
                "podAntiAffinity": {
                  "preferredDuringSchedulingIgnoredDuringExecution": [
                    {
                      "podAffinityTerm": {
                        "labelSelector": {
                          "matchExpressions": [
                            {
                              "key": "app",
                              "operator": "In",
                              "values": [
                                "neuvector-controller-pod"
                              ]
                            }
                          ]
                        },
                        "topologyKey": "kubernetes.io/hostname"
                      },
                      "weight": 100
                    }
                  ]
                }
              },
              "apisvc": {
                "annotations": {},
                "route": {
                  "enabled": false,
                  "host": "",
                  "termination": "passthrough"
                },
                "type": ""
              },
              "azureFileShare": {
                "enabled": false,
                "secretName": "",
                "shareName": ""
              },
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "configmap": {
                "data": "",
                "enabled": false
              },
              "disruptionbudget": 0,
              "enabled": true,
              "env": [],
              "federation": {
                "managedsvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                },
                "mastersvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                }
              },
              "image": "registry.connect.redhat.com/neuvector/controller",
              "ingress": {
                "annotations": {
                  "ingress.kubernetes.io/protocol": "https"
                },
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "pvc": {
                "accessModes": [
                  "ReadWriteMany"
                ],
                "capacity": "",
                "enabled": false,
                "storageClass": ""
              },
              "replicas": 3,
              "resources": {},
              "schedulerName": "",
              "secret": {
                "data": {},
                "enabled": false
              },
              "strategy": {
                "rollingUpdate": {
                  "maxSurge": 1,
                  "maxUnavailable": 0
                },
                "type": "RollingUpdate"
              },
              "tolerations": []
            },
            "crdwebhook": {
              "enabled": true,
              "type": "ClusterIP"
            },
            "crio": {
              "enabled": true,
              "path": "/var/run/crio/crio.sock"
            },
            "cve": {
              "scanner": {
                "affinity": {},
                "dockerPath": "",
                "enabled": true,
                "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
                "nodeSelector": {},
                "priorityClassName": "",
                "replicas": 3,
                "resources": {},
                "strategy": {
                  "rollingUpdate": {
                    "maxSurge": 1,
                    "maxUnavailable": 0
                  },
                  "type": "RollingUpdate"
                },
                "tolerations": []
              },
              "updater": {
                "enabled": true,
                "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
                "priorityClassName": "",
                "schedule": "0 0 * * *",
                "secure": false
              }
            },
            "docker": {
              "enabled": false,
              "path": "/var/run/docker.sock"
            },
            "enforcer": {
              "enabled": true,
              "image": "registry.connect.redhat.com/neuvector/enforcer",
              "priorityClassName": "",
              "resources": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                }
              ]
            },
            "k3s": {
              "enabled": false,
              "runtimePath": "/run/k3s/containerd/containerd.sock"
            },
            "manager": {
              "affinity": {},
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "enabled": true,
              "env": {
                "ssl": true
              },
              "image": "registry.connect.redhat.com/neuvector/manager",
              "ingress": {
                "annotations": {},
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "resources": {},
              "route": {
                "enabled": true,
                "host": "",
                "termination": "passthrough"
              },
              "svc": {
                "annotations": {},
                "loadBalancerIP": "",
                "type": "NodePort"
              },
              "tolerations": []
            },
            "openshift": true,
            "psp": false,
            "resources": {},
            "serviceAccount": "default"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/neuvector/neuvector-operator-bundle@sha256:ceb11d8e4544f3bb43fa3b217ccf2e2bb7f1e1887340fb7bf8cdafab7a25a25d",
      "bundle_path_digest": "sha256:ceb11d8e4544f3bb43fa3b217ccf2e2bb7f1e1887340fb7bf8cdafab7a25a25d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-03-18T10:32:42.898000+00:00",
      "csv_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.\n\nThe NeuVector Operator runs  in the openshift container platform to deploy and manage the NeuVector Security cluster components. The NeuVector operator contains all necessary information to deploy NeuVector using helm charts. You simply need to install the NeuVector operator from the OpenShift embeded operator hub and create NeuVector instance. You can modify the NeuVector installation configuration by modifying yaml while creating the NeuVector instance such as imagePullSecrets, tag version, etc. Please refer to [github link](https://github.com/neuvector/neuvector-helm/tree/master/charts/core) for the values that can be modifed during installation. To upgrade to a newer version of NeuVector, just reapply the NeuVector instance with desired tag , which in turn pulls the specified NeuVector image tags and upgrades as per upgrade plan configured on the helm chart.  NeuVector Operator versions are tied to NeuVector product versions. Version 1.3.3 of the NeuVector Certified Operator deploys version 4.4.3 of NeuVector.\n\n**Complete below steps to Grant Service Account Access to the Privileged SCC before installation.**\n\nCreate the NeuVector namespace\n\n         oc new-project  neuvector\nLogin as system:admin account\n\n         oc login -u system:admin\n\nGrant Service Account Access to the Privileged SCC\n\n         oc -n neuvector adm policy add-scc-to-user privileged -z default\n\nThe following info will be added in the Privileged SCC users:\n\n         - system:serviceaccount:neuvector:default\n\nIn OpenShift 4.6+ use the following to check:\n\n         oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide\n         system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/default\n\n\n**Add NeuVector license from NeuVector WebUI->setting**\n\n\n#Deploying the NeuVector Operator#\n\n\nPlease refer to the instructions [here](https://github.com/neuvector/neuvector-operator/blob/master/README.md)\n\n\n",
      "csv_display_name": "NeuVector Operator",
      "csv_metadata_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.",
      "csv_name": "neuvector-operator.v1.3.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:45:37.856000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "neuvector-certified-operator",
      "provided_apis": [
        {
          "group": "apm.neuvector.com",
          "kind": "Neuvector",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:6155ac3c95aa6471c9857e0a6f5e5d19e6fc1d8cc7d014108d7d4a10d14f96bb",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:6155ac3c95aa6471c9857e0a6f5e5d19e6fc1d8cc7d014108d7d4a10d14f96bb",
          "name": "neuvector-operator-6155ac3c95aa6471c9857e0a6f5e5d19e6fc1d8cc7d014108d7d4a10d14f96bb-annotation"
        },
        {
          "digest": "sha256:6155ac3c95aa6471c9857e0a6f5e5d19e6fc1d8cc7d014108d7d4a10d14f96bb",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:6155ac3c95aa6471c9857e0a6f5e5d19e6fc1d8cc7d014108d7d4a10d14f96bb",
          "name": "neuvector-operator"
        },
        {
          "digest": "sha256:ecc4814bf9e38d41898ae2354bbafd2f1ed7c6e5602bb30cb40486e67725395c",
          "image": "registry.connect.redhat.com/neuvector/controller@sha256:ecc4814bf9e38d41898ae2354bbafd2f1ed7c6e5602bb30cb40486e67725395c",
          "name": "controller"
        },
        {
          "digest": "sha256:4621d69ca47929eedcab2c9163fc9d73ede09e0cd14f2a14db495e610590f5c2",
          "image": "registry.connect.redhat.com/neuvector/enforcer@sha256:4621d69ca47929eedcab2c9163fc9d73ede09e0cd14f2a14db495e610590f5c2",
          "name": "enforcer"
        },
        {
          "digest": "sha256:b49ba8bba9aaf292603896d5d3b9e5328b23260dfd977c70e7f3e39460564679",
          "image": "registry.connect.redhat.com/neuvector/manager@sha256:b49ba8bba9aaf292603896d5d3b9e5328b23260dfd977c70e7f3e39460564679",
          "name": "manager"
        },
        {
          "digest": "sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "name": "scanner"
        },
        {
          "digest": "sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "name": "updater"
        },
        {
          "digest": "sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "name": "scanner-d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038-annotation"
        },
        {
          "digest": "sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "name": "ubi8-228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.3.3",
      "version_original": "1.3.3"
    },
    {
      "_id": "62345fcc670f4cadbafad2a7",
      "alm_examples": [
        {
          "api_version": "apm.neuvector.com/v1alpha1",
          "kind": "Neuvector",
          "metadata": {
            "name": "neuvector"
          },
          "spec": {
            "admissionwebhook": {
              "type": "ClusterIP"
            },
            "bottlerocket": {
              "enabled": false,
              "runtimePath": "/run/dockershim.sock"
            },
            "containerd": {
              "enabled": false,
              "path": "/var/run/containerd/containerd.sock"
            },
            "controller": {
              "affinity": {
                "podAntiAffinity": {
                  "preferredDuringSchedulingIgnoredDuringExecution": [
                    {
                      "podAffinityTerm": {
                        "labelSelector": {
                          "matchExpressions": [
                            {
                              "key": "app",
                              "operator": "In",
                              "values": [
                                "neuvector-controller-pod"
                              ]
                            }
                          ]
                        },
                        "topologyKey": "kubernetes.io/hostname"
                      },
                      "weight": 100
                    }
                  ]
                }
              },
              "apisvc": {
                "annotations": {},
                "route": {
                  "enabled": false,
                  "host": "",
                  "termination": "passthrough"
                },
                "type": ""
              },
              "azureFileShare": {
                "enabled": false,
                "secretName": "",
                "shareName": ""
              },
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "configmap": {
                "data": "",
                "enabled": false
              },
              "disruptionbudget": 0,
              "enabled": true,
              "env": [],
              "federation": {
                "managedsvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                },
                "mastersvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                }
              },
              "image": "registry.connect.redhat.com/neuvector/controller",
              "ingress": {
                "annotations": {
                  "ingress.kubernetes.io/protocol": "https"
                },
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "pvc": {
                "accessModes": [
                  "ReadWriteMany"
                ],
                "capacity": "",
                "enabled": false,
                "storageClass": ""
              },
              "replicas": 3,
              "resources": {},
              "schedulerName": "",
              "secret": {
                "data": {},
                "enabled": false
              },
              "strategy": {
                "rollingUpdate": {
                  "maxSurge": 1,
                  "maxUnavailable": 0
                },
                "type": "RollingUpdate"
              },
              "tolerations": []
            },
            "crdwebhook": {
              "enabled": true,
              "type": "ClusterIP"
            },
            "crio": {
              "enabled": true,
              "path": "/var/run/crio/crio.sock"
            },
            "cve": {
              "scanner": {
                "affinity": {},
                "dockerPath": "",
                "enabled": true,
                "image": "registry.connect.redhat.com/neuvector/scanner@sha256:42004e13b348bb43b58ae8538c983a70b237e3aca870758ac629fb4fc43e8130",
                "nodeSelector": {},
                "priorityClassName": "",
                "replicas": 3,
                "resources": {},
                "strategy": {
                  "rollingUpdate": {
                    "maxSurge": 1,
                    "maxUnavailable": 0
                  },
                  "type": "RollingUpdate"
                },
                "tolerations": []
              },
              "updater": {
                "enabled": true,
                "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
                "priorityClassName": "",
                "schedule": "0 0 * * *",
                "secure": false
              }
            },
            "docker": {
              "enabled": false,
              "path": "/var/run/docker.sock"
            },
            "enforcer": {
              "enabled": true,
              "image": "registry.connect.redhat.com/neuvector/enforcer",
              "priorityClassName": "",
              "resources": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                }
              ]
            },
            "k3s": {
              "enabled": false,
              "runtimePath": "/run/k3s/containerd/containerd.sock"
            },
            "manager": {
              "affinity": {},
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "enabled": true,
              "env": {
                "ssl": true
              },
              "image": "registry.connect.redhat.com/neuvector/manager",
              "ingress": {
                "annotations": {},
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "resources": {},
              "route": {
                "enabled": true,
                "host": "",
                "termination": "passthrough"
              },
              "svc": {
                "annotations": {},
                "loadBalancerIP": "",
                "type": "NodePort"
              },
              "tolerations": []
            },
            "openshift": true,
            "psp": false,
            "resources": {},
            "serviceAccount": "default"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/neuvector/neuvector-operator-bundle@sha256:7060f7f130f0de1b20e377a846cfea20353202ea6dddce915b2b7918a3ef8efa",
      "bundle_path_digest": "sha256:7060f7f130f0de1b20e377a846cfea20353202ea6dddce915b2b7918a3ef8efa",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-03-18T10:32:44.905000+00:00",
      "csv_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.\n\nThe NeuVector Operator runs  in the openshift container platform to deploy and manage the NeuVector Security cluster components. The NeuVector operator contains all necessary information to deploy NeuVector using helm charts. You simply need to install the NeuVector operator from the OpenShift embeded operator hub and create NeuVector instance. You can modify the NeuVector installation configuration by modifying yaml while creating the NeuVector instance such as imagePullSecrets, tag version, etc. Please refer to [github link](https://github.com/neuvector/neuvector-helm/tree/master/charts/core) for the values that can be modifed during installation. To upgrade to a newer version of NeuVector, just reapply the NeuVector instance with desired tag , which in turn pulls the specified NeuVector image tags and upgrades as per upgrade plan configured on the helm chart.  NeuVector Operator versions are tied to NeuVector product versions. Version 1.3.4 of the NeuVector Certified Operator deploys version 4.4.3 of NeuVector.\n\n**Complete below steps to Grant Service Account Access to the Privileged SCC before installation.**\n\nCreate the NeuVector namespace\n\n         oc new-project  neuvector\nLogin as system:admin account\n\n         oc login -u system:admin\n\nGrant Service Account Access to the Privileged SCC\n\n         oc -n neuvector adm policy add-scc-to-user privileged -z default\n\nThe following info will be added in the Privileged SCC users:\n\n         - system:serviceaccount:neuvector:default\n\nIn OpenShift 4.6+ use the following to check:\n\n         oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide\n         system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/default\n\n\n**Add NeuVector license from NeuVector WebUI->setting**\n\n\n#Deploying the NeuVector Operator#\n\n\nPlease refer to the instructions [here](https://github.com/neuvector/neuvector-operator/blob/master/README.md)\n\n\n",
      "csv_display_name": "NeuVector Operator",
      "csv_metadata_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.",
      "csv_name": "neuvector-operator.v1.3.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:45:41.485000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "neuvector-certified-operator",
      "provided_apis": [
        {
          "group": "apm.neuvector.com",
          "kind": "Neuvector",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:6155ac3c95aa6471c9857e0a6f5e5d19e6fc1d8cc7d014108d7d4a10d14f96bb",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:6155ac3c95aa6471c9857e0a6f5e5d19e6fc1d8cc7d014108d7d4a10d14f96bb",
          "name": "neuvector-operator-6155ac3c95aa6471c9857e0a6f5e5d19e6fc1d8cc7d014108d7d4a10d14f96bb-annotation"
        },
        {
          "digest": "sha256:6155ac3c95aa6471c9857e0a6f5e5d19e6fc1d8cc7d014108d7d4a10d14f96bb",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:6155ac3c95aa6471c9857e0a6f5e5d19e6fc1d8cc7d014108d7d4a10d14f96bb",
          "name": "neuvector-operator"
        },
        {
          "digest": "sha256:acc943568520282061547b310c50080dc32924a531bbb543d959b281eb6664f4",
          "image": "registry.connect.redhat.com/neuvector/controller@sha256:acc943568520282061547b310c50080dc32924a531bbb543d959b281eb6664f4",
          "name": "controller"
        },
        {
          "digest": "sha256:be1d299ec3532d55444681a882e9fd1238949da6598987308e2800ed26291b7a",
          "image": "registry.connect.redhat.com/neuvector/enforcer@sha256:be1d299ec3532d55444681a882e9fd1238949da6598987308e2800ed26291b7a",
          "name": "enforcer"
        },
        {
          "digest": "sha256:8245cd179d11fff279690c5a422f46b4ff252ed72b9b998f0c9b5453bc7d8fc0",
          "image": "registry.connect.redhat.com/neuvector/manager@sha256:8245cd179d11fff279690c5a422f46b4ff252ed72b9b998f0c9b5453bc7d8fc0",
          "name": "manager"
        },
        {
          "digest": "sha256:42004e13b348bb43b58ae8538c983a70b237e3aca870758ac629fb4fc43e8130",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:42004e13b348bb43b58ae8538c983a70b237e3aca870758ac629fb4fc43e8130",
          "name": "scanner"
        },
        {
          "digest": "sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "name": "updater"
        },
        {
          "digest": "sha256:42004e13b348bb43b58ae8538c983a70b237e3aca870758ac629fb4fc43e8130",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:42004e13b348bb43b58ae8538c983a70b237e3aca870758ac629fb4fc43e8130",
          "name": "scanner-42004e13b348bb43b58ae8538c983a70b237e3aca870758ac629fb4fc43e8130-annotation"
        },
        {
          "digest": "sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "name": "ubi8-228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.3.4",
      "version_original": "1.3.4"
    },
    {
      "_id": "62345fd006c5dada0193e07b",
      "alm_examples": [
        {
          "api_version": "apm.neuvector.com/v1alpha1",
          "kind": "Neuvector",
          "metadata": {
            "name": "neuvector"
          },
          "spec": {
            "admissionwebhook": {
              "type": "ClusterIP"
            },
            "bottlerocket": {
              "enabled": false,
              "runtimePath": "/run/dockershim.sock"
            },
            "containerd": {
              "enabled": false,
              "path": "/var/run/containerd/containerd.sock"
            },
            "controller": {
              "affinity": {
                "podAntiAffinity": {
                  "preferredDuringSchedulingIgnoredDuringExecution": [
                    {
                      "podAffinityTerm": {
                        "labelSelector": {
                          "matchExpressions": [
                            {
                              "key": "app",
                              "operator": "In",
                              "values": [
                                "neuvector-controller-pod"
                              ]
                            }
                          ]
                        },
                        "topologyKey": "kubernetes.io/hostname"
                      },
                      "weight": 100
                    }
                  ]
                }
              },
              "apisvc": {
                "annotations": {},
                "route": {
                  "enabled": false,
                  "host": "",
                  "termination": "passthrough"
                },
                "type": ""
              },
              "azureFileShare": {
                "enabled": false,
                "secretName": "",
                "shareName": ""
              },
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "configmap": {
                "data": "",
                "enabled": false
              },
              "disruptionbudget": 0,
              "enabled": true,
              "env": [],
              "federation": {
                "managedsvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                },
                "mastersvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                }
              },
              "image": "registry.connect.redhat.com/neuvector/controller",
              "ingress": {
                "annotations": {
                  "ingress.kubernetes.io/protocol": "https"
                },
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "pvc": {
                "accessModes": [
                  "ReadWriteMany"
                ],
                "capacity": "",
                "enabled": false,
                "storageClass": ""
              },
              "replicas": 3,
              "resources": {},
              "schedulerName": "",
              "secret": {
                "data": {},
                "enabled": false
              },
              "strategy": {
                "rollingUpdate": {
                  "maxSurge": 1,
                  "maxUnavailable": 0
                },
                "type": "RollingUpdate"
              },
              "tolerations": []
            },
            "crdwebhook": {
              "enabled": true,
              "type": "ClusterIP"
            },
            "crio": {
              "enabled": true,
              "path": "/var/run/crio/crio.sock"
            },
            "cve": {
              "scanner": {
                "affinity": {},
                "dockerPath": "",
                "enabled": true,
                "image": "registry.connect.redhat.com/neuvector/scanner@sha256:30b8c4ad5ab2a616bd07c7bd2e24dd58e19bf743a56788fd53808b2c54503515",
                "nodeSelector": {},
                "priorityClassName": "",
                "replicas": 3,
                "resources": {},
                "strategy": {
                  "rollingUpdate": {
                    "maxSurge": 1,
                    "maxUnavailable": 0
                  },
                  "type": "RollingUpdate"
                },
                "tolerations": []
              },
              "updater": {
                "enabled": true,
                "image": "registry.access.redhat.com/ubi8@sha256:f3e11575aee05d474cb994c0ece89d992ece85be0596480582251fdec7a68f0b",
                "priorityClassName": "",
                "schedule": "0 0 * * *",
                "secure": false
              }
            },
            "docker": {
              "enabled": false,
              "path": "/var/run/docker.sock"
            },
            "enforcer": {
              "enabled": true,
              "image": "registry.connect.redhat.com/neuvector/enforcer",
              "priorityClassName": "",
              "resources": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                }
              ]
            },
            "k3s": {
              "enabled": false,
              "runtimePath": "/run/k3s/containerd/containerd.sock"
            },
            "manager": {
              "affinity": {},
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "enabled": true,
              "env": {
                "ssl": true
              },
              "image": "registry.connect.redhat.com/neuvector/manager",
              "ingress": {
                "annotations": {},
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "resources": {},
              "route": {
                "enabled": true,
                "host": "",
                "termination": "passthrough"
              },
              "svc": {
                "annotations": {},
                "loadBalancerIP": "",
                "type": "NodePort"
              },
              "tolerations": []
            },
            "openshift": true,
            "psp": false,
            "resources": {},
            "serviceAccount": "default"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/neuvector/neuvector-operator-bundle@sha256:aa613d5a3f9f2f111cbdc8bbb0d8e66a785a80983b26f591fe065b1a6ad3b714",
      "bundle_path_digest": "sha256:aa613d5a3f9f2f111cbdc8bbb0d8e66a785a80983b26f591fe065b1a6ad3b714",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-03-18T10:32:48.249000+00:00",
      "csv_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.\n\nThe NeuVector Operator runs  in the openshift container platform to deploy and manage the NeuVector Security cluster components. The NeuVector operator contains all necessary information to deploy NeuVector using helm charts. You simply need to install the NeuVector operator from the OpenShift embeded operator hub and create NeuVector instance. You can modify the NeuVector installation configuration by modifying yaml while creating the NeuVector instance such as imagePullSecrets, tag version, etc. Please refer to [github link](https://github.com/neuvector/neuvector-helm/tree/master/charts/core) for the values that can be modifed during installation. To upgrade to a newer version of NeuVector, just reapply the NeuVector instance with desired tag , which in turn pulls the specified NeuVector image tags and upgrades as per upgrade plan configured on the helm chart.  NeuVector Operator versions are tied to NeuVector product versions. Version 1.3.5 of the NeuVector Certified Operator deploys version 4.4.4 of NeuVector.\n\n**Complete below steps to Grant Service Account Access to the Privileged SCC before installation.**\n\nCreate the NeuVector namespace\n\n         oc new-project  neuvector\nLogin as system:admin account\n\n         oc login -u system:admin\n\nGrant Service Account Access to the Privileged SCC\n\n         oc -n neuvector adm policy add-scc-to-user privileged -z default\n\nThe following info will be added in the Privileged SCC users:\n\n         - system:serviceaccount:neuvector:default\n\nIn OpenShift 4.6+ use the following to check:\n\n         oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide\n         system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/default\n\n\n**Add NeuVector license from NeuVector WebUI->setting**\n\n\n#Deploying the NeuVector Operator#\n\n\nPlease refer to the instructions [here](https://github.com/neuvector/neuvector-operator/blob/master/README.md)\n\n\n",
      "csv_display_name": "NeuVector Operator",
      "csv_metadata_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.",
      "csv_name": "neuvector-operator.v1.3.5",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:45:44.959000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "neuvector-certified-operator",
      "provided_apis": [
        {
          "group": "apm.neuvector.com",
          "kind": "Neuvector",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:725bace9f5d0302b4c6681cfd8b1523aa70f7951f1d03677b388341d91043e4c",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:725bace9f5d0302b4c6681cfd8b1523aa70f7951f1d03677b388341d91043e4c",
          "name": "neuvector-operator-725bace9f5d0302b4c6681cfd8b1523aa70f7951f1d03677b388341d91043e4c-annotation"
        },
        {
          "digest": "sha256:725bace9f5d0302b4c6681cfd8b1523aa70f7951f1d03677b388341d91043e4c",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:725bace9f5d0302b4c6681cfd8b1523aa70f7951f1d03677b388341d91043e4c",
          "name": "neuvector-operator"
        },
        {
          "digest": "sha256:cfbc29a7179c0a9dad1b4952317eed1573d340cd36dc50b25b06a345ae2cbaad",
          "image": "registry.connect.redhat.com/neuvector/controller@sha256:cfbc29a7179c0a9dad1b4952317eed1573d340cd36dc50b25b06a345ae2cbaad",
          "name": "controller"
        },
        {
          "digest": "sha256:f38526a125ff0f884ec834db6779875228879927a810b47e7955dc5ed9585f44",
          "image": "registry.connect.redhat.com/neuvector/enforcer@sha256:f38526a125ff0f884ec834db6779875228879927a810b47e7955dc5ed9585f44",
          "name": "enforcer"
        },
        {
          "digest": "sha256:48839dec3d696b2540646c2e92f54df7fd32699b871f4243d485fc5a4a23da70",
          "image": "registry.connect.redhat.com/neuvector/manager@sha256:48839dec3d696b2540646c2e92f54df7fd32699b871f4243d485fc5a4a23da70",
          "name": "manager"
        },
        {
          "digest": "sha256:30b8c4ad5ab2a616bd07c7bd2e24dd58e19bf743a56788fd53808b2c54503515",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:30b8c4ad5ab2a616bd07c7bd2e24dd58e19bf743a56788fd53808b2c54503515",
          "name": "scanner"
        },
        {
          "digest": "sha256:f3e11575aee05d474cb994c0ece89d992ece85be0596480582251fdec7a68f0b",
          "image": "registry.access.redhat.com/ubi8@sha256:f3e11575aee05d474cb994c0ece89d992ece85be0596480582251fdec7a68f0b",
          "name": "updater"
        },
        {
          "digest": "sha256:30b8c4ad5ab2a616bd07c7bd2e24dd58e19bf743a56788fd53808b2c54503515",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:30b8c4ad5ab2a616bd07c7bd2e24dd58e19bf743a56788fd53808b2c54503515",
          "name": "scanner-30b8c4ad5ab2a616bd07c7bd2e24dd58e19bf743a56788fd53808b2c54503515-annotation"
        },
        {
          "digest": "sha256:f3e11575aee05d474cb994c0ece89d992ece85be0596480582251fdec7a68f0b",
          "image": "registry.access.redhat.com/ubi8@sha256:f3e11575aee05d474cb994c0ece89d992ece85be0596480582251fdec7a68f0b",
          "name": "ubi8-f3e11575aee05d474cb994c0ece89d992ece85be0596480582251fdec7a68f0b-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.3.5",
      "version_original": "1.3.5"
    },
    {
      "_id": "62345fd25593ce895a7b535b",
      "alm_examples": [
        {
          "api_version": "cilium.io/v1alpha1",
          "kind": "CiliumConfig",
          "metadata": {
            "name": "cilium-openshift-default",
            "namespace": "placeholder"
          },
          "spec": {
            "cni": {
              "binPath": "/var/lib/cni/bin",
              "confPath": "/var/run/multus/cni/net.d"
            },
            "endpointRoutes": {
              "enabled": true
            },
            "hubble": {
              "tls": {
                "enabled": false
              }
            },
            "ipam": {
              "mode": "cluster-pool",
              "operator": {
                "clusterPoolIPv4MaskSize": "23",
                "clusterPoolIPv4PodCIDR": "10.128.0.0/14"
              }
            },
            "kubeProxyReplacement": "probe",
            "nativeRoutingCIDR": "10.128.0.0/14",
            "prometheus": {
              "serviceMonitor": {
                "enabled": false
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/isovalent/cilium-olm-metadata@sha256:33a2e21a069ff24af4bf0ffc51e83ddf398df5d9735d0123120768e9dc2c27f9",
      "bundle_path_digest": "sha256:33a2e21a069ff24af4bf0ffc51e83ddf398df5d9735d0123120768e9dc2c27f9",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:32:50.995000+00:00",
      "csv_description": "Cilium - eBPF-based Networking, Security, and Observability",
      "csv_display_name": "Cilium",
      "csv_metadata_description": "",
      "csv_name": "cilium.v1.10.4-x5bfd7b3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-06-17T01:44:34.253000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "cilium",
      "provided_apis": [
        {
          "group": "cilium.io",
          "kind": "CiliumConfig",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:b45ff6a6552d71cbc26e358e0b25759d33818fd92301f1656453c5bcf826ff13",
          "image": "registry.connect.redhat.com/isovalent/cilium-olm@sha256:b45ff6a6552d71cbc26e358e0b25759d33818fd92301f1656453c5bcf826ff13",
          "name": "operator"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.10.4+x5bfd7b3",
      "version_original": "1.10.4+x5bfd7b3"
    },
    {
      "_id": "62345fd5314381d2b0756b39",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1alpha1",
          "kind": "OpenshiftArtifactoryHa",
          "metadata": {
            "name": "openshiftartifactoryha"
          },
          "spec": {
            "artifactory-ha": {
              "artifactory": {
                "image": {
                  "registry": "registry.connect.redhat.com",
                  "repository": "jfrog/artifactory-pro",
                  "tag": "7.25.7-2"
                },
                "joinKey": "OVERRIDE",
                "masterKey": "OVERRIDE",
                "node": {
                  "replicaCount": 2,
                  "waitForPrimaryStartup": {
                    "enabled": false
                  }
                },
                "uid": "1000721030"
              },
              "database": {
                "driver": "OVERRIDE",
                "password": "OVERRIDE",
                "type": "OVERRIDE",
                "url": "OVERRIDE",
                "user": "OVERRIDE"
              },
              "databaseUpgradeReady": true,
              "initContainerImage": "registry.connect.redhat.com/jfrog/init@sha256:175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03",
              "nginx": {
                "gid": "1000720107",
                "http": {
                  "externalPort": 80,
                  "internalPort": 8080
                },
                "https": {
                  "externalPort": 443,
                  "internalPort": 8443
                },
                "image": {
                  "registry": "registry.redhat.io",
                  "repository": "rhel8/nginx-116",
                  "tag": "latest"
                },
                "service": {
                  "ssloffload": false
                },
                "tlsSecretName": "OVERRIDE",
                "uid": "1000720104"
              },
              "postgresql": {
                "enabled": false
              },
              "waitForDatabase": true
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/jfrog/artifactory-operator-bundle@sha256:49229329083f8836be365b25beda86290cf8c6985dbeb1c46991c2121b54dda9",
      "bundle_path_digest": "sha256:49229329083f8836be365b25beda86290cf8c6985dbeb1c46991c2121b54dda9",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-03-18T10:32:53.947000+00:00",
      "csv_description": " ## Breaking change\nPlease update to version 1.1.10 of the operator.\nVersion 1.1.8 and 1.1.9 have issues. Please skip these versions.\n\n## Overview\nOpenshift Operator to deploy JFrog Artifactory Enterprise into your Openshift cluster.\n## Security Context Constraints\nTo deploy this helm chart you will need to be a cluster admin w/ access to the anyuid scc and add the operator service account to the anyuid scc.\n```\noc adm policy add-scc-to-user anyuid -z artifactory-ha-operator -n openshift-operators\n```\nAdd the service account for the Artifactory chart to deploy successfully:\n``` oc adm policy add-scc-to-user anyuid -z openshiftartifactoryha-artifactory-ha -n artifactory ```\n### Usage\n\nAn external DB is required. The operator will not deploy a DB but will require you to specify the configuration values to connect to it.\n\nSearch for JFrog and click JFrog Artifactory Enterprise Operator to install.\n\nGo to the Installed Operators.\n\nWait for the JFrog Artifactory Enterprise Operator to complete the installation.\n\nOpen the Operator and click on the provided API: Artifactory HA.\n\nClick Create New Instance and provide the following parameters for your DB configuration:\n\n```\nDATABASE_TYPE\nDATABASE_DRIVER\nDATABASE_URL\nDATABASE_USER\nDATABASE_PASSWORD\n```\nMaster key and Join key must be supplied. To generate a new key for each run the command below:\n\n```\n# Create a key\nexport JOIN_KEY=$(openssl rand -hex 32)\necho ${JOIN_KEY}\n```\n\nTo use TLS you will need to first create a k8s tls secret to store your .crt and .key file into.\nThen supply the value of this k8s secret into the TLS_SECRET field.\n``` oc create secret tls my_tls_secret --cert=tls.crt --key=tls.key --namespace=my_namespace ```\nClick Create for Artifactory Enterprise to deploy into OpenShift and connect to it on the external IP exposed by the load balancer.\n### Create a route\nTo expose Artifactory from Openshift we recommend you create a new route in Openshift.\nYou can either use the oc command line tool or the Openshift web console to generate a new route.\nDepending upon where you terminate TLS you will need to either specify pass through or edge.\nCommand Line (Edge):\n``` oc create route edge --service=openshiftartifactory-ha --cert=tls.crt --key=tls.key --ca-cert=ca.crt --hostname=www.example.com ```\nOr for more information visit the official Openshift documentation on routes here:\nhttps://docs.openshift.com/container-platform/4.6/networking/routes/route-configuration.html\n\n",
      "csv_display_name": "JFrog Artifactory Enterprise Operator",
      "csv_metadata_description": "JFrog Artifactory Enterprise deploys Artifactory in a high availability environment across multiple pods",
      "csv_name": "artifactory-ha-operator.v1.1.14",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:33:39.685000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "openshiftartifactoryha-operator",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "OpenshiftArtifactoryHa",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "name": "artifactory-operator-9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4-annotation"
        },
        {
          "digest": "sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "name": "artifactory-ha-operator"
        },
        {
          "digest": "sha256:abd96a07bbeffcdcdf69b5998b9256b684e72bcecb9b94b9a623a0c02b276322",
          "image": "registry.connect.redhat.com/jfrog/artifactory-pro@sha256:abd96a07bbeffcdcdf69b5998b9256b684e72bcecb9b94b9a623a0c02b276322",
          "name": "artifactory_image_repository"
        },
        {
          "digest": "sha256:225b9d8cac2b4d3a1d193782f4bba749194048b87bf31dcd12ea88422e6350c8",
          "image": "registry.redhat.io/rhel8/nginx-116@sha256:225b9d8cac2b4d3a1d193782f4bba749194048b87bf31dcd12ea88422e6350c8",
          "name": "nginx_image_repository"
        },
        {
          "digest": "sha256:175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03",
          "image": "registry.connect.redhat.com/jfrog/init@sha256:175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03",
          "name": "init-175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.1.14",
      "version_original": "1.1.14"
    },
    {
      "_id": "62345fd7314381d2b0756b3a",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1alpha1",
          "kind": "OpenshiftArtifactoryHa",
          "metadata": {
            "name": "openshiftartifactoryha"
          },
          "spec": {
            "artifactory-ha": {
              "artifactory": {
                "image": {
                  "registry": "registry.connect.redhat.com",
                  "repository": "jfrog/artifactory-pro",
                  "tag": "7.25.7-2"
                },
                "joinKey": "OVERRIDE",
                "masterKey": "OVERRIDE",
                "node": {
                  "replicaCount": 2,
                  "waitForPrimaryStartup": {
                    "enabled": false
                  }
                },
                "uid": "1000721030"
              },
              "database": {
                "driver": "OVERRIDE",
                "password": "OVERRIDE",
                "type": "OVERRIDE",
                "url": "OVERRIDE",
                "user": "OVERRIDE"
              },
              "databaseUpgradeReady": true,
              "initContainerImage": "registry.connect.redhat.com/jfrog/init@sha256:175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03",
              "nginx": {
                "gid": "1000720107",
                "http": {
                  "externalPort": 80,
                  "internalPort": 8080
                },
                "https": {
                  "externalPort": 443,
                  "internalPort": 8443
                },
                "image": {
                  "registry": "registry.redhat.io",
                  "repository": "rhel8/nginx-116",
                  "tag": "latest"
                },
                "service": {
                  "ssloffload": false
                },
                "tlsSecretName": "OVERRIDE",
                "uid": "1000720104"
              },
              "postgresql": {
                "enabled": false
              },
              "waitForDatabase": true
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/jfrog/artifactory-operator-bundle@sha256:55712df39fd00efa21711d24459e5a0610d9d2221af37a893fd80f7951838fab",
      "bundle_path_digest": "sha256:55712df39fd00efa21711d24459e5a0610d9d2221af37a893fd80f7951838fab",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-03-18T10:32:55.700000+00:00",
      "csv_description": " ## Breaking change\nPlease update to version 1.1.10 of the operator.\nVersion 1.1.8 and 1.1.9 have issues. Please skip these versions.\n\n## Overview\nOpenshift Operator to deploy JFrog Artifactory Enterprise into your Openshift cluster.\n## Security Context Constraints\nTo deploy this helm chart you will need to be a cluster admin w/ access to the anyuid scc and add the operator service account to the anyuid scc.\n```\noc adm policy add-scc-to-user anyuid -z artifactory-ha-operator -n openshift-operators\n```\nAdd the service account for the Artifactory chart to deploy successfully:\n``` oc adm policy add-scc-to-user anyuid -z openshiftartifactoryha-artifactory-ha -n artifactory ```\n### Usage\n\nAn external DB is required. The operator will not deploy a DB but will require you to specify the configuration values to connect to it.\n\nSearch for JFrog and click JFrog Artifactory Enterprise Operator to install.\n\nGo to the Installed Operators.\n\nWait for the JFrog Artifactory Enterprise Operator to complete the installation.\n\nOpen the Operator and click on the provided API: Artifactory HA.\n\nClick Create New Instance and provide the following parameters for your DB configuration:\n\n```\nDATABASE_TYPE\nDATABASE_DRIVER\nDATABASE_URL\nDATABASE_USER\nDATABASE_PASSWORD\n```\nMaster key and Join key must be supplied. To generate a new key for each run the command below:\n\n```\n# Create a key\nexport JOIN_KEY=$(openssl rand -hex 32)\necho ${JOIN_KEY}\n```\n\nTo use TLS you will need to first create a k8s tls secret to store your .crt and .key file into.\nThen supply the value of this k8s secret into the TLS_SECRET field.\n``` oc create secret tls my_tls_secret --cert=tls.crt --key=tls.key --namespace=my_namespace ```\nClick Create for Artifactory Enterprise to deploy into OpenShift and connect to it on the external IP exposed by the load balancer.\n### Create a route\nTo expose Artifactory from Openshift we recommend you create a new route in Openshift.\nYou can either use the oc command line tool or the Openshift web console to generate a new route.\nDepending upon where you terminate TLS you will need to either specify pass through or edge.\nCommand Line (Edge):\n``` oc create route edge --service=openshiftartifactory-ha --cert=tls.crt --key=tls.key --ca-cert=ca.crt --hostname=www.example.com ```\nOr for more information visit the official Openshift documentation on routes here:\nhttps://docs.openshift.com/container-platform/4.6/networking/routes/route-configuration.html\n\n",
      "csv_display_name": "JFrog Artifactory Enterprise Operator",
      "csv_metadata_description": "JFrog Artifactory Enterprise deploys Artifactory in a high availability environment across multiple pods",
      "csv_name": "artifactory-ha-operator.v1.1.15",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:33:44.016000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "openshiftartifactoryha-operator",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "OpenshiftArtifactoryHa",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "name": "artifactory-operator-9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4-annotation"
        },
        {
          "digest": "sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "name": "artifactory-ha-operator"
        },
        {
          "digest": "sha256:abd96a07bbeffcdcdf69b5998b9256b684e72bcecb9b94b9a623a0c02b276322",
          "image": "registry.connect.redhat.com/jfrog/artifactory-pro@sha256:abd96a07bbeffcdcdf69b5998b9256b684e72bcecb9b94b9a623a0c02b276322",
          "name": "artifactory_image_repository"
        },
        {
          "digest": "sha256:d71d368d6094a5777000a8d99164959ccb97fca355e855e24bd92c13a8df04f6",
          "image": "registry.redhat.io/rhel8/nginx-116@sha256:d71d368d6094a5777000a8d99164959ccb97fca355e855e24bd92c13a8df04f6",
          "name": "nginx_image_repository"
        },
        {
          "digest": "sha256:175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03",
          "image": "registry.connect.redhat.com/jfrog/init@sha256:175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03",
          "name": "init-175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.1.15",
      "version_original": "1.1.15"
    },
    {
      "_id": "62345fda670f4cadbafad2a8",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "OpenshiftArtifactoryHa",
          "metadata": {
            "name": "openshiftartifactoryha"
          },
          "spec": {
            "artifactory-ha": {
              "artifactory": {
                "image": {
                  "registry": "registry.connect.redhat.com",
                  "repository": "jfrog/artifactory-pro",
                  "tag": "7.27.3-1"
                },
                "joinKey": "OVERRIDE",
                "masterKey": "OVERRIDE",
                "node": {
                  "replicaCount": 2,
                  "waitForPrimaryStartup": {
                    "enabled": false
                  }
                },
                "uid": "1000721030"
              },
              "database": {
                "driver": "OVERRIDE",
                "password": "OVERRIDE",
                "type": "OVERRIDE",
                "url": "OVERRIDE",
                "user": "OVERRIDE"
              },
              "databaseUpgradeReady": true,
              "initContainerImage": "registry.connect.redhat.com/jfrog/init@sha256:164b41720a37f75c6129c8a28d05cc56f821022313d44ff918cce4a2146d93e8",
              "nginx": {
                "gid": "1000720107",
                "http": {
                  "externalPort": 80,
                  "internalPort": 8080
                },
                "https": {
                  "externalPort": 443,
                  "internalPort": 8443
                },
                "image": {
                  "registry": "registry.redhat.io",
                  "repository": "rhel8/nginx-116",
                  "tag": "latest"
                },
                "service": {
                  "ssloffload": false
                },
                "tlsSecretName": "OVERRIDE",
                "uid": "1000720104"
              },
              "postgresql": {
                "enabled": false
              },
              "waitForDatabase": true
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/jfrog/artifactory-operator-bundle@sha256:3c12c9d9537b12f610b9f759ad0a94ed465608f69e6bd1cd175a8c3d177151b8",
      "bundle_path_digest": "sha256:3c12c9d9537b12f610b9f759ad0a94ed465608f69e6bd1cd175a8c3d177151b8",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-03-18T10:32:58.203000+00:00",
      "csv_description": " ## Breaking change\nPlease update to version 1.1.10 of the operator.\nVersion 1.1.8 and 1.1.9 have issues. Please skip these versions.\n\n## Overview\nOpenshift Operator to deploy JFrog Artifactory Enterprise into your Openshift cluster.\n## Security Context Constraints\nTo deploy this helm chart you will need to be a cluster admin w/ access to the anyuid scc and add the operator service account to the anyuid scc.\n```\noc adm policy add-scc-to-user anyuid -z artifactory-ha-operator -n openshift-operators\n```\nAdd the service account for the Artifactory chart to deploy successfully:\n``` oc adm policy add-scc-to-user anyuid -z openshiftartifactoryha-artifactory-ha -n artifactory ```\n### Usage\n\nAn external DB is required. The operator will not deploy a DB but will require you to specify the configuration values to connect to it.\n\nSearch for JFrog and click JFrog Artifactory Enterprise Operator to install.\n\nGo to the Installed Operators.\n\nWait for the JFrog Artifactory Enterprise Operator to complete the installation.\n\nOpen the Operator and click on the provided API: Artifactory HA.\n\nClick Create New Instance and provide the following parameters for your DB configuration:\n\n```\nDATABASE_TYPE\nDATABASE_DRIVER\nDATABASE_URL\nDATABASE_USER\nDATABASE_PASSWORD\n```\nMaster key and Join key must be supplied. To generate a new key for each run the command below:\n\n```\n# Create a key\nexport JOIN_KEY=$(openssl rand -hex 32)\necho ${JOIN_KEY}\n```\n\nTo use TLS you will need to first create a k8s tls secret to store your .crt and .key file into.\nThen supply the value of this k8s secret into the TLS_SECRET field.\n``` oc create secret tls my_tls_secret --cert=tls.crt --key=tls.key --namespace=my_namespace ```\nClick Create for Artifactory Enterprise to deploy into OpenShift and connect to it on the external IP exposed by the load balancer.\n### Create a route\nTo expose Artifactory from Openshift we recommend you create a new route in Openshift.\nYou can either use the oc command line tool or the Openshift web console to generate a new route.\nDepending upon where you terminate TLS you will need to either specify pass through or edge.\nCommand Line (Edge):\n``` oc create route edge --service=openshiftartifactory-ha --cert=tls.crt --key=tls.key --ca-cert=ca.crt --hostname=www.example.com ```\nOr for more information visit the official Openshift documentation on routes here:\nhttps://docs.openshift.com/container-platform/4.6/networking/routes/route-configuration.html\n\n",
      "csv_display_name": "JFrog Artifactory Enterprise Operator",
      "csv_metadata_description": "JFrog Artifactory Enterprise deploys Artifactory in a high availability environment across multiple pods",
      "csv_name": "artifactory-ha-operator.v1.1.20",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:33:48.648000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "openshiftartifactoryha-operator",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "OpenshiftArtifactoryHa",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:29dad888f9b74b2c19f221aa6634c94dcd2144237dc039157056a77cbb0c74a4",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:29dad888f9b74b2c19f221aa6634c94dcd2144237dc039157056a77cbb0c74a4",
          "name": "artifactory-operator-29dad888f9b74b2c19f221aa6634c94dcd2144237dc039157056a77cbb0c74a4-annotation"
        },
        {
          "digest": "sha256:29dad888f9b74b2c19f221aa6634c94dcd2144237dc039157056a77cbb0c74a4",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:29dad888f9b74b2c19f221aa6634c94dcd2144237dc039157056a77cbb0c74a4",
          "name": "artifactory-ha-operator"
        },
        {
          "digest": "sha256:7289dde95d1e4d8e161a28cffd9c4a0cc96f92f7536d069ab63ec304a92254fd",
          "image": "registry.connect.redhat.com/jfrog/artifactory-pro@sha256:7289dde95d1e4d8e161a28cffd9c4a0cc96f92f7536d069ab63ec304a92254fd",
          "name": "artifactory_image_repository"
        },
        {
          "digest": "sha256:d71d368d6094a5777000a8d99164959ccb97fca355e855e24bd92c13a8df04f6",
          "image": "registry.redhat.io/rhel8/nginx-116@sha256:d71d368d6094a5777000a8d99164959ccb97fca355e855e24bd92c13a8df04f6",
          "name": "nginx_image_repository"
        },
        {
          "digest": "sha256:164b41720a37f75c6129c8a28d05cc56f821022313d44ff918cce4a2146d93e8",
          "image": "registry.connect.redhat.com/jfrog/init@sha256:164b41720a37f75c6129c8a28d05cc56f821022313d44ff918cce4a2146d93e8",
          "name": "init-164b41720a37f75c6129c8a28d05cc56f821022313d44ff918cce4a2146d93e8-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.1.20",
      "version_original": "1.1.20"
    },
    {
      "_id": "62345fdc5593ce895a7b535c",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1alpha1",
          "kind": "OpenshiftArtifactoryHa",
          "metadata": {
            "name": "openshiftartifactoryha"
          },
          "spec": {
            "artifactory-ha": {
              "artifactory": {
                "image": {
                  "registry": "registry.connect.redhat.com",
                  "repository": "jfrog/artifactory-pro",
                  "tag": "7.25.7-2"
                },
                "joinKey": "OVERRIDE",
                "masterKey": "OVERRIDE",
                "node": {
                  "replicaCount": 2,
                  "waitForPrimaryStartup": {
                    "enabled": false
                  }
                },
                "uid": "1000721030"
              },
              "database": {
                "driver": "OVERRIDE",
                "password": "OVERRIDE",
                "type": "OVERRIDE",
                "url": "OVERRIDE",
                "user": "OVERRIDE"
              },
              "databaseUpgradeReady": true,
              "initContainerImage": "registry.connect.redhat.com/jfrog/init@sha256:175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03",
              "nginx": {
                "gid": "1000720107",
                "http": {
                  "externalPort": 80,
                  "internalPort": 8080
                },
                "https": {
                  "externalPort": 443,
                  "internalPort": 8443
                },
                "image": {
                  "registry": "registry.redhat.io",
                  "repository": "rhel8/nginx-116",
                  "tag": "latest"
                },
                "service": {
                  "ssloffload": false
                },
                "tlsSecretName": "OVERRIDE",
                "uid": "1000720104"
              },
              "postgresql": {
                "enabled": false
              },
              "waitForDatabase": true
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/jfrog/artifactory-operator-bundle@sha256:49229329083f8836be365b25beda86290cf8c6985dbeb1c46991c2121b54dda9",
      "bundle_path_digest": "sha256:49229329083f8836be365b25beda86290cf8c6985dbeb1c46991c2121b54dda9",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:33:00.267000+00:00",
      "csv_description": " ## Breaking change\nPlease update to version 1.1.10 of the operator.\nVersion 1.1.8 and 1.1.9 have issues. Please skip these versions.\n\n## Overview\nOpenshift Operator to deploy JFrog Artifactory Enterprise into your Openshift cluster.\n## Security Context Constraints\nTo deploy this helm chart you will need to be a cluster admin w/ access to the anyuid scc and add the operator service account to the anyuid scc.\n```\noc adm policy add-scc-to-user anyuid -z artifactory-ha-operator -n openshift-operators\n```\nAdd the service account for the Artifactory chart to deploy successfully:\n``` oc adm policy add-scc-to-user anyuid -z openshiftartifactoryha-artifactory-ha -n artifactory ```\n### Usage\n\nAn external DB is required. The operator will not deploy a DB but will require you to specify the configuration values to connect to it.\n\nSearch for JFrog and click JFrog Artifactory Enterprise Operator to install.\n\nGo to the Installed Operators.\n\nWait for the JFrog Artifactory Enterprise Operator to complete the installation.\n\nOpen the Operator and click on the provided API: Artifactory HA.\n\nClick Create New Instance and provide the following parameters for your DB configuration:\n\n```\nDATABASE_TYPE\nDATABASE_DRIVER\nDATABASE_URL\nDATABASE_USER\nDATABASE_PASSWORD\n```\nMaster key and Join key must be supplied. To generate a new key for each run the command below:\n\n```\n# Create a key\nexport JOIN_KEY=$(openssl rand -hex 32)\necho ${JOIN_KEY}\n```\n\nTo use TLS you will need to first create a k8s tls secret to store your .crt and .key file into.\nThen supply the value of this k8s secret into the TLS_SECRET field.\n``` oc create secret tls my_tls_secret --cert=tls.crt --key=tls.key --namespace=my_namespace ```\nClick Create for Artifactory Enterprise to deploy into OpenShift and connect to it on the external IP exposed by the load balancer.\n### Create a route\nTo expose Artifactory from Openshift we recommend you create a new route in Openshift.\nYou can either use the oc command line tool or the Openshift web console to generate a new route.\nDepending upon where you terminate TLS you will need to either specify pass through or edge.\nCommand Line (Edge):\n``` oc create route edge --service=openshiftartifactory-ha --cert=tls.crt --key=tls.key --ca-cert=ca.crt --hostname=www.example.com ```\nOr for more information visit the official Openshift documentation on routes here:\nhttps://docs.openshift.com/container-platform/4.6/networking/routes/route-configuration.html\n\n",
      "csv_display_name": "JFrog Artifactory Enterprise Operator",
      "csv_metadata_description": "JFrog Artifactory Enterprise deploys Artifactory in a high availability environment across multiple pods",
      "csv_name": "artifactory-ha-operator.v1.1.14",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-06-17T01:33:53.775000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "openshiftartifactoryha-operator",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "OpenshiftArtifactoryHa",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "name": "artifactory-operator-9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4-annotation"
        },
        {
          "digest": "sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "name": "artifactory-ha-operator"
        },
        {
          "digest": "sha256:abd96a07bbeffcdcdf69b5998b9256b684e72bcecb9b94b9a623a0c02b276322",
          "image": "registry.connect.redhat.com/jfrog/artifactory-pro@sha256:abd96a07bbeffcdcdf69b5998b9256b684e72bcecb9b94b9a623a0c02b276322",
          "name": "artifactory_image_repository"
        },
        {
          "digest": "sha256:225b9d8cac2b4d3a1d193782f4bba749194048b87bf31dcd12ea88422e6350c8",
          "image": "registry.redhat.io/rhel8/nginx-116@sha256:225b9d8cac2b4d3a1d193782f4bba749194048b87bf31dcd12ea88422e6350c8",
          "name": "nginx_image_repository"
        },
        {
          "digest": "sha256:175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03",
          "image": "registry.connect.redhat.com/jfrog/init@sha256:175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03",
          "name": "init-175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.1.14",
      "version_original": "1.1.14"
    },
    {
      "_id": "62345fdf06c5dada0193e07d",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "OpenshiftArtifactoryHa",
          "metadata": {
            "name": "openshiftartifactoryha"
          },
          "spec": {
            "artifactory-ha": {
              "artifactory": {
                "image": {
                  "registry": "registry.connect.redhat.com",
                  "repository": "jfrog/artifactory-pro",
                  "tag": "7.27.3-1"
                },
                "joinKey": "OVERRIDE",
                "masterKey": "OVERRIDE",
                "node": {
                  "replicaCount": 2,
                  "waitForPrimaryStartup": {
                    "enabled": false
                  }
                },
                "uid": "1000721030"
              },
              "database": {
                "driver": "OVERRIDE",
                "password": "OVERRIDE",
                "type": "OVERRIDE",
                "url": "OVERRIDE",
                "user": "OVERRIDE"
              },
              "databaseUpgradeReady": true,
              "initContainerImage": "registry.connect.redhat.com/jfrog/init@sha256:164b41720a37f75c6129c8a28d05cc56f821022313d44ff918cce4a2146d93e8",
              "nginx": {
                "gid": "1000720107",
                "http": {
                  "externalPort": 80,
                  "internalPort": 8080
                },
                "https": {
                  "externalPort": 443,
                  "internalPort": 8443
                },
                "image": {
                  "registry": "registry.redhat.io",
                  "repository": "rhel8/nginx-116",
                  "tag": "latest"
                },
                "service": {
                  "ssloffload": false
                },
                "tlsSecretName": "OVERRIDE",
                "uid": "1000720104"
              },
              "postgresql": {
                "enabled": false
              },
              "waitForDatabase": true
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/jfrog/artifactory-operator-bundle@sha256:fc374491270b9566b0a5c80f3dd665b2227b1e8fb224eada7e5c98c82926ae08",
      "bundle_path_digest": "sha256:fc374491270b9566b0a5c80f3dd665b2227b1e8fb224eada7e5c98c82926ae08",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:33:03.477000+00:00",
      "csv_description": " ## Breaking change\nPlease update to version 1.1.10 of the operator.\nVersion 1.1.8 and 1.1.9 have issues. Please skip these versions.\n\n## Overview\nOpenshift Operator to deploy JFrog Artifactory Enterprise into your Openshift cluster.\n## Security Context Constraints\nTo deploy this helm chart you will need to be a cluster admin w/ access to the anyuid scc and add the operator service account to the anyuid scc.\n```\noc adm policy add-scc-to-user anyuid -z artifactory-ha-operator -n openshift-operators\n```\nAdd the service account for the Artifactory chart to deploy successfully:\n``` oc adm policy add-scc-to-user anyuid -z openshiftartifactoryha-artifactory-ha -n artifactory ```\n### Usage\n\nAn external DB is required. The operator will not deploy a DB but will require you to specify the configuration values to connect to it.\n\nSearch for JFrog and click JFrog Artifactory Enterprise Operator to install.\n\nGo to the Installed Operators.\n\nWait for the JFrog Artifactory Enterprise Operator to complete the installation.\n\nOpen the Operator and click on the provided API: Artifactory HA.\n\nClick Create New Instance and provide the following parameters for your DB configuration:\n\n```\nDATABASE_TYPE\nDATABASE_DRIVER\nDATABASE_URL\nDATABASE_USER\nDATABASE_PASSWORD\n```\nMaster key and Join key must be supplied. To generate a new key for each run the command below:\n\n```\n# Create a key\nexport JOIN_KEY=$(openssl rand -hex 32)\necho ${JOIN_KEY}\n```\n\nTo use TLS you will need to first create a k8s tls secret to store your .crt and .key file into.\nThen supply the value of this k8s secret into the TLS_SECRET field.\n``` oc create secret tls my_tls_secret --cert=tls.crt --key=tls.key --namespace=my_namespace ```\nClick Create for Artifactory Enterprise to deploy into OpenShift and connect to it on the external IP exposed by the load balancer.\n### Create a route\nTo expose Artifactory from Openshift we recommend you create a new route in Openshift.\nYou can either use the oc command line tool or the Openshift web console to generate a new route.\nDepending upon where you terminate TLS you will need to either specify pass through or edge.\nCommand Line (Edge):\n``` oc create route edge --service=openshiftartifactory-ha --cert=tls.crt --key=tls.key --ca-cert=ca.crt --hostname=www.example.com ```\nOr for more information visit the official Openshift documentation on routes here:\nhttps://docs.openshift.com/container-platform/4.6/networking/routes/route-configuration.html\n\n",
      "csv_display_name": "JFrog Artifactory Enterprise Operator",
      "csv_metadata_description": "JFrog Artifactory Enterprise deploys Artifactory in a high availability environment across multiple pods",
      "csv_name": "artifactory-ha-operator.v1.1.18",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-06-17T01:33:58.775000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "openshiftartifactoryha-operator",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "OpenshiftArtifactoryHa",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:e292553e1b6e792ff19276c7f6565d7ed61dd95289eb176066329954bc93e371",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:e292553e1b6e792ff19276c7f6565d7ed61dd95289eb176066329954bc93e371",
          "name": "artifactory-operator-e292553e1b6e792ff19276c7f6565d7ed61dd95289eb176066329954bc93e371-annotation"
        },
        {
          "digest": "sha256:e292553e1b6e792ff19276c7f6565d7ed61dd95289eb176066329954bc93e371",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:e292553e1b6e792ff19276c7f6565d7ed61dd95289eb176066329954bc93e371",
          "name": "artifactory-ha-operator"
        },
        {
          "digest": "sha256:7289dde95d1e4d8e161a28cffd9c4a0cc96f92f7536d069ab63ec304a92254fd",
          "image": "registry.connect.redhat.com/jfrog/artifactory-pro@sha256:7289dde95d1e4d8e161a28cffd9c4a0cc96f92f7536d069ab63ec304a92254fd",
          "name": "artifactory_image_repository"
        },
        {
          "digest": "sha256:d71d368d6094a5777000a8d99164959ccb97fca355e855e24bd92c13a8df04f6",
          "image": "registry.redhat.io/rhel8/nginx-116@sha256:d71d368d6094a5777000a8d99164959ccb97fca355e855e24bd92c13a8df04f6",
          "name": "nginx_image_repository"
        },
        {
          "digest": "sha256:164b41720a37f75c6129c8a28d05cc56f821022313d44ff918cce4a2146d93e8",
          "image": "registry.connect.redhat.com/jfrog/init@sha256:164b41720a37f75c6129c8a28d05cc56f821022313d44ff918cce4a2146d93e8",
          "name": "init-164b41720a37f75c6129c8a28d05cc56f821022313d44ff918cce4a2146d93e8-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.1.18",
      "version_original": "1.1.18"
    },
    {
      "_id": "62345fe1670f4cadbafad2a9",
      "alm_examples": [
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageCluster",
          "metadata": {
            "annotations": {
              "portworx.io/is-openshift": "true"
            },
            "name": "portworx",
            "namespace": "test-operator"
          },
          "spec": {}
        },
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageNode",
          "metadata": {
            "name": "example",
            "namespace": "test-operator"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/portworx/portworx-certified-bundle@sha256:45853a8612cc9da123094499ac975eb2bc943346a0092fe9d892c5942170e77f",
      "bundle_path_digest": "sha256:45853a8612cc9da123094499ac975eb2bc943346a0092fe9d892c5942170e77f",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-03-18T10:33:05.381000+00:00",
      "csv_description": "Portworx-Enterprise is the most widely-used and reliable cloud-native\nstorage solution for production workloads and provides high-availability,\ndata protection and security for containerized applications.\n\nPortworx Enterprise enables you to migrate entire applications, including\ndata, between clusters in a single data center or cloud, or between clouds,\nwith a single kubectl command.\n\nThe cloud native storage and data management platform that enterprises trust\nto manage data in containers now has an operator which simplifies the install,\nconfiguration, upgrades and manages the Portworx Enterprise cluster lifecycle.\n\nLearn more about the Portworx Enterprise\n[the data platform for Kubernetes](https://portworx.com/products/introduction)\n\nTo learn more about the platform features, please visit our\n[product features page](https://portworx.com/products/features)\n\n### About Portworx\n\nPortworx is the solution for running stateful containers in production,\ndesigned with DevOps in mind. With Portworx, users can manage any database\nor stateful service on any infrastructure using any container scheduler,\nincluding Kubernetes, Mesosphere DC/OS, and Docker Swarm. Portworx solves\nthe five most common problems DevOps teams encounter when running stateful\nservices in production: persistence, high availability, data automation,\nsecurity, and support for multiple data stores and infrastructure.\n\n### How to install StorageCluster\n\nTo customize your cluster's configuration (specification), use the\n[Spec Generator](https://central.portworx.com/) from PX-Central.\n\n### Prerequisite\n\nEnsure ports 17001-17020 on worker nodes are reachable from master and other worker nodes.\n\n### Tutorials\n\n* [Portworx Enterprise on Openshift](https://portworx.com/openshift)\n\n* [Stateful applications on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes/application-install-with-kubernetes)\n\n* [Portworx Enterprise on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes)\n\n* [Kafka on Kubernetes](https://portworx.com/kafka-kubernetes)\n\n* [Elastisearch on Kubernetes](https://portworx.com/elasticsearch-kubernetes)\n\n* [PostgreSQL on Kubernetes](https://portworx.com/postgres-kubernetes/)\n\n* [MongoDB on Kubernetes](https://portworx.com/mongodb-kubernetes/)\n\n* [Cassandra on Kubernetes](https://portworx.com/cassandra-kubernetes/)\n\n* [Kubernetes backup and recovery](https://portworx.com/kubernetes-backup/)\n\n* [Disaster Recovery for Kubernetes](https://portworx.com/kubernetes-disaster-recovery/)\n\n### Uninstall\n\nDeleting the StorageCluster object for Portworx cluster does not stop Portworx\nservice running on the nodes, to avoid application downtime.\n\nTo uninstall Portworx completely without wiping the data, you should add the\nfollowing delete strategy to the StorageCluster spec:\n```\nspec:\n  deleteStrategy:\n    type: Uninstall\n```\n**Caution:** To uninstall Portworx and **wipe all the data**, you should use the following\ndelete strategy:\n```\nspec:\n  deleteStrategy:\n    type: UninstallAndWipe\n```\n",
      "csv_display_name": "Portworx Enterprise",
      "csv_metadata_description": "Cloud native storage solution for production workloads",
      "csv_name": "portworx-operator.v1.6.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-06-17T01:36:30.776000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "portworx-certified",
      "provided_apis": [
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1alpha1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47",
          "name": "openstorage-operator-5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47-annotation"
        },
        {
          "digest": "sha256:5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47",
          "name": "portworx-operator"
        }
      ],
      "replaces": "",
      "skip_range": "<1.6.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.6.1",
      "version_original": "1.6.1"
    },
    {
      "_id": "62345fe306c5dada0193e07e",
      "alm_examples": [
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageCluster",
          "metadata": {
            "annotations": {
              "portworx.io/is-openshift": "true"
            },
            "name": "portworx",
            "namespace": "test-operator"
          },
          "spec": {}
        },
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageNode",
          "metadata": {
            "name": "example",
            "namespace": "test-operator"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/portworx/portworx-certified-bundle@sha256:6b840a6631b9f345d9a66dc3b57568d2528d08dd78fdd0f5c027bdb49c97a3bd",
      "bundle_path_digest": "sha256:6b840a6631b9f345d9a66dc3b57568d2528d08dd78fdd0f5c027bdb49c97a3bd",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-03-18T10:33:07.614000+00:00",
      "csv_description": "Portworx-Enterprise is the most widely-used and reliable cloud-native\nstorage solution for production workloads and provides high-availability,\ndata protection and security for containerized applications.\n\nPortworx Enterprise enables you to migrate entire applications, including\ndata, between clusters in a single data center or cloud, or between clouds,\nwith a single kubectl command.\n\nThe cloud native storage and data management platform that enterprises trust\nto manage data in containers now has an operator which simplifies the install,\nconfiguration, upgrades and manages the Portworx Enterprise cluster lifecycle.\n\nLearn more about the Portworx Enterprise\n[the data platform for Kubernetes](https://portworx.com/products/introduction)\n\nTo learn more about the platform features, please visit our\n[product features page](https://portworx.com/products/features)\n\n### About Portworx\n\nPortworx is the solution for running stateful containers in production,\ndesigned with DevOps in mind. With Portworx, users can manage any database\nor stateful service on any infrastructure using any container scheduler,\nincluding Kubernetes, Mesosphere DC/OS, and Docker Swarm. Portworx solves\nthe five most common problems DevOps teams encounter when running stateful\nservices in production: persistence, high availability, data automation,\nsecurity, and support for multiple data stores and infrastructure.\n\n### How to install StorageCluster\n\nTo customize your cluster's configuration (specification), use the\n[Spec Generator](https://central.portworx.com/) from PX-Central.\n\n### Prerequisite\n\nEnsure ports 17001-17020 on worker nodes are reachable from master and other worker nodes.\n\n### Tutorials\n\n* [Portworx Enterprise on Openshift](https://portworx.com/openshift)\n\n* [Stateful applications on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes/application-install-with-kubernetes)\n\n* [Portworx Enterprise on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes)\n\n* [Kafka on Kubernetes](https://portworx.com/kafka-kubernetes)\n\n* [Elastisearch on Kubernetes](https://portworx.com/elasticsearch-kubernetes)\n\n* [PostgreSQL on Kubernetes](https://portworx.com/postgres-kubernetes/)\n\n* [MongoDB on Kubernetes](https://portworx.com/mongodb-kubernetes/)\n\n* [Cassandra on Kubernetes](https://portworx.com/cassandra-kubernetes/)\n\n* [Kubernetes backup and recovery](https://portworx.com/kubernetes-backup/)\n\n* [Disaster Recovery for Kubernetes](https://portworx.com/kubernetes-disaster-recovery/)\n\n### Uninstall\n\nDeleting the StorageCluster object for Portworx cluster does not stop Portworx\nservice running on the nodes, to avoid application downtime.\n\nTo uninstall Portworx completely without wiping the data, you should add the\nfollowing delete strategy to the StorageCluster spec:\n```\nspec:\n  deleteStrategy:\n    type: Uninstall\n```\n**Caution:** To uninstall Portworx and **wipe all the data**, you should use the following\ndelete strategy:\n```\nspec:\n  deleteStrategy:\n    type: UninstallAndWipe\n```\n",
      "csv_display_name": "Portworx Enterprise",
      "csv_metadata_description": "Cloud native storage solution for production workloads",
      "csv_name": "portworx-operator.v1.7.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-06-17T01:36:35.493000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "portworx-certified",
      "provided_apis": [
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1alpha1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:c4ba573632798d9d78b069a0e396e434e5209abaa4ad82be106c12ad91bb162c",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:c4ba573632798d9d78b069a0e396e434e5209abaa4ad82be106c12ad91bb162c",
          "name": "openstorage-operator-c4ba573632798d9d78b069a0e396e434e5209abaa4ad82be106c12ad91bb162c-annotation"
        },
        {
          "digest": "sha256:c4ba573632798d9d78b069a0e396e434e5209abaa4ad82be106c12ad91bb162c",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:c4ba573632798d9d78b069a0e396e434e5209abaa4ad82be106c12ad91bb162c",
          "name": "portworx-operator"
        }
      ],
      "replaces": "",
      "skip_range": "=1.7.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.7.1",
      "version_original": "1.7.1"
    },
    {
      "_id": "62345fe506c5dada0193e07f",
      "alm_examples": [
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageCluster",
          "metadata": {
            "annotations": {
              "portworx.io/is-openshift": "true"
            },
            "name": "portworx",
            "namespace": "test-operator"
          },
          "spec": {}
        },
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageNode",
          "metadata": {
            "name": "example",
            "namespace": "test-operator"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/portworx/portworx-certified-bundle@sha256:45853a8612cc9da123094499ac975eb2bc943346a0092fe9d892c5942170e77f",
      "bundle_path_digest": "sha256:45853a8612cc9da123094499ac975eb2bc943346a0092fe9d892c5942170e77f",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:33:09.375000+00:00",
      "csv_description": "Portworx-Enterprise is the most widely-used and reliable cloud-native\nstorage solution for production workloads and provides high-availability,\ndata protection and security for containerized applications.\n\nPortworx Enterprise enables you to migrate entire applications, including\ndata, between clusters in a single data center or cloud, or between clouds,\nwith a single kubectl command.\n\nThe cloud native storage and data management platform that enterprises trust\nto manage data in containers now has an operator which simplifies the install,\nconfiguration, upgrades and manages the Portworx Enterprise cluster lifecycle.\n\nLearn more about the Portworx Enterprise\n[the data platform for Kubernetes](https://portworx.com/products/introduction)\n\nTo learn more about the platform features, please visit our\n[product features page](https://portworx.com/products/features)\n\n### About Portworx\n\nPortworx is the solution for running stateful containers in production,\ndesigned with DevOps in mind. With Portworx, users can manage any database\nor stateful service on any infrastructure using any container scheduler,\nincluding Kubernetes, Mesosphere DC/OS, and Docker Swarm. Portworx solves\nthe five most common problems DevOps teams encounter when running stateful\nservices in production: persistence, high availability, data automation,\nsecurity, and support for multiple data stores and infrastructure.\n\n### How to install StorageCluster\n\nTo customize your cluster's configuration (specification), use the\n[Spec Generator](https://central.portworx.com/) from PX-Central.\n\n### Prerequisite\n\nEnsure ports 17001-17020 on worker nodes are reachable from master and other worker nodes.\n\n### Tutorials\n\n* [Portworx Enterprise on Openshift](https://portworx.com/openshift)\n\n* [Stateful applications on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes/application-install-with-kubernetes)\n\n* [Portworx Enterprise on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes)\n\n* [Kafka on Kubernetes](https://portworx.com/kafka-kubernetes)\n\n* [Elastisearch on Kubernetes](https://portworx.com/elasticsearch-kubernetes)\n\n* [PostgreSQL on Kubernetes](https://portworx.com/postgres-kubernetes/)\n\n* [MongoDB on Kubernetes](https://portworx.com/mongodb-kubernetes/)\n\n* [Cassandra on Kubernetes](https://portworx.com/cassandra-kubernetes/)\n\n* [Kubernetes backup and recovery](https://portworx.com/kubernetes-backup/)\n\n* [Disaster Recovery for Kubernetes](https://portworx.com/kubernetes-disaster-recovery/)\n\n### Uninstall\n\nDeleting the StorageCluster object for Portworx cluster does not stop Portworx\nservice running on the nodes, to avoid application downtime.\n\nTo uninstall Portworx completely without wiping the data, you should add the\nfollowing delete strategy to the StorageCluster spec:\n```\nspec:\n  deleteStrategy:\n    type: Uninstall\n```\n**Caution:** To uninstall Portworx and **wipe all the data**, you should use the following\ndelete strategy:\n```\nspec:\n  deleteStrategy:\n    type: UninstallAndWipe\n```\n",
      "csv_display_name": "Portworx Enterprise",
      "csv_metadata_description": "Cloud native storage solution for production workloads",
      "csv_name": "portworx-operator.v1.6.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:36:50.095000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "portworx-certified",
      "provided_apis": [
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1alpha1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47",
          "name": "openstorage-operator-5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47-annotation"
        },
        {
          "digest": "sha256:5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47",
          "name": "portworx-operator"
        }
      ],
      "replaces": "",
      "skip_range": "<1.6.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.6.1",
      "version_original": "1.6.1"
    },
    {
      "_id": "62345fe706c5dada0193e080",
      "alm_examples": [
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageCluster",
          "metadata": {
            "annotations": {
              "portworx.io/is-openshift": "true"
            },
            "name": "portworx",
            "namespace": "test-operator"
          },
          "spec": {}
        },
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageNode",
          "metadata": {
            "name": "example",
            "namespace": "test-operator"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/portworx/portworx-certified-bundle@sha256:6b840a6631b9f345d9a66dc3b57568d2528d08dd78fdd0f5c027bdb49c97a3bd",
      "bundle_path_digest": "sha256:6b840a6631b9f345d9a66dc3b57568d2528d08dd78fdd0f5c027bdb49c97a3bd",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:33:11.103000+00:00",
      "csv_description": "Portworx-Enterprise is the most widely-used and reliable cloud-native\nstorage solution for production workloads and provides high-availability,\ndata protection and security for containerized applications.\n\nPortworx Enterprise enables you to migrate entire applications, including\ndata, between clusters in a single data center or cloud, or between clouds,\nwith a single kubectl command.\n\nThe cloud native storage and data management platform that enterprises trust\nto manage data in containers now has an operator which simplifies the install,\nconfiguration, upgrades and manages the Portworx Enterprise cluster lifecycle.\n\nLearn more about the Portworx Enterprise\n[the data platform for Kubernetes](https://portworx.com/products/introduction)\n\nTo learn more about the platform features, please visit our\n[product features page](https://portworx.com/products/features)\n\n### About Portworx\n\nPortworx is the solution for running stateful containers in production,\ndesigned with DevOps in mind. With Portworx, users can manage any database\nor stateful service on any infrastructure using any container scheduler,\nincluding Kubernetes, Mesosphere DC/OS, and Docker Swarm. Portworx solves\nthe five most common problems DevOps teams encounter when running stateful\nservices in production: persistence, high availability, data automation,\nsecurity, and support for multiple data stores and infrastructure.\n\n### How to install StorageCluster\n\nTo customize your cluster's configuration (specification), use the\n[Spec Generator](https://central.portworx.com/) from PX-Central.\n\n### Prerequisite\n\nEnsure ports 17001-17020 on worker nodes are reachable from master and other worker nodes.\n\n### Tutorials\n\n* [Portworx Enterprise on Openshift](https://portworx.com/openshift)\n\n* [Stateful applications on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes/application-install-with-kubernetes)\n\n* [Portworx Enterprise on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes)\n\n* [Kafka on Kubernetes](https://portworx.com/kafka-kubernetes)\n\n* [Elastisearch on Kubernetes](https://portworx.com/elasticsearch-kubernetes)\n\n* [PostgreSQL on Kubernetes](https://portworx.com/postgres-kubernetes/)\n\n* [MongoDB on Kubernetes](https://portworx.com/mongodb-kubernetes/)\n\n* [Cassandra on Kubernetes](https://portworx.com/cassandra-kubernetes/)\n\n* [Kubernetes backup and recovery](https://portworx.com/kubernetes-backup/)\n\n* [Disaster Recovery for Kubernetes](https://portworx.com/kubernetes-disaster-recovery/)\n\n### Uninstall\n\nDeleting the StorageCluster object for Portworx cluster does not stop Portworx\nservice running on the nodes, to avoid application downtime.\n\nTo uninstall Portworx completely without wiping the data, you should add the\nfollowing delete strategy to the StorageCluster spec:\n```\nspec:\n  deleteStrategy:\n    type: Uninstall\n```\n**Caution:** To uninstall Portworx and **wipe all the data**, you should use the following\ndelete strategy:\n```\nspec:\n  deleteStrategy:\n    type: UninstallAndWipe\n```\n",
      "csv_display_name": "Portworx Enterprise",
      "csv_metadata_description": "Cloud native storage solution for production workloads",
      "csv_name": "portworx-operator.v1.7.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:36:40.432000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "portworx-certified",
      "provided_apis": [
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1alpha1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:c4ba573632798d9d78b069a0e396e434e5209abaa4ad82be106c12ad91bb162c",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:c4ba573632798d9d78b069a0e396e434e5209abaa4ad82be106c12ad91bb162c",
          "name": "openstorage-operator-c4ba573632798d9d78b069a0e396e434e5209abaa4ad82be106c12ad91bb162c-annotation"
        },
        {
          "digest": "sha256:c4ba573632798d9d78b069a0e396e434e5209abaa4ad82be106c12ad91bb162c",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:c4ba573632798d9d78b069a0e396e434e5209abaa4ad82be106c12ad91bb162c",
          "name": "portworx-operator"
        }
      ],
      "replaces": "",
      "skip_range": "=1.7.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.7.1",
      "version_original": "1.7.1"
    },
    {
      "_id": "62345fe85593ce895a7b535d",
      "alm_examples": [
        {
          "api_version": "citrix.com/v1alpha1",
          "kind": "CitrixCpxWithIngressController",
          "metadata": {
            "name": "cpx-cic"
          },
          "spec": {
            "ADMSettings": {
              "ADMIP": "",
              "bandWidth": "",
              "bandWidthLicense": false,
              "cpxCores": "",
              "licenseServerIP": "",
              "licenseServerPort": 27000,
              "loginSecret": "",
              "vCPULicense": false
            },
            "bgpSettings": {
              "bgpConfig": [
                {
                  "bgpRouter": {
                    "localAS": 100,
                    "neighbor": [
                      {
                        "ASOriginationInterval": 10,
                        "address": "",
                        "advertisementInterval": 10,
                        "remoteAS": 100
                      }
                    ]
                  }
                }
              ],
              "required": false
            },
            "cic": {
              "image": "registry.connect.redhat.com/citrix/citrix-ingress-controller@sha256:91e7f337aab58db503e218ba3ac6b9f73173772314f57fc234ea340576426821",
              "pullPolicy": "Always",
              "required": true
            },
            "coeConfig": {
              "distributedTracing": {
                "enable": false,
                "samplingrate": 100
              },
              "endpoint": {
                "server": ""
              },
              "required": false,
              "timeseries": {
                "auditlogs": {
                  "enable": false
                },
                "events": {
                  "enable": false
                },
                "metrics": {
                  "enable": false,
                  "mode": "avro"
                },
                "port": 5563
              },
              "transactions": {
                "enable": false,
                "port": 5557
              }
            },
            "cpxBgpRouter": false,
            "crds": {
              "install": false,
              "retainOnDelete": false
            },
            "defaultSSLCertSecret": "",
            "entityPrefix": "",
            "exporter": {
              "image": "registry.connect.redhat.com/citrix/citrix-adc-metrics-exporter@sha256:6ce388d8f6324713b2db96385311d1e7a06c41dc54353c4ed81e6cf3dfdfb4b8",
              "ports": {
                "containerPort": 8888
              },
              "pullPolicy": "Always",
              "required": false
            },
            "image": "quay.io/citrix/citrix-k8s-cpx-ingress@sha256:8f28c8af17909f0c0ced2109701755be1edea22b2a80f00aa37da70168abe1dc",
            "imagePullSecrets": [],
            "ingressClass": [],
            "ingressIP": "",
            "ipam": false,
            "kubernetesURL": "",
            "license": {
              "accept": "no"
            },
            "logLevel": "INFO",
            "logProxy": "",
            "mgmtHttpPort": 9080,
            "mgmtHttpsPort": 9443,
            "namespaceLabels": "",
            "nodeSelector": {
              "key": "",
              "value": ""
            },
            "nsCookieVersion": "0",
            "nsGateway": "192.168.1.1",
            "nsHTTP2ServerSide": "OFF",
            "nsIP": "192.168.1.2",
            "nsProtocol": "http",
            "openshift": true,
            "pullPolicy": "Always",
            "routeLabels": "",
            "serviceAccount": {
              "create": true
            },
            "serviceAnnotations": {},
            "servicePorts": [],
            "serviceSpec": {
              "loadBalancerSourceRanges": []
            },
            "serviceType": {
              "loadBalancer": {
                "enabled": false,
                "externalTrafficPolicy": "Local"
              },
              "nodePort": {
                "enabled": false,
                "httpPort": "",
                "httpsPort": ""
              }
            },
            "setAsDefaultIngressClass": false,
            "sslCertManagedByAWS": false,
            "tolerations": [],
            "updateIngressStatus": false
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/citrix/citrix-k8s-cpx-ingress-bundle@sha256:cb78fbaa6e154066b70b1e36731fc268bd61b514493f1541f630fff7f7e16d59",
      "bundle_path_digest": "sha256:cb78fbaa6e154066b70b1e36731fc268bd61b514493f1541f630fff7f7e16d59",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-03-18T10:33:12.488000+00:00",
      "csv_description": "Citrix ADC CPX is a container-based application delivery controller that can be provisioned on a Docker host. Citrix ADC CPX enables customers to leverage Docker engine capabilities and use NetScaler load balancing and traffic management features for container-based applications. Citrix Ingress Controller which will be running in side-car mode with Citrix ADC CPX will automatically configures Citrix ADC CPX based on the Ingress resource configuration. This operator can be used deploy Citrix ADC CPX with Citrix ingress controller in an OpenShift environment.",
      "csv_display_name": "Citrix ADC CPX with Ingress Controller",
      "csv_metadata_description": "Citrix ADC CPX is a container-based application delivery controller that can be provisioned on a Docker host. Citrix ADC CPX enables customers to leverage Docker engine capabilities and use NetScaler load balancing and traffic management features for container-based applications. Citrix Ingress Controller which will be running in side-car mode with Citrix ADC CPX will automatically configures Citrix ADC CPX based on the Ingress resource configuration. This operator can be used deploy Citrix ADC CPX with Citrix ingress controller in an Openshift environment.",
      "csv_name": "citrix-cpx-with-ingress-controller-operator.v1.18.5",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:34:04.156000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "citrix-cpx-with-ingress-controller-operator",
      "provided_apis": [
        {
          "group": "citrix.com",
          "kind": "CitrixCpxWithIngressController",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:92677d3e130f52490b52729a192b61ea5a03bd8eefd29f4ffe0222abfe2f9a1d",
          "image": "registry.connect.redhat.com/citrix/citrix-k8s-cpx-ingress-controller@sha256:92677d3e130f52490b52729a192b61ea5a03bd8eefd29f4ffe0222abfe2f9a1d",
          "name": "citrix-k8s-cpx-ingress-controller-92677d3e130f52490b52729a192b61ea5a03bd8eefd29f4ffe0222abfe2f9a1d-annotation"
        },
        {
          "digest": "sha256:71527b0033776ac8a68e9c52937cbdac5909a56058105bcb6489c4a0cb9e4f4d",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:71527b0033776ac8a68e9c52937cbdac5909a56058105bcb6489c4a0cb9e4f4d",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:92677d3e130f52490b52729a192b61ea5a03bd8eefd29f4ffe0222abfe2f9a1d",
          "image": "registry.connect.redhat.com/citrix/citrix-k8s-cpx-ingress-controller@sha256:92677d3e130f52490b52729a192b61ea5a03bd8eefd29f4ffe0222abfe2f9a1d",
          "name": "manager"
        },
        {
          "digest": "sha256:8f28c8af17909f0c0ced2109701755be1edea22b2a80f00aa37da70168abe1dc",
          "image": "quay.io/citrix/citrix-k8s-cpx-ingress@sha256:8f28c8af17909f0c0ced2109701755be1edea22b2a80f00aa37da70168abe1dc",
          "name": "cpx"
        },
        {
          "digest": "sha256:91e7f337aab58db503e218ba3ac6b9f73173772314f57fc234ea340576426821",
          "image": "registry.connect.redhat.com/citrix/citrix-ingress-controller@sha256:91e7f337aab58db503e218ba3ac6b9f73173772314f57fc234ea340576426821",
          "name": "cic"
        },
        {
          "digest": "sha256:6ce388d8f6324713b2db96385311d1e7a06c41dc54353c4ed81e6cf3dfdfb4b8",
          "image": "registry.connect.redhat.com/citrix/citrix-adc-metrics-exporter@sha256:6ce388d8f6324713b2db96385311d1e7a06c41dc54353c4ed81e6cf3dfdfb4b8",
          "name": "exporter"
        },
        {
          "digest": "sha256:8f28c8af17909f0c0ced2109701755be1edea22b2a80f00aa37da70168abe1dc",
          "image": "quay.io/citrix/citrix-k8s-cpx-ingress@sha256:8f28c8af17909f0c0ced2109701755be1edea22b2a80f00aa37da70168abe1dc",
          "name": "citrix-k8s-cpx-ingress-8f28c8af17909f0c0ced2109701755be1edea22b2a80f00aa37da70168abe1dc-annotation"
        },
        {
          "digest": "sha256:6ce388d8f6324713b2db96385311d1e7a06c41dc54353c4ed81e6cf3dfdfb4b8",
          "image": "registry.connect.redhat.com/citrix/citrix-adc-metrics-exporter@sha256:6ce388d8f6324713b2db96385311d1e7a06c41dc54353c4ed81e6cf3dfdfb4b8",
          "name": "citrix-adc-metrics-exporter-6ce388d8f6324713b2db96385311d1e7a06c41dc54353c4ed81e6cf3dfdfb4b8-annotation"
        },
        {
          "digest": "sha256:91e7f337aab58db503e218ba3ac6b9f73173772314f57fc234ea340576426821",
          "image": "registry.connect.redhat.com/citrix/citrix-ingress-controller@sha256:91e7f337aab58db503e218ba3ac6b9f73173772314f57fc234ea340576426821",
          "name": "citrix-ingress-controller-91e7f337aab58db503e218ba3ac6b9f73173772314f57fc234ea340576426821-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.18.5",
      "version_original": "1.18.5"
    },
    {
      "_id": "62345fe9314381d2b0756b3b",
      "alm_examples": [
        {
          "api_version": "instana.io/v1",
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent": {
              "configuration_yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n",
              "endpointHost": "ingress-red-saas.instana.io",
              "endpointPort": "443",
              "env": {},
              "key": "replace-key"
            },
            "cluster": {
              "name": "my-cluster"
            },
            "zone": {
              "name": "edited-zone"
            }
          }
        },
        {
          "api_version": "instana.io/v1beta1",
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent.endpoint.host": "ingress-red-saas.instana.io",
            "agent.endpoint.port": 443,
            "agent.env": {
              "INSTANA_AGENT_TAGS": "example"
            },
            "agent.key": "replace-me",
            "agent.zone.name": "my-zone",
            "cluster.name": "replace-me",
            "config.files": {
              "configuration.yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/instana/instana-agent-operator-bundle@sha256:5aa72362012e1162708614b3dba4339797d757d04d22683f521328b63ed169d1",
      "bundle_path_digest": "sha256:5aa72362012e1162708614b3dba4339797d757d04d22683f521328b63ed169d1",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:33:13.750000+00:00",
      "csv_description": "# Instana\n\nInstana is an [APM solution](https://www.instana.com/product-overview/) built for microservices that enables IT Ops to build applications faster and deliver higher quality services by automating monitoring, tracing and root cause analysis. The solution is optimized for [Kubernetes](https://www.instana.com/automatic-kubernetes-monitoring/) and [OpenShift](https://www.instana.com/blog/automatic-root-cause-analysis-for-openshift-applications/).\n\n## Instana Agent Operator\n\nThis is the Kubernetes Operator for installing the Instana Agent on Kubernetes or OpenShift.\n\n## Prerequisites for OpenShift\n\nBefore the agent will be able to run in OpenShift, you need to perform a couple of extra configuration steps.\n\nYou need to set up a project for the Instana Agent and configure it's permissions.\n\nThe project you create here needs to be the namespace where you create the Instana Agent custom resource that the operator will use to deploy the agent.\n\nFor example, create the `instana-agent` project:\n\n    oc new-project instana-agent\n\nThen, ensure the `instana-agent` service account is in the privileged security context:\n\n    oc adm policy add-scc-to-user privileged -z instana-agent\n\nThis service account will be created by the operator.\n\nNow you can proceed with installing the operator for the Instana agent.\n\n## Installation and Configuration\n\nFirst, install this operator from [OperatorHub.io](https://operatorhub.io/), [OpenShift Container Platform](https://www.openshift.com/), or [OKD](https://www.okd.io/).\n\nSecond, create a custom resource with the agent configuration in the target namespace (for now, this MUST always be the `instana-agent` namespace). The operator will pick up the custom resource and install the Instana agent accordingly.\n\nThe following is a minimal template of the custom resource:\n\n```yaml\napiVersion: instana.io/v1\nkind: InstanaAgent\nmetadata:\n  name: instana-agent\n  namespace: instana-agent\nspec:\n  zone:\n    name: my-zone # (optional) name of the zone of the host\n  cluster:\n    name: replace-me # replace with the name of your Kubernetes cluster\n  agent:\n    key: replace-me # replace with your Instana agent key\n    endpointHost: ingress-red-saas.instana.io # the monitoring ingress endpoint\n    endpointPort: \"443\" # the monitoring ingress endpoint port, wrapped in quotes\n    env:\n      INSTANA_AGENT_TAGS: example\n    configuration_yaml: |\n      # You can leave this empty, or use this to configure your instana agent.\n      # See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n```\n\nSave the template in a file `instana-agent.yaml` and edit the following values:\n\n* If your target namespace is not `instana-agent`, replace the `namespace:` accordingly.\n* `agent.key` must be set with your Instana agent key.\n* `agent.endpointHost` must be set with the monitoring ingress endpoint, generally either `saas-us-west-2.instana.io` or `saas-eu-west-1.instana.io`.\n* `agent.endpointPort` must be set with the monitoring ingress port, generally \"443\" (wrapped in quotes).\n* `zone.name` should be set with the name of the Kubernetes cluster that is be displayed in Instana.\n\nFor advanced configuration, you can edit the contents of the `configuration.yaml` file. View documentation [here](https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/).\n\nApply the custom resource with `kubectl apply -f instana-agent.yaml`. After some time, you should see `instana-agent` Pods being created on each node of your cluster, and your cluster should show on the infrastructure map on your Instana Web interface.\n\n## Uninstalling\n\nIn order to uninstall the Instana agent, simply remove the custom resource with `kubectl delete -f instana-agent.yaml`.\n\n## Source Code\n\nThe Instana agent operator is an open source project hosted on [https://github.com/instana/instana-agent-operator](https://github.com/instana/instana-agent-operator/).\n",
      "csv_display_name": "Instana Agent Operator",
      "csv_metadata_description": "Fully automated Application Performance Monitoring (APM) for microservices.",
      "csv_name": "instana-agent-operator.v2.0.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:33:17.611000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "instana-agent-operator",
      "provided_apis": [
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "version": "v1"
        },
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "version": "v1beta1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "image": "instana/instana-agent-operator@sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "name": "instana-agent-operator"
        },
        {
          "digest": "sha256:3076921ebb8d3ff127511cc7289eacc2e0835ea88500bd4a2798ff2fdbe8b26a",
          "image": "instana/agent@sha256:3076921ebb8d3ff127511cc7289eacc2e0835ea88500bd4a2798ff2fdbe8b26a",
          "name": "instana-agent"
        },
        {
          "digest": "sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "image": "instana/instana-agent-operator@sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "name": "instana-agent-operator-abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2-annotation"
        },
        {
          "digest": "sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "image": "instana/instana-agent-operator@sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "name": "manager"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2.0.4",
      "version_original": "2.0.4"
    },
    {
      "_id": "62345fef06c5dada0193e082",
      "alm_examples": [
        {
          "api_version": "cache.omarg.net/v1alpha1",
          "kind": "Memcached",
          "metadata": {
            "name": "memcached-sample"
          },
          "spec": {
            "foo": "bar"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ogaye/ogaye@sha256:f35a21fb3936b259aabe27b453612616fca4e6327c9042361b4d00ef332905c0",
      "bundle_path_digest": "sha256:f35a21fb3936b259aabe27b453612616fca4e6327c9042361b4d00ef332905c0",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-03-18T10:33:19.441000+00:00",
      "csv_description": "Omar memcached operator",
      "csv_display_name": "memcached-operator-ogaye",
      "csv_metadata_description": "",
      "csv_name": "memcached-operator.v0.0.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:44:13.167000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "memcached-operator-ogaye",
      "provided_apis": [
        {
          "group": "cache.omarg.net",
          "kind": "Memcached",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:9211b70edbb93d718428e1c9a992e5fc74a20cb213f8a0592ffe340c362890fe",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:9211b70edbb93d718428e1c9a992e5fc74a20cb213f8a0592ffe340c362890fe",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:5340ac11ce676dd3204bf3807a4c2333a8dddcbcec918db0aeafbc977163c1c6",
          "image": "quay.io/ogaye/memcached-operator@sha256:5340ac11ce676dd3204bf3807a4c2333a8dddcbcec918db0aeafbc977163c1c6",
          "name": "manager"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "0.0.1",
      "version_original": "0.0.1"
    },
    {
      "_id": "62345ff5670f4cadbafad2aa",
      "alm_examples": [
        {
          "api_version": "sysdig.com/v1",
          "kind": "SysdigAgent",
          "metadata": {
            "name": "sysdigagent-sample"
          },
          "spec": {
            "sysdig": {
              "accessKey": "REPLACE ME",
              "disableCaptures": false,
              "existingAccessKeySecret": "",
              "settings": {}
            },
            "tolerations": [
              {
                "effect": "NoSchedule",
                "key": "node-role.kubernetes.io/master"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/sysdig/sysdig-operator-bundle@sha256:4f4f1bf24be82a2879596c353daf28425bdaccb2323869412fecb4eef2086d2f",
      "bundle_path_digest": "sha256:4f4f1bf24be82a2879596c353daf28425bdaccb2323869412fecb4eef2086d2f",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:33:25.448000+00:00",
      "csv_description": "[Sysdig](https://www.sysdig.com/) is a unified platform for container and\nmicroservices monitoring, troubleshooting, security and forensics. Sysdig\nplatform has been built on top of\n[Sysdig tool](https://sysdig.com/opensource/sysdig/) and\n[Sysdig Inspect](https://sysdig.com/blog/sysdig-inspect/) open-source\ntechnologies.\nThis operator installs the Sysdig Agent for\n[Sysdig Monitor](https://sysdig.com/product/monitor/) and\n[Sysdig Secure](https://sysdig.com/product/secure/) to all nodes in your\ncluster via a DaemonSet.\n## Settings\nThis operator, uses the same options than the\n[Helm Chart](https://hub.helm.sh/charts/stable/sysdig), please take a look\nto all the options in the following table:\n| Parameter                         | Description                                                            | Default                                     |\n| ---                               | ---                                                                    | ---                                         |\n| `image.registry`                  | Sysdig agent image registry                                            | `docker.io`                                 |\n| `image.repository`                | The image repository to pull from                                      | `sysdig/agent`                              |\n| `image.tag`                       | The image tag to pull                                                  | `REPLACE_AGENT_VERSION`                                     |\n| `image.pullPolicy`                | The Image pull policy                                                  | `IfNotPresent`                              |\n| `image.pullSecrets`               | Image pull secrets                                                     | `nil`                                       |\n| `resources.requests.cpu`          | CPU requested for being run in a node                                  | `600m`                                      |\n| `resources.requests.memory`       | Memory requested for being run in a node                               | `512Mi`                                     |\n| `resources.limits.cpu`            | CPU limit                                                              | `2000m`                                     |\n| `resources.limits.memory`         | Memory limit                                                           | `1536Mi`                                    |\n| `rbac.create`                     | If true, create & use RBAC resources                                   | `true`                                      |\n| `serviceAccount.create`           | Create serviceAccount                                                  | `true`                                      |\n| `serviceAccount.name`             | Use this value as serviceAccountName                                   | ` `                                         |\n| `daemonset.updateStrategy.type`   | The updateStrategy for updating the daemonset                          | `RollingUpdate`                             |\n| `daemonset.affinity`              | Node affinities                                                        | `nil`                                       |\n| `daemonset.annotations`           | Custom annotations for daemonset                                       | `{}`                                        |\n| `slim.enabled`                    | Use the slim based Sysdig Agent image                                  | `false`                                     |\n| `slim.kmoduleImage.repository`    | The kernel module image builder repository to pull from                | `sysdig/agent-kmodule`                      |\n| `slim.resources.requests.cpu`     | CPU requested for building the kernel module                           | `1000m`                                     |\n| `slim.resources.requests.memory`  | Memory requested for building the kernel module                        | `348Mi`                                     |\n| `slim.resources.limits.memory`    | Memory limit for building the kernel module                            | `512Mi`                                     |\n| `ebpf.enabled`                    | Enable eBPF support for Sysdig instead of `sysdig-probe` kernel module | `false`                                     |\n| `ebpf.settings.mountEtcVolume`    | Needed to detect which kernel version are running in Google COS        | `true`                                      |\n| `sysdig.accessKey`                | Your Sysdig Monitor Access Key                                         | `Nil` You must provide your own key         |\n| `sysdig.settings`                 | Settings for agent's configuration file                                | ` `                                         |\n| `secure.enabled`                  | Enable Sysdig Secure                                                   | `true`                                      |\n| `auditLog.enabled`                | Enable K8s audit log support for Sysdig Secure                         | `false`                                     |\n| `auditLog.auditServerUrl`         | The URL where Sysdig Agent listens for K8s audit log events            | `0.0.0.0`                                   |\n| `auditLog.auditServerPort`        | Port where Sysdig Agent listens for K8s audit log events               | `7765`                                      |\n| `auditLog.dynamicBackend.enabled` | Deploy the Audit Sink where Sysdig listens for K8s audit log events    | `false`                                     |\n| `customAppChecks`                 | The custom app checks deployed with your agent                         | `{}`                                        |\n| `tolerations`                     | The tolerations for scheduling                                         | `node-role.kubernetes.io/master:NoSchedule` |\n| `scc.create`                      | Create OpenShift's Security Context Constraint                         | `false`                                     |\nFor example, if you want to deploy a DaemonSet with eBPF and with Sysdig Secure\nenabled:\n```yaml\napiVersion: sysdig.com/v1\nkind: SysdigAgent\nmetadata:\n  name: agent-with-ebpf-and-secure\nspec:\n  ebpf:\n    enabled: true\n  daemonset:\n    annotations:\n      productID: SysdigSecureDevopsPlatform\n      productName: Sysdig Secure DevOps Platform\n      productVersion: REPLACE_VERSION\n  scc:\n    create: true\n  sysdig:\n    accessKey: XXX\n```\nPlease, notice that `sysdig.accessKey` is **mandatory**. Once you have provided\nthe accessKey, you can apply this file with `kubectl apply -f`\n## Getting your Access Key\nTo retrieve the key and use it in the agent:\n1. Log in to Sysdig Monitor or Sysdig Secure (maybe as administrator) and\n   select **Settings**.\n2. Choose Agent Installation.\n3. Use the Copy button to copy the access key at the top of the page.\nIf you need more help, you can read more about this process in the [Agent Installation: Overview and Key](\nhttps://sysdigdocs.atlassian.net/wiki/spaces/Platform/pages/213352719/Agent+Installation+Overview+and+Key)\ndocumentation page.\n## Verify Metrics in Sysdig Monitor UI\nOnce you have deployed the Sysdig Agent, it's time to verify that everything is\nworking as expected. So, we are going to log in Sysdig Monitor to do the check.\n1. Access Sysdig Monitor:\n   **SaaS**: https://app.sysdigcloud.com\n   Log in with your Sysdig user name and password.\n2. Select the **Explore** tab to see if metrics are displayed.\n3. To verify that kube state metrics and cluster name are working correctly:\n   Select the **Explore tab** and create a grouping by `kubernetes.cluster.name` and `kubernetes.pod.name`.\n4. Select an individual container or pod to see details.\nDon't rush about getting Kubernetes metadata. Pods, deployments ... appear a\nminute or two later than the nodes/containers themselves; if pod names do not\nappear immediately, wait and retry the Explore view.\nYou can read more about verification in the [Verify Metrics in Sysdig Monitor UI section](https://sysdigdocs.atlassian.net/wiki/spaces/Platform/pages/256475257/GKE+Installation+Steps#GKEInstallationSteps-VerifyMetricsinSysdigMonitorUI)\nin the documentation pages.",
      "csv_display_name": "Sysdig Agent Operator",
      "csv_metadata_description": "Sysdig is a unified platform for container and microservices monitoring, troubleshooting, security and forensics. Sysdig platform has been built on top of Sysdig tool and Sysdig Inspect open-source technologies.\n",
      "csv_name": "sysdig-certified.v1.12.43",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:42:22.852000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "sysdig-certified",
      "provided_apis": [
        {
          "group": "sysdig.com",
          "kind": "SysdigAgent",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:f367e4888fa2094bd3815e204dbf1a179a06e44b9be2863df339573e8dc6299d",
          "image": "registry.connect.redhat.com/sysdig/sysdig-operator@sha256:f367e4888fa2094bd3815e204dbf1a179a06e44b9be2863df339573e8dc6299d",
          "name": "sysdig-operator-f367e4888fa2094bd3815e204dbf1a179a06e44b9be2863df339573e8dc6299d-annotation"
        },
        {
          "digest": "sha256:f367e4888fa2094bd3815e204dbf1a179a06e44b9be2863df339573e8dc6299d",
          "image": "registry.connect.redhat.com/sysdig/sysdig-operator@sha256:f367e4888fa2094bd3815e204dbf1a179a06e44b9be2863df339573e8dc6299d",
          "name": "manager"
        },
        {
          "digest": "sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "name": "kube-rbac-proxy"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.12.43",
      "version_original": "1.12.43"
    },
    {
      "_id": "62345ff75593ce895a7b535e",
      "alm_examples": [
        {
          "api_version": "sysdig.com/v1",
          "kind": "SysdigAgent",
          "metadata": {
            "name": "sysdigagent-sample"
          },
          "spec": {
            "sysdig": {
              "accessKey": "REPLACE ME",
              "disableCaptures": false,
              "existingAccessKeySecret": "",
              "settings": {}
            },
            "tolerations": [
              {
                "effect": "NoSchedule",
                "key": "node-role.kubernetes.io/master"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/sysdig/sysdig-operator-bundle@sha256:72fa8220017452583ffaeba2fc0c57f9c1b218adf1aeeb4fbbd0e63c427312c6",
      "bundle_path_digest": "sha256:72fa8220017452583ffaeba2fc0c57f9c1b218adf1aeeb4fbbd0e63c427312c6",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:33:27.686000+00:00",
      "csv_description": "[Sysdig](https://www.sysdig.com/) is a unified platform for container and\nmicroservices monitoring, troubleshooting, security and forensics. Sysdig\nplatform has been built on top of\n[Sysdig tool](https://sysdig.com/opensource/sysdig/) and\n[Sysdig Inspect](https://sysdig.com/blog/sysdig-inspect/) open-source\ntechnologies.\nThis operator installs the Sysdig Agent for\n[Sysdig Monitor](https://sysdig.com/product/monitor/) and\n[Sysdig Secure](https://sysdig.com/product/secure/) to all nodes in your\ncluster via a DaemonSet.\n## Settings\nThis operator, uses the same options than the\n[Helm Chart](https://hub.helm.sh/charts/stable/sysdig), please take a look\nto all the options in the following table:\n| Parameter                         | Description                                                            | Default                                     |\n| ---                               | ---                                                                    | ---                                         |\n| `image.registry`                  | Sysdig agent image registry                                            | `docker.io`                                 |\n| `image.repository`                | The image repository to pull from                                      | `sysdig/agent`                              |\n| `image.tag`                       | The image tag to pull                                                  | `REPLACE_AGENT_VERSION`                                     |\n| `image.pullPolicy`                | The Image pull policy                                                  | `IfNotPresent`                              |\n| `image.pullSecrets`               | Image pull secrets                                                     | `nil`                                       |\n| `resources.requests.cpu`          | CPU requested for being run in a node                                  | `600m`                                      |\n| `resources.requests.memory`       | Memory requested for being run in a node                               | `512Mi`                                     |\n| `resources.limits.cpu`            | CPU limit                                                              | `2000m`                                     |\n| `resources.limits.memory`         | Memory limit                                                           | `1536Mi`                                    |\n| `rbac.create`                     | If true, create & use RBAC resources                                   | `true`                                      |\n| `serviceAccount.create`           | Create serviceAccount                                                  | `true`                                      |\n| `serviceAccount.name`             | Use this value as serviceAccountName                                   | ` `                                         |\n| `daemonset.updateStrategy.type`   | The updateStrategy for updating the daemonset                          | `RollingUpdate`                             |\n| `daemonset.affinity`              | Node affinities                                                        | `nil`                                       |\n| `daemonset.annotations`           | Custom annotations for daemonset                                       | `{}`                                        |\n| `slim.enabled`                    | Use the slim based Sysdig Agent image                                  | `false`                                     |\n| `slim.kmoduleImage.repository`    | The kernel module image builder repository to pull from                | `sysdig/agent-kmodule`                      |\n| `slim.resources.requests.cpu`     | CPU requested for building the kernel module                           | `1000m`                                     |\n| `slim.resources.requests.memory`  | Memory requested for building the kernel module                        | `348Mi`                                     |\n| `slim.resources.limits.memory`    | Memory limit for building the kernel module                            | `512Mi`                                     |\n| `ebpf.enabled`                    | Enable eBPF support for Sysdig instead of `sysdig-probe` kernel module | `false`                                     |\n| `ebpf.settings.mountEtcVolume`    | Needed to detect which kernel version are running in Google COS        | `true`                                      |\n| `sysdig.accessKey`                | Your Sysdig Monitor Access Key                                         | `Nil` You must provide your own key         |\n| `sysdig.settings`                 | Settings for agent's configuration file                                | ` `                                         |\n| `secure.enabled`                  | Enable Sysdig Secure                                                   | `true`                                      |\n| `auditLog.enabled`                | Enable K8s audit log support for Sysdig Secure                         | `false`                                     |\n| `auditLog.auditServerUrl`         | The URL where Sysdig Agent listens for K8s audit log events            | `0.0.0.0`                                   |\n| `auditLog.auditServerPort`        | Port where Sysdig Agent listens for K8s audit log events               | `7765`                                      |\n| `auditLog.dynamicBackend.enabled` | Deploy the Audit Sink where Sysdig listens for K8s audit log events    | `false`                                     |\n| `customAppChecks`                 | The custom app checks deployed with your agent                         | `{}`                                        |\n| `tolerations`                     | The tolerations for scheduling                                         | `node-role.kubernetes.io/master:NoSchedule` |\n| `scc.create`                      | Create OpenShift's Security Context Constraint                         | `false`                                     |\nFor example, if you want to deploy a DaemonSet with eBPF and with Sysdig Secure\nenabled:\n```yaml\napiVersion: sysdig.com/v1\nkind: SysdigAgent\nmetadata:\n  name: agent-with-ebpf-and-secure\nspec:\n  ebpf:\n    enabled: true\n  daemonset:\n    annotations:\n      productID: SysdigSecureDevopsPlatform\n      productName: Sysdig Secure DevOps Platform\n      productVersion: REPLACE_VERSION\n  scc:\n    create: true\n  sysdig:\n    accessKey: XXX\n```\nPlease, notice that `sysdig.accessKey` is **mandatory**. Once you have provided\nthe accessKey, you can apply this file with `kubectl apply -f`\n## Getting your Access Key\nTo retrieve the key and use it in the agent:\n1. Log in to Sysdig Monitor or Sysdig Secure (maybe as administrator) and\n   select **Settings**.\n2. Choose Agent Installation.\n3. Use the Copy button to copy the access key at the top of the page.\nIf you need more help, you can read more about this process in the [Agent Installation: Overview and Key](\nhttps://sysdigdocs.atlassian.net/wiki/spaces/Platform/pages/213352719/Agent+Installation+Overview+and+Key)\ndocumentation page.\n## Verify Metrics in Sysdig Monitor UI\nOnce you have deployed the Sysdig Agent, it's time to verify that everything is\nworking as expected. So, we are going to log in Sysdig Monitor to do the check.\n1. Access Sysdig Monitor:\n   **SaaS**: https://app.sysdigcloud.com\n   Log in with your Sysdig user name and password.\n2. Select the **Explore** tab to see if metrics are displayed.\n3. To verify that kube state metrics and cluster name are working correctly:\n   Select the **Explore tab** and create a grouping by `kubernetes.cluster.name` and `kubernetes.pod.name`.\n4. Select an individual container or pod to see details.\nDon't rush about getting Kubernetes metadata. Pods, deployments ... appear a\nminute or two later than the nodes/containers themselves; if pod names do not\nappear immediately, wait and retry the Explore view.\nYou can read more about verification in the [Verify Metrics in Sysdig Monitor UI section](https://sysdigdocs.atlassian.net/wiki/spaces/Platform/pages/256475257/GKE+Installation+Steps#GKEInstallationSteps-VerifyMetricsinSysdigMonitorUI)\nin the documentation pages.",
      "csv_display_name": "Sysdig Agent Operator",
      "csv_metadata_description": "Sysdig is a unified platform for container and microservices monitoring, troubleshooting, security and forensics. Sysdig platform has been built on top of Sysdig tool and Sysdig Inspect open-source technologies.\n",
      "csv_name": "sysdig-certified.v1.12.44",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:42:27.361000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "sysdig-certified",
      "provided_apis": [
        {
          "group": "sysdig.com",
          "kind": "SysdigAgent",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:f367e4888fa2094bd3815e204dbf1a179a06e44b9be2863df339573e8dc6299d",
          "image": "registry.connect.redhat.com/sysdig/sysdig-operator@sha256:f367e4888fa2094bd3815e204dbf1a179a06e44b9be2863df339573e8dc6299d",
          "name": "sysdig-operator-f367e4888fa2094bd3815e204dbf1a179a06e44b9be2863df339573e8dc6299d-annotation"
        },
        {
          "digest": "sha256:f367e4888fa2094bd3815e204dbf1a179a06e44b9be2863df339573e8dc6299d",
          "image": "registry.connect.redhat.com/sysdig/sysdig-operator@sha256:f367e4888fa2094bd3815e204dbf1a179a06e44b9be2863df339573e8dc6299d",
          "name": "manager"
        },
        {
          "digest": "sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "name": "kube-rbac-proxy"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.12.44",
      "version_original": "1.12.44"
    },
    {
      "_id": "62345ff95593ce895a7b535f",
      "alm_examples": [
        {
          "api_version": "ako.vmware.com/v1alpha1",
          "kind": "AKOConfig",
          "metadata": {
            "name": "ako-sample",
            "namespace": "avi-system"
          },
          "spec": {
            "akoSettings": {
              "apiServerPort": 8080,
              "clusterName": "my-cluster",
              "cniPlugin": "openshift",
              "deleteConfig": false,
              "disableStaticRouteSync": false,
              "enableEVH": false,
              "enableEvents": "true",
              "fullSyncFrequency": "1800",
              "layer7Only": false,
              "logLevel": "INFO",
              "namespaceSelector": {
                "labelKey": "",
                "labelValue": ""
              },
              "servicesAPI": false,
              "vipPerNamespace": "false"
            },
            "controllerSettings": {
              "cloudName": "Default-Cloud",
              "controllerHost": "",
              "controllerVersion": "20.1.5",
              "serviceEngineGroupName": "Default-Group",
              "tenantName": "admin",
              "tenantsPerCluster": "false"
            },
            "imagePullPolicy": "IfNotPresent",
            "imageRepository": "projects.registry.vmware.com/ako/ako-operator@sha256:ae215384004f6e13f0bfe184820a329400c49ef158d13ca6b308784c2589985d",
            "l4Settings": {
              "advancedL4": false,
              "autoFQDN": "default",
              "defaultDomain": ""
            },
            "l7Settings": {
              "defaultIngController": true,
              "noPGForSNI": false,
              "passthroughShardSize": "SMALL",
              "serviceType": "ClusterIP",
              "shardVSSize": "LARGE"
            },
            "logFile": "avi.log",
            "mountPath": "/log",
            "networkSettings": {
              "bgpPeerLabels": [],
              "enableRHI": false,
              "nodeNetworkList": [
                {
                  "cidrs": [],
                  "networkName": ""
                }
              ],
              "nsxtT1LR": "",
              "vipNetworkList": [
                {
                  "cidr": "",
                  "networkName": ""
                }
              ]
            },
            "nodePortSelector": {
              "key": "",
              "value": ""
            },
            "resources": {
              "limits": {
                "cpu": "250m",
                "memory": "300Mi"
              },
              "requests": {
                "cpu": "100m",
                "memory": "200Mi"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/wavefronthq/ako-operator-bundle@sha256:7d9d22becafceef1428f9a2ed1cabb6cbf10ddfe27a5216a0ab477ba7fdce523",
      "bundle_path_digest": "sha256:7d9d22becafceef1428f9a2ed1cabb6cbf10ddfe27a5216a0ab477ba7fdce523",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-03-18T10:33:29.324000+00:00",
      "csv_description": "Operator to manage the artifacts of the AKO Controller",
      "csv_display_name": "AKO Operator",
      "csv_metadata_description": "",
      "csv_name": "ako-operator.v1.6.2-alpha",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-06-17T01:43:06.420000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "ako-operator",
      "provided_apis": [
        {
          "group": "ako.vmware.com",
          "kind": "AKOConfig",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:ae215384004f6e13f0bfe184820a329400c49ef158d13ca6b308784c2589985d",
          "image": "projects.registry.vmware.com/ako/ako-operator@sha256:ae215384004f6e13f0bfe184820a329400c49ef158d13ca6b308784c2589985d",
          "name": "ako-operator"
        },
        {
          "digest": "sha256:ae215384004f6e13f0bfe184820a329400c49ef158d13ca6b308784c2589985d",
          "image": "projects.registry.vmware.com/ako/ako-operator@sha256:ae215384004f6e13f0bfe184820a329400c49ef158d13ca6b308784c2589985d",
          "name": "ako-operator-ae215384004f6e13f0bfe184820a329400c49ef158d13ca6b308784c2589985d-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.6.2-alpha",
      "version_original": "1.6.2-alpha"
    },
    {
      "_id": "62345ffb670f4cadbafad2ab",
      "alm_examples": [
        {
          "api_version": "ako.vmware.com/v1alpha1",
          "kind": "AKOConfig",
          "metadata": {
            "name": "ako-sample",
            "namespace": "avi-system"
          },
          "spec": {
            "akoSettings": {
              "apiServerPort": 8080,
              "clusterName": "my-cluster",
              "cniPlugin": "openshift",
              "deleteConfig": false,
              "disableStaticRouteSync": false,
              "enableEVH": false,
              "enableEvents": "true",
              "fullSyncFrequency": "1800",
              "layer7Only": false,
              "logLevel": "INFO",
              "namespaceSelector": {
                "labelKey": "",
                "labelValue": ""
              },
              "servicesAPI": false,
              "vipPerNamespace": "false"
            },
            "controllerSettings": {
              "cloudName": "Default-Cloud",
              "controllerHost": "",
              "controllerVersion": "20.1.5",
              "serviceEngineGroupName": "Default-Group",
              "tenantName": "admin",
              "tenantsPerCluster": "false"
            },
            "imagePullPolicy": "IfNotPresent",
            "imageRepository": "projects.registry.vmware.com/ako/ako-operator@sha256:ae215384004f6e13f0bfe184820a329400c49ef158d13ca6b308784c2589985d",
            "l4Settings": {
              "advancedL4": false,
              "autoFQDN": "default",
              "defaultDomain": ""
            },
            "l7Settings": {
              "defaultIngController": true,
              "noPGForSNI": false,
              "passthroughShardSize": "SMALL",
              "serviceType": "ClusterIP",
              "shardVSSize": "LARGE"
            },
            "logFile": "avi.log",
            "mountPath": "/log",
            "networkSettings": {
              "bgpPeerLabels": [],
              "enableRHI": false,
              "nodeNetworkList": [
                {
                  "cidrs": [],
                  "networkName": ""
                }
              ],
              "nsxtT1LR": "",
              "vipNetworkList": [
                {
                  "cidr": "",
                  "networkName": ""
                }
              ]
            },
            "nodePortSelector": {
              "key": "",
              "value": ""
            },
            "resources": {
              "limits": {
                "cpu": "250m",
                "memory": "300Mi"
              },
              "requests": {
                "cpu": "100m",
                "memory": "200Mi"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/wavefronthq/ako-operator-bundle@sha256:3acb960334e73a628ce3887def93927b2bfad252d07eb83cf70e1e81b4674108",
      "bundle_path_digest": "sha256:3acb960334e73a628ce3887def93927b2bfad252d07eb83cf70e1e81b4674108",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-03-18T10:33:31.169000+00:00",
      "csv_description": "Operator to manage the artifacts of the AKO Controller",
      "csv_display_name": "AKO Operator",
      "csv_metadata_description": "",
      "csv_name": "ako-operator.v1.6.2-beta",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-06-17T01:43:10.911000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "ako-operator",
      "provided_apis": [
        {
          "group": "ako.vmware.com",
          "kind": "AKOConfig",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:ae215384004f6e13f0bfe184820a329400c49ef158d13ca6b308784c2589985d",
          "image": "projects.registry.vmware.com/ako/ako-operator@sha256:ae215384004f6e13f0bfe184820a329400c49ef158d13ca6b308784c2589985d",
          "name": "ako-operator"
        },
        {
          "digest": "sha256:ae215384004f6e13f0bfe184820a329400c49ef158d13ca6b308784c2589985d",
          "image": "projects.registry.vmware.com/ako/ako-operator@sha256:ae215384004f6e13f0bfe184820a329400c49ef158d13ca6b308784c2589985d",
          "name": "ako-operator-ae215384004f6e13f0bfe184820a329400c49ef158d13ca6b308784c2589985d-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.6.2-beta",
      "version_original": "1.6.2-beta"
    },
    {
      "_id": "62346004670f4cadbafad2ac",
      "alm_examples": [
        {
          "api_version": "elasticsearch.k8s.elastic.co/v1",
          "kind": "Elasticsearch",
          "metadata": {
            "name": "elasticsearch-sample"
          },
          "spec": {
            "nodeSets": [
              {
                "config": {
                  "node.attr.attr_name": "attr_value",
                  "node.roles": [
                    "master",
                    "data"
                  ],
                  "node.store.allow_mmap": false
                },
                "count": 3,
                "name": "default",
                "podTemplate": {
                  "metadata": {
                    "labels": {
                      "foo": "bar"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "name": "elasticsearch",
                        "resources": {
                          "limits": {
                            "cpu": 2,
                            "memory": "4Gi"
                          },
                          "requests": {
                            "cpu": 1,
                            "memory": "4Gi"
                          }
                        }
                      }
                    ]
                  }
                }
              }
            ],
            "version": "8.0.0"
          }
        },
        {
          "api_version": "kibana.k8s.elastic.co/v1",
          "kind": "Kibana",
          "metadata": {
            "name": "kibana-sample"
          },
          "spec": {
            "count": 1,
            "elasticsearchRef": {
              "name": "elasticsearch-sample"
            },
            "podTemplate": {
              "metadata": {
                "labels": {
                  "foo": "bar"
                }
              },
              "spec": {
                "containers": [
                  {
                    "name": "kibana",
                    "resources": {
                      "limits": {
                        "cpu": 2,
                        "memory": "2Gi"
                      },
                      "requests": {
                        "cpu": 0.5,
                        "memory": "1Gi"
                      }
                    }
                  }
                ]
              }
            },
            "version": "8.0.0"
          }
        },
        {
          "api_version": "apm.k8s.elastic.co/v1",
          "kind": "ApmServer",
          "metadata": {
            "name": "apmserver-sample"
          },
          "spec": {
            "count": 1,
            "elasticsearchRef": {
              "name": "elasticsearch-sample"
            },
            "version": "8.0.0"
          }
        },
        {
          "api_version": "enterprisesearch.k8s.elastic.co/v1",
          "kind": "EnterpriseSearch",
          "metadata": {
            "name": "ent-sample"
          },
          "spec": {
            "config": {
              "ent_search.external_url": "https://localhost:3002"
            },
            "count": 1,
            "elasticsearchRef": {
              "name": "elasticsearch-sample"
            },
            "version": "8.0.0"
          }
        },
        {
          "api_version": "beat.k8s.elastic.co/v1beta1",
          "kind": "Beat",
          "metadata": {
            "name": "heartbeat-sample"
          },
          "spec": {
            "config": {
              "heartbeat.monitors": [
                {
                  "hosts": [
                    "elasticsearch-sample-es-http.default.svc:9200"
                  ],
                  "schedule": "@every 5s",
                  "type": "tcp"
                }
              ]
            },
            "deployment": {
              "podTemplate": {
                "spec": {
                  "securityContext": {
                    "runAsUser": 0
                  }
                }
              },
              "replicas": 1
            },
            "elasticsearchRef": {
              "name": "elasticsearch-sample"
            },
            "type": "heartbeat",
            "version": "8.0.0"
          }
        },
        {
          "api_version": "agent.k8s.elastic.co/v1alpha1",
          "kind": "Agent",
          "metadata": {
            "name": "agent-sample"
          },
          "spec": {
            "config": {
              "inputs": [
                {
                  "data_stream": {
                    "namespace": "default"
                  },
                  "meta": {
                    "package": {
                      "name": "system",
                      "version": "0.9.1"
                    }
                  },
                  "name": "system-1",
                  "revision": 1,
                  "streams": [
                    {
                      "cpu.metrics": [
                        "percentages",
                        "normalized_percentages"
                      ],
                      "data_stream": {
                        "dataset": "system.cpu",
                        "type": "metrics"
                      },
                      "id": "system/metrics-system.cpu",
                      "metricsets": [
                        "cpu"
                      ],
                      "period": "10s"
                    }
                  ],
                  "type": "system/metrics",
                  "use_output": "default"
                }
              ]
            },
            "daemonSet": {},
            "elasticsearchRefs": [
              {
                "name": "elasticsearch-sample"
              }
            ],
            "version": "8.0.0"
          }
        },
        {
          "api_version": "maps.k8s.elastic.co/v1alpha1",
          "kind": "ElasticMapsServer",
          "metadata": {
            "name": "ems-sample"
          },
          "spec": {
            "count": 1,
            "elasticsearchRef": {
              "name": "elasticsearch-sample"
            },
            "version": "8.0.0"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/elastic/eck@sha256:4bb009507010225a10589c29d79ae970e53aa1c501c31879b8a6bd80418e6605",
      "bundle_path_digest": "sha256:4bb009507010225a10589c29d79ae970e53aa1c501c31879b8a6bd80418e6605",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:33:40.265000+00:00",
      "csv_description": "Elastic Cloud on Kubernetes (ECK) is the official operator by Elastic for automating the deployment, provisioning, management, and orchestration of Elasticsearch, Kibana, APM Server, Beats, Enterprise Search, Elastic Agent and Elastic Maps Server on Kubernetes.\n\nCurrent features:\n\n*  Elasticsearch, Kibana, APM Server, Enterprise Search, Beats, Elastic Agent and Elastic Maps Server deployments\n*  TLS Certificates management\n*  Safe Elasticsearch cluster configuration and topology changes\n*  Persistent volumes usage\n*  Custom node configuration and attributes\n*  Secure settings keystore updates\n\nSupported versions:\n\n* Kubernetes 1.19-1.23\n* OpenShift 4.6-4.10\n* Google Kubernetes Engine (GKE), Azure Kubernetes Service (AKS), and Amazon Elastic Kubernetes Service (EKS)\n* Elasticsearch, Kibana, APM Server: 7.10+\n* Enterprise Search: 7.10+\n* Beats: 7.10+\n* Elastic Agent: 7.10+\n* Elastic Maps Server: 7.11+\n\nECK should work with all conformant installers as listed in these [FAQs](https://github.com/cncf/k8s-conformance/blob/master/faq.md#what-is-a-distribution-hosted-platform-and-an-installer). Distributions include source patches and so may not work as-is with ECK.\nAlpha, beta, and stable API versions follow the same [conventions used by Kubernetes](https://kubernetes.io/docs/concepts/overview/kubernetes-api/#api-versioning).\nSee the full [Elastic support matrix](https://www.elastic.co/support/matrix#matrix_kubernetes) for more information.\nSee the [Quickstart](https://www.elastic.co/guide/en/cloud-on-k8s/2.0/k8s-quickstart.html) to get started with ECK.",
      "csv_display_name": "Elasticsearch (ECK) Operator",
      "csv_metadata_description": "Run Elasticsearch, Kibana, APM Server, Beats, Enterprise Search, Elastic Agent and Elastic Maps Server on Kubernetes and OpenShift",
      "csv_name": "elasticsearch-eck-operator-certified.v2.0.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:41:42.077000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "elasticsearch-eck-operator-certified",
      "provided_apis": [
        {
          "group": "agent.k8s.elastic.co",
          "kind": "Agent",
          "version": "v1alpha1"
        },
        {
          "group": "apm.k8s.elastic.co",
          "kind": "ApmServer",
          "version": "v1"
        },
        {
          "group": "apm.k8s.elastic.co",
          "kind": "ApmServer",
          "version": "v1alpha1"
        },
        {
          "group": "apm.k8s.elastic.co",
          "kind": "ApmServer",
          "version": "v1beta1"
        },
        {
          "group": "beat.k8s.elastic.co",
          "kind": "Beat",
          "version": "v1beta1"
        },
        {
          "group": "elasticsearch.k8s.elastic.co",
          "kind": "Elasticsearch",
          "version": "v1"
        },
        {
          "group": "elasticsearch.k8s.elastic.co",
          "kind": "Elasticsearch",
          "version": "v1alpha1"
        },
        {
          "group": "elasticsearch.k8s.elastic.co",
          "kind": "Elasticsearch",
          "version": "v1beta1"
        },
        {
          "group": "enterprisesearch.k8s.elastic.co",
          "kind": "EnterpriseSearch",
          "version": "v1"
        },
        {
          "group": "enterprisesearch.k8s.elastic.co",
          "kind": "EnterpriseSearch",
          "version": "v1beta1"
        },
        {
          "group": "kibana.k8s.elastic.co",
          "kind": "Kibana",
          "version": "v1"
        },
        {
          "group": "kibana.k8s.elastic.co",
          "kind": "Kibana",
          "version": "v1alpha1"
        },
        {
          "group": "kibana.k8s.elastic.co",
          "kind": "Kibana",
          "version": "v1beta1"
        },
        {
          "group": "maps.k8s.elastic.co",
          "kind": "ElasticMapsServer",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:dc2ace972ad6dbf30caa920d092b9358ea93c4290173f501d80ba486cccae64f",
          "image": "registry.connect.redhat.com/elastic/eck-operator@sha256:dc2ace972ad6dbf30caa920d092b9358ea93c4290173f501d80ba486cccae64f",
          "name": "eck-operator-dc2ace972ad6dbf30caa920d092b9358ea93c4290173f501d80ba486cccae64f-annotation"
        },
        {
          "digest": "sha256:dc2ace972ad6dbf30caa920d092b9358ea93c4290173f501d80ba486cccae64f",
          "image": "registry.connect.redhat.com/elastic/eck-operator@sha256:dc2ace972ad6dbf30caa920d092b9358ea93c4290173f501d80ba486cccae64f",
          "name": "manager"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2.0.0",
      "version_original": "2.0.0"
    },
    {
      "_id": "6234600606c5dada0193e084",
      "alm_examples": [
        {
          "api_version": "elasticsearch.k8s.elastic.co/v1",
          "kind": "Elasticsearch",
          "metadata": {
            "name": "elasticsearch-sample"
          },
          "spec": {
            "nodeSets": [
              {
                "config": {
                  "node.attr.attr_name": "attr_value",
                  "node.roles": [
                    "master",
                    "data"
                  ],
                  "node.store.allow_mmap": false
                },
                "count": 3,
                "name": "default",
                "podTemplate": {
                  "metadata": {
                    "labels": {
                      "foo": "bar"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "name": "elasticsearch",
                        "resources": {
                          "limits": {
                            "cpu": 2,
                            "memory": "4Gi"
                          },
                          "requests": {
                            "cpu": 1,
                            "memory": "4Gi"
                          }
                        }
                      }
                    ]
                  }
                }
              }
            ],
            "version": "8.1.0"
          }
        },
        {
          "api_version": "kibana.k8s.elastic.co/v1",
          "kind": "Kibana",
          "metadata": {
            "name": "kibana-sample"
          },
          "spec": {
            "count": 1,
            "elasticsearchRef": {
              "name": "elasticsearch-sample"
            },
            "podTemplate": {
              "metadata": {
                "labels": {
                  "foo": "bar"
                }
              },
              "spec": {
                "containers": [
                  {
                    "name": "kibana",
                    "resources": {
                      "limits": {
                        "cpu": 2,
                        "memory": "2Gi"
                      },
                      "requests": {
                        "cpu": 0.5,
                        "memory": "1Gi"
                      }
                    }
                  }
                ]
              }
            },
            "version": "8.1.0"
          }
        },
        {
          "api_version": "apm.k8s.elastic.co/v1",
          "kind": "ApmServer",
          "metadata": {
            "name": "apmserver-sample"
          },
          "spec": {
            "count": 1,
            "elasticsearchRef": {
              "name": "elasticsearch-sample"
            },
            "version": "8.1.0"
          }
        },
        {
          "api_version": "enterprisesearch.k8s.elastic.co/v1",
          "kind": "EnterpriseSearch",
          "metadata": {
            "name": "ent-sample"
          },
          "spec": {
            "config": {
              "ent_search.external_url": "https://localhost:3002"
            },
            "count": 1,
            "elasticsearchRef": {
              "name": "elasticsearch-sample"
            },
            "version": "8.1.0"
          }
        },
        {
          "api_version": "beat.k8s.elastic.co/v1beta1",
          "kind": "Beat",
          "metadata": {
            "name": "heartbeat-sample"
          },
          "spec": {
            "config": {
              "heartbeat.monitors": [
                {
                  "hosts": [
                    "elasticsearch-sample-es-http.default.svc:9200"
                  ],
                  "schedule": "@every 5s",
                  "type": "tcp"
                }
              ]
            },
            "deployment": {
              "podTemplate": {
                "spec": {
                  "securityContext": {
                    "runAsUser": 0
                  }
                }
              },
              "replicas": 1
            },
            "elasticsearchRef": {
              "name": "elasticsearch-sample"
            },
            "type": "heartbeat",
            "version": "8.1.0"
          }
        },
        {
          "api_version": "agent.k8s.elastic.co/v1alpha1",
          "kind": "Agent",
          "metadata": {
            "name": "agent-sample"
          },
          "spec": {
            "config": {
              "inputs": [
                {
                  "data_stream": {
                    "namespace": "default"
                  },
                  "meta": {
                    "package": {
                      "name": "system",
                      "version": "0.9.1"
                    }
                  },
                  "name": "system-1",
                  "revision": 1,
                  "streams": [
                    {
                      "cpu.metrics": [
                        "percentages",
                        "normalized_percentages"
                      ],
                      "data_stream": {
                        "dataset": "system.cpu",
                        "type": "metrics"
                      },
                      "id": "system/metrics-system.cpu",
                      "metricsets": [
                        "cpu"
                      ],
                      "period": "10s"
                    }
                  ],
                  "type": "system/metrics",
                  "use_output": "default"
                }
              ]
            },
            "daemonSet": {},
            "elasticsearchRefs": [
              {
                "name": "elasticsearch-sample"
              }
            ],
            "version": "8.1.0"
          }
        },
        {
          "api_version": "maps.k8s.elastic.co/v1alpha1",
          "kind": "ElasticMapsServer",
          "metadata": {
            "name": "ems-sample"
          },
          "spec": {
            "count": 1,
            "elasticsearchRef": {
              "name": "elasticsearch-sample"
            },
            "version": "8.1.0"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/elastic/eck@sha256:a386d9aefcfd7cfb9f7b2b5fd30733efac2e4ce8c265fcddaff9252398bfe821",
      "bundle_path_digest": "sha256:a386d9aefcfd7cfb9f7b2b5fd30733efac2e4ce8c265fcddaff9252398bfe821",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:33:42.140000+00:00",
      "csv_description": "Elastic Cloud on Kubernetes (ECK) is the official operator by Elastic for automating the deployment, provisioning, management, and orchestration of Elasticsearch, Kibana, APM Server, Beats, Enterprise Search, Elastic Agent and Elastic Maps Server on Kubernetes.\n\nCurrent features:\n\n*  Elasticsearch, Kibana, APM Server, Enterprise Search, Beats, Elastic Agent and Elastic Maps Server deployments\n*  TLS Certificates management\n*  Safe Elasticsearch cluster configuration and topology changes\n*  Persistent volumes usage\n*  Custom node configuration and attributes\n*  Secure settings keystore updates\n\nSupported versions:\n\n* Kubernetes 1.19-1.23\n* OpenShift 4.6-4.10\n* Google Kubernetes Engine (GKE), Azure Kubernetes Service (AKS), and Amazon Elastic Kubernetes Service (EKS)\n* Elasticsearch, Kibana, APM Server: 7.10+\n* Enterprise Search: 7.10+\n* Beats: 7.10+\n* Elastic Agent: 7.10+\n* Elastic Maps Server: 7.11+\n\nECK should work with all conformant installers as listed in these [FAQs](https://github.com/cncf/k8s-conformance/blob/master/faq.md#what-is-a-distribution-hosted-platform-and-an-installer). Distributions include source patches and so may not work as-is with ECK.\nAlpha, beta, and stable API versions follow the same [conventions used by Kubernetes](https://kubernetes.io/docs/concepts/overview/kubernetes-api/#api-versioning).\nSee the full [Elastic support matrix](https://www.elastic.co/support/matrix#matrix_kubernetes) for more information.\nSee the [Quickstart](https://www.elastic.co/guide/en/cloud-on-k8s/2.1/k8s-quickstart.html) to get started with ECK.",
      "csv_display_name": "Elasticsearch (ECK) Operator",
      "csv_metadata_description": "Run Elasticsearch, Kibana, APM Server, Beats, Enterprise Search, Elastic Agent and Elastic Maps Server on Kubernetes and OpenShift",
      "csv_name": "elasticsearch-eck-operator-certified.v2.1.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:41:47.756000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "elasticsearch-eck-operator-certified",
      "provided_apis": [
        {
          "group": "agent.k8s.elastic.co",
          "kind": "Agent",
          "version": "v1alpha1"
        },
        {
          "group": "apm.k8s.elastic.co",
          "kind": "ApmServer",
          "version": "v1"
        },
        {
          "group": "apm.k8s.elastic.co",
          "kind": "ApmServer",
          "version": "v1alpha1"
        },
        {
          "group": "apm.k8s.elastic.co",
          "kind": "ApmServer",
          "version": "v1beta1"
        },
        {
          "group": "beat.k8s.elastic.co",
          "kind": "Beat",
          "version": "v1beta1"
        },
        {
          "group": "elasticsearch.k8s.elastic.co",
          "kind": "Elasticsearch",
          "version": "v1"
        },
        {
          "group": "elasticsearch.k8s.elastic.co",
          "kind": "Elasticsearch",
          "version": "v1alpha1"
        },
        {
          "group": "elasticsearch.k8s.elastic.co",
          "kind": "Elasticsearch",
          "version": "v1beta1"
        },
        {
          "group": "enterprisesearch.k8s.elastic.co",
          "kind": "EnterpriseSearch",
          "version": "v1"
        },
        {
          "group": "enterprisesearch.k8s.elastic.co",
          "kind": "EnterpriseSearch",
          "version": "v1beta1"
        },
        {
          "group": "kibana.k8s.elastic.co",
          "kind": "Kibana",
          "version": "v1"
        },
        {
          "group": "kibana.k8s.elastic.co",
          "kind": "Kibana",
          "version": "v1alpha1"
        },
        {
          "group": "kibana.k8s.elastic.co",
          "kind": "Kibana",
          "version": "v1beta1"
        },
        {
          "group": "maps.k8s.elastic.co",
          "kind": "ElasticMapsServer",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:465a4e646a5cf9c2ede1c3d9a02c4c3b55371115fde1c4864f429a8141a685bb",
          "image": "registry.connect.redhat.com/elastic/eck-operator@sha256:465a4e646a5cf9c2ede1c3d9a02c4c3b55371115fde1c4864f429a8141a685bb",
          "name": "eck-operator-465a4e646a5cf9c2ede1c3d9a02c4c3b55371115fde1c4864f429a8141a685bb-annotation"
        },
        {
          "digest": "sha256:465a4e646a5cf9c2ede1c3d9a02c4c3b55371115fde1c4864f429a8141a685bb",
          "image": "registry.connect.redhat.com/elastic/eck-operator@sha256:465a4e646a5cf9c2ede1c3d9a02c4c3b55371115fde1c4864f429a8141a685bb",
          "name": "manager"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2.1.0",
      "version_original": "2.1.0"
    },
    {
      "_id": "62346008314381d2b0756b3f",
      "alm_examples": [
        {
          "api_version": "infoscale.veritas.com/v1",
          "kind": "InfoScaleCluster",
          "metadata": {
            "name": "infoscalecluster-dev"
          },
          "spec": {
            "clusterInfo": [
              {},
              {}
            ],
            "version": "8.0.0.0000"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/veritas-technologies/infoscale-operator-bundle@sha256:aa898cb65de29ecae7075b30fd3b79ff5f2bedf6f6224fd104ad930be7e82dcd",
      "bundle_path_digest": "sha256:aa898cb65de29ecae7075b30fd3b79ff5f2bedf6f6224fd104ad930be7e82dcd",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:33:44.240000+00:00",
      "csv_description": "## InfoScale\u2122 SDS Operator\n\nInfoScale\u2122 SDS Operator manages the lifecycle of the InfoScale\u2122 cluster\n\n## Overview\n\n- Veritas InfoScale\u2122 delivers Infrastructure resiliency and persistent storage for your critical containerized applications for OpenShift\u00ae and Kubernetes Native deployments\n- Engineered to support stateful workloads generated for mission-critical containerized applications.\n\n---\n\n## Data Services & Benefits\n\n**1. Software-Defined Persistent Storage Volumes:** Enables customers to support multiple container application requirements leveraging existing SAN or DAS storage\n\n**2. CSI API Driver:** Facilitates static and dynamic provisioning for applications with RWX, RWO and ROX access modes\n\n**3. Life Cycle Management:** Enables automated deployment, configuration and upgrades of InfoScale Software-defined container images. Certified and Integrated with Red Hat OpenShift for a single-click deployment\n\n**4. Availability:** Provides scaling, mounting and/or movement of InfoScale persistent storage volumes on cluster nodes with minimal disruption\n\n**5. Data Integrity:** Prevents data corruption by allowing only the active cluster nodes to write to the volume. The I/O fencing feature recovers from cluster disruptions quickly by ensuring that application pods are moved to another node to continue normal operations\n\n**6. Point-in-Time Data Copies:** Create snapshots of Persistent Volumes for backup products, data analytics or forensic discovery and analysis\n\n**7. Disaster Recovery (DR) Tech Preview:** This DR feature provides the ability to test and validate disaster recovery capabilities by migrating Kubernetes cluster metadata and application components to peer cluster in case of a local or remote disaster\n\n---\n\n## Pre-requisites\n\n- [Please refer to pre-requisite section from official documentation](https://www.veritas.com/support/en_US/doc/151215298-151215302-0)\n\n## InfoScale Cluster custom resource\n\n```\nkind: InfoScaleCluster\nmetadata:\n  name:  < Infoscale Cluster Name >\n\nspec:\n  version: \"8.0.0.0000\"\n\n  clusterInfo:\n  - nodeName: <Name of the first node>\n  ip:\n  - <Optional - First IP address of the first node >\n  - <Optional - Second IP address of the first node>\n  excludeDevice:\n  - <Optional - Device path of the disk on the node that you want to exclude from Infoscale disk group.>\n\n  - nodeName: <Name of the second node>\n  ip:\n  - <Optional - First IP address of the second node >\n  - <Optional - Second IP address of the second node>\n  excludeDevice:\n  - <Optional - Device path of the disk on the node that you want to exclude from Infoscale disk group.>\n\n  # You can add up to 16 nodes.\n\n  licenseServer: < Optional - License server name/IP address >\n  licensePort: < Optional - License port number >\n\n  customImageRegistry: < Optional \u2013 Registry for Infoscale Container images>\n\n```\n\n#### Note\n\nYou can specify up to 16 worker nodes in CR. Although cluster configuration is allowed even with one Network Interface Card,\nVeritas recommends a minimum of two physical links for performance and High Availability (HA). Number of links for each network link must be same on all\nnodes. Optionally, you can enter node level IP addresses. If IP addresses are not provided, IP addresses of OpenShift cluster nodes are used.\n",
      "csv_display_name": "InfoScale\u2122 SDS Operator",
      "csv_metadata_description": "",
      "csv_name": "infoscale-operator.v7.9.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:40:16.261000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "infoscale-operator",
      "provided_apis": [
        {
          "group": "infoscale.veritas.com",
          "kind": "InfoScaleCluster",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:686f4fa379400e1c2151f5086276625241b5674ed91e90f1b328c510ca1034f0",
          "image": "registry.connect.redhat.com/veritas-technologies/infoscale-operator@sha256:686f4fa379400e1c2151f5086276625241b5674ed91e90f1b328c510ca1034f0",
          "name": "manager"
        },
        {
          "digest": "sha256:686f4fa379400e1c2151f5086276625241b5674ed91e90f1b328c510ca1034f0",
          "image": "registry.connect.redhat.com/veritas-technologies/infoscale-operator@sha256:686f4fa379400e1c2151f5086276625241b5674ed91e90f1b328c510ca1034f0",
          "name": "pre-manager"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "7.9.1",
      "version_original": "7.9.1"
    },
    {
      "_id": "623460095593ce895a7b5361",
      "alm_examples": [
        {
          "api_version": "triliovault.trilio.io/v1",
          "kind": "License",
          "metadata": {
            "name": "tvk-license-one",
            "namespace": "openshift-marketplace"
          },
          "spec": {
            "key": "xLkNDgwKD3jafZJNb8IwDIbv+RWRdo6Uj5a2SD1MwKRtjE0bsLOTuiISpFWaovHv145NQy3iPcb249d27j6xoE/tnkpJOZ/KaBrFVHLJycwjBFu5OQSk/8r7IOMJk5IsCttn0IHyB4+49hb2BEywR6SjjOBbJHtr0DW4Rd9cUnJJXsC6gA6cwcVXbf3pbKLvrRhPmersVYca3GlEfsdiB4Gs2oNG/1pumo5+EWaCfKA/on+cDysh5gWokjOjU8WEQGBaQMSM0DrDiTKTpCterOgV5d07+wXIm4Dleehh+3y9vd8s138MdduEqWq8YsLBAZsaDBbkudW4Gc1Ic56ITHMwrEwTwSIlY5bqLGGGx1kW6QQzUZKfncPotJfrf2u92UGDN37HDDorNgxPlAtOe3d0VRXYfAMj8ZzrMEYCIQCVaI/QJN+2M/QJWimd28dWOi/6o5s5I5+z30JrmzwGnQIhAKrSu8NeUIqXGEBTQvPKe3n2U0LNPht/ZAQIs5CZNeWlX02gk"
          }
        },
        {
          "api_version": "triliovault.trilio.io/v1",
          "kind": "Target",
          "metadata": {
            "labels": {
              "app": "triliovault"
            },
            "name": "triliovault-target",
            "namespace": "openshift-marketplace"
          },
          "spec": {
            "nfsCredentials": {
              "nfsExport": "00.00.00.00:/src/nfs/kubedata",
              "nfsOptions": "nfsvers=4"
            },
            "type": "NFS",
            "vendor": "Other"
          }
        },
        {
          "api_version": "triliovault.trilio.io/v1",
          "kind": "BackupPlan",
          "metadata": {
            "name": "tvk-backupplan"
          },
          "spec": {
            "backupConfig": {
              "retentionPolicy": {
                "name": "retention-policy",
                "namespace": "openshift-marketplace"
              },
              "schedulePolicy": {
                "fullBackupPolicy": {
                  "name": "full-bp-policy",
                  "namespace": "openshift-marketplace"
                },
                "incrementalBackupPolicy": {
                  "name": "inc-bp-policy",
                  "namespace": "openshift-marketplace"
                }
              },
              "target": {
                "name": "triliovault-target",
                "namespace": "openshift-marketplace"
              }
            },
            "backupPlanComponents": {
              "custom": [
                {
                  "matchLabels": {
                    "app": "nginx"
                  }
                }
              ],
              "helmReleases": [
                "sample-release"
              ],
              "operators": [
                {
                  "applicationResourceSelector": [
                    {
                      "matchLabels": {
                        "app": "etcd"
                      }
                    }
                  ],
                  "customResources": [
                    {
                      "groupVersionKind": {
                        "group": "etcd.database.coreos.com",
                        "kind": "EtcdCluster",
                        "version": "v1beta2"
                      },
                      "objects": [
                        "demo-etcd-cluster"
                      ]
                    }
                  ],
                  "operatorId": "demo-etcd-cluster",
                  "operatorResourceSelector": [
                    {
                      "matchLabels": {
                        "release": "demo-etcd-operator"
                      }
                    }
                  ]
                }
              ]
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [
        "ppc64le"
      ],
      "bundle_path": "registry.connect.redhat.com/trilio/k8s-triliovault-ibm@sha256:85bdda572f98163d5e84adddb0ca47fb183ecd2cbeaa2ff0e905387c4d8f3d2d",
      "bundle_path_digest": "sha256:85bdda572f98163d5e84adddb0ca47fb183ecd2cbeaa2ff0e905387c4d8f3d2d",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:33:45.854000+00:00",
      "csv_description": "TrilioVault for Kubernetes is an enterprise-grade, cloud-native platform purpose built for data protection and management of Kubernetes applications for IT managers, administrators and developers. TrilioVault supports upstream Kubernetes and OpenShift environments and offers the following features:\n  * Application-Centric - protects both data and metadata for Helm, Operator or custom Label based applications.\n  * Red Hat Certified - first backup and recovery solution with OpenShift Operator Certification.\n  * Native to Kubernetes & OpenShift: Packaged and deployed as an Operator, integrated via Kubernetes API and with all features that it provides.\n  * Infrastructure Agnostic: Compatible with any Storage (CSI, NFS, S3), or any Cloud (Private or Public).\n  * Application Deployment & Tooling: Helm, Operators, Labels, Prometheus, Fluentd.\nTutorials\n------------\nPlease click the link below to access the TrilioVault for Kubernetes \"How-To\" series for deployment, best practice and use-case videos\n<a href=\"https://www.trilio.io/triliovault-for-kubernetes\">TrilioVault for Kubernetes - Tutorials and How-To </a>\u201d\nLicensing\n--------\nCustomers can download a 30-day Free Trial or a 10-node Basic Edition at no cost.  You can also connect with the Trilio team for an Enterprise Edition license with no limitations and Premium Support.\nFor more information on license plans please vist:\n<a href=\"www.trilio.io/plans\"> Trilio Vault for Kubernetes licensing and plans </a>\nAbout Trilio\n----------------\nTrilio is trusted by global cloud infrastructure operators to deliver data protection, application resiliency, infrastructure migration and infrastructure version management. Our TrilioVault technology supports Kubernetes, OpenStack and Virtualization environments to recover from disasters, migrate tenant workloads, move workloads to new infrastructures and migrate to new infrastructure software distributions. www.trilio.io and @triliodata on Twitter.",
      "csv_display_name": "TrilioVault for Kubernetes",
      "csv_metadata_description": "Cloud-Native Data Protection for Kubernetes",
      "csv_name": "k8s-triliovault-ibm-stable.2.7.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:37:19.954000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "k8s-triliovault-ibm",
      "provided_apis": [
        {
          "group": "triliovault.trilio.io",
          "kind": "Backup",
          "version": "v1"
        },
        {
          "group": "triliovault.trilio.io",
          "kind": "BackupPlan",
          "version": "v1"
        },
        {
          "group": "triliovault.trilio.io",
          "kind": "ClusterBackup",
          "version": "v1"
        },
        {
          "group": "triliovault.trilio.io",
          "kind": "ClusterBackupPlan",
          "version": "v1"
        },
        {
          "group": "triliovault.trilio.io",
          "kind": "ClusterRestore",
          "version": "v1"
        },
        {
          "group": "triliovault.trilio.io",
          "kind": "Hook",
          "version": "v1"
        },
        {
          "group": "triliovault.trilio.io",
          "kind": "License",
          "version": "v1"
        },
        {
          "group": "triliovault.trilio.io",
          "kind": "Policy",
          "version": "v1"
        },
        {
          "group": "triliovault.trilio.io",
          "kind": "Restore",
          "version": "v1"
        },
        {
          "group": "triliovault.trilio.io",
          "kind": "Target",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:1eea5404a92bf1a408559d3b7f7ac700f4df5559ce5e4737db866804930d720a",
          "image": "eu.gcr.io/amazing-chalice-243510/control-plane@sha256:1eea5404a92bf1a408559d3b7f7ac700f4df5559ce5e4737db866804930d720a",
          "name": "control-plane-1eea5404a92bf1a408559d3b7f7ac700f4df5559ce5e4737db866804930d720a-annotation"
        },
        {
          "digest": "sha256:1eea5404a92bf1a408559d3b7f7ac700f4df5559ce5e4737db866804930d720a",
          "image": "eu.gcr.io/amazing-chalice-243510/control-plane@sha256:1eea5404a92bf1a408559d3b7f7ac700f4df5559ce5e4737db866804930d720a",
          "name": "k8s-triliovault-control-plane"
        },
        {
          "digest": "sha256:8a1f8d4ef507034e9210f49cf6d20a42e18a480bff9974ac73efd35438610ba8",
          "image": "eu.gcr.io/amazing-chalice-243510/analyzer@sha256:8a1f8d4ef507034e9210f49cf6d20a42e18a480bff9974ac73efd35438610ba8",
          "name": "k8s-triliovault-analyzer"
        },
        {
          "digest": "sha256:b1318b3e0ee719ae183a48a1876f158862f958e9c85fadb672ccab3de5593311",
          "image": "eu.gcr.io/amazing-chalice-243510/trilio-admission-webhook@sha256:b1318b3e0ee719ae183a48a1876f158862f958e9c85fadb672ccab3de5593311",
          "name": "triliovault-admission-webhook"
        },
        {
          "digest": "sha256:3900293f0afbd3c594136768b89b3233611b115918ede5834eb8eab7ac5c3f70",
          "image": "eu.gcr.io/amazing-chalice-243510/exporter@sha256:3900293f0afbd3c594136768b89b3233611b115918ede5834eb8eab7ac5c3f70",
          "name": "triliovault-exporter"
        },
        {
          "digest": "sha256:0c0691485ff10b2318ce378fcb37a77130db556d8cba9f895a6bf6814774b604",
          "image": "eu.gcr.io/amazing-chalice-243510/web@sha256:0c0691485ff10b2318ce378fcb37a77130db556d8cba9f895a6bf6814774b604",
          "name": "triliovault-web"
        },
        {
          "digest": "sha256:c66c43fde40f9bf910b56c519d09cea3509de03973c6962ae57ceb3e924a9542",
          "image": "eu.gcr.io/amazing-chalice-243510/web-backend@sha256:c66c43fde40f9bf910b56c519d09cea3509de03973c6962ae57ceb3e924a9542",
          "name": "triliovault-web-backend"
        },
        {
          "digest": "sha256:040caf348ac11511b63271dd473bf31bf1d96d3e0fcbfc40e6d1bf4df2bb0f76",
          "image": "eu.gcr.io/amazing-chalice-243510/dex@sha256:040caf348ac11511b63271dd473bf31bf1d96d3e0fcbfc40e6d1bf4df2bb0f76",
          "name": "triliovault-dex"
        },
        {
          "digest": "sha256:73dd29b19b61a8fea3c4b94c7e479a5bc4546abf00deb35d47341b83246abf62",
          "image": "eu.gcr.io/amazing-chalice-243510/trilio-init@sha256:73dd29b19b61a8fea3c4b94c7e479a5bc4546abf00deb35d47341b83246abf62",
          "name": "webhook-init"
        },
        {
          "digest": "sha256:73dd29b19b61a8fea3c4b94c7e479a5bc4546abf00deb35d47341b83246abf62",
          "image": "eu.gcr.io/amazing-chalice-243510/trilio-init@sha256:73dd29b19b61a8fea3c4b94c7e479a5bc4546abf00deb35d47341b83246abf62",
          "name": "dex-init"
        },
        {
          "digest": "sha256:dc868ce5d6aa0f0fb194af84951f3e22922aa523f17ca1d7174441d72022cb77",
          "image": "eu.gcr.io/amazing-chalice-243510/metamover@sha256:dc868ce5d6aa0f0fb194af84951f3e22922aa523f17ca1d7174441d72022cb77",
          "name": "metamover"
        },
        {
          "digest": "sha256:222b9317935dd19e9a333520bdf0b1f68d9768880bce6f482cb1b2250806da76",
          "image": "eu.gcr.io/amazing-chalice-243510/datamover@sha256:222b9317935dd19e9a333520bdf0b1f68d9768880bce6f482cb1b2250806da76",
          "name": "datamover"
        },
        {
          "digest": "sha256:806090cc5ac8a65fcc5e90d82143dc7df230f742c29ff1c21e685bb49879aaa7",
          "image": "eu.gcr.io/amazing-chalice-243510/datastore-attacher@sha256:806090cc5ac8a65fcc5e90d82143dc7df230f742c29ff1c21e685bb49879aaa7",
          "name": "datastore_attacher"
        },
        {
          "digest": "sha256:8b3f03459aedfb7829dad4c2e9f731d2f11abf9ba38319c3d2f0d8303a642c5e",
          "image": "eu.gcr.io/amazing-chalice-243510/backup-scheduler@sha256:8b3f03459aedfb7829dad4c2e9f731d2f11abf9ba38319c3d2f0d8303a642c5e",
          "name": "backup_scheduler"
        },
        {
          "digest": "sha256:e687443babeb3b9850aa3050b6c6935976358bcdea66666fb79b487ee35c5c25",
          "image": "eu.gcr.io/amazing-chalice-243510/backup-cleaner@sha256:e687443babeb3b9850aa3050b6c6935976358bcdea66666fb79b487ee35c5c25",
          "name": "backup_cleaner"
        },
        {
          "digest": "sha256:3eb71f17b6b04a7207f3cc921f29cd070993402d951aa940a6c0be61733fe958",
          "image": "eu.gcr.io/amazing-chalice-243510/backup-retention@sha256:3eb71f17b6b04a7207f3cc921f29cd070993402d951aa940a6c0be61733fe958",
          "name": "backup_retention"
        },
        {
          "digest": "sha256:6729338fadd130c21e830fc9c5dacb4efae3ffb37427c415d377ee7c8f152872",
          "image": "eu.gcr.io/amazing-chalice-243510/target-browser@sha256:6729338fadd130c21e830fc9c5dacb4efae3ffb37427c415d377ee7c8f152872",
          "name": "target_browser"
        },
        {
          "digest": "sha256:7a76cad51eab8ceb492426507cf6c92ed90047184ae2a8d0ce6c2e1a57762078",
          "image": "eu.gcr.io/amazing-chalice-243510/hook-executor@sha256:7a76cad51eab8ceb492426507cf6c92ed90047184ae2a8d0ce6c2e1a57762078",
          "name": "hook"
        },
        {
          "digest": "sha256:08b4bb891506388fe6bc96490c3ee8117a2c4b7f99919e2e8a5333d2bc12ee5d",
          "image": "eu.gcr.io/amazing-chalice-243510/resource-cleaner@sha256:08b4bb891506388fe6bc96490c3ee8117a2c4b7f99919e2e8a5333d2bc12ee5d",
          "name": "resource_cleaner"
        },
        {
          "digest": "sha256:6015efd6fe0f935ee77588573d1f1e8c4a4d453d27e6925ef1c89fbab0aa1068",
          "image": "eu.gcr.io/amazing-chalice-243510/minio@sha256:6015efd6fe0f935ee77588573d1f1e8c4a4d453d27e6925ef1c89fbab0aa1068",
          "name": "minio"
        },
        {
          "digest": "sha256:040caf348ac11511b63271dd473bf31bf1d96d3e0fcbfc40e6d1bf4df2bb0f76",
          "image": "eu.gcr.io/amazing-chalice-243510/dex@sha256:040caf348ac11511b63271dd473bf31bf1d96d3e0fcbfc40e6d1bf4df2bb0f76",
          "name": "dex"
        },
        {
          "digest": "sha256:73dd29b19b61a8fea3c4b94c7e479a5bc4546abf00deb35d47341b83246abf62",
          "image": "eu.gcr.io/amazing-chalice-243510/trilio-init@sha256:73dd29b19b61a8fea3c4b94c7e479a5bc4546abf00deb35d47341b83246abf62",
          "name": "tvk_init"
        }
      ],
      "replaces": "",
      "skip_range": "<2.7.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2.7.0",
      "version_original": "2.7.0"
    },
    {
      "_id": "6234600b670f4cadbafad2ad",
      "alm_examples": [
        {
          "api_version": "game.marketplace.redhat.com/v1",
          "kind": "Arcade",
          "metadata": {
            "name": "arcade-sample"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/rhm-labs/arcade-operator-bundle@sha256:f5f025c7f56643fab9148bb5de8ee34a84d02b78a6abb4b5592306cf54296654",
      "bundle_path_digest": "sha256:f5f025c7f56643fab9148bb5de8ee34a84d02b78a6abb4b5592306cf54296654",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-03-18T10:33:47.098000+00:00",
      "csv_description": "RHM Arcade Operator - a simple operator used to showcase how to build an operator around an existing web application that can can run on Openshift, Vanilla k8s, or on-boarded to Red Hat Marketplace.",
      "csv_display_name": "Arcade Operator",
      "csv_metadata_description": "",
      "csv_name": "marketplace-games-operator.v1.0.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:42:18.105000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "marketplace-games-operator",
      "provided_apis": [
        {
          "group": "game.marketplace.redhat.com",
          "kind": "Arcade",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:e10d1d982dd653db74ca87a1d1ad017bc5ef1aeb651bdea089debf16485b080b",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:e10d1d982dd653db74ca87a1d1ad017bc5ef1aeb651bdea089debf16485b080b",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:d6959be6693728d2dc4cd38b69251551d23c5002cb52db2684df31a0a8f7b0ab",
          "image": "registry.connect.redhat.com/rhm-labs/arcade-operator@sha256:d6959be6693728d2dc4cd38b69251551d23c5002cb52db2684df31a0a8f7b0ab",
          "name": "manager"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.0.0",
      "version_original": "1.0.0"
    },
    {
      "_id": "6234600c670f4cadbafad2ae",
      "alm_examples": [
        {
          "api_version": "cassandra.datastax.com/v1beta1",
          "kind": "CassandraDatacenter",
          "metadata": {
            "name": "dc1"
          },
          "spec": {
            "clusterName": "development",
            "config": {
              "cassandra-yaml": {
                "authenticator": "PasswordAuthenticator",
                "authorizer": "CassandraAuthorizer",
                "num_tokens": 16,
                "role_manager": "CassandraRoleManager"
              },
              "jvm-server-options": {
                "initial_heap#": "1G",
                "max_heap#": "1G"
              }
            },
            "dockerImageRunsAsCassandra": false,
            "managementApiAuth": {
              "insecure": {}
            },
            "podTemplateSpec": {
              "containers": [
                {
                  "name": "cassandra",
                  "securityContext": {}
                }
              ],
              "securityContext": {}
            },
            "racks": [
              {
                "name": "rack1"
              }
            ],
            "resources": {
              "requests": {
                "cpu": "1000m",
                "memory": "2Gi"
              }
            },
            "serverType": "cassandra",
            "serverVersion": "4.0.1",
            "size": 3,
            "storageConfig": {
              "cassandraDataVolumeClaimSpec": {
                "accessModes": [
                  "ReadWriteOnce"
                ],
                "resources": {
                  "requests": {
                    "storage": "10Gi"
                  }
                },
                "storageClassName": "server-storage"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/datastax/cass-operator-bundle@sha256:ab3fdcc6fab45909f7824bf3c794b27a166c3faa920f5bf3326c4623b02c27d2",
      "bundle_path_digest": "sha256:ab3fdcc6fab45909f7824bf3c794b27a166c3faa920f5bf3326c4623b02c27d2",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:33:48.513000+00:00",
      "csv_description": "## Apache Cassandra\n\nThe Apache Cassandra database is the right choice when you need scalability and\nhigh availability without compromising performance. Linear scalability and\nproven fault-tolerance on commodity hardware or cloud infrastructure make it the\nperfect platform for mission-critical data. Cassandra's support for replicating\nacross multiple datacenters is best-in-class, providing lower latency for your\nusers and the peace of mind of knowing that you can survive regional outages.\n\n## DataStax Enterprise\n\nThe most advanced distribution of Apache Cassandra\u2122 on the market, with the\nenterprise functionality needed for serious production systems and backed up and\nsupported by the best distributed-experts in the world. It's one platform for\nall types of applications anywhere, any cloud, any model: key-value, graph,\ntabular, JSON.\n\nDataStax Enterprise is a fully integrated and optimized database, with graph,\nanalytics, and search included, all with a unified security model. Simply put,\nit's the only database capable of meeting today's demanding requirements\n\n## Operator Details\n\n`cass-operator` is designed as a modular operator for Apache Cassandra and\nderived  distributions. Apache Cassandra is a distributed database consisting of\nmultiple nodes working in concert to store data and process queries along a\nnumber of fault domains. `cass-operator` has the deployment of a Cassandra\ncluster around the logical domain of a datacenter with the `CassandraDatacenter`\ncustom resource.\n    \nUpon submission of one of these resources it handles provisioning the underlying\nstateful sets (analogous to C\\* logical racks), services, and configuration.\nAdditionally through monitoring pod state via Kubernetes callbacks it handles day to day\noperations such as restarting failed processes, scaling clusters up, and deploying\nconfiguration changes in a rolling, non-disruptive, fashion.\n    \nThis operator is designed to be `Namespace` scoped. A single Kubernetes cluster may\nbe running multiple instances of this operator, in separate namespaces, to support\na number of C\\* clusters and environments. Configuration is simple with the usage of\nYAML based overrides in the Custom Resource paired with an `init` container.\n    \nIn C\\* clusters ordering and timing of certain operations are important to keep the system\nevenly distributed. `cass-operator` takes advantage of a sidecar process within the\nmain container to handle the orchestration of starting our main C* process.",
      "csv_display_name": "DataStax Kubernetes Operator for Apache Cassandra",
      "csv_metadata_description": "Simple provisioning, turn-key operations, and automated remediation of Apache Cassandra clusters\n",
      "csv_name": "cass-operator.v1.10.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:37:47.714000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "cass-operator",
      "provided_apis": [
        {
          "group": "cassandra.datastax.com",
          "kind": "CassandraDatacenter",
          "version": "v1beta1"
        },
        {
          "group": "control.k8ssandra.io",
          "kind": "CassandraTask",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:ae709b680dde2aa43c92d6b331af0554c9af92aa9fad673454892ca2b40bd3f7",
          "image": "registry.connect.redhat.com/datastax/cass-operator@sha256:ae709b680dde2aa43c92d6b331af0554c9af92aa9fad673454892ca2b40bd3f7",
          "name": "cass-operator"
        },
        {
          "digest": "sha256:33e75d0c78a277cdc37be24f2b116cade0d9b7dc7249610cdf9bf0705c8a040e",
          "image": "registry.connect.redhat.com/datastax/system-logger@sha256:33e75d0c78a277cdc37be24f2b116cade0d9b7dc7249610cdf9bf0705c8a040e",
          "name": "system-logger"
        },
        {
          "digest": "sha256:ae709b680dde2aa43c92d6b331af0554c9af92aa9fad673454892ca2b40bd3f7",
          "image": "registry.connect.redhat.com/datastax/cass-operator@sha256:ae709b680dde2aa43c92d6b331af0554c9af92aa9fad673454892ca2b40bd3f7",
          "name": "cass-operator-ae709b680dde2aa43c92d6b331af0554c9af92aa9fad673454892ca2b40bd3f7-annotation"
        },
        {
          "digest": "sha256:ae709b680dde2aa43c92d6b331af0554c9af92aa9fad673454892ca2b40bd3f7",
          "image": "registry.connect.redhat.com/datastax/cass-operator@sha256:ae709b680dde2aa43c92d6b331af0554c9af92aa9fad673454892ca2b40bd3f7",
          "name": "manager"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.10.1",
      "version_original": "1.10.1"
    },
    {
      "_id": "6234600f670f4cadbafad2af",
      "alm_examples": [
        {
          "api_version": "citrix.citrix.com/v1alpha1",
          "kind": "Citrix-adc-istio-ingress-gateway",
          "metadata": {
            "name": "cxa-ingress-gateway-sample"
          },
          "spec": {
            "ADMSettings": {
              "ADMIP": "",
              "bandWidth": "",
              "bandWidthLicense": false,
              "cpxCores": "",
              "licenseServerIP": "",
              "licenseServerPort": 27000,
              "vCPULicense": false
            },
            "certProvider": {
              "caAddr": "istiod.istio-system.svc",
              "caPort": 15012,
              "certTTLinHours": 720,
              "clusterId": "Kubernetes",
              "jwtPolicy": "",
              "trustDomain": "cluster.local"
            },
            "citrixCPX": false,
            "coe": {
              "coeTracing": false,
              "coeURL": ""
            },
            "ingressGateway": {
              "EULA": false,
              "adcServerName": "",
              "httpNodePort": 30180,
              "httpsNodePort": 31443,
              "image": "quay.io/citrix/citrix-k8s-cpx-ingress@sha256:8f28c8af17909f0c0ced2109701755be1edea22b2a80f00aa37da70168abe1dc",
              "imagePullPolicy": "IfNotPresent",
              "label": "citrix-ingressgateway",
              "lightWeightCPX": 1,
              "mgmtHttpPort": 10080,
              "mgmtHttpsPort": 10443,
              "multiClusterIngress": false,
              "multiClusterListenerNodePort": 32443,
              "multiClusterListenerPort": 15443,
              "multiClusterSvcDomain": "global",
              "netProfile": "",
              "netscalerUrl": "",
              "nodePortRequired": false,
              "secretVolumes": [],
              "tcpPort": [],
              "vserverIP": "nsip"
            },
            "istioPilot": {
              "insecureGrpcPort": 15010,
              "name": "istiod",
              "namespace": "istio-system",
              "secureGrpcPort": 15012
            },
            "metricExporter": {
              "image": "quay.io/citrix/citrix-adc-metrics-exporter@sha256:edc7f42fed88a1652904abb3a9cca09cd555374320a55693087eea2da629e536",
              "imagePullPolicy": "IfNotPresent",
              "logLevel": "ERROR",
              "port": 8888,
              "required": true,
              "secure": "YES"
            },
            "secretName": "nslogin",
            "xDSAdaptor": {
              "image": "quay.io/citrix/citrix-xds-adaptor@sha256:b5b5ab8435d65dcbe4348c0f1b4b69fef8fcc8a27e67927821ff4b4f0b8594f6",
              "imagePullPolicy": "IfNotPresent",
              "jsonLog": false,
              "logLevel": "DEBUG",
              "proxyType": "router",
              "secureConnect": true
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/citrix/istioingressgateway-bundle@sha256:5af6bafd200b94629bf0c5371a779ec19a726225821daa796d494fa99ef2c6e8",
      "bundle_path_digest": "sha256:5af6bafd200b94629bf0c5371a779ec19a726225821daa796d494fa99ef2c6e8",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-03-18T10:33:51.659000+00:00",
      "csv_description": "An Istio ingress gateway acts as an entry point for the incoming traffic and secures and controls access to the service mesh from outside. It also performs routing and load balancing. Citrix ADC CPX, MPX, or VPX can be deployed as an ingress gateway to the Istio service mesh",
      "csv_display_name": "Citrix ADC Istio Ingress Gateway Operator",
      "csv_metadata_description": "An Istio ingress gateway acts as an entry point for the incoming traffic. Citrix ADC CPX, MPX, or VPX can be deployed as an ingress gateway to the Istio service jeee An Istio ingress gateway acts as an entry point for the incoming traffic and secures and controls access to the service mesh from outside. It also perform routing and load balancing. Citrix ADC CPX, MPX, or VPX can be deployed as an ingress gateway to the Istio service mesh.",
      "csv_name": "citrix-adc-istio-ingress-gateway-operator.v0.9.9",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:37:04.759000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "citrix-adc-istio-ingress-gateway-operator",
      "provided_apis": [
        {
          "group": "citrix.citrix.com",
          "kind": "Citrix-adc-istio-ingress-gateway",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:8333b7fb73ad7479be45cb6a71d391554480ee0a623744e0a2e185cd1f45c226",
          "image": "registry.connect.redhat.com/citrix/citrix-adc-istio-ingress-gateway@sha256:8333b7fb73ad7479be45cb6a71d391554480ee0a623744e0a2e185cd1f45c226",
          "name": "citrix-adc-istio-ingress-gateway-8333b7fb73ad7479be45cb6a71d391554480ee0a623744e0a2e185cd1f45c226-annotation"
        },
        {
          "digest": "sha256:a5c16c64229aac3564c66816c123e81a849ff93b8a443cd6ff14bd8d63c06644",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:a5c16c64229aac3564c66816c123e81a849ff93b8a443cd6ff14bd8d63c06644",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:8333b7fb73ad7479be45cb6a71d391554480ee0a623744e0a2e185cd1f45c226",
          "image": "registry.connect.redhat.com/citrix/citrix-adc-istio-ingress-gateway@sha256:8333b7fb73ad7479be45cb6a71d391554480ee0a623744e0a2e185cd1f45c226",
          "name": "manager"
        },
        {
          "digest": "sha256:b5b5ab8435d65dcbe4348c0f1b4b69fef8fcc8a27e67927821ff4b4f0b8594f6",
          "image": "quay.io/citrix/citrix-xds-adaptor@sha256:b5b5ab8435d65dcbe4348c0f1b4b69fef8fcc8a27e67927821ff4b4f0b8594f6",
          "name": "citrix-xds-adaptor-b5b5ab8435d65dcbe4348c0f1b4b69fef8fcc8a27e67927821ff4b4f0b8594f6-annotation"
        },
        {
          "digest": "sha256:edc7f42fed88a1652904abb3a9cca09cd555374320a55693087eea2da629e536",
          "image": "quay.io/citrix/citrix-adc-metrics-exporter@sha256:edc7f42fed88a1652904abb3a9cca09cd555374320a55693087eea2da629e536",
          "name": "citrix-adc-metrics-exporter-edc7f42fed88a1652904abb3a9cca09cd555374320a55693087eea2da629e536-annotation"
        },
        {
          "digest": "sha256:8f28c8af17909f0c0ced2109701755be1edea22b2a80f00aa37da70168abe1dc",
          "image": "quay.io/citrix/citrix-k8s-cpx-ingress@sha256:8f28c8af17909f0c0ced2109701755be1edea22b2a80f00aa37da70168abe1dc",
          "name": "citrix-k8s-cpx-ingress-8f28c8af17909f0c0ced2109701755be1edea22b2a80f00aa37da70168abe1dc-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "0.9.9",
      "version_original": "0.9.9"
    },
    {
      "_id": "6234601a06c5dada0193e087",
      "alm_examples": [
        {
          "api_version": "pmem-csi.intel.com/v1beta1",
          "kind": "PmemCSIDeployment",
          "metadata": {
            "name": "pmem-csi.intel.com"
          },
          "spec": {
            "deviceMode": "lvm",
            "nodeSelector": {
              "feature.node.kubernetes.io/memory-nv.dax": "true"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/intel/pmem-csi-operator-os@sha256:72c1ec043ba8bba57e710d1cabac54374612a18cbce05caca9b14310942faa8d",
      "bundle_path_digest": "sha256:72c1ec043ba8bba57e710d1cabac54374612a18cbce05caca9b14310942faa8d",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-03-18T10:34:02.440000+00:00",
      "csv_description": "\nIntel PMEM-CSI is a [CSI](https://github.com/container-storage-interface/spec)\nstorage driver for container orchestrators like Kubernetes. It makes local\npersistent memory ([PMEM](https://pmem.io/)) available as a filesystem volume to\ncontainer applications. This is the operator to deploy and manage the\n[PMEM-CSI](https://intel.github.io/pmem-csi/1.0/README.html)\ndriver on a Kubernetes cluster.\n\nRefer to the [PMEM-CSI documentation](https://intel.github.io/pmem-csi/1.0/README.html)\nfor more details on deploying and using the PMEM-CSI driver.\n",
      "csv_display_name": "Operator for PMEM-CSI driver",
      "csv_metadata_description": "An operator for deploying and managing the PMEM-CSI driver",
      "csv_name": "pmem-csi-operator.v1.0.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-06-17T01:42:55.245000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "pmem-csi-operator-os",
      "provided_apis": [
        {
          "group": "pmem-csi.intel.com",
          "kind": "PmemCSIDeployment",
          "version": "v1beta1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:09c98a6588f3d9227f8ae8fc175b533b38590048b79cbdf367eeaa140926010a",
          "image": "registry.connect.redhat.com/intel/pmem-csi-driver-os@sha256:09c98a6588f3d9227f8ae8fc175b533b38590048b79cbdf367eeaa140926010a",
          "name": "pmem-csi-driver-os-09c98a6588f3d9227f8ae8fc175b533b38590048b79cbdf367eeaa140926010a-annotation"
        },
        {
          "digest": "sha256:09c98a6588f3d9227f8ae8fc175b533b38590048b79cbdf367eeaa140926010a",
          "image": "registry.connect.redhat.com/intel/pmem-csi-driver-os@sha256:09c98a6588f3d9227f8ae8fc175b533b38590048b79cbdf367eeaa140926010a",
          "name": "pmem-csi-operator"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.0.0",
      "version_original": "1.0.0"
    },
    {
      "_id": "6234601f5593ce895a7b5364",
      "alm_examples": [
        {
          "api_version": "pmem-csi.intel.com/v1beta1",
          "kind": "PmemCSIDeployment",
          "metadata": {
            "name": "pmem-csi.intel.com"
          },
          "spec": {
            "deviceMode": "lvm",
            "nodeSelector": {
              "feature.node.kubernetes.io/memory-nv.dax": "true"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/intel/pmem-csi-operator-os@sha256:72c1ec043ba8bba57e710d1cabac54374612a18cbce05caca9b14310942faa8d",
      "bundle_path_digest": "sha256:72c1ec043ba8bba57e710d1cabac54374612a18cbce05caca9b14310942faa8d",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:34:07.862000+00:00",
      "csv_description": "\nIntel PMEM-CSI is a [CSI](https://github.com/container-storage-interface/spec)\nstorage driver for container orchestrators like Kubernetes. It makes local\npersistent memory ([PMEM](https://pmem.io/)) available as a filesystem volume to\ncontainer applications. This is the operator to deploy and manage the\n[PMEM-CSI](https://intel.github.io/pmem-csi/1.0/README.html)\ndriver on a Kubernetes cluster.\n\nRefer to the [PMEM-CSI documentation](https://intel.github.io/pmem-csi/1.0/README.html)\nfor more details on deploying and using the PMEM-CSI driver.\n",
      "csv_display_name": "Operator for PMEM-CSI driver",
      "csv_metadata_description": "An operator for deploying and managing the PMEM-CSI driver",
      "csv_name": "pmem-csi-operator.v1.0.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:43:01.702000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "pmem-csi-operator-os",
      "provided_apis": [
        {
          "group": "pmem-csi.intel.com",
          "kind": "PmemCSIDeployment",
          "version": "v1beta1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:09c98a6588f3d9227f8ae8fc175b533b38590048b79cbdf367eeaa140926010a",
          "image": "registry.connect.redhat.com/intel/pmem-csi-driver-os@sha256:09c98a6588f3d9227f8ae8fc175b533b38590048b79cbdf367eeaa140926010a",
          "name": "pmem-csi-driver-os-09c98a6588f3d9227f8ae8fc175b533b38590048b79cbdf367eeaa140926010a-annotation"
        },
        {
          "digest": "sha256:09c98a6588f3d9227f8ae8fc175b533b38590048b79cbdf367eeaa140926010a",
          "image": "registry.connect.redhat.com/intel/pmem-csi-driver-os@sha256:09c98a6588f3d9227f8ae8fc175b533b38590048b79cbdf367eeaa140926010a",
          "name": "pmem-csi-operator"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.0.0",
      "version_original": "1.0.0"
    },
    {
      "_id": "623460225593ce895a7b5365",
      "alm_examples": [
        {
          "api_version": "rc.app.stacks/v1beta2",
          "kind": "RuntimeComponent",
          "metadata": {
            "name": "runtimecomponent-sample"
          },
          "spec": {
            "applicationImage": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
            "expose": true,
            "replicas": 1,
            "service": {
              "port": 9080
            }
          }
        },
        {
          "api_version": "rc.app.stacks/v1beta2",
          "kind": "RuntimeOperation",
          "metadata": {
            "name": "runtimeoperation-sample"
          },
          "spec": {
            "command": [
              "./your_script.sh"
            ],
            "containerName": "app",
            "podName": "Specify_Pod_Name_Here"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/runtime-component-operator-bundle@sha256:65cc8aa40608b76956ff8c19316b63f805d7a28e8d7697b9ea1d427888a2ccdf",
      "bundle_path_digest": "sha256:65cc8aa40608b76956ff8c19316b63f805d7a28e8d7697b9ea1d427888a2ccdf",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "beta2",
      "creation_date": "2022-03-18T10:34:10.464000+00:00",
      "csv_description": "This advanced Operator is capable of deploying any runtime component image with consistent, production-grade QoS. It enables enterprise architects to govern the way their applications get deployed & managed in the cluster, while dramatically reducing the learning curve for developers to deploy into Kubernetes - allowing them to focus on writing the code!\nHere are some key features:\n\n#### Application Lifecyle\nYou can deploy your runtime component container by either pointing to a container image, or an OpenShift ImageStream. When using an ImageStream the Operator will watch for any updates and will re-deploy the modified image.\n\n#### Custom RBAC\nThis Operator is capable of using a custom ServiceAccount from the caller, allowing it to follow RBAC restrictions. By default it creates a ServiceAccount if one is not specified, which can also be bound with specific roles.\n\n#### Environment Configuration\nYou can configure a variety of artifacts with your deployment, such as: labels, annotations, and environment variables from a ConfigMap, a Secret or a value.\n\n#### Routing\nExpose your application to external users via a single toggle to create a Route on OpenShift or an Ingress on other Kubernetes environments. Advanced configuration, such as TLS settings, are also easily enabled.  Expiring Route certificates are re-issued.\n\n#### High Availability via Horizontal Pod Autoscaling\nRun multiple instances of your application for high availability. Either specify a static number of replicas or easily configure horizontal auto scaling to create (and delete) instances based on resource consumption.\n\n#### Persistence and advanced storage\nEnable persistence for your application by specifying simple requirements: just tell us the size of the storage and where you would like it to be mounted and We will create and manage that storage for you.\nThis toggles a StatefulSet resource instead of a Deployment resource, so your container can recover transactions and state upon a pod restart.\nWe offer an advanced mode where the user specifies a built-in PersistentVolumeClaim, allowing them to configure many details of the persistent volume, such as its storage class and access mode.\n\n#### Service Binding\nEasily bind to available services in your cluster.  Your runtime components can expose and consume other services by simply specifying the target endpoinds: we take care of the heavy lifting such as creating k8s Secrets, injecting them into your container and watching for any changes in configuration!  This way your applications can dynamically reconnect to its required services without any intervention or interruption.\n\n#### Exposing metrics to Prometheus\nThe Runtime Component Operator exposes the runtime container's metrics via the [Prometheus Operator](https://operatorhub.io/operator/prometheus).\nUsers can pick between a basic mode, where they simply specify the label that Prometheus is watching to scrape the metrics from the container, or they can specify the full `ServiceMonitor` spec embedded into the RuntimeComponent's `spec.monitoring` key controlling things like the poll internal and security credentials.\n\n#### Easily mount logs and transaction directories\nIf you need to mount the logs and transaction data from your runtime component to an external volume such as NFS (or any storage supported in your cluster), simply add the following (customizing the folder location and size) to your RuntimeComponent CR:\n``` storage: size: 2Gi mountPath: \"/logs\" ```\n\n#### Integration with OpenShift Serverless\nDeploy your serverless runtime component using a single toggle.  The Operator will convert all of its generated resources into [Knative](https://knative.dev) resources, allowing your pod to automatically scale to 0 when it is idle.\n\n#### Integration with OpenShift's Topology UI\nWe set the corresponding labels to support OpenShift's Developer Topology UI, which allows you to visualize your entire set of deployments and how they are connected.\n\nSee our [**documentation**](https://github.com/application-stacks/runtime-component-operator/tree/main/doc/) for more information.\n",
      "csv_display_name": "Runtime Component",
      "csv_metadata_description": "Deploys any runtime component with dynamic and auto-tuning configuration",
      "csv_name": "runtime-component.v0.8.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:41:05.726000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "runtime-component-operator-certified",
      "provided_apis": [
        {
          "group": "rc.app.stacks",
          "kind": "RuntimeComponent",
          "version": "v1beta2"
        },
        {
          "group": "rc.app.stacks",
          "kind": "RuntimeOperation",
          "version": "v1beta2"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:febfbe4a75018bfdb1f3cb13caaa3e5e321bf9f8ac5ca1405dae96f9798bde2b",
          "image": "registry.connect.redhat.com/ibm/runtime-component-operator@sha256:febfbe4a75018bfdb1f3cb13caaa3e5e321bf9f8ac5ca1405dae96f9798bde2b",
          "name": "runtime-component-operator-febfbe4a75018bfdb1f3cb13caaa3e5e321bf9f8ac5ca1405dae96f9798bde2b-annotation"
        },
        {
          "digest": "sha256:febfbe4a75018bfdb1f3cb13caaa3e5e321bf9f8ac5ca1405dae96f9798bde2b",
          "image": "registry.connect.redhat.com/ibm/runtime-component-operator@sha256:febfbe4a75018bfdb1f3cb13caaa3e5e321bf9f8ac5ca1405dae96f9798bde2b",
          "name": "manager"
        },
        {
          "digest": "sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "image": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "name": "open-liberty-samples-8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "0.8.0",
      "version_original": "0.8.0"
    },
    {
      "_id": "623460245593ce895a7b5366",
      "alm_examples": [
        {
          "api_version": "anzo.cambridgesemantics.com/v1",
          "kind": "Anzo",
          "metadata": {
            "name": "agent01"
          },
          "spec": {
            "nodeConfig": {
              "spec": {
                "replicas": 1,
                "selector": {
                  "matchLabels": {
                    "app": "anzo"
                  }
                },
                "serviceName": "anzo-agent01",
                "template": {
                  "metadata": {
                    "labels": {
                      "app": "anzo"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "image": "registry.connect.redhat.com/cambridgesemantics/anzo@sha256:d1c2d54ca205d669c5ea1bb6aae105afe2385cc5695cecd78423ffa1d98929f8",
                        "name": "anzo",
                        "resources": {
                          "limits": {
                            "cpu": "4000m",
                            "memory": "12Gi"
                          },
                          "requests": {
                            "cpu": "4000m",
                            "memory": "12Gi"
                          }
                        }
                      }
                    ],
                    "serviceAccountName": "anzo-operator"
                  }
                }
              }
            },
            "role": "AnzoAgent"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cambridgesemantics/anzo-operator-bundle@sha256:28703523a1c160570fc23fb1236d2a02108b97e4423d42b0d3cde98c94d351cb",
      "bundle_path_digest": "sha256:28703523a1c160570fc23fb1236d2a02108b97e4423d42b0d3cde98c94d351cb",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:34:12.674000+00:00",
      "csv_description": "The Anzo Operator provides the way to install and configure an anzo agent setup on Red Hat K8S environment.\nCurrently, this is supported only through when deployed as an Anzo Agent as part of an Anzo Unstructured deployment.\n\n### Installation\n Refer [installation instructions]( https://github.com/cambridgesemantics/csi-k8s-operator-anzo/blob/v2.0.0/README.md )\n\n### Documentation\n\nYou can find our documentation [here.]( https://docs.cambridgesemantics.com/anzo/userdoc/cloud-deployments.htm )\n\n### Support\n\nWe offer Support to our customers through [ Cambridge Semantics Customer Center ]( https://customercenter.cambridgesemantics.com/ ).",
      "csv_display_name": "Anzo Operator",
      "csv_metadata_description": "kubernetes operator for Anzo",
      "csv_name": "anzo-operator.v2.0.101",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:38:30.474000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "anzo-operator",
      "provided_apis": [
        {
          "group": "anzo.cambridgesemantics.com",
          "kind": "Anzo",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:563e964f5771b9bfd860ea993b6e0936a54504908f5b2d1dff6f99ade74bb7a0",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-operator@sha256:563e964f5771b9bfd860ea993b6e0936a54504908f5b2d1dff6f99ade74bb7a0",
          "name": "anzo-operator-563e964f5771b9bfd860ea993b6e0936a54504908f5b2d1dff6f99ade74bb7a0-annotation"
        },
        {
          "digest": "sha256:563e964f5771b9bfd860ea993b6e0936a54504908f5b2d1dff6f99ade74bb7a0",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo-operator@sha256:563e964f5771b9bfd860ea993b6e0936a54504908f5b2d1dff6f99ade74bb7a0",
          "name": "manager"
        },
        {
          "digest": "sha256:d1c2d54ca205d669c5ea1bb6aae105afe2385cc5695cecd78423ffa1d98929f8",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo@sha256:d1c2d54ca205d669c5ea1bb6aae105afe2385cc5695cecd78423ffa1d98929f8",
          "name": "anzo"
        },
        {
          "digest": "sha256:d1c2d54ca205d669c5ea1bb6aae105afe2385cc5695cecd78423ffa1d98929f8",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzo@sha256:d1c2d54ca205d669c5ea1bb6aae105afe2385cc5695cecd78423ffa1d98929f8",
          "name": "anzo-d1c2d54ca205d669c5ea1bb6aae105afe2385cc5695cecd78423ffa1d98929f8-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2.0.0",
      "version_original": "2.0.0"
    },
    {
      "_id": "623460265593ce895a7b5367",
      "alm_examples": [
        {
          "api_version": "anzograph.clusters.cambridgesemantics.com/v2",
          "kind": "AnzoGraph",
          "metadata": {
            "name": "azg01"
          },
          "spec": {
            "db": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app_data": "anzograph-data-grpc",
                      "app_mgmt": "anzograph-mgmt-grpc"
                    }
                  },
                  "serviceName": "anzograph-azg01",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app_data": "anzograph-data-grpc",
                        "app_mgmt": "anzograph-mgmt-grpc"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:8a5bd26551990929fdb776d6b421a9713cb84e03b19c18f81b625582f7f41af5",
                          "name": "db",
                          "resources": {
                            "limits": {
                              "cpu": "8000m",
                              "memory": "8Gi"
                            },
                            "requests": {
                              "cpu": "8000m",
                              "memory": "8Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "anzograph-operator"
                    }
                  }
                }
              }
            },
            "deployFrontend": false,
            "frontend": {
              "nodeConfig": {
                "spec": {
                  "replicas": 1,
                  "selector": {
                    "matchLabels": {
                      "app_mgmt": "anzograph-frontend"
                    }
                  },
                  "serviceName": "anzograph-azg01",
                  "template": {
                    "metadata": {
                      "labels": {
                        "app_mgmt": "anzograph-frontend"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:c1443bcdc8e998fc699f61980a665f1a083350adf2d3d1d55a7cb55e31ca50b3",
                          "name": "frontend",
                          "resources": {
                            "limits": {
                              "cpu": "2000m",
                              "memory": "4Gi"
                            },
                            "requests": {
                              "cpu": "2000m",
                              "memory": "4Gi"
                            }
                          }
                        }
                      ],
                      "serviceAccountName": "anzograph-operator"
                    }
                  }
                }
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cambridgesemantics/anzograph-operator-bundle@sha256:9418a3505873ac387f2b5455ec7e696739a2bb6f03232f8c0f59489c605b96f2",
      "bundle_path_digest": "sha256:9418a3505873ac387f2b5455ec7e696739a2bb6f03232f8c0f59489c605b96f2",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:34:14.980000+00:00",
      "csv_description": "The AnzoGraph Operator provides the way to install and configure an AnzoGraph\ncluster on Red Hat K8S environment.\n\n### Installation\n Refer [installation instructions]( https://github.com/cambridgesemantics/csi-k8s-operator-anzograph/blob/v2.0.1/README_openshift_marketplace.md )\n\n### Documentation\n\nYou can find our documentation [here.]( https://docs.cambridgesemantics.com/anzograph/userdoc/ )\n\n### Support\n\nWe offer Support to our customers with the AnzoGraph db Enterprise Edition License [here]( https://customercenter.cambridgesemantics.com/ ). For AnzoGraph db Free Edition questions, get help from our Anzograph User Community at Stack Overflow. When submitting a question, include the tag 'anzograph'.",
      "csv_display_name": "AnzoGraph Operator",
      "csv_metadata_description": "kubernetes operator for AnzoGraph DB",
      "csv_name": "anzograph-operator.v2.0.102",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:34:42.475000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "anzograph-operator",
      "provided_apis": [
        {
          "group": "anzograph.clusters.cambridgesemantics.com",
          "kind": "AnzoGraph",
          "version": "v2"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:a5b212558f748ddc8156541b546290320b656506e039a18903ad9fa6e638e732",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-operator@sha256:a5b212558f748ddc8156541b546290320b656506e039a18903ad9fa6e638e732",
          "name": "anzograph-operator-a5b212558f748ddc8156541b546290320b656506e039a18903ad9fa6e638e732-annotation"
        },
        {
          "digest": "sha256:a5b212558f748ddc8156541b546290320b656506e039a18903ad9fa6e638e732",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-operator@sha256:a5b212558f748ddc8156541b546290320b656506e039a18903ad9fa6e638e732",
          "name": "manager"
        },
        {
          "digest": "sha256:e3bdddf811b5ba69f388d023aea1ba538edd00e9f415c33ec555321d39129a36",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph@sha256:e3bdddf811b5ba69f388d023aea1ba538edd00e9f415c33ec555321d39129a36",
          "name": "anzograph_allinone"
        },
        {
          "digest": "sha256:8a5bd26551990929fdb776d6b421a9713cb84e03b19c18f81b625582f7f41af5",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:8a5bd26551990929fdb776d6b421a9713cb84e03b19c18f81b625582f7f41af5",
          "name": "anzograph_db"
        },
        {
          "digest": "sha256:c1443bcdc8e998fc699f61980a665f1a083350adf2d3d1d55a7cb55e31ca50b3",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:c1443bcdc8e998fc699f61980a665f1a083350adf2d3d1d55a7cb55e31ca50b3",
          "name": "anzograph_frontend"
        },
        {
          "digest": "sha256:c1443bcdc8e998fc699f61980a665f1a083350adf2d3d1d55a7cb55e31ca50b3",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-frontend@sha256:c1443bcdc8e998fc699f61980a665f1a083350adf2d3d1d55a7cb55e31ca50b3",
          "name": "anzograph-frontend-c1443bcdc8e998fc699f61980a665f1a083350adf2d3d1d55a7cb55e31ca50b3-annotation"
        },
        {
          "digest": "sha256:8a5bd26551990929fdb776d6b421a9713cb84e03b19c18f81b625582f7f41af5",
          "image": "registry.connect.redhat.com/cambridgesemantics/anzograph-db@sha256:8a5bd26551990929fdb776d6b421a9713cb84e03b19c18f81b625582f7f41af5",
          "name": "anzograph-db-8a5bd26551990929fdb776d6b421a9713cb84e03b19c18f81b625582f7f41af5-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2.0.1",
      "version_original": "2.0.1"
    },
    {
      "_id": "62346029670f4cadbafad2b1",
      "alm_examples": [
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoDeBundle",
          "metadata": {
            "name": "my-bundle",
            "namespace": "my-namespace"
          },
          "spec": {
            "details": {
              "name": "my-bundle"
            }
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoDatabaseService",
          "metadata": {
            "name": "my-entando-database-service",
            "namespace": "my-namespace"
          },
          "spec": {
            "createDeployment": true,
            "databaseName": "my_database",
            "dbms": "postgresql"
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoKeycloakServer",
          "metadata": {
            "name": "my-keycloak",
            "namespace": "my-namespace"
          },
          "spec": {
            "dbms": "postgresql",
            "environmentVariables": [],
            "replicas": 1,
            "standardImage": "redhat-sso"
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoClusterInfrastructure",
          "metadata": {
            "name": "my-entando-cluster-infrastructure",
            "namespace": "my-namespace"
          },
          "spec": {
            "environmentVariables": [],
            "replicas": 1
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoPlugin",
          "metadata": {
            "name": "my-entando-plugin",
            "namespace": "my-namespace"
          },
          "spec": {
            "dbms": "postgresql",
            "healthCheckPath": "/management/health",
            "image": "entando/entando-avatar-plugin:6.0.5",
            "ingressHostName": "my-plugin.apps-crc.testing",
            "ingressPath": "/avatarPlugin",
            "replicas": 1,
            "roles": [
              {
                "code": "admin",
                "name": "user"
              },
              {
                "code": "user",
                "name": "user"
              }
            ],
            "securityLevel": "strict"
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoApp",
          "metadata": {
            "name": "my-app",
            "namespace": "my-namespace"
          },
          "spec": {
            "dbms": "postgresql",
            "environmentVariables": [],
            "ingressHostName": "my-app.apps-crc.testing",
            "replicas": 1,
            "standardServerImage": "eap"
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoAppPluginLink",
          "metadata": {
            "name": "my-link",
            "namespace": "my-namespace"
          },
          "spec": {
            "entandoAppName": "my-app",
            "entandoPluginName": "my-plugin"
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoCompositeApp",
          "metadata": {
            "name": "my-entando-composite-app",
            "namespace": "my-namespace"
          },
          "spec": {
            "components": [
              {
                "kind": "EntandoDatabaseService",
                "metadata": {
                  "name": "inline-entando-database-service"
                },
                "spec": {
                  "createDeployment": true
                }
              },
              {
                "kind": "EntandoKeycloakServer",
                "metadata": {
                  "name": "inline-keycloak"
                },
                "spec": {
                  "standardImage": "redhat-sso"
                }
              },
              {
                "kind": "EntandoClusterInfrastructure",
                "metadata": {
                  "name": "inline-entando-cluster-infrastructure"
                },
                "spec": {}
              },
              {
                "kind": "EntandoApp",
                "metadata": {
                  "name": "inline-app"
                },
                "spec": {
                  "standardServerImage": "eap"
                }
              },
              {
                "kind": "EntandoPlugin",
                "metadata": {
                  "name": "inline-plugin"
                },
                "spec": {
                  "healthCheckPath": "/management/health",
                  "image": "entando/entando-avatar-plugin:6.0.5",
                  "ingressPath": "/avatarPlugin",
                  "roles": [
                    {
                      "code": "admin",
                      "name": "admin"
                    },
                    {
                      "code": "user",
                      "name": "user"
                    }
                  ]
                }
              },
              {
                "kind": "EntandoAppPluginLink",
                "metadata": {
                  "name": "inline-link"
                },
                "spec": {
                  "entandoAppName": "inline-app",
                  "entandoPluginName": "inline-plugin"
                }
              }
            ],
            "dbmsOverride": "postgresql",
            "ingressHostNameOverride": "entando.apps-crc.testing"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/entando/entando-operator@sha256:110de9cf2e6ecc1d3f6bff990ec9eb890b26c6ade5c03a232421d30e6bbace57",
      "bundle_path_digest": "sha256:110de9cf2e6ecc1d3f6bff990ec9eb890b26c6ade5c03a232421d30e6bbace57",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-03-18T10:34:17.044000+00:00",
      "csv_description": "## Entando\n\nThe Entando platform accelerates the development and lifecycle  management of fully modularized applications on Kubernetes. It  provides tools to help developers create and manage applications  using modular frontend and backend components.\nThe Entando Operator automates the installation, provisioning, and  configuration management of the components that make up an Entando  application. Specifically, the operator manages the following custom  resources:\n**EntandoKeycloakServers** for centralized authentication of frontend  and backend components. The operator can deploy Keycloak, or in certified  environments, Red Hat SSO servers that can then be used by subsequent  deployments as an OpenID Connect provider.\n**EntandoApps** for hosting an Entando application. EntandoApps are hosted on Wildfly or JBoss EAP containers, and can also be used to deploy custom  EntandoApp containers.\n**EntandoPlugins** for deploying microservices to customize or enhance your EntandoApp. Entando microservice plugins are deployed to your cluster, and  then linked to one or more EntandoApps.\n## Using the Operator\nThe Entando Operator can be deployed using the default settings without any  configuration. Once deployed, the operator can be customized by editing  the *configmap* and secrets.\n### ConfigMap: entando-operator-config\nThe 'entando-operator-config' ConfigMap can be added after deployment and any changes to it will be picked up by the operator on subsequent event processing. It supports the following keys:\n\n    entando.k8s.operator.gc.controller.pods: set this to \"false\" to keep controller pods after completion.\n    entando.k8s.operator.compliance.mode: set this to \"community\" if there is no requirement for Red Hat compliance.\n    entando.k8s.operator.image.pull.secrets: a comma separated list containing the names of pull secrets that will be linked to all service accounts.\n    entando.k8s.operator.disable.pvc.garbage.collection: set this to \"false\" if you want Persistent Volume Claims to be deleted with the custom resources they are associated with.\n    entando.k8s.operator.impose.default.limits: set this to \"false\" if there is no need to limit the resource consumption of pods on your cluster.\n    entando.k8s.operator.request.to.limit.ratio: a decimal number that default limits will be multiplied by to calculate default requests for resources.\n    entando.k8s.operator.force.db.password.reset: set this to \"true\" if you plan to delete Secrets from your namespace but you want to retain the Database they point to.\n    entando.k8s.operator.pull.policy.override: specify your preferred pullPolicy for images. The default is Always.\n    entando.tls.secret.name: The name of a standard TLS secret to use for HTTPS Ingresses. See the section entando-tls-secret.\n    entando.ca.secret.name: The name of a secret containing CA certificates. See the section entando-ca-cert-secret.\n    entando.assume.external.https.provider: Set this to \"true\" if your cloud provider handles HTTPS for you.\n    entando.use.auto.cert.generation: Set this to \"true\" to have Openshift use its internal CA to generate certificates for your Routes.\n    entando.default.routing.suffix: The domain name that can be suffixed to deployment names when the ingressHostName is omitted. Needs to be preconfigured on your DNS provider.\n    entando.pod.completion.timeout.seconds: The time it will take before Entando fails a run-to-completion Pod.\n    entando.pod.readiness.timeout.seconds: The time it will take before Entando fails a Service Pod.\n    entando.pod.shutdown.timeout.seconds: The time Entando will give a Pod to shutdown gracefully.\n\n\n### entando-pull-secret\nThe secret to be used to pull Entando images from the Red Hat container registry. The name of this secret is hard coded as it is required for the ClusterServiceVersion of this Operator\n### entando-tls-secret\nA standard Kubernetes TLS secret that will be used on all deployments where no custom TLS secret name is specified.\n### entando-ca-cert-secret\nThis is an opaque secret in the Entando Operator's namespace that contains the certificates of all trusted certificate authorities in your environment. This is generally used mainly for self signed certificates. As is generally the case for opaque secrets, there are no constraints on the keys in this secret. However, limit the files inside the secret to X509 certificates or certificate chains. The Entando Operator will load all of these files into a Java keystore that it then configures as the trust store for each container that uses Java.\n",
      "csv_display_name": "Entando Operator",
      "csv_metadata_description": "Processes EntandoKeycloakServer, EntandoApp and EntandoPlugin custom resources and deploys the relevant containers in the Kubernetes cluster.",
      "csv_name": "entando-k8s-operator.v6.3.2-pr2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-06-17T01:43:44.269000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "entando-k8s-operator",
      "provided_apis": [
        {
          "group": "entando.org",
          "kind": "EntandoApp",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoAppPluginLink",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoClusterInfrastructure",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoCompositeApp",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoDatabaseService",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoDeBundle",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoKeycloakServer",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoPlugin",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:c8a93ebd69af3cf822dd7d4fcce5d4241cd8dca229c4e25c771bcfecca916839",
          "image": "entando/entando-k8s-controller-coordinator@sha256:c8a93ebd69af3cf822dd7d4fcce5d4241cd8dca229c4e25c771bcfecca916839",
          "name": "entando-k8s-controller-coordinator-c8a93ebd69af3cf822dd7d4fcce5d4241cd8dca229c4e25c771bcfecca916839-annotation"
        },
        {
          "digest": "sha256:c8a93ebd69af3cf822dd7d4fcce5d4241cd8dca229c4e25c771bcfecca916839",
          "image": "entando/entando-k8s-controller-coordinator@sha256:c8a93ebd69af3cf822dd7d4fcce5d4241cd8dca229c4e25c771bcfecca916839",
          "name": "entando-operator"
        },
        {
          "digest": "sha256:570bce7dc649ac7ac85e7ecb196aabc281c77a94590aa7df7d9746869ce757ea",
          "image": "registry.redhat.io/rhel8/mysql-80@sha256:570bce7dc649ac7ac85e7ecb196aabc281c77a94590aa7df7d9746869ce757ea",
          "name": "rhel8_mysql_80"
        },
        {
          "digest": "sha256:f4e5c728b644bf1888ec8086424852ed74b5596a511be29e636fb10218fc9b6f",
          "image": "registry.redhat.io/rhel8/postgresql-12@sha256:f4e5c728b644bf1888ec8086424852ed74b5596a511be29e636fb10218fc9b6f",
          "name": "rhel8_postgresql_12"
        },
        {
          "digest": "sha256:1ca90c09302b9cadf8950278d92ad4d7f3a14f02dea8704320794aa77ada8631",
          "image": "docker.io/entando/app-builder@sha256:1ca90c09302b9cadf8950278d92ad4d7f3a14f02dea8704320794aa77ada8631",
          "name": "app_builder"
        },
        {
          "digest": "sha256:668191fc86b090452baaba18ec7bbc3d07df5a99750e0c5b98759599d565cfbe",
          "image": "docker.io/entando/entando-component-manager@sha256:668191fc86b090452baaba18ec7bbc3d07df5a99750e0c5b98759599d565cfbe",
          "name": "entando_component_manager"
        },
        {
          "digest": "sha256:1f0e35d7f7ee8123721cf8e80ac96ac2f594f21a2b68cf9e720917d090c8095e",
          "image": "docker.io/entando/entando-de-app-eap@sha256:1f0e35d7f7ee8123721cf8e80ac96ac2f594f21a2b68cf9e720917d090c8095e",
          "name": "entando_de_app_eap"
        },
        {
          "digest": "sha256:c68d3b129fc625f5d1ee10ed2a107e28c145049d4b513dcdb2c736555025e339",
          "image": "docker.io/entando/entando-k8s-app-controller@sha256:c68d3b129fc625f5d1ee10ed2a107e28c145049d4b513dcdb2c736555025e339",
          "name": "entando_k8s_app_controller"
        },
        {
          "digest": "sha256:aa7ba0861705213434e610530c5bf5da1bdb33f1834d3c346174f5a28145c0bd",
          "image": "docker.io/entando/entando-k8s-app-plugin-link-controller@sha256:aa7ba0861705213434e610530c5bf5da1bdb33f1834d3c346174f5a28145c0bd",
          "name": "entando_k8s_app_plugin_link_controller"
        },
        {
          "digest": "sha256:86dbea6696349d7b2393e12bacef4d1acec2dd3f8551e397fa26c92706a18dd3",
          "image": "docker.io/entando/entando-k8s-cluster-infrastructure-controller@sha256:86dbea6696349d7b2393e12bacef4d1acec2dd3f8551e397fa26c92706a18dd3",
          "name": "entando_k8s_cluster_infrastructure_controller"
        },
        {
          "digest": "sha256:4bc6797bb41b3e407b64530c3cff7a78f3fc2c22863caad9c606ccd650310b61",
          "image": "docker.io/entando/entando-k8s-composite-app-controller@sha256:4bc6797bb41b3e407b64530c3cff7a78f3fc2c22863caad9c606ccd650310b61",
          "name": "entando_k8s_composite_app_controller"
        },
        {
          "digest": "sha256:58ca4ad2fca83a715aba9b68609f9056f633d556eb9845b3aff5c05769369539",
          "image": "docker.io/entando/entando-k8s-database-service-controller@sha256:58ca4ad2fca83a715aba9b68609f9056f633d556eb9845b3aff5c05769369539",
          "name": "entando_k8s_database_service_controller"
        },
        {
          "digest": "sha256:8ae47dbf93201965106663299f06daad544982fa244d4a0f365a1b717727e5ed",
          "image": "docker.io/entando/entando-k8s-dbjob@sha256:8ae47dbf93201965106663299f06daad544982fa244d4a0f365a1b717727e5ed",
          "name": "entando_k8s_dbjob"
        },
        {
          "digest": "sha256:f1ed42001260802353197433cea7df4c2d0e5fd9bcd926bb5ae7c654dfad2ffe",
          "image": "docker.io/entando/entando-k8s-keycloak-controller@sha256:f1ed42001260802353197433cea7df4c2d0e5fd9bcd926bb5ae7c654dfad2ffe",
          "name": "entando_k8s_keycloak_controller"
        },
        {
          "digest": "sha256:a20c753dda86e0f54f210e446b404733045ba426fc7186dc3936daed8224fbcb",
          "image": "docker.io/entando/entando-k8s-plugin-controller@sha256:a20c753dda86e0f54f210e446b404733045ba426fc7186dc3936daed8224fbcb",
          "name": "entando_k8s_plugin_controller"
        },
        {
          "digest": "sha256:775391f0005e64764288bfe007d9ea576f13618c02ea400d030a7502cfb551bd",
          "image": "docker.io/entando/entando-k8s-service@sha256:775391f0005e64764288bfe007d9ea576f13618c02ea400d030a7502cfb551bd",
          "name": "entando_k8s_service"
        },
        {
          "digest": "sha256:3692adb3694b3bf278bed7a678c9d0eaa0aba8e3e3ed4117ca04156525bcac72",
          "image": "docker.io/entando/entando-redhat-sso@sha256:3692adb3694b3bf278bed7a678c9d0eaa0aba8e3e3ed4117ca04156525bcac72",
          "name": "entando_redhat_sso"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "6.3.2-pr2",
      "version_original": "6.3.2-pr2"
    },
    {
      "_id": "6234602b06c5dada0193e088",
      "alm_examples": [
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoDeBundle",
          "metadata": {
            "name": "my-bundle",
            "namespace": "my-namespace"
          },
          "spec": {
            "details": {
              "name": "my-bundle"
            }
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoDatabaseService",
          "metadata": {
            "name": "my-entando-database-service",
            "namespace": "my-namespace"
          },
          "spec": {
            "createDeployment": true,
            "databaseName": "my_database",
            "dbms": "postgresql"
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoKeycloakServer",
          "metadata": {
            "name": "my-keycloak",
            "namespace": "my-namespace"
          },
          "spec": {
            "dbms": "postgresql",
            "environmentVariables": [],
            "replicas": 1,
            "standardImage": "redhat-sso"
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoClusterInfrastructure",
          "metadata": {
            "name": "my-entando-cluster-infrastructure",
            "namespace": "my-namespace"
          },
          "spec": {
            "environmentVariables": [],
            "replicas": 1
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoPlugin",
          "metadata": {
            "name": "my-entando-plugin",
            "namespace": "my-namespace"
          },
          "spec": {
            "dbms": "postgresql",
            "healthCheckPath": "/management/health",
            "image": "entando/entando-avatar-plugin:6.0.5",
            "ingressHostName": "my-plugin.apps-crc.testing",
            "ingressPath": "/avatarPlugin",
            "replicas": 1,
            "roles": [
              {
                "code": "admin",
                "name": "user"
              },
              {
                "code": "user",
                "name": "user"
              }
            ],
            "securityLevel": "strict"
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoApp",
          "metadata": {
            "name": "my-app",
            "namespace": "my-namespace"
          },
          "spec": {
            "dbms": "postgresql",
            "environmentVariables": [],
            "ingressHostName": "my-app.apps-crc.testing",
            "replicas": 1,
            "standardServerImage": "eap"
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoAppPluginLink",
          "metadata": {
            "name": "my-link",
            "namespace": "my-namespace"
          },
          "spec": {
            "entandoAppName": "my-app",
            "entandoPluginName": "my-plugin"
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoCompositeApp",
          "metadata": {
            "name": "my-entando-composite-app",
            "namespace": "my-namespace"
          },
          "spec": {
            "components": [
              {
                "kind": "EntandoDatabaseService",
                "metadata": {
                  "name": "inline-entando-database-service"
                },
                "spec": {
                  "createDeployment": true
                }
              },
              {
                "kind": "EntandoKeycloakServer",
                "metadata": {
                  "name": "inline-keycloak"
                },
                "spec": {
                  "standardImage": "redhat-sso"
                }
              },
              {
                "kind": "EntandoClusterInfrastructure",
                "metadata": {
                  "name": "inline-entando-cluster-infrastructure"
                },
                "spec": {}
              },
              {
                "kind": "EntandoApp",
                "metadata": {
                  "name": "inline-app"
                },
                "spec": {
                  "standardServerImage": "eap"
                }
              },
              {
                "kind": "EntandoPlugin",
                "metadata": {
                  "name": "inline-plugin"
                },
                "spec": {
                  "healthCheckPath": "/management/health",
                  "image": "entando/entando-avatar-plugin:6.0.5",
                  "ingressPath": "/avatarPlugin",
                  "roles": [
                    {
                      "code": "admin",
                      "name": "admin"
                    },
                    {
                      "code": "user",
                      "name": "user"
                    }
                  ]
                }
              },
              {
                "kind": "EntandoAppPluginLink",
                "metadata": {
                  "name": "inline-link"
                },
                "spec": {
                  "entandoAppName": "inline-app",
                  "entandoPluginName": "inline-plugin"
                }
              }
            ],
            "dbmsOverride": "postgresql",
            "ingressHostNameOverride": "entando.apps-crc.testing"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/entando/entando-operator@sha256:66f8db604ac4d104cd88d786c4a9437dd1a22b3d7f8fd856c1251191f7d4856a",
      "bundle_path_digest": "sha256:66f8db604ac4d104cd88d786c4a9437dd1a22b3d7f8fd856c1251191f7d4856a",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-03-18T10:34:19.463000+00:00",
      "csv_description": "## Entando\n\nThe Entando platform accelerates the development and lifecycle  management of fully modularized applications on Kubernetes. It  provides tools to help developers create and manage applications  using modular frontend and backend components.\nThe Entando Operator automates the installation, provisioning, and  configuration management of the components that make up an Entando  application. Specifically, the operator manages the following custom  resources:\n**EntandoKeycloakServers** for centralized authentication of frontend  and backend components. The operator can deploy Keycloak, or in certified  environments, Red Hat SSO servers that can then be used by subsequent  deployments as an OpenID Connect provider.\n**EntandoApps** for hosting an Entando application. EntandoApps are hosted on Wildfly or JBoss EAP containers, and can also be used to deploy custom  EntandoApp containers.\n**EntandoPlugins** for deploying microservices to customize or enhance your EntandoApp. Entando microservice plugins are deployed to your cluster, and  then linked to one or more EntandoApps.\n## Using the Operator\nThe Entando Operator can be deployed using the default settings without any  configuration. Once deployed, the operator can be customized by editing  the *configmap* and secrets.\n### ConfigMap: entando-operator-config\nThe 'entando-operator-config' ConfigMap can be added after deployment and any changes to it will be picked up by the operator on subsequent event processing. It supports the following keys:\n\n    entando.k8s.operator.gc.controller.pods: set this to \"false\" to keep controller pods after completion.\n    entando.k8s.operator.compliance.mode: set this to \"community\" if there is no requirement for Red Hat compliance.\n    entando.k8s.operator.image.pull.secrets: a comma separated list containing the names of pull secrets that will be linked to all service accounts.\n    entando.k8s.operator.disable.pvc.garbage.collection: set this to \"false\" if you want Persistent Volume Claims to be deleted with the custom resources they are associated with.\n    entando.k8s.operator.impose.default.limits: set this to \"false\" if there is no need to limit the resource consumption of pods on your cluster.\n    entando.k8s.operator.request.to.limit.ratio: a decimal number that default limits will be multiplied by to calculate default requests for resources.\n    entando.k8s.operator.force.db.password.reset: set this to \"true\" if you plan to delete Secrets from your namespace but you want to retain the Database they point to.\n    entando.k8s.operator.pull.policy.override: specify your preferred pullPolicy for images. The default is Always.\n    entando.tls.secret.name: The name of a standard TLS secret to use for HTTPS Ingresses. See the section entando-tls-secret.\n    entando.ca.secret.name: The name of a secret containing CA certificates. See the section entando-ca-cert-secret.\n    entando.assume.external.https.provider: Set this to \"true\" if your cloud provider handles HTTPS for you.\n    entando.use.auto.cert.generation: Set this to \"true\" to have Openshift use its internal CA to generate certificates for your Routes.\n    entando.default.routing.suffix: The domain name that can be suffixed to deployment names when the ingressHostName is omitted. Needs to be preconfigured on your DNS provider.\n    entando.pod.completion.timeout.seconds: The time it will take before Entando fails a run-to-completion Pod.\n    entando.pod.readiness.timeout.seconds: The time it will take before Entando fails a Service Pod.\n    entando.pod.shutdown.timeout.seconds: The time Entando will give a Pod to shutdown gracefully.\n\n\n### entando-pull-secret\nThe secret to be used to pull Entando images from the Red Hat container registry. The name of this secret is hard coded as it is required for the ClusterServiceVersion of this Operator\n### entando-tls-secret\nA standard Kubernetes TLS secret that will be used on all deployments where no custom TLS secret name is specified.\n### entando-ca-cert-secret\nThis is an opaque secret in the Entando Operator's namespace that contains the certificates of all trusted certificate authorities in your environment. This is generally used mainly for self signed certificates. As is generally the case for opaque secrets, there are no constraints on the keys in this secret. However, limit the files inside the secret to X509 certificates or certificate chains. The Entando Operator will load all of these files into a Java keystore that it then configures as the trust store for each container that uses Java.\n",
      "csv_display_name": "Entando Operator",
      "csv_metadata_description": "Processes EntandoKeycloakServer, EntandoApp and EntandoPlugin custom resources and deploys the relevant containers in the Kubernetes cluster.",
      "csv_name": "entando-k8s-operator.v6.3.2-pr4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-06-17T01:43:50.530000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "entando-k8s-operator",
      "provided_apis": [
        {
          "group": "entando.org",
          "kind": "EntandoApp",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoAppPluginLink",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoClusterInfrastructure",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoCompositeApp",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoDatabaseService",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoDeBundle",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoKeycloakServer",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoPlugin",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:c8a93ebd69af3cf822dd7d4fcce5d4241cd8dca229c4e25c771bcfecca916839",
          "image": "entando/entando-k8s-controller-coordinator@sha256:c8a93ebd69af3cf822dd7d4fcce5d4241cd8dca229c4e25c771bcfecca916839",
          "name": "entando-k8s-controller-coordinator-c8a93ebd69af3cf822dd7d4fcce5d4241cd8dca229c4e25c771bcfecca916839-annotation"
        },
        {
          "digest": "sha256:c8a93ebd69af3cf822dd7d4fcce5d4241cd8dca229c4e25c771bcfecca916839",
          "image": "entando/entando-k8s-controller-coordinator@sha256:c8a93ebd69af3cf822dd7d4fcce5d4241cd8dca229c4e25c771bcfecca916839",
          "name": "entando-operator"
        },
        {
          "digest": "sha256:570bce7dc649ac7ac85e7ecb196aabc281c77a94590aa7df7d9746869ce757ea",
          "image": "registry.redhat.io/rhel8/mysql-80@sha256:570bce7dc649ac7ac85e7ecb196aabc281c77a94590aa7df7d9746869ce757ea",
          "name": "rhel8_mysql_80"
        },
        {
          "digest": "sha256:f4e5c728b644bf1888ec8086424852ed74b5596a511be29e636fb10218fc9b6f",
          "image": "registry.redhat.io/rhel8/postgresql-12@sha256:f4e5c728b644bf1888ec8086424852ed74b5596a511be29e636fb10218fc9b6f",
          "name": "rhel8_postgresql_12"
        },
        {
          "digest": "sha256:1ca90c09302b9cadf8950278d92ad4d7f3a14f02dea8704320794aa77ada8631",
          "image": "docker.io/entando/app-builder@sha256:1ca90c09302b9cadf8950278d92ad4d7f3a14f02dea8704320794aa77ada8631",
          "name": "app_builder"
        },
        {
          "digest": "sha256:668191fc86b090452baaba18ec7bbc3d07df5a99750e0c5b98759599d565cfbe",
          "image": "docker.io/entando/entando-component-manager@sha256:668191fc86b090452baaba18ec7bbc3d07df5a99750e0c5b98759599d565cfbe",
          "name": "entando_component_manager"
        },
        {
          "digest": "sha256:1f0e35d7f7ee8123721cf8e80ac96ac2f594f21a2b68cf9e720917d090c8095e",
          "image": "docker.io/entando/entando-de-app-eap@sha256:1f0e35d7f7ee8123721cf8e80ac96ac2f594f21a2b68cf9e720917d090c8095e",
          "name": "entando_de_app_eap"
        },
        {
          "digest": "sha256:c68d3b129fc625f5d1ee10ed2a107e28c145049d4b513dcdb2c736555025e339",
          "image": "docker.io/entando/entando-k8s-app-controller@sha256:c68d3b129fc625f5d1ee10ed2a107e28c145049d4b513dcdb2c736555025e339",
          "name": "entando_k8s_app_controller"
        },
        {
          "digest": "sha256:aa7ba0861705213434e610530c5bf5da1bdb33f1834d3c346174f5a28145c0bd",
          "image": "docker.io/entando/entando-k8s-app-plugin-link-controller@sha256:aa7ba0861705213434e610530c5bf5da1bdb33f1834d3c346174f5a28145c0bd",
          "name": "entando_k8s_app_plugin_link_controller"
        },
        {
          "digest": "sha256:86dbea6696349d7b2393e12bacef4d1acec2dd3f8551e397fa26c92706a18dd3",
          "image": "docker.io/entando/entando-k8s-cluster-infrastructure-controller@sha256:86dbea6696349d7b2393e12bacef4d1acec2dd3f8551e397fa26c92706a18dd3",
          "name": "entando_k8s_cluster_infrastructure_controller"
        },
        {
          "digest": "sha256:4bc6797bb41b3e407b64530c3cff7a78f3fc2c22863caad9c606ccd650310b61",
          "image": "docker.io/entando/entando-k8s-composite-app-controller@sha256:4bc6797bb41b3e407b64530c3cff7a78f3fc2c22863caad9c606ccd650310b61",
          "name": "entando_k8s_composite_app_controller"
        },
        {
          "digest": "sha256:58ca4ad2fca83a715aba9b68609f9056f633d556eb9845b3aff5c05769369539",
          "image": "docker.io/entando/entando-k8s-database-service-controller@sha256:58ca4ad2fca83a715aba9b68609f9056f633d556eb9845b3aff5c05769369539",
          "name": "entando_k8s_database_service_controller"
        },
        {
          "digest": "sha256:8ae47dbf93201965106663299f06daad544982fa244d4a0f365a1b717727e5ed",
          "image": "docker.io/entando/entando-k8s-dbjob@sha256:8ae47dbf93201965106663299f06daad544982fa244d4a0f365a1b717727e5ed",
          "name": "entando_k8s_dbjob"
        },
        {
          "digest": "sha256:f1ed42001260802353197433cea7df4c2d0e5fd9bcd926bb5ae7c654dfad2ffe",
          "image": "docker.io/entando/entando-k8s-keycloak-controller@sha256:f1ed42001260802353197433cea7df4c2d0e5fd9bcd926bb5ae7c654dfad2ffe",
          "name": "entando_k8s_keycloak_controller"
        },
        {
          "digest": "sha256:a20c753dda86e0f54f210e446b404733045ba426fc7186dc3936daed8224fbcb",
          "image": "docker.io/entando/entando-k8s-plugin-controller@sha256:a20c753dda86e0f54f210e446b404733045ba426fc7186dc3936daed8224fbcb",
          "name": "entando_k8s_plugin_controller"
        },
        {
          "digest": "sha256:775391f0005e64764288bfe007d9ea576f13618c02ea400d030a7502cfb551bd",
          "image": "docker.io/entando/entando-k8s-service@sha256:775391f0005e64764288bfe007d9ea576f13618c02ea400d030a7502cfb551bd",
          "name": "entando_k8s_service"
        },
        {
          "digest": "sha256:3692adb3694b3bf278bed7a678c9d0eaa0aba8e3e3ed4117ca04156525bcac72",
          "image": "docker.io/entando/entando-redhat-sso@sha256:3692adb3694b3bf278bed7a678c9d0eaa0aba8e3e3ed4117ca04156525bcac72",
          "name": "entando_redhat_sso"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "6.3.2-pr4",
      "version_original": "6.3.2-pr4"
    },
    {
      "_id": "6234602e5593ce895a7b5368",
      "alm_examples": [
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoDeBundle",
          "metadata": {
            "name": "my-bundle",
            "namespace": "my-namespace"
          },
          "spec": {
            "details": {
              "name": "my-bundle"
            }
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoDatabaseService",
          "metadata": {
            "name": "my-entando-database-service",
            "namespace": "my-namespace"
          },
          "spec": {
            "createDeployment": true,
            "databaseName": "my_database",
            "dbms": "postgresql"
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoKeycloakServer",
          "metadata": {
            "name": "my-keycloak",
            "namespace": "my-namespace"
          },
          "spec": {
            "dbms": "postgresql",
            "environmentVariables": [],
            "replicas": 1,
            "standardImage": "redhat-sso"
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoClusterInfrastructure",
          "metadata": {
            "name": "my-entando-cluster-infrastructure",
            "namespace": "my-namespace"
          },
          "spec": {
            "environmentVariables": [],
            "replicas": 1
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoPlugin",
          "metadata": {
            "name": "my-entando-plugin",
            "namespace": "my-namespace"
          },
          "spec": {
            "dbms": "postgresql",
            "healthCheckPath": "/management/health",
            "image": "entando/entando-avatar-plugin:6.0.5",
            "ingressHostName": "my-plugin.apps-crc.testing",
            "ingressPath": "/avatarPlugin",
            "replicas": 1,
            "roles": [
              {
                "code": "admin",
                "name": "user"
              },
              {
                "code": "user",
                "name": "user"
              }
            ],
            "securityLevel": "strict"
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoApp",
          "metadata": {
            "name": "my-app",
            "namespace": "my-namespace"
          },
          "spec": {
            "dbms": "postgresql",
            "environmentVariables": [],
            "ingressHostName": "my-app.apps-crc.testing",
            "replicas": 1,
            "standardServerImage": "eap"
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoAppPluginLink",
          "metadata": {
            "name": "my-link",
            "namespace": "my-namespace"
          },
          "spec": {
            "entandoAppName": "my-app",
            "entandoPluginName": "my-plugin"
          }
        },
        {
          "api_version": "entando.org/v1",
          "kind": "EntandoCompositeApp",
          "metadata": {
            "name": "my-entando-composite-app",
            "namespace": "my-namespace"
          },
          "spec": {
            "components": [
              {
                "kind": "EntandoDatabaseService",
                "metadata": {
                  "name": "inline-entando-database-service"
                },
                "spec": {
                  "createDeployment": true
                }
              },
              {
                "kind": "EntandoKeycloakServer",
                "metadata": {
                  "name": "inline-keycloak"
                },
                "spec": {
                  "standardImage": "redhat-sso"
                }
              },
              {
                "kind": "EntandoClusterInfrastructure",
                "metadata": {
                  "name": "inline-entando-cluster-infrastructure"
                },
                "spec": {}
              },
              {
                "kind": "EntandoApp",
                "metadata": {
                  "name": "inline-app"
                },
                "spec": {
                  "standardServerImage": "eap"
                }
              },
              {
                "kind": "EntandoPlugin",
                "metadata": {
                  "name": "inline-plugin"
                },
                "spec": {
                  "healthCheckPath": "/management/health",
                  "image": "entando/entando-avatar-plugin:6.0.5",
                  "ingressPath": "/avatarPlugin",
                  "roles": [
                    {
                      "code": "admin",
                      "name": "admin"
                    },
                    {
                      "code": "user",
                      "name": "user"
                    }
                  ]
                }
              },
              {
                "kind": "EntandoAppPluginLink",
                "metadata": {
                  "name": "inline-link"
                },
                "spec": {
                  "entandoAppName": "inline-app",
                  "entandoPluginName": "inline-plugin"
                }
              }
            ],
            "dbmsOverride": "postgresql",
            "ingressHostNameOverride": "entando.apps-crc.testing"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/entando/entando-operator@sha256:639e2d35738483c6c092ebe8636bbab50c0f2101bc06f2fe9a1c7f68b3ffc4a6",
      "bundle_path_digest": "sha256:639e2d35738483c6c092ebe8636bbab50c0f2101bc06f2fe9a1c7f68b3ffc4a6",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:34:22.097000+00:00",
      "csv_description": "## Entando\n\nThe Entando platform accelerates the development and lifecycle  management of fully modularized applications on Kubernetes. It  provides tools to help developers create and manage applications  using modular frontend and backend components.\nThe Entando Operator automates the installation, provisioning, and  configuration management of the components that make up an Entando  application. Specifically, the operator manages the following custom  resources:\n**EntandoKeycloakServers** for centralized authentication of frontend  and backend components. The operator can deploy Keycloak, or in certified  environments, Red Hat SSO servers that can then be used by subsequent  deployments as an OpenID Connect provider.\n**EntandoApps** for hosting an Entando application. EntandoApps are hosted on Wildfly or JBoss EAP containers, and can also be used to deploy custom  EntandoApp containers.\n**EntandoPlugins** for deploying microservices to customize or enhance your EntandoApp. Entando microservice plugins are deployed to your cluster, and  then linked to one or more EntandoApps.\n## Using the Operator\nThe Entando Operator can be deployed using the default settings without any  configuration. Once deployed, the operator can be customized by editing  the *configmap* and secrets.\n### ConfigMap: entando-operator-config\nThe 'entando-operator-config' ConfigMap can be added after deployment and any changes to it will be picked up by the operator on subsequent event processing. It supports the following keys:\n\n    entando.k8s.operator.gc.controller.pods: set this to \"false\" to keep controller pods after completion.\n    entando.k8s.operator.compliance.mode: set this to \"community\" if there is no requirement for Red Hat compliance.\n    entando.k8s.operator.image.pull.secrets: a comma separated list containing the names of pull secrets that will be linked to all service accounts.\n    entando.k8s.operator.disable.pvc.garbage.collection: set this to \"false\" if you want Persistent Volume Claims to be deleted with the custom resources they are associated with.\n    entando.k8s.operator.impose.default.limits: set this to \"false\" if there is no need to limit the resource consumption of pods on your cluster.\n    entando.k8s.operator.request.to.limit.ratio: a decimal number that default limits will be multiplied by to calculate default requests for resources.\n    entando.k8s.operator.force.db.password.reset: set this to \"true\" if you plan to delete Secrets from your namespace but you want to retain the Database they point to.\n    entando.k8s.operator.pull.policy.override: specify your preferred pullPolicy for images. The default is Always.\n    entando.tls.secret.name: The name of a standard TLS secret to use for HTTPS Ingresses. See the section entando-tls-secret.\n    entando.ca.secret.name: The name of a secret containing CA certificates. See the section entando-ca-cert-secret.\n    entando.assume.external.https.provider: Set this to \"true\" if your cloud provider handles HTTPS for you.\n    entando.use.auto.cert.generation: Set this to \"true\" to have Openshift use its internal CA to generate certificates for your Routes.\n    entando.default.routing.suffix: The domain name that can be suffixed to deployment names when the ingressHostName is omitted. Needs to be preconfigured on your DNS provider.\n    entando.pod.completion.timeout.seconds: The time it will take before Entando fails a run-to-completion Pod.\n    entando.pod.readiness.timeout.seconds: The time it will take before Entando fails a Service Pod.\n    entando.pod.shutdown.timeout.seconds: The time Entando will give a Pod to shutdown gracefully.\n\n\n### entando-pull-secret\nThe secret to be used to pull Entando images from the Red Hat container registry. The name of this secret is hard coded as it is required for the ClusterServiceVersion of this Operator\n### entando-tls-secret\nA standard Kubernetes TLS secret that will be used on all deployments where no custom TLS secret name is specified.\n### entando-ca-cert-secret\nThis is an opaque secret in the Entando Operator's namespace that contains the certificates of all trusted certificate authorities in your environment. This is generally used mainly for self signed certificates. As is generally the case for opaque secrets, there are no constraints on the keys in this secret. However, limit the files inside the secret to X509 certificates or certificate chains. The Entando Operator will load all of these files into a Java keystore that it then configures as the trust store for each container that uses Java.\n",
      "csv_display_name": "Entando Operator",
      "csv_metadata_description": "Processes EntandoKeycloakServer, EntandoApp and EntandoPlugin custom resources and deploys the relevant containers in the Kubernetes cluster.",
      "csv_name": "entando-k8s-operator.v6.3.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:43:55.307000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "entando-k8s-operator",
      "provided_apis": [
        {
          "group": "entando.org",
          "kind": "EntandoApp",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoAppPluginLink",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoClusterInfrastructure",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoCompositeApp",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoDatabaseService",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoDeBundle",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoKeycloakServer",
          "version": "v1"
        },
        {
          "group": "entando.org",
          "kind": "EntandoPlugin",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "6.3.2",
      "version_original": "6.3.2"
    },
    {
      "_id": "6234603106c5dada0193e089",
      "alm_examples": [
        {
          "api_version": "ezmeral.hpe.com/v1",
          "kind": "HPEEzmeralCSIDriver",
          "metadata": {
            "name": "hpeezmeralcsidriver"
          },
          "spec": {
            "controllerImage": "registry.connect.redhat.com/maprtech/csi-kdfprovisioner@sha256:89a397c26960ba05542ac069e3a47059bced2bc958cfff4aa0f1eb081fab5d42",
            "nodeImage": "registry.connect.redhat.com/maprtech/csi-kdfplugin@sha256:480b6fb8b2501caa76013c94feac91bef7f9b5ae6ad0b286ec621fd6a9ce4bef",
            "pullPolicy": "Always"
          }
        },
        {
          "api_version": "ezmeral.hpe.com/v1",
          "kind": "HPEEzmeralNFSCSIDriver",
          "metadata": {
            "name": "hpeezmeralnfscsidriver"
          },
          "spec": {
            "controllerImage": "registry.connect.redhat.com/maprtech/csi-kdfprovisioner@sha256:89a397c26960ba05542ac069e3a47059bced2bc958cfff4aa0f1eb081fab5d42",
            "nodeImage": "registry.connect.redhat.com/maprtech/csi-nfsplugin@sha256:35c275363a6949fed56b8ddfe3886ed42a6267fb07271494d8367abbd4d8c822",
            "pullPolicy": "Always"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/maprtech/hpe-ezmeral-csi-operator-bundle@sha256:b23ef079d0bcbeaa227a0d759c900c103f97310ad2e00a566a74b100f95a37ff",
      "bundle_path_digest": "sha256:b23ef079d0bcbeaa227a0d759c900c103f97310ad2e00a566a74b100f95a37ff",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:34:25.003000+00:00",
      "csv_description": "The HPE Ezmeral CSI Operator for Kubernetes packages, deploys, manages, upgrades the HPE Ezmeral CSI Driver on Kubernetes and OpenShift for dynamic provisioning of persistent volumes on HPE Ezmeral Data Fabric platform.\nThe HPE Ezmeral CSI Driver for Kubernetes leverages HPE Ezmeral Data Fabric platform to provide scalable and persistent storage for stateful applications. Please refer to our CSI driver [documentation](https://docs.datafabric.hpe.com/home/CSIdriver/csi_overview.html) for full list of supported CSI features.\n## Installation\nRefer to the HPE Ezmeral CSI Operator for Kubernetes [documentation](https://docs.datafabric.hpe.com/home/CSIdriver/csi_installing_operator.html)\n",
      "csv_display_name": "HPE Ezmeral Data Fabric CSI Operator for Kubernetes",
      "csv_metadata_description": "A Container Storage Interface (CSI) driver for HPE Ezmeral Data Fabric platform. The CSI driver allows you to use HPE Ezmeral Data Fabric with your preferred container orchestrator.",
      "csv_name": "hpe-ezmeral-csi-operator.v1.0.9",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:42:01.322000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "hpe-ezmeral-csi-operator",
      "provided_apis": [
        {
          "group": "ezmeral.hpe.com",
          "kind": "HPEEzmeralCSIDriver",
          "version": "v1"
        },
        {
          "group": "ezmeral.hpe.com",
          "kind": "HPEEzmeralNFSCSIDriver",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:82f52179dcd59a1e16f249bcd21f7aae22c09e84f24b479a923fef2adee45c7f",
          "image": "registry.connect.redhat.com/maprtech/hpe-ezmeral-csi-operator@sha256:82f52179dcd59a1e16f249bcd21f7aae22c09e84f24b479a923fef2adee45c7f",
          "name": "hpe-ezmeral-csi-operator-82f52179dcd59a1e16f249bcd21f7aae22c09e84f24b479a923fef2adee45c7f-annotation"
        },
        {
          "digest": "sha256:82f52179dcd59a1e16f249bcd21f7aae22c09e84f24b479a923fef2adee45c7f",
          "image": "registry.connect.redhat.com/maprtech/hpe-ezmeral-csi-operator@sha256:82f52179dcd59a1e16f249bcd21f7aae22c09e84f24b479a923fef2adee45c7f",
          "name": "hpe-ezmeral-csi-operator"
        },
        {
          "digest": "sha256:35c275363a6949fed56b8ddfe3886ed42a6267fb07271494d8367abbd4d8c822",
          "image": "registry.connect.redhat.com/maprtech/csi-nfsplugin@sha256:35c275363a6949fed56b8ddfe3886ed42a6267fb07271494d8367abbd4d8c822",
          "name": "csi-nfsplugin-35c275363a6949fed56b8ddfe3886ed42a6267fb07271494d8367abbd4d8c822-annotation"
        },
        {
          "digest": "sha256:89a397c26960ba05542ac069e3a47059bced2bc958cfff4aa0f1eb081fab5d42",
          "image": "registry.connect.redhat.com/maprtech/csi-kdfprovisioner@sha256:89a397c26960ba05542ac069e3a47059bced2bc958cfff4aa0f1eb081fab5d42",
          "name": "csi-kdfprovisioner-89a397c26960ba05542ac069e3a47059bced2bc958cfff4aa0f1eb081fab5d42-annotation"
        },
        {
          "digest": "sha256:480b6fb8b2501caa76013c94feac91bef7f9b5ae6ad0b286ec621fd6a9ce4bef",
          "image": "registry.connect.redhat.com/maprtech/csi-kdfplugin@sha256:480b6fb8b2501caa76013c94feac91bef7f9b5ae6ad0b286ec621fd6a9ce4bef",
          "name": "csi-kdfplugin-480b6fb8b2501caa76013c94feac91bef7f9b5ae6ad0b286ec621fd6a9ce4bef-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.0.9",
      "version_original": "1.0.9"
    },
    {
      "_id": "62346034670f4cadbafad2b2",
      "alm_examples": [
        {
          "api_version": "core.k8s.kubemq.io/v1beta1",
          "kind": "KubemqCluster",
          "metadata": {
            "name": "kubemq-cluster"
          },
          "spec": {
            "replicas": 3
          }
        },
        {
          "api_version": "core.k8s.kubemq.io/v1beta1",
          "kind": "KubemqDashboard",
          "metadata": {
            "name": "kubemq-dashboard"
          }
        },
        {
          "api_version": "core.k8s.kubemq.io/v1beta1",
          "kind": "KubemqConnector",
          "metadata": {
            "name": "kubemq-bridges"
          },
          "spec": {
            "config": "bindings: null",
            "type": "bridges"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/kubemq/kubemq-operator-bundle@sha256:9009198860c7a1e0de4f429261d442b75b5b2893a943bb77914b14d643db8829",
      "bundle_path_digest": "sha256:9009198860c7a1e0de4f429261d442b75b5b2893a943bb77914b14d643db8829",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-03-18T10:34:28.394000+00:00",
      "csv_description": "\n## Kubernetes Messaging Platform\nA message-based architecture for microservices providing flexible connectivity for hybrid environments: multi-cloud, on-premises, and at the edge. Powered by enterprise-grade message broker and message queue with ready to use connectors, bridges, and control center.\n\nMessaging platform components:\n  - **KubeMQ Cluster** - Enterprise-grade message broker and message queue, scalable, high available, and secured.\n  - **KubeMQ Targets Connector** - connects a KubeMQ cluster with external systems and cloud services.\n  - **KubeMQ Bridges Connector** - bridge, replicate, aggregate, and transform messages between KubeMQ clusters.\n  - **KubeMQ Sources Connector** - transform external systems and cloud services data to KubeMQ cluster messages.\n  - **KubeMQ Dashboard** - monitor KubeMQ cluster metrics.\n\n### Kubernetes Native\nInnovative and modern message queue and message broker in a lightweight container developed to run in Kubernetes, certified in the CNCF landscape, and connect natively to the cloud-native ecosystem.\n\n### Ease of use\n\nSimple deployment in Kubernetes in less than 1 minute. Developer friendly by simple to use SDKs and elimination of the many developers and DevOps-centered challenges to define exchanges, brokers, channels, routes, and predefined topics\n\n### All messaging patterns\n\nKubeMQ is available with all messaging patterns such as Queue, Stream, Pub/Sub, and RPC, Saving the need to maintain multiple messaging platforms for different use cases.\n\n### Hybrid Environments\n\nKubeMQ enables the microservices from multiple environments to communicate and build one hybrid infrastructure solution across clouds, on-prem, and at the edge.\n\n### KubeMQ Cluster key features\n\n- All-batteries included Messaging Queue Broker for the Kubernetes environment\n- Deployed with Operator for full life cycle operation\n- Blazing fast (written in Go), small and lightweight Docker container\n- Asynchronous and Synchronous messaging with support for  `At Most Once Delivery` and `At Least Once Delivery` models\n- Supports durable FIFO based Queue, Publish-Subscribe Events, Publish-Subscribe with Persistence (Events Store), RPC Command and Query messaging patterns\n- Supports gRPC, Rest and WebSocket Transport protocols with TLS support (both RPC and Stream modes)\n- Supports Access control Authorization and Authentication\n- Supports message masticating and smart routing\n- No Message broker configuration needed (i.e., queues, exchanges)\n- .Net, Java, Python, Go, and NodeJS SDKs\n\n### KubeMQ Targets Connector key features\n\n- Runs anywhere - Kubernetes, Cloud, on-prem, anywhere\n- Stand-alone - small docker container / binary\n- Single Interface - One interface all the services\n- Any Service - Support all major services types (databases, cache, messaging, serverless, HTTP, etc.)\n- Plug-in Architecture Easy to extend, easy to connect\n- Middleware Supports - Logs, Metrics, Retries, and Rate Limiters\n- Easy Configuration - simple yaml file builds your topology\n\n[Check out Github page](https://github.com/kubemq-io/kubemq-targets)\n\n### KubeMQ Bridges Connector key features\n\n- Runs anywhere - Kubernetes, Cloud, on-prem, anywhere\n- Stand-alone - small docker container / binary\n- Build Any Topology - connects KubeMQ clusters in 1:1, 1:n , n:1, n:n\n- Middleware Supports - Logs, Metrics, Retries, and Rate Limiters\n- Easy Configuration - simple yaml file builds your topology\n\n[Check out Github page](https://github.com/kubemq-io/kubemq-bridges)\n\n### KubeMQ Sources Connector key features\n\n- Runs anywhere - Kubernetes, Cloud, on-prem, anywhere\n- Stand-alone - small docker container / binary\n- Single Interface - One interface all the services\n- Any Service - Support all major messaging services such as Kafka, ActiveMQ, SQS, and more.\n- Plug-in Architecture Easy to extend, easy to connect\n- Middleware Supports - Logs, Metrics, Retries, and Rate Limiters\n- Easy Configuration - simple yaml file builds your topology\n\n[Check out Github page](https://github.com/kubemq-io/kubemq-sources)\n\n## Getting Started\n\n[Start with OpenShift](https://docs.kubemq.io/getting-started/create-cluster/openshift)\n\n## Get Enterprise Trial License\n\n[Register](https://account.kubemq.io/login/register)\n\n## Request a Demo\n\n[See KubeMQ in Action](https://kubemq.io/request-a-demo/)",
      "csv_display_name": "Kubemq Enterprise Operator",
      "csv_metadata_description": "Kubernetes Messaging Platform",
      "csv_name": "kubemq-operator.v1.7.8",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:46:14.192000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "kubemq-operator-marketplace",
      "provided_apis": [
        {
          "group": "core.k8s.kubemq.io",
          "kind": "KubemqCluster",
          "version": "v1alpha1"
        },
        {
          "group": "core.k8s.kubemq.io",
          "kind": "KubemqCluster",
          "version": "v1beta1"
        },
        {
          "group": "core.k8s.kubemq.io",
          "kind": "KubemqConnector",
          "version": "v1alpha1"
        },
        {
          "group": "core.k8s.kubemq.io",
          "kind": "KubemqConnector",
          "version": "v1beta1"
        },
        {
          "group": "core.k8s.kubemq.io",
          "kind": "KubemqDashboard",
          "version": "v1alpha1"
        },
        {
          "group": "core.k8s.kubemq.io",
          "kind": "KubemqDashboard",
          "version": "v1beta1"
        }
      ],
      "provider": null,
      "related_images": [],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.7.8",
      "version_original": "1.7.8"
    },
    {
      "_id": "6234603b314381d2b0756b43",
      "alm_examples": [
        {
          "api_version": "charts.cloudbees.com/v1alpha1",
          "kind": "CloudBeesCI",
          "metadata": {
            "name": "cloudbeesci-sample"
          },
          "spec": {
            "Agents": {
              "Enabled": true,
              "Image": {
                "dockerImage": "cloudbees/cloudbees-core-agent:2.289.3.2"
              },
              "SeparateNamespace": {
                "Create": false,
                "Enabled": false
              }
            },
            "Hibernation": {
              "Enabled": false,
              "Image": {
                "dockerImage": "cloudbees/managed-master-hibernation-monitor:247.c5dfce00a179"
              },
              "NodeSelector": {},
              "Tolerations": []
            },
            "Master": {
              "Enabled": true,
              "Image": {
                "dockerImage": "cloudbees/cloudbees-core-mm:2.289.3.2"
              }
            },
            "NetworkPolicy": {
              "Enabled": false,
              "JMXSelectors": [],
              "ingressControllerSelector": []
            },
            "OperationsCenter": {
              "AgentListenerPort": 50000,
              "Annotations": {},
              "CSRF": {
                "ProxyCompatibility": false
              },
              "CasC": {
                "ConfigMapName": "oc-casc-bundle",
                "Enabled": false
              },
              "ContainerPort": 8080,
              "Enabled": true,
              "ExtraConfigMaps": [],
              "ExtraContainers": [],
              "ExtraGroovyConfiguration": {},
              "ExtraVolumeMounts": [],
              "ExtraVolumes": [],
              "HealthProbeLivenessFailureThreshold": 12,
              "HealthProbes": true,
              "Image": {
                "dockerImage": "cloudbees/cloudbees-cloud-core-oc:2.289.3.2"
              },
              "Ingress": {
                "Annotations": {
                  "kubernetes.io/tls-acme": "false"
                },
                "Class": "nginx",
                "tls": {
                  "Enable": false
                }
              },
              "LoadBalancerSourceRanges": [
                "0.0.0.0/0"
              ],
              "Name": "cjoc",
              "NodeSelector": {},
              "Platform": "standard",
              "Protocol": "http",
              "Resources": {
                "Limits": {
                  "Cpu": 1,
                  "Memory": "2G"
                },
                "Requests": {
                  "Cpu": 1,
                  "Memory": "2G"
                }
              },
              "Route": {
                "tls": {
                  "Enable": false,
                  "InsecureEdgeTerminationPolicy": "Redirect",
                  "Termination": "edge"
                }
              },
              "ServiceAgentListenerPort": 50000,
              "ServiceAnnotations": {},
              "ServicePort": 80,
              "ServiceType": "ClusterIP",
              "Tolerations": []
            },
            "Persistence": {
              "AccessMode": "ReadWriteOnce",
              "Annotations": {},
              "Size": "20Gi"
            },
            "PodSecurityPolicy": {
              "Annotations": {},
              "Enabled": false
            },
            "Subdomain": false,
            "ingress-nginx": {
              "Enabled": false,
              "controller": {
                "admissionWebhooks": {
                  "patch": {
                    "nodeSelector": {
                      "kubernetes.io/os": "linux"
                    }
                  }
                },
                "ingressClass": "nginx",
                "nodeSelector": {
                  "kubernetes.io/os": "linux"
                },
                "service": {
                  "externalTrafficPolicy": "Local"
                }
              },
              "defaultBackend": {
                "nodeSelector": {
                  "kubernetes.io/os": "linux"
                }
              }
            },
            "nginx-ingress": {
              "Enabled": false,
              "controller": {
                "ingressClass": "nginx",
                "nodeSelector": {
                  "kubernetes.io/os": "linux"
                },
                "service": {
                  "externalTrafficPolicy": "Local"
                }
              },
              "defaultBackend": {
                "nodeSelector": {
                  "kubernetes.io/os": "linux"
                }
              }
            },
            "rbac": {
              "agentsServiceAccountName": "jenkins-agents",
              "hibernationMonitorServiceAccountName": "managed-master-hibernation-monitor",
              "install": true,
              "masterServiceAccountName": "jenkins",
              "serviceAccountName": "cjoc"
            },
            "sidecarinjector": {
              "Enabled": false
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cloudbees/cloudbees-core-modern@sha256:2cf058c819b40512094f84f4d374457455370ec4994d34cee6e39b9d87841f05",
      "bundle_path_digest": "sha256:2cf058c819b40512094f84f4d374457455370ec4994d34cee6e39b9d87841f05",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-03-18T10:34:35.226000+00:00",
      "csv_description": "CloudBees CI",
      "csv_display_name": "CloudBees CI",
      "csv_metadata_description": "",
      "csv_name": "cloudbees-ci.v3.34.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:37:37.207000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "cloudbees-ci",
      "provided_apis": [
        {
          "group": "charts.cloudbees.com",
          "kind": "CloudBeesCI",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:bd0bd72e9e7807b0fa307de8a93a56967221fe2dd181bac02383f0f9be9120e4",
          "image": "registry.connect.redhat.com/cloudbees/cloudbees-ci-operator@sha256:bd0bd72e9e7807b0fa307de8a93a56967221fe2dd181bac02383f0f9be9120e4",
          "name": "manager"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "3.34.1",
      "version_original": "3.34.1"
    },
    {
      "_id": "6234603d5593ce895a7b5369",
      "alm_examples": [
        {
          "api_version": "federatorai.containers.ai/v1alpha1",
          "kind": "AlamedaService",
          "metadata": {
            "name": "my-alamedaservice"
          },
          "spec": {
            "alamedaAi": {
              "storages": [
                {
                  "accessModes": [
                    "ReadWriteOnce"
                  ],
                  "size": "10Gi",
                  "type": "pvc",
                  "usage": "data"
                }
              ]
            },
            "alamedaInfluxdb": {
              "storages": [
                {
                  "accessModes": [
                    "ReadWriteOnce"
                  ],
                  "size": "100Gi",
                  "type": "pvc",
                  "usage": "data"
                }
              ]
            },
            "fedemeterInfluxdb": {
              "storages": [
                {
                  "accessModes": [
                    "ReadWriteOnce"
                  ],
                  "size": "10Gi",
                  "type": "pvc",
                  "usage": "data"
                }
              ]
            },
            "imageLocation": "registry.connect.redhat.com/prophetstor",
            "keycode": {
              "codeNumber": ""
            },
            "storages": [
              {
                "accessMode": [
                  "ReadWriteOnce"
                ],
                "size": "2Gi",
                "type": "pvc",
                "usage": "log"
              }
            ],
            "version": "v4.6.1-b1655-2"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/prophetstor/federatorai-operator-bundle@sha256:66fa5c8e525ce32eef696b286ba2278c0fca6be668bda76d28f5f78dc45c37e3",
      "bundle_path_digest": "sha256:66fa5c8e525ce32eef696b286ba2278c0fca6be668bda76d28f5f78dc45c37e3",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:34:37.349000+00:00",
      "csv_description": "Federator.ai helps enterprises optimize cloud resources, maximize application performance, and save significant cost without excessive over-provisioning or under-provisioning of resources, meeting the service-level requirements of their applications.\n\nEnterprises often lack understanding of the resources needed to support their applications. This leads to either excessive over-provisioning or under-provisioning of resources (CPU, memory, storage). Using machine learning, Federator.ai determines the optimal cloud resources needed to support any workload on OpenShift and helps users find the best-cost instances from cloud providers for their applications.\n\n\n**Multi-layer workload prediction**\n\nUsing machine learning and math-based algorithms, Federator.ai predicts containerized application and cluster node resource usage as the basis for resource recommendations at application level as well as at cluster node level. Federator.ai supports prediction for both physical/virtual CPUs and memories.\n\n\n**Auto-scaling via resource recommendation**\n\nFederator.ai utilizes the predicted resource usage to recommend the right number and size of pods for applications. Integrated with Datadog's WPA, applications are automatically scaled to meet the predicted resource usage.\n\n\n**Application-aware recommendation execution**\n\nOptimizing the resource usage and performance goals, Federator.ai uses application specific metrics for workload prediction and pod capacity estimation to auto-scale the right number of pods for best performance without overprovisioning.\n\n\n**Multi-cloud Cost Analysis**\n\nWith resource usage prediction, Federator.ai analyzes potential cost of a cluster on different public cloud providers. It also recommend appropriate cluster nodes and instance types based on resource usage.\n\n\n**Custom Datadog/Sysdig Dashboards**\n\nPredefined custom Datadog/Sysdig Dashboards for workload prediction/recommendation visualization for cluster nodes and applications.\n\n\n**Additional resources**\n\nWant more product information? Explore detailed information about using this product and where to find additional help.\n\n* [Federator.ai Datasheet](https://prophetstor.com/wp-content/uploads/datasheets/Federator.ai.pdf)\n* [Quick Start Guide](https://prophetstor.com/wp-content/uploads/documentation/Federator.ai/Latest%20Version/ProphetStor%20Federator.ai%20Quick%20Installation%20Guide.pdf)\n* [Installation Guide](https://prophetstor.com/wp-content/uploads/2021/07/ProphetStor-Federator.ai-v4.6.1-Installation-Guide-v1.0.pdf)\n* [User Guide](https://prophetstor.com/wp-content/uploads/2021/07/Federator.ai-4.6.1-User-Guide.pdf)\n* [Company Information](https://www.prophetstor.com/)\n\n\n### Prerequisite\n*  The [Openshift](https://www.openshift.com) version 4.4.x or later if using OpenShift platform.\n*  The [Kubernetes](https://kubernetes.io/) version 1.16 or later if using Kubernetes environment.",
      "csv_display_name": "Federator.ai",
      "csv_metadata_description": "Federator.ai Operator provides easy configuration and management of AI-based Kubernetes resource orchestrator",
      "csv_name": "federatorai.v4.6.1-4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:37:52.514000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "federatorai-certified",
      "provided_apis": [
        {
          "group": "federatorai.containers.ai",
          "kind": "AlamedaService",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:2c7070dcd426598c97e528b4fbc79de5585c4aeb4e5902406435a9e6d7e3bf0d",
          "image": "registry.connect.redhat.com/prophetstor/federatorai-operator@sha256:2c7070dcd426598c97e528b4fbc79de5585c4aeb4e5902406435a9e6d7e3bf0d",
          "name": "federatorai-operator-2c7070dcd426598c97e528b4fbc79de5585c4aeb4e5902406435a9e6d7e3bf0d-annotation"
        },
        {
          "digest": "sha256:2c7070dcd426598c97e528b4fbc79de5585c4aeb4e5902406435a9e6d7e3bf0d",
          "image": "registry.connect.redhat.com/prophetstor/federatorai-operator@sha256:2c7070dcd426598c97e528b4fbc79de5585c4aeb4e5902406435a9e6d7e3bf0d",
          "name": "federatorai-operator"
        },
        {
          "digest": "sha256:2c7070dcd426598c97e528b4fbc79de5585c4aeb4e5902406435a9e6d7e3bf0d",
          "image": "registry.connect.redhat.com/prophetstor/federatorai-operator@sha256:2c7070dcd426598c97e528b4fbc79de5585c4aeb4e5902406435a9e6d7e3bf0d",
          "name": "upgrader"
        },
        {
          "digest": "sha256:17aed4cd6a97f8ee5655660d2d13911e7c99c9f304b2fa09de891e4bf3141c69",
          "image": "registry.connect.redhat.com/prophetstor/alameda-ai-dispatcher@sha256:17aed4cd6a97f8ee5655660d2d13911e7c99c9f304b2fa09de891e4bf3141c69",
          "name": "ai_dispatcher"
        },
        {
          "digest": "sha256:0f946dde5fcb2f631153ea778ea24cac3e53b052a6bc97d09a0d2c04a8860446",
          "image": "registry.connect.redhat.com/prophetstor/alameda-ai@sha256:0f946dde5fcb2f631153ea778ea24cac3e53b052a6bc97d09a0d2c04a8860446",
          "name": "ai_engine"
        },
        {
          "digest": "sha256:222f6166fef3c74f187446adf5ab6361a03231eabab88a54ebd8f6f2a0ebd5c4",
          "image": "registry.connect.redhat.com/prophetstor/alameda-analyzer-ubi@sha256:222f6166fef3c74f187446adf5ab6361a03231eabab88a54ebd8f6f2a0ebd5c4",
          "name": "analyzer"
        },
        {
          "digest": "sha256:7601000fdaf7b937847cea40c4ac1b60ab843b1439e8a0c7e9dc4723408055ba",
          "image": "registry.connect.redhat.com/prophetstor/alameda-datahub-ubi@sha256:7601000fdaf7b937847cea40c4ac1b60ab843b1439e8a0c7e9dc4723408055ba",
          "name": "datahub"
        },
        {
          "digest": "sha256:d59db2fa0cdf0b0a66955297174641bef668db1d010e306b2bb711756ca57c38",
          "image": "registry.connect.redhat.com/prophetstor/alameda-executor-ubi@sha256:d59db2fa0cdf0b0a66955297174641bef668db1d010e306b2bb711756ca57c38",
          "name": "executor"
        },
        {
          "digest": "sha256:ae1e6994e8e1414a117308d7fb24bccfb093aaa8492d1d357a26f9e2ab7acf7c",
          "image": "registry.connect.redhat.com/prophetstor/fedemeter-api-ubi@sha256:ae1e6994e8e1414a117308d7fb24bccfb093aaa8492d1d357a26f9e2ab7acf7c",
          "name": "fedemeter_api"
        },
        {
          "digest": "sha256:d3b5505dd4fe688071f2d685773ed691cebcb04ff35eaf41e4f7a0331ff6e688",
          "image": "registry.connect.redhat.com/prophetstor/fedemeter-influxdb@sha256:d3b5505dd4fe688071f2d685773ed691cebcb04ff35eaf41e4f7a0331ff6e688",
          "name": "fedemeter_influxdb"
        },
        {
          "digest": "sha256:c5c2794413aea8384e8325a8cd9d86b4ec29ee5652e6b3bd172f15269e1d8ae0",
          "image": "registry.connect.redhat.com/prophetstor/federatorai-agent-ubi@sha256:c5c2794413aea8384e8325a8cd9d86b4ec29ee5652e6b3bd172f15269e1d8ae0",
          "name": "federatorai_agent"
        },
        {
          "digest": "sha256:468dfd11a6877103809cb17f56165d06e00d93a3c89411307249f921289fc1e4",
          "image": "registry.connect.redhat.com/prophetstor/federatorai-agent-preloader@sha256:468dfd11a6877103809cb17f56165d06e00d93a3c89411307249f921289fc1e4",
          "name": "federatorai_agent_preloader"
        },
        {
          "digest": "sha256:5a552ec0a78ae167ad7ff8dbdb02ac3de49d60df49bcbe6ca11091077e744a12",
          "image": "registry.connect.redhat.com/prophetstor/federatorai-dashboard-frontend@sha256:5a552ec0a78ae167ad7ff8dbdb02ac3de49d60df49bcbe6ca11091077e744a12",
          "name": "federatorai_dashboard_frontend"
        },
        {
          "digest": "sha256:77709a35443202cffd2ef4df9daabd6a00ab4e536525ce99a9fd4203a0669e9a",
          "image": "registry.connect.redhat.com/prophetstor/federatorai-dashboard-backend@sha256:77709a35443202cffd2ef4df9daabd6a00ab4e536525ce99a9fd4203a0669e9a",
          "name": "federatorai_dashboard_backend"
        },
        {
          "digest": "sha256:9c4ce48758ea58003cd25351c440e9aa12664cd59ee75bed8063374815f4d4da",
          "image": "registry.connect.redhat.com/prophetstor/federatorai-data-adapter@sha256:9c4ce48758ea58003cd25351c440e9aa12664cd59ee75bed8063374815f4d4da",
          "name": "federatorai_data_adapter"
        },
        {
          "digest": "sha256:801059280ae54de7eaa518f5701ea320696e5aa83b3cd7ef3ad82ba1e3e1d395",
          "image": "registry.connect.redhat.com/prophetstor/federatorai-rest-ubi@sha256:801059280ae54de7eaa518f5701ea320696e5aa83b3cd7ef3ad82ba1e3e1d395",
          "name": "federatorai_restapi"
        },
        {
          "digest": "sha256:a20096b566e7dde77e7e5885a60d47e6c8824f8db896f20b90676d14f7d2bcc8",
          "image": "registry.connect.redhat.com/prophetstor/alameda-influxdb@sha256:a20096b566e7dde77e7e5885a60d47e6c8824f8db896f20b90676d14f7d2bcc8",
          "name": "influxdb"
        },
        {
          "digest": "sha256:87afe424d8d205b8a2f01262e3edac73e8f3eee0aa597610b8a4ee57e17f4ac0",
          "image": "registry.connect.redhat.com/prophetstor/alameda-notifier-ubi@sha256:87afe424d8d205b8a2f01262e3edac73e8f3eee0aa597610b8a4ee57e17f4ac0",
          "name": "notifier"
        },
        {
          "digest": "sha256:d4fceace6cc1f0e80b8b6abe870ec9722ea69e91c481246b13e3d50a2c3e1ffb",
          "image": "registry.connect.redhat.com/prophetstor/alameda-operator-ubi@sha256:d4fceace6cc1f0e80b8b6abe870ec9722ea69e91c481246b13e3d50a2c3e1ffb",
          "name": "operator"
        },
        {
          "digest": "sha256:2b61bfd1ba9186cc50b8f960f54d0ec94643715292bb874762009b3045477799",
          "image": "registry.connect.redhat.com/prophetstor/alameda-rabbitmq@sha256:2b61bfd1ba9186cc50b8f960f54d0ec94643715292bb874762009b3045477799",
          "name": "rabbitmq"
        },
        {
          "digest": "sha256:288cb6c29200d07451b8e2ab53b9a5112108cb5f2b6dc288026f9c2f12f5f9fd",
          "image": "registry.connect.redhat.com/prophetstor/alameda-recommender-ubi@sha256:288cb6c29200d07451b8e2ab53b9a5112108cb5f2b6dc288026f9c2f12f5f9fd",
          "name": "recommender"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "4.6.1-4",
      "version_original": "4.6.1-4"
    },
    {
      "_id": "6234603f314381d2b0756b44",
      "alm_examples": [
        {
          "api_version": "federatorai.containers.ai/v1alpha1",
          "kind": "AlamedaService",
          "metadata": {
            "name": "my-alamedaservice"
          },
          "spec": {
            "alamedaAi": {
              "storages": [
                {
                  "accessModes": [
                    "ReadWriteOnce"
                  ],
                  "size": "10Gi",
                  "type": "pvc",
                  "usage": "data"
                }
              ]
            },
            "alamedaInfluxdb": {
              "storages": [
                {
                  "accessModes": [
                    "ReadWriteOnce"
                  ],
                  "size": "100Gi",
                  "type": "pvc",
                  "usage": "data"
                }
              ]
            },
            "fedemeterInfluxdb": {
              "storages": [
                {
                  "accessModes": [
                    "ReadWriteOnce"
                  ],
                  "size": "10Gi",
                  "type": "pvc",
                  "usage": "data"
                }
              ]
            },
            "imageLocation": "registry.connect.redhat.com/prophetstor",
            "storages": [
              {
                "accessMode": [
                  "ReadWriteOnce"
                ],
                "size": "2Gi",
                "type": "pvc",
                "usage": "log"
              }
            ],
            "version": "v4.7.1-b1760"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/prophetstor/federatorai-operator-bundle@sha256:d0ac978d749654ddf4cc20823805ba7d33ee62e9a7ec98fdd53d9926b697c347",
      "bundle_path_digest": "sha256:d0ac978d749654ddf4cc20823805ba7d33ee62e9a7ec98fdd53d9926b697c347",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:34:39.845000+00:00",
      "csv_description": "Federator.ai helps enterprises optimize cloud resources, maximize application performance, and save significant cost without excessive over-provisioning or under-provisioning of resources, meeting the service-level requirements of their applications.\n\nEnterprises often lack understanding of the resources needed to support their applications. This leads to either excessive over-provisioning or under-provisioning of resources (CPU, memory, storage). Using machine learning, Federator.ai determines the optimal cloud resources needed to support any workload on OpenShift and helps users find the best-cost instances from cloud providers for their applications.\n\n\n**Multi-layer workload prediction**\n\nUsing machine learning and math-based algorithms, Federator.ai predicts containerized application and cluster node resource usage as the basis for resource recommendations at application level as well as at cluster node level. Federator.ai supports prediction for both physical/virtual CPUs and memories.\n\n\n**Auto-scaling via resource recommendation**\n\nFederator.ai utilizes the predicted resource usage to recommend the right number and size of pods for applications. Integrated with Datadog's WPA, applications are automatically scaled to meet the predicted resource usage.\n\n\n**Application-aware recommendation execution**\n\nOptimizing the resource usage and performance goals, Federator.ai uses application specific metrics for workload prediction and pod capacity estimation to auto-scale the right number of pods for best performance without overprovisioning.\n\n\n**Multi-cloud Cost Analysis**\n\nWith resource usage prediction, Federator.ai analyzes potential cost of a cluster on different public cloud providers. It also recommend appropriate cluster nodes and instance types based on resource usage.\n\n\n**Custom Datadog/Sysdig Dashboards**\n\nPredefined custom Datadog/Sysdig Dashboards for workload prediction/recommendation visualization for cluster nodes and applications.\n\n\n**Additional resources**\n\nWant more product information? Explore detailed information about using this product and where to find additional help.\n\n* [Federator.ai Datasheet](https://prophetstor.com/wp-content/uploads/datasheets/Federator.ai.pdf)\n* [Quick Start Guide](https://prophetstor.com/wp-content/uploads/documentation/Federator.ai/Latest%20Version/ProphetStor%20Federator.ai%20Quick%20Installation%20Guide.pdf)\n* [Installation Guide](https://prophetstor.com/wp-content/uploads/2021/08/ProphetStor-Federator.ai-v4.7.0-Installation-Guide-v1.0.pdf)\n* [User Guide](https://prophetstor.com/wp-content/uploads/2021/08/Federator.ai-4.7.0-User-Guide.pdf)\n* [Release Notes](https://prophetstor.com/wp-content/uploads/2021/08/Federator.ai-4.7.0-Release-Notes.pdf)\n* [Company Information](https://www.prophetstor.com/)\n\n\n### Prerequisite\n*  The [Openshift](https://www.openshift.com) version 4.4.x or later if using OpenShift platform.\n*  The [Kubernetes](https://kubernetes.io/) version 1.16 or later if using Kubernetes environment.",
      "csv_display_name": "Federator.ai",
      "csv_metadata_description": "Federator.ai Operator provides easy configuration and management of AI-based Kubernetes resource orchestrator",
      "csv_name": "federatorai.v4.7.1-1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:37:58.393000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "federatorai-certified",
      "provided_apis": [
        {
          "group": "federatorai.containers.ai",
          "kind": "AlamedaService",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:bdd87f6b7d7ba9d12ed8ddb9c5151e5a89781e88d7a02b73814b16a766968047",
          "image": "registry.connect.redhat.com/prophetstor/federatorai-operator@sha256:bdd87f6b7d7ba9d12ed8ddb9c5151e5a89781e88d7a02b73814b16a766968047",
          "name": "federatorai-operator-bdd87f6b7d7ba9d12ed8ddb9c5151e5a89781e88d7a02b73814b16a766968047-annotation"
        },
        {
          "digest": "sha256:bdd87f6b7d7ba9d12ed8ddb9c5151e5a89781e88d7a02b73814b16a766968047",
          "image": "registry.connect.redhat.com/prophetstor/federatorai-operator@sha256:bdd87f6b7d7ba9d12ed8ddb9c5151e5a89781e88d7a02b73814b16a766968047",
          "name": "federatorai-operator"
        },
        {
          "digest": "sha256:bdd87f6b7d7ba9d12ed8ddb9c5151e5a89781e88d7a02b73814b16a766968047",
          "image": "registry.connect.redhat.com/prophetstor/federatorai-operator@sha256:bdd87f6b7d7ba9d12ed8ddb9c5151e5a89781e88d7a02b73814b16a766968047",
          "name": "upgrader"
        },
        {
          "digest": "sha256:6e0dc1136b0f8e5971d92b95ce0d6dfac475044c073bada50f23b315f4478ae4",
          "image": "registry.connect.redhat.com/prophetstor/alameda-ai-dispatcher@sha256:6e0dc1136b0f8e5971d92b95ce0d6dfac475044c073bada50f23b315f4478ae4",
          "name": "ai_dispatcher"
        },
        {
          "digest": "sha256:9293298bb2a72d0b0764050b6f6d8da707b46a83363a3b6aa7be60f512e2ec61",
          "image": "registry.connect.redhat.com/prophetstor/alameda-ai@sha256:9293298bb2a72d0b0764050b6f6d8da707b46a83363a3b6aa7be60f512e2ec61",
          "name": "ai_engine"
        },
        {
          "digest": "sha256:6117ac4692793d49bc0204f13091dec119bdbc7b169e9deb86c243aca00ded27",
          "image": "registry.connect.redhat.com/prophetstor/alameda-analyzer-ubi@sha256:6117ac4692793d49bc0204f13091dec119bdbc7b169e9deb86c243aca00ded27",
          "name": "analyzer"
        },
        {
          "digest": "sha256:3819d6acce8d376dbe3b12469be2528d0ce9ac95c2a86507aeb76b6e3a5f5f38",
          "image": "registry.connect.redhat.com/prophetstor/alameda-datahub-ubi@sha256:3819d6acce8d376dbe3b12469be2528d0ce9ac95c2a86507aeb76b6e3a5f5f38",
          "name": "datahub"
        },
        {
          "digest": "sha256:4512e3be7a89d0ca9f120b68f6ab9766d000bf2b01b279cd55b2dbc433aacfb6",
          "image": "registry.connect.redhat.com/prophetstor/alameda-executor-ubi@sha256:4512e3be7a89d0ca9f120b68f6ab9766d000bf2b01b279cd55b2dbc433aacfb6",
          "name": "executor"
        },
        {
          "digest": "sha256:451456207fe8d16b9824b3f64d00645766dcccbc8d685b6942e6c00d0d0c627e",
          "image": "registry.connect.redhat.com/prophetstor/fedemeter-api-ubi@sha256:451456207fe8d16b9824b3f64d00645766dcccbc8d685b6942e6c00d0d0c627e",
          "name": "fedemeter_api"
        },
        {
          "digest": "sha256:36904f003e8e29d4a9fd738655f401fbe840d60158d7d820cda79a09858dc2c2",
          "image": "registry.connect.redhat.com/prophetstor/fedemeter-influxdb@sha256:36904f003e8e29d4a9fd738655f401fbe840d60158d7d820cda79a09858dc2c2",
          "name": "fedemeter_influxdb"
        },
        {
          "digest": "sha256:cfadc84f31f3776ded15d4d8dda92e00b7d9b1bce0ff5440277176292f9304d3",
          "image": "registry.connect.redhat.com/prophetstor/federatorai-agent-ubi@sha256:cfadc84f31f3776ded15d4d8dda92e00b7d9b1bce0ff5440277176292f9304d3",
          "name": "federatorai_agent"
        },
        {
          "digest": "sha256:66daea6193e399f8363df5ba42e1fcd643db6df3a9075dbcd8c3464fdc91e776",
          "image": "registry.connect.redhat.com/prophetstor/federatorai-agent-preloader@sha256:66daea6193e399f8363df5ba42e1fcd643db6df3a9075dbcd8c3464fdc91e776",
          "name": "federatorai_agent_preloader"
        },
        {
          "digest": "sha256:1c1147425ca6302103363a1a3bcf27baeef13b10ec6780ef266b7f52fe27ffeb",
          "image": "registry.connect.redhat.com/prophetstor/federatorai-dashboard-frontend@sha256:1c1147425ca6302103363a1a3bcf27baeef13b10ec6780ef266b7f52fe27ffeb",
          "name": "federatorai_dashboard_frontend"
        },
        {
          "digest": "sha256:022dbf6696edb8eaf389fdbd1dff14c40a51c237c01f8a02a7ea65c60cd59f38",
          "image": "registry.connect.redhat.com/prophetstor/federatorai-dashboard-backend@sha256:022dbf6696edb8eaf389fdbd1dff14c40a51c237c01f8a02a7ea65c60cd59f38",
          "name": "federatorai_dashboard_backend"
        },
        {
          "digest": "sha256:adf5d655fa030dc05133516d45642d7282fdd66e0aa8e7a7331ed614a41d3fe0",
          "image": "registry.connect.redhat.com/prophetstor/federatorai-data-adapter@sha256:adf5d655fa030dc05133516d45642d7282fdd66e0aa8e7a7331ed614a41d3fe0",
          "name": "federatorai_data_adapter"
        },
        {
          "digest": "sha256:3e92528615543ea900bf38387c4eb8439b60759be5be2ac5311a9dbaafc7026b",
          "image": "registry.connect.redhat.com/prophetstor/federatorai-rest-ubi@sha256:3e92528615543ea900bf38387c4eb8439b60759be5be2ac5311a9dbaafc7026b",
          "name": "federatorai_restapi"
        },
        {
          "digest": "sha256:485c2119a6a56807e28ad03b2087129950118b55531126a66bb414063052ae76",
          "image": "registry.connect.redhat.com/prophetstor/alameda-influxdb@sha256:485c2119a6a56807e28ad03b2087129950118b55531126a66bb414063052ae76",
          "name": "influxdb"
        },
        {
          "digest": "sha256:1f75034fb78d62924a87cb4a5435661b4afa990d6960431e784029742fbae0da",
          "image": "registry.connect.redhat.com/prophetstor/alameda-notifier-ubi@sha256:1f75034fb78d62924a87cb4a5435661b4afa990d6960431e784029742fbae0da",
          "name": "notifier"
        },
        {
          "digest": "sha256:9a863394cb1c89228223b26addb0d12bb91a97233fe2d5d19ecd5998e0cfe0d6",
          "image": "registry.connect.redhat.com/prophetstor/alameda-operator-ubi@sha256:9a863394cb1c89228223b26addb0d12bb91a97233fe2d5d19ecd5998e0cfe0d6",
          "name": "operator"
        },
        {
          "digest": "sha256:b396d9aa0470e593a36f5799c04fc3c9e59b5723f703f4b019f7ef92528e6741",
          "image": "registry.connect.redhat.com/prophetstor/alameda-rabbitmq@sha256:b396d9aa0470e593a36f5799c04fc3c9e59b5723f703f4b019f7ef92528e6741",
          "name": "rabbitmq"
        },
        {
          "digest": "sha256:13e941df9252cea3024ecb5e2247a696b64928015c1a3a4a04ee4e362388b1e4",
          "image": "registry.connect.redhat.com/prophetstor/alameda-recommender-ubi@sha256:13e941df9252cea3024ecb5e2247a696b64928015c1a3a4a04ee4e362388b1e4",
          "name": "federatorai_recommend_dispatcher"
        },
        {
          "digest": "sha256:13e941df9252cea3024ecb5e2247a696b64928015c1a3a4a04ee4e362388b1e4",
          "image": "registry.connect.redhat.com/prophetstor/alameda-recommender-ubi@sha256:13e941df9252cea3024ecb5e2247a696b64928015c1a3a4a04ee4e362388b1e4",
          "name": "federatorai_recommend_worker"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "4.7.1-1",
      "version_original": "4.7.1-1"
    },
    {
      "_id": "623460415593ce895a7b536a",
      "alm_examples": [],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/runai/runai-operator@sha256:c9379256b0ce19b686f999ec2f0cfac1e8c69c8fbb47d574d8ccf485cc5f920a",
      "bundle_path_digest": "sha256:c9379256b0ce19b686f999ec2f0cfac1e8c69c8fbb47d574d8ccf485cc5f920a",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "fast",
      "creation_date": "2022-03-18T10:34:41.539000+00:00",
      "csv_description": "Run:AI is a cloud-native compute management platform for the AI era. Run:AI gives data scientists access to all of the pooled compute power they need to accelerate AI development and deployment - whether on-premises or in the cloud. The platform provides IT and MLOps with real-time visibility and control over scheduling and dynamic provisioning of GPUs to deliver more than 2X gains in utilization of existing GPU infrastructure. Built on Kubernetes, Run:AI enables seamless integration with existing IT and data science workflows. More at www.run.ai.",
      "csv_display_name": "Run:AI",
      "csv_metadata_description": "",
      "csv_name": "installkit-customer.v2.0.15",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-16T16:38:32.742000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "installkit-customer",
      "provided_apis": [],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:75d3eaaa698a72b25fae2ebd414e1a49339517f3a75f752bb76704f673edeb08",
          "image": "gcr.io/runai-openshift/operator@sha256:75d3eaaa698a72b25fae2ebd414e1a49339517f3a75f752bb76704f673edeb08",
          "name": "operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2.1.5",
      "version_original": "2.1.5"
    },
    {
      "_id": "62346043314381d2b0756b45",
      "alm_examples": [],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/runai/runai-operator@sha256:c9379256b0ce19b686f999ec2f0cfac1e8c69c8fbb47d574d8ccf485cc5f920a",
      "bundle_path_digest": "sha256:c9379256b0ce19b686f999ec2f0cfac1e8c69c8fbb47d574d8ccf485cc5f920a",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "preview",
      "creation_date": "2022-03-18T10:34:43.572000+00:00",
      "csv_description": "Run:AI is a cloud-native compute management platform for the AI era. Run:AI gives data scientists access to all of the pooled compute power they need to accelerate AI development and deployment - whether on-premises or in the cloud. The platform provides IT and MLOps with real-time visibility and control over scheduling and dynamic provisioning of GPUs to deliver more than 2X gains in utilization of existing GPU infrastructure. Built on Kubernetes, Run:AI enables seamless integration with existing IT and data science workflows. More at www.run.ai.",
      "csv_display_name": "Run:AI",
      "csv_metadata_description": "",
      "csv_name": "installkit-customer.v2.0.15",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-04-16T16:38:37.309000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "installkit-customer",
      "provided_apis": [],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:75d3eaaa698a72b25fae2ebd414e1a49339517f3a75f752bb76704f673edeb08",
          "image": "gcr.io/runai-openshift/operator@sha256:75d3eaaa698a72b25fae2ebd414e1a49339517f3a75f752bb76704f673edeb08",
          "name": "operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2.1.5",
      "version_original": "2.1.5"
    },
    {
      "_id": "62346045670f4cadbafad2b3",
      "alm_examples": [],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/runai/runai-operator@sha256:c9379256b0ce19b686f999ec2f0cfac1e8c69c8fbb47d574d8ccf485cc5f920a",
      "bundle_path_digest": "sha256:c9379256b0ce19b686f999ec2f0cfac1e8c69c8fbb47d574d8ccf485cc5f920a",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:34:45.862000+00:00",
      "csv_description": "Run:AI is a cloud-native compute management platform for the AI era. Run:AI gives data scientists access to all of the pooled compute power they need to accelerate AI development and deployment - whether on-premises or in the cloud. The platform provides IT and MLOps with real-time visibility and control over scheduling and dynamic provisioning of GPUs to deliver more than 2X gains in utilization of existing GPU infrastructure. Built on Kubernetes, Run:AI enables seamless integration with existing IT and data science workflows. More at www.run.ai.",
      "csv_display_name": "Run:AI",
      "csv_metadata_description": "",
      "csv_name": "installkit-customer.v2.0.15",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-04-16T16:38:42.384000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "installkit-customer",
      "provided_apis": [],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:75d3eaaa698a72b25fae2ebd414e1a49339517f3a75f752bb76704f673edeb08",
          "image": "gcr.io/runai-openshift/operator@sha256:75d3eaaa698a72b25fae2ebd414e1a49339517f3a75f752bb76704f673edeb08",
          "name": "operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2.1.5",
      "version_original": "2.1.5"
    },
    {
      "_id": "623460475593ce895a7b536b",
      "alm_examples": [
        {
          "api_version": "dynatrace.com/v1alpha1",
          "kind": "DynaKube",
          "metadata": {
            "name": "dynakube",
            "namespace": "dynatrace"
          },
          "spec": {
            "activeGate": {
              "image": ""
            },
            "apiUrl": "https://ENVIRONMENTID.live.dynatrace.com/api",
            "classicFullStack": {
              "enabled": true,
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master",
                  "operator": "Exists"
                }
              ]
            },
            "kubernetesMonitoring": {
              "enabled": true
            },
            "oneAgent": {
              "image": ""
            },
            "routing": {
              "enabled": true
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/dynatrace/dynatrace-operator-bundle@sha256:1a3898915535373eed8f860b8eb906fa2ecaebbb95c4e2d74488e12ca1540f9b",
      "bundle_path_digest": "sha256:1a3898915535373eed8f860b8eb906fa2ecaebbb95c4e2d74488e12ca1540f9b",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-03-18T10:34:47.845000+00:00",
      "csv_description": "The Dynatrace Operator supports rollout and lifecycle of various Dynatrace components in Kubernetes and OpenShift.\n\nAs of launch, the Dynatrace Operator can be used to deploy a containerized ActiveGate for Kubernetes API monitoring. New capabilities will be added to the Dynatrace Operator over time including metric routing, and API monitoring for AWS, Azure, GCP, and vSphere.\n\nWith v0.2.0 we added the classicFullStack functionality which allows rolling out the OneAgent to your Kubernetes cluster.\nFurthermore, the Dynatrace Operator is now capable of rolling out a containerized ActiveGate for routing the OneAgent traffic.\n\n### Installation\nOnce you've installed the Dynatrace Operator, you can create a DynaKube custom resource.\n\nFirst, please add a Secret within the Project you've deployed the Dynatrace Operator to, which would contain your API and PaaS tokens. Create tokens of type *Dynatrace API* (`API_TOKEN`) and *Platform as a Service* (`PAAS_TOKEN`) and use their values in the following commands respectively.\n\nFor assistance please refer to [Create user-generated access tokens](https://www.dynatrace.com/support/help/shortlink/token#create-user-generated-access-tokens).\n\n``` $ oc -n <project> create secret generic dynakube --from-literal=\"apiToken=API_TOKEN\" --from-literal=\"paasToken=PAAS_TOKEN\" ```\n\nYou may update this Secret at any time to rotate the tokens.\n\nAfter creation of the secret add the DynaKube object in the project where the Dynatrace Operator has been deployed, configured to your needs.\n\n### Required Parameters\n* `apiUrl` - provide the URL to the API of your Dynatrace environment. In Dynatrace SaaS it will look like `https://<ENVIRONMENTID>.live.dynatrace.com/api` . In Dynatrace Managed like `https://<YourDynatraceServerURL>/e/<ENVIRONMENTID>/api` .\n\n### Advanced Options\n* **Disable Certificate Checking** - disable any certificate validation that may interact poorly with proxies with in your cluster\n* **Image Override** - use a copy of the ActiveGate container image from a registry other than Docker's or Red Hat's\n\n#### Kubernetes Monitoring\n* **Kubernetes Monitoring** - when enabled the Dynatrace Operator will create a containerized ActiveGate with the capability to monitor your OpenShift cluster\n* **Replicas** - defines how many replicas of the containerized ActiveGate should be created\n* **NodeSelectors** - select a subset of your cluster's nodes to run the Dynatrace ActiveGate on, based on labels\n* **Environment variables** - define environment variables for the ActiveGate container\n\nFor a complete list of supported parameters please consult the [Operator Deploy Guide](https://www.dynatrace.com/support/help/shortlink/openshift-deploy).\n\n### Help\nYou can find more about our instructions in our [documentation](https://www.dynatrace.com/support/help/shortlink/openshift-deploy#install-dynatrace-operator).\n",
      "csv_display_name": "Dynatrace Operator",
      "csv_metadata_description": "",
      "csv_name": "dynatrace-operator.v0.2.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:35:17.615000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "dynatrace-operator",
      "provided_apis": [
        {
          "group": "dynatrace.com",
          "kind": "DynaKube",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:afac1c0f4035ac032a0224f1214e12ab58fb6262f90e630598482abbfdccbac3",
          "image": "registry.connect.redhat.com/dynatrace/dynatrace-operator@sha256:afac1c0f4035ac032a0224f1214e12ab58fb6262f90e630598482abbfdccbac3",
          "name": "dynatrace-operator-afac1c0f4035ac032a0224f1214e12ab58fb6262f90e630598482abbfdccbac3-annotation"
        },
        {
          "digest": "sha256:afac1c0f4035ac032a0224f1214e12ab58fb6262f90e630598482abbfdccbac3",
          "image": "registry.connect.redhat.com/dynatrace/dynatrace-operator@sha256:afac1c0f4035ac032a0224f1214e12ab58fb6262f90e630598482abbfdccbac3",
          "name": "dynatrace-operator"
        },
        {
          "digest": "sha256:3975446f23bfd4cab0930d3cba62a795893f9085084e6887121ceaa94391c849",
          "image": "registry.connect.redhat.com/dynatrace/oneagent@sha256:3975446f23bfd4cab0930d3cba62a795893f9085084e6887121ceaa94391c849",
          "name": "dynatrace_oneagent"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "0.2.2",
      "version_original": "0.2.2"
    },
    {
      "_id": "62346049670f4cadbafad2b4",
      "alm_examples": [
        {
          "api_version": "aiml.pachyderm.com/v1beta1",
          "kind": "Pachyderm",
          "metadata": {
            "name": "pachyderm-sample"
          },
          "spec": {
            "console": {
              "disable": true
            },
            "pachd": {
              "metrics": {
                "disable": false
              },
              "storage": {
                "amazon": {
                  "credentialSecretName": "pachyderm-aws-secret"
                },
                "backend": "AMAZON"
              }
            }
          }
        },
        {
          "api_version": "aiml.pachyderm.com/v1beta1",
          "kind": "PachydermExport",
          "metadata": {
            "name": "pachydermexport-sample"
          },
          "spec": {
            "backup": {
              "target": "pachyderm-sample"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/pachyderm/pachyderm-bundle@sha256:73dd26531fc6c4b245e8b955981e12b556b9ecd0806444f275e8c8a02522acce",
      "bundle_path_digest": "sha256:73dd26531fc6c4b245e8b955981e12b556b9ecd0806444f275e8c8a02522acce",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:34:49.749000+00:00",
      "csv_description": "The Pachyderm operator aims to make deploying and managing Pachyderm instances on Openshift container platform easier.\n\nPachyderm is the data foundation for machine learning.  Pachyderm provides industry leading data versioning, pipelines and lineage that allow data science teams to automate the machine learning lifecycle and optimize their machine learning operations (MLOps). \n\n## Getting started\n\n1. Pachyderm uses an object store to store your data. Set the pachd storage backend at `pachyderm.spec.pachd.storage.backend` to `AMAZON`, `MICROSOFT`, `GOOGLE` or `MINIO` depending on your storage provider. Additionally, create a user with read/write access to the object store.\n\n2. Setup the user credentials in the section, `pachyderm.spec.pachd.storage`. Required fields depend on the backend type set in step 1 above.\n\n3. Finally, deploy the pachyderm cluster in its own namespace.\n\nFor more information on getting started, reference the documentation.\n",
      "csv_display_name": "Pachyderm",
      "csv_metadata_description": "Pachyderm provides the data layer that allows data science teams to productionize and scale their machine learning lifecycle with data driven automation, petabyte scalability and end-to-end reproducibility.",
      "csv_name": "pachyderm-operator.v0.1.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:36:20.736000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "pachyderm-operator",
      "provided_apis": [
        {
          "group": "aiml.pachyderm.com",
          "kind": "Pachyderm",
          "version": "v1beta1"
        },
        {
          "group": "aiml.pachyderm.com",
          "kind": "PachydermExport",
          "version": "v1beta1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:1c8df9a3d91c94abea9a69c5606339bd6468b74dee18ac0a24ad5d035f797387",
          "image": "registry.connect.redhat.com/pachyderm/pachyderm-operator@sha256:1c8df9a3d91c94abea9a69c5606339bd6468b74dee18ac0a24ad5d035f797387",
          "name": "pachyderm-operator"
        },
        {
          "digest": "sha256:5e33f9d095952866b9743cc8268fb740cce6d93439f00ce333a2de1e5974837e",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:5e33f9d095952866b9743cc8268fb740cce6d93439f00ce333a2de1e5974837e",
          "name": "ose-kube-rbac-proxy"
        },
        {
          "digest": "sha256:87eb579178095756d755b7d6d4025391e24e3e802e783f80c095c6546ed83b69",
          "image": "registry.connect.redhat.com/pachyderm/pachd@sha256:87eb579178095756d755b7d6d4025391e24e3e802e783f80c095c6546ed83b69",
          "name": "pachd"
        },
        {
          "digest": "sha256:b431eb982f267b3ed962f9f84864bdac78071071c43b5ec82c1d3d2f08d8e20a",
          "image": "registry.connect.redhat.com/pachyderm/worker@sha256:b431eb982f267b3ed962f9f84864bdac78071071c43b5ec82c1d3d2f08d8e20a",
          "name": "worker"
        },
        {
          "digest": "sha256:89726ad77875670475288419b61bcf2729cf1aa7606738a916bf78c3dbf8f10f",
          "image": "registry.connect.redhat.com/pachyderm/etcd@sha256:89726ad77875670475288419b61bcf2729cf1aa7606738a916bf78c3dbf8f10f",
          "name": "etcd"
        },
        {
          "digest": "sha256:2eadf50ef5c5709b5a2a67f2888a1cddbd3c283ace280d844cc1ef0c4a6fb6cd",
          "image": "registry.redhat.io/rhel8/postgresql-13@sha256:2eadf50ef5c5709b5a2a67f2888a1cddbd3c283ace280d844cc1ef0c4a6fb6cd",
          "name": "postgresql"
        },
        {
          "digest": "sha256:305b1f447a57bba7cf69b56130e95e817507d5cbc5ab5a0a63b77772eb71a12a",
          "image": "registry.connect.redhat.com/pachyderm/pgbouncer@sha256:305b1f447a57bba7cf69b56130e95e817507d5cbc5ab5a0a63b77772eb71a12a",
          "name": "pgbouncer"
        },
        {
          "digest": "sha256:bef6d565ba29eaeb07450ca0594ec1ee76f9fabd67e8bc4809bdb5d6799c4f3e",
          "image": "registry.connect.redhat.com/pachyderm/init-utils@sha256:bef6d565ba29eaeb07450ca0594ec1ee76f9fabd67e8bc4809bdb5d6799c4f3e",
          "name": "init-utils"
        },
        {
          "digest": "sha256:1c8df9a3d91c94abea9a69c5606339bd6468b74dee18ac0a24ad5d035f797387",
          "image": "registry.connect.redhat.com/pachyderm/pachyderm-operator@sha256:1c8df9a3d91c94abea9a69c5606339bd6468b74dee18ac0a24ad5d035f797387",
          "name": "pachyderm-operator-1c8df9a3d91c94abea9a69c5606339bd6468b74dee18ac0a24ad5d035f797387-annotation"
        },
        {
          "digest": "sha256:5e33f9d095952866b9743cc8268fb740cce6d93439f00ce333a2de1e5974837e",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:5e33f9d095952866b9743cc8268fb740cce6d93439f00ce333a2de1e5974837e",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:1c8df9a3d91c94abea9a69c5606339bd6468b74dee18ac0a24ad5d035f797387",
          "image": "registry.connect.redhat.com/pachyderm/pachyderm-operator@sha256:1c8df9a3d91c94abea9a69c5606339bd6468b74dee18ac0a24ad5d035f797387",
          "name": "manager"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "0.1.0",
      "version_original": "0.1.0"
    },
    {
      "_id": "6234604b670f4cadbafad2b5",
      "alm_examples": [
        {
          "api_version": "vfunction.com/v1",
          "kind": "VfunctionServer",
          "metadata": {
            "labels": {
              "app.kubernetes.io/instance": "vfunction-server",
              "app.kubernetes.io/managed-by": "operator",
              "app.kubernetes.io/name": "vfunction",
              "name": "vfunction"
            },
            "name": "example-vfunction-server",
            "namespace": "vfunction"
          },
          "spec": {
            "admin": {
              "email": "admin@mycompany.com",
              "name": "Admin",
              "password": "Password1!"
            },
            "host": "http://my.domain.com",
            "measurements": {
              "auto_scaling": "No",
              "max_number_of_services": "10",
              "min_number_of_services": "2"
            },
            "org_name": "MyCompany",
            "smtp": {
              "identity": "",
              "password": "",
              "url": "",
              "user": ""
            },
            "tls": {
              "crt": "",
              "key": ""
            },
            "upgrade": "Daily"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/vfunction/vfunction-server-operator-bundle@sha256:75cb80116afa46260ad077967679040ee495535933a640f152ed2e2012226d13",
      "bundle_path_digest": "sha256:75cb80116afa46260ad077967679040ee495535933a640f152ed2e2012226d13",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-18T10:34:51.447000+00:00",
      "csv_description": "\n## Introduction\n\n[vFunction](https://www.vfunction.com/) is a cloud-native modernization platform that combines dynamic and static code analysis, machine learning, and automation to automatically identify and extract services from existing applications. vFunction is the only platform purpose-built for modernization of Java applications.\n\nThe vFunction modernization process starts by learning the running monolithic application, and surfacing the interdependencies within it. Using AI, the platform analyzes and identifies services that can be separated from the application. This decomposition can present a range of micro, mini, or even macro services, depending on your application environment, each being an independently deployable and scalable application component.\n\nvFunction automates the extraction of these services, enabling you to modernize your monolith, quickly and easily.\n\n## The vFunction platform\n\nThe platform consists of 3 basic components; the server, the controller package, and a tools package. The server runs as an operand on an OpenShift environment. The controller package is installed on the machine that runs the monolithic application which can be either a Linux or a Windows machine, and the tools are run on a development machine, with access to the code of the monolithic application.\n\nThe controller package consists of three elements: the vFunction agent, that collects data during the dynamic analysis phase; the vFunction Viper application, that performs static analysis on the binaries of the application; and the vFunction controller that handles all the communication between the agent, Viper, and the vFunction server.\n\nThe vFunction agent is a mix of a Java and native agent, and needs to run on the JVM that is currently running your application. [Refer to the vFunction OOB Support Matrix document](https://drive.google.com/file/d/1ccq8LFab1FrYAimDUxwgjiCOdk4QuVzs/view) for a list of supported application servers and JVMs.\n\nThis operator installs a vFunction server instance to be connected later with one or more vFunction controllers installed on your application machine(s).\n\n## Before You Start\n\nThe vFunction operator requires a Red Hat OpenShift Kubernetes Application Platform 4.x.\n\nThe cluster recommended configuration (which is the same as the minimal one) should consist of:\n\n- *1 master node*\n\n- *1 worker node*\n\n- *Storage capacity enough for dynamically provision 2 PVs of 50G each*\n\n- *A default StorageClass configured*\n\nvFunction doesn\u2019t provide any encryption mechanism for data stored on any attached storage. If required, encryption can be achieved by the client by using its own external means on the storage itself.\n\nvFunction supports backup of all critical data as part of the application. Nevertheless, for complete backup of entire data it is recommended that the client apply its own storage based backup mechanism.\n\n## Install Prerequisites\n\n###Cluster:\nThe operator was certified and tested on OCP 4.6 and 4.7.\nIf you encounter any issue with other OCP versions or cloud providers please contact info@vfunction.com.\n\n###Storage:\nThe operator creates two new PersistentVolumeClaims (PVCs) during installation time. For their creation, it relies on the default StorageClass to dynamically provision two PersistentVolumes (PVs). The system must have a default StorageClass in place.\n\nBoth PersistentVolumes are accessed with ReadWriteOnce mode.\n\n###Project:\nThe operator should be installed in a new and dedicated project (namespace). If you intend to install more than one vFunction operands in the same cluster, please use different projects for each one. Installation of more than one operand on the same cluster will allow scaling by load balancing multiple applications to different vFunction servers.\n\n## Installation instructions\n\n1. Prepare the YAML file to use in the installation:\n\n    a. Copy the following YAML template into a text editor:\n\n    ```yaml\n        apiVersion: vfunction.com/v1\n        kind: VfunctionServer\n        metadata:\n          name: vfunction\n          namespace: vfunction\n          labels:\n            name: vfunction\n            app.kubernetes.io/name: vfunction\n            app.kubernetes.io/instance: vfunction-server\n            app.kubernetes.io/managed-by: operator\n        spec:\n          host: \"http://my.domain.com\"\n          org_name: \"MyCompany\"\n          upgrade: \"Daily\"\n          admin:\n            email: \"admin@mycompany.com\"\n            name: \"Admin\"\n            password: \"Password1!\"\n          smtp:\n            password: \"\"\n            url: \"\"\n            identity: \"\"\n            user: \"\"\n          measurements:\n            auto_scaling: \"No\"\n            min_number_of_services: \"2\"\n            max_number_of_services: \"10\"\n          tls:\n            crt: |\n              -----BEGIN CERTIFICATE-----\n              ...\n              -----END CERTIFICATE-----\n            key: |\n              -----BEGIN PRIVATE KEY-----\n              ...\n              -----END PRIVATE KEY-----\n    ```\n    b. Customize the template fields by replacing with your information:\n\n    - **host**: Enter the FQDN for accessing the vFunction dashboard.\n                Make sure that you use a domain name and not an IP address. Writing \"https://\" will mandate TLS while writing \"http://\" will expose the server through HTTP.\n    - **org_name**: Enter your organization name.\n    - **upgrade**: Choose auto-upgrade mode\n        - **Daily**: The operator will check for a new version every day at 3 AM and will install it automatically (default).\n        - **Always**: The operator will check for a new version every 10 minutes and will install it automatically.\n        - **Never**: The automatic upgrading mechanism is off.\n        - **Maintenance**: Put the operator in a maintenance mode.\n\n    - **admin.email**: Enter the email address of your administrator.\n    - **admin.name**: Enter the name of your administrator.\n    - **admin.password**: Enter the password you want to use for the vFunction administrator.\n                          The password should be at least 8 characters long, and consist of at least one lowercase letter, at least one uppercase letter, at least one number, and at least one special character.\n    - **smtp.user**: Enter the email address for a designated user for the SMTP server (optional).\n    - **smtp.password**: Enter this user\u2019s password (optional).\n    - **smtp.identity**: Enter this user\u2019s password (optional).\n    - **smtp.url**: Enter the SMTP server URL (optional).\n    - **tls.crt**: If your host FQDN starts with \u201chttps\u201d, paste in the certifications you have for using the TLS connection.\n    - **tls.key**: If your host FQDN starts with \u201chttps\u201d, enter the key you have for using the TLS connection.\n    - **measurements.auto_scaling**: Indicates if the measurement services auto scalling is active.\n    - **measurements.min_num_of_services**: Minimum Number of measurement service pods.\n    - **measurements.max_num_of_services**: Maximum Number of measurement service pods.\n    - **measurements.S3**: Save all measurements data to S3, instead of local PV (optional).\n        - **measurements.S3.bucket**: Measurements S3 bucket name.\n        - **measurements.S3.key**: Measurements S3 key.\n        - **measurements.S3.secret**: Measurements S3 secret.\n        - **measurements.S3.region**: Measurements S3 region.\n    - **backup.mysql.S3**: Backup MySQL to S3 (optional).\n        - **backup.mysql.S3.bucket**: MySQL backup S3 bucket name.\n        - **backup.mysql.S3.key**: MySQL backup S3 key.\n        - **backup.mysql.S3.secret**: MySQL backup S3 secret.\n        - **backup.mysql.S3.region**: MySQL backup S3 region.\n\n1. In the Installed Operators window choose and click on vFunction Operator and then Create Instance.\n1. In the Create vFunctionServer window, paste the YAML file that you created in step 1.\n1. Click Create.\n1. You can now click on your new created vFunction operand in order to see its details and installation progress.\n\n## Verifying the installation\n\nCheck that the operand installed successfully:\n\n1. Check that the \"Operand State\" property shows \u201cWorking\u201d.\n1. Check that the \"Successfully Installed\" property shows \"Yes\".\n\nIf \"Operand State\" shows \"Failed\", it indicates the operand wasn\u2019t installed correctly. Check the events and logs for all pods (operator and image containers) for any issues. In the event that you cannot troubleshoot, contact vFunction support.\n\n## After installation\n\nThe vFunction site is now accessible via the newly created vFunction application custom address, for example, my.domain.com. There are two ways you can access the vFunction dashboard.\n\n### Access using the router canonical hostname\n\n1. Update your DNS provider by creating a canonical name (CNAME) record.\nThis record should point to your host address, and to the \u201dvfunction\u201d subdomain of the  OpenShift canonical router hostname as the alias.\nFor example, ***my.domain.com.   CNAME   vfunction.apps.ocp4.my-openshift.com.***\n2. Find your cluster Router Canonical Hostname address in the newly created vfunction-route-xxx under your vFunction OpenShift project -> **Networking** -> **Routes** -> **vfunction-route-xxx** route -> **Router Canonical Hostname** field.\nYou can now access the dashboard using your defined \"host\" spec property (as above).\n\n### Access using the nginx service location\n\nYou may use this access method if your OpenShift is installed on a provider that supports exposing LoadBalancer-type services.\n1. Update your DNS provider by creating a canonical name (CNAME) record.\nThis record should point to your host address and to the vfunction-nginx-xxx service location.\nFor example, ***my.domain.com.   CNAME   a05951ed7cdf-1394239323.us-east-1.elb.amazonaws.com.***\n1. Point your custom domain to the vfunction-nginx-xxx service's external IP location, which you can find in the OpenShift project > **Networking** -> **Services** -> **vfunction-nginx-xxx** service > **Service Address** > **Location** field.\n\n## Upgrade and Rollback\n\nThe vFunction operator includes a built-in auto-upgrade mechanism.\n\nYou can choose one of 4 upgrading modes:\n- **Daily**: The operator will check for a new version every day at 3 AM and will install it automatically (default).\n- **Always**: The operator will check for a new version every 10 minutes and will install it automatically.\n- **Never**: The automatic upgrading mechanism is off.\n- **Maintenance**: Put the operator in a maintenance mode.\n\nFor an on-demand upgrade,  you can change anytime the upgrading mode from \u201cNever\u201d to \u201cAlways\u201d, wait for the operand to be upgraded, and change again to \u201cNever\u201d.\n\nDuring the upgrade, the \"Operand State\" property will change to \u201cUpgrading...\u201d and back again to \u201cWorking\u201d after a successful upgrade.\n\nIn case of a failure upgrading the operand, an automatic rollback to the last working version will occur. The failed version will be marked as defective and the operator will not try to upgrade to it again.\n\nChoosing the \"Maintenance\" option will tell the operator to take down all pods, so you can safely fix storage issues, return volumes from snapshots, etc.\nAfter finishing the maintenance, return the upgrade mode to your original desired policy.",
      "csv_display_name": "vFunction Operator",
      "csv_metadata_description": "vFunction is a cutting-edge code analysis, machine learning, and automation to boost your Java modernization projects.",
      "csv_name": "vfunction-server-operator.v2.2.469",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:39:41.551000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "vfunction-server-operator",
      "provided_apis": [
        {
          "group": "vfunction.com",
          "kind": "VfunctionServer",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:60d1965460101d0fd90ecc9499d0a6d4c9684a54ada61a43a253d30661fab22f",
          "image": "registry.connect.redhat.com/vfunction/vfunction-server-operator@sha256:60d1965460101d0fd90ecc9499d0a6d4c9684a54ada61a43a253d30661fab22f",
          "name": "vfunction-server-operator-60d1965460101d0fd90ecc9499d0a6d4c9684a54ada61a43a253d30661fab22f-annotation"
        },
        {
          "digest": "sha256:60d1965460101d0fd90ecc9499d0a6d4c9684a54ada61a43a253d30661fab22f",
          "image": "registry.connect.redhat.com/vfunction/vfunction-server-operator@sha256:60d1965460101d0fd90ecc9499d0a6d4c9684a54ada61a43a253d30661fab22f",
          "name": "vfunction-server-operator"
        },
        {
          "digest": "sha256:a6e06ea08fffa33b709d4d1240587bb3ab5b4cc6a28f493a227555e88e645798",
          "image": "registry.connect.redhat.com/vfunction/vfunction-mysql@sha256:a6e06ea08fffa33b709d4d1240587bb3ab5b4cc6a28f493a227555e88e645798",
          "name": "vfunction_mysql_original_image"
        },
        {
          "digest": "sha256:435d1489aaf29a811081ddb51f40ae692e5833f42c31dbced6bc189c0ddc40ab",
          "image": "registry.connect.redhat.com/vfunction/vfunction-nginx@sha256:435d1489aaf29a811081ddb51f40ae692e5833f42c31dbced6bc189c0ddc40ab",
          "name": "vfunction_nginx_original_image"
        },
        {
          "digest": "sha256:b778cb9c724a59e51b4cb9088047be471cdf338f1138c31b81f79e50a491203f",
          "image": "registry.connect.redhat.com/vfunction/vfunction-storage@sha256:b778cb9c724a59e51b4cb9088047be471cdf338f1138c31b81f79e50a491203f",
          "name": "vfunction_storage_original_image"
        },
        {
          "digest": "sha256:21ca95a0209f3c557a45658452d154777f928539a93129148470562c79e68d70",
          "image": "registry.connect.redhat.com/vfunction/vfunction-vfapi-idp@sha256:21ca95a0209f3c557a45658452d154777f928539a93129148470562c79e68d70",
          "name": "vfunction_vfapi_idp_original_image"
        },
        {
          "digest": "sha256:35ffbee4b0eead58706b23cf5a702b1d55d2a7913cd0019cefbff94957d4e5d6",
          "image": "registry.connect.redhat.com/vfunction/vfunction-vfapi-measurements@sha256:35ffbee4b0eead58706b23cf5a702b1d55d2a7913cd0019cefbff94957d4e5d6",
          "name": "vfunction_vfapi_measurements_original_image"
        },
        {
          "digest": "sha256:bcc2c3d6222af95e614318daea3108fffc6bc77aa17b23031cce296a3811b79f",
          "image": "registry.connect.redhat.com/vfunction/vfunction-vfapi-organizations@sha256:bcc2c3d6222af95e614318daea3108fffc6bc77aa17b23031cce296a3811b79f",
          "name": "vfunction_vfapi_organizations_original_image"
        },
        {
          "digest": "sha256:e47cc051953976a0e075e8cfb457cd4749e9b9e4394f2fbecab2458c2ade92ca",
          "image": "registry.connect.redhat.com/vfunction/vfunction-vfapi-users@sha256:e47cc051953976a0e075e8cfb457cd4749e9b9e4394f2fbecab2458c2ade92ca",
          "name": "vfunction_vfapi_users_original_image"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "2.2.469",
      "version_original": "2.2.469"
    },
    {
      "_id": "6234604e314381d2b0756b46",
      "alm_examples": [
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixAgent",
          "metadata": {
            "labels": {
              "app": "agent",
              "vendor": "zabbix"
            },
            "name": "zabbix-agent"
          },
          "spec": {
            "active_allow": true,
            "activeservers": "",
            "allow_key": "",
            "allow_privileged": true,
            "buffer#": 100,
            "buffer_send": 5,
            "debug_level": 3,
            "deny_key": "system.run[*]",
            "host_interface": "",
            "host_interface_item": "",
            "hostname": "",
            "hostname_item": "system.hostname",
            "load_module": "",
            "log_remote_commands": true,
            "max_lines_per_second": 20,
            "metadata": "",
            "metadata_item": "",
            "passive_allow": true,
            "passive_servers": "",
            "refresh_active_checks": 120,
            "server_host": "zabbix-server",
            "start_agents": 3,
            "timeout": 3,
            "tls_accept": "unencrypted",
            "tls_ca_file_name": "",
            "tls_cert_file_name": "",
            "tls_cipher_all": "",
            "tls_cipher_cert_13": "",
            "tls_cipher_psk": "",
            "tls_cipherall_13": "",
            "tls_connect": "unencrypted",
            "tls_crl_file_name": "",
            "tls_key_file_name": "",
            "tls_psk_file_name": "",
            "tls_psk_identity": "",
            "tls_server_cert_issuer": "",
            "tls_server_cert_subject": "",
            "tlsciphercert": "",
            "tlscipherpsk13": "",
            "unsafe_user_parameters": false
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixAppliance",
          "metadata": {
            "labels": {
              "app": "appliance",
              "vendor": "zabbix"
            },
            "name": "zabbix-appliance"
          },
          "spec": {
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher13": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_double_ieee754": true,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web_enable_route": true,
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "zabbix-mysql-secrets"
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixFull",
          "metadata": {
            "labels": {
              "app": "server",
              "vendor": "zabbix"
            },
            "name": "zabbix-full"
          },
          "spec": {
            "history_storage_url": "",
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlsciphercert": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_cipher_list": "",
              "db_double_ieee754": true,
              "db_encryption": false,
              "db_verify_host": false,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web#": 2,
            "web_enable_route": true,
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "zabbix-mysql-secrets"
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixProxyMysql",
          "metadata": {
            "labels": {
              "app": "proxy",
              "vendor": "zabbix"
            },
            "name": "zabbix-proxy-mysql"
          },
          "spec": {
            "db_server_port": 3306,
            "internal_db": true,
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "mysql_database": "zabbix_proxy",
            "proxy": {
              "cache#": "8M",
              "config_frequency": 3600,
              "data_sender_frequency": 1,
              "db_tls_cipher": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "enable_remote_commands": false,
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "hostname": "",
              "hostname_item": "system.hostname",
              "housekeeping_frequency": 1,
              "log_remote_commands": true,
              "log_slow_queries": 0,
              "proxy_heartbeat_frequency": 60,
              "proxy_local_buffer": 0,
              "proxy_mode": 0,
              "proxy_offline_buffer": 1,
              "server_host": "zabbix-server",
              "server_port": 10051,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "timeout": 4,
              "tls_accept": "unencrypted",
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_connect": "unencrypted",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tls_psk_file_name": "",
              "tls_psk_identity": "",
              "tls_server_cert_issuer": "",
              "tls_server_cert_subject": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "zabbix-mysql-secrets"
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixProxySqlite",
          "metadata": {
            "labels": {
              "app": "proxy",
              "vendor": "zabbix"
            },
            "name": "zabbix-proxy-sqlite"
          },
          "spec": {
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "proxy": {
              "cache#": "8M",
              "config_frequency": 3600,
              "data_sender_frequency": 1,
              "debug_level": 3,
              "enable_remote_commands": false,
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "hostname": "",
              "hostname_item": "system.hostname",
              "housekeeping_frequency": 1,
              "log_remote_commands": true,
              "log_slow_queries": 0,
              "proxy_heartbeat_frequency": 60,
              "proxy_local_buffer": 0,
              "proxy_mode": 0,
              "proxy_offline_buffer": 1,
              "server_host": "zabbix-server",
              "server_port": 10051,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "timeout": 4,
              "tls_accept": "unencrypted",
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_connect": "unencrypted",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tls_psk_file_name": "",
              "tls_psk_identity": "",
              "tls_server_cert_issuer": "",
              "tls_server_cert_subject": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "proxy#": 1
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixServer",
          "metadata": {
            "labels": {
              "app": "server",
              "vendor": "zabbix"
            },
            "name": "zabbix-server"
          },
          "spec": {
            "db_server_host": "mysql-server",
            "db_server_port": 3306,
            "history_storage_url": "",
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "mysql_database": "zabbix",
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher13": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_cipher_list": "",
              "db_double_ieee754": true,
              "db_encryption": false,
              "db_verify_host": false,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web#": 2,
            "web_enable_route": true,
            "zabbix_mysqlsecret": "zabbix-mysql-secrets"
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixAgent",
          "metadata": {
            "labels": {
              "app": "agent",
              "vendor": "zabbix"
            },
            "name": "zabbix-agent"
          },
          "spec": {
            "active_allow": true,
            "activeservers": "",
            "allow_key": "",
            "allow_privileged": true,
            "buffer#": 100,
            "buffer_send": 5,
            "debug_level": 3,
            "deny_key": "system.run[*]",
            "host_interface": "",
            "host_interface_item": "",
            "hostname": "",
            "hostname_item": "system.hostname",
            "load_module": "",
            "log_remote_commands": true,
            "max_lines_per_second": 20,
            "metadata": "",
            "metadata_item": "",
            "passive_allow": true,
            "passive_servers": "",
            "refresh_active_checks": 120,
            "server_host": "zabbix-server",
            "start_agents": 3,
            "timeout": 3,
            "tls_accept": "unencrypted",
            "tls_ca_file_name": "",
            "tls_cert_file_name": "",
            "tls_cipher_all": "",
            "tls_cipher_cert_13": "",
            "tls_cipher_psk": "",
            "tls_cipherall_13": "",
            "tls_connect": "unencrypted",
            "tls_crl_file_name": "",
            "tls_key_file_name": "",
            "tls_psk_file_name": "",
            "tls_psk_identity": "",
            "tls_server_cert_issuer": "",
            "tls_server_cert_subject": "",
            "tlsciphercert": "",
            "tlscipherpsk13": "",
            "unsafe_user_parameters": false
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixServer",
          "metadata": {
            "labels": {
              "app": "server",
              "vendor": "zabbix"
            },
            "name": "zabbix-server"
          },
          "spec": {
            "db_server_host": "mysql-server",
            "db_server_port": 3306,
            "history_storage_url": "",
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "mysql_database": "zabbix",
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher13": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_cipher_list": "",
              "db_double_ieee754": true,
              "db_encryption": false,
              "db_verify_host": false,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web#": 2,
            "web_enable_route": true,
            "zabbix_mysqlsecret": "mysql-secrets"
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixProxySqlite",
          "metadata": {
            "labels": {
              "app": "proxy",
              "vendor": "zabbix"
            },
            "name": "zabbix-proxy-sqlite"
          },
          "spec": {
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "proxy": {
              "cache#": "8M",
              "config_frequency": 3600,
              "data_sender_frequency": 1,
              "debug_level": 3,
              "enable_remote_commands": false,
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "hostname": "",
              "hostname_item": "system.hostname",
              "housekeeping_frequency": 1,
              "log_remote_commands": true,
              "log_slow_queries": 0,
              "proxy_heartbeat_frequency": 60,
              "proxy_local_buffer": 0,
              "proxy_mode": 0,
              "proxy_offline_buffer": 1,
              "server_host": "zabbix-server",
              "server_port": 10051,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "timeout": 4,
              "tls_accept": "unencrypted",
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_connect": "unencrypted",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tls_psk_file_name": "",
              "tls_psk_identity": "",
              "tls_server_cert_issuer": "",
              "tls_server_cert_subject": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "proxy#": 1
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixProxyMysql",
          "metadata": {
            "labels": {
              "app": "proxy",
              "vendor": "zabbix"
            },
            "name": "zabbix-proxy-mysql"
          },
          "spec": {
            "db_server_port": 3306,
            "internal_db": true,
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "mysql_database": "zabbix_proxy",
            "proxy": {
              "cache#": "8M",
              "config_frequency": 3600,
              "data_sender_frequency": 1,
              "db_tls_cipher": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "enable_remote_commands": false,
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "hostname": "",
              "hostname_item": "system.hostname",
              "housekeeping_frequency": 1,
              "log_remote_commands": true,
              "log_slow_queries": 0,
              "proxy_heartbeat_frequency": 60,
              "proxy_local_buffer": 0,
              "proxy_mode": 0,
              "proxy_offline_buffer": 1,
              "server_host": "zabbix-server",
              "server_port": 10051,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "timeout": 4,
              "tls_accept": "unencrypted",
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_connect": "unencrypted",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tls_psk_file_name": "",
              "tls_psk_identity": "",
              "tls_server_cert_issuer": "",
              "tls_server_cert_subject": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "zabbix-mysql-secrets"
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixFull",
          "metadata": {
            "labels": {
              "app": "server",
              "vendor": "zabbix"
            },
            "name": "zabbix-full"
          },
          "spec": {
            "history_storage_url": "",
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlsciphercert": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_cipher_list": "",
              "db_double_ieee754": true,
              "db_encryption": false,
              "db_verify_host": false,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web#": 2,
            "web_enable_route": true,
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "mysql-secrets"
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixAppliance",
          "metadata": {
            "labels": {
              "app": "appliance",
              "vendor": "zabbix"
            },
            "name": "zabbix-appliance"
          },
          "spec": {
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher13": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_double_ieee754": true,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web_enable_route": true,
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "mysql-secrets"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/zabbix/zabbixoperator-certified-bundle@sha256:236d7cc772634f20540dc153f9a7fc66357d7d4852962c5c7b5daff61c99e5c8",
      "bundle_path_digest": "sha256:236d7cc772634f20540dc153f9a7fc66357d7d4852962c5c7b5daff61c99e5c8",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "lts",
      "creation_date": "2022-03-18T10:34:54.004000+00:00",
      "csv_description": "## About this Operator\n\nZabbix helps you to real-time monitoring of millions of metrics collected from tens of thousands of servers, virtual machines and network devices.\nThe Zabbix Operator allows users to easily deploy, manage, and maintain Zabbix deployments on OpenShift. By installing this integration you will be able to deploy Zabbix server / proxies and other components with a single command.\n## Supported Features\n* **Zabbix Server** - Simple Zabbix installation with included Zabbix server, Zabbix web-interface and Zabbix Java Gateway with MySQL database support. The feature does not provide MySQL service and requires an external MySQL database. \n* **Zabbix Server (Full)** - Zabbix installation with included Zabbix server, Zabbix web-interface, Zabbix Java Gateway and MySQL server instance.\n* **Zabbix proxy (SQLite3)** - Very simple way to gain power of Zabbix proxy. The feature has  SQLite3 support for Zabbix proxies and allow to specify amount of proxies. \n* **Zabbix proxy (MySQL)** - Another option of Zabbix proxy. The option support and deliver MySQL database.\n* **Zabbix agent** - Zabbix agent can be deployed on each available node for stability and performance monitoring on remote nodes. It allows to gather metrics with full automation!\n* **Zabbix Appliance** - Zabbix appliance very simple way to test and check Zabbix features. The option provides all core components in one solution. It includes Zabbix server, Zabbix Java Gateway, Zabbix web-interface and MySQL server in deployment. It is very useful for testing Zabbix features!\n## Prerequisites\nAll deployment options are require additional information during deployment. Please, check the following instructions and provide required configuration:\n* **Zabbix Server** - MySQL database host information and MySQL database credentials in specially formatted *Secret*. Additionally it is possible to specify SSL certificates for HTTPS support in *Secret*.\n* **Zabbix Server (Full)** - MySQL database credentials in specially formatted *Secret*. MySQL database volume name information. Additionally it is possible to specify SSL certificates for HTTPS support in *Secret*.\n* **Zabbix proxy (SQLite3)** - Zabbix server host information only.\n* **Zabbix proxy (MySQL)** - MySQL database credentials in specially formatted *Secrets* and Zabbix server host information.\n* **Zabbix agent** - Zabbix server host information only for outgoing and incoming connections. Zabbix agent uses \"privileged\" mode to monitor node resources! For example, running processes.\n* **Zabbix Appliance** - MySQL database credentials in specially formatted *Secret*. MySQL database volume name information. Additionally it is possible to specify SSL certificates for HTTPS support in *Secret*.\n### MySQL credentials\n```\nkind: Secret\napiVersion: v1\nmetadata:\n  name: zabbix-full-secrets\ndata:\n  mysql_root_password: emFiYml4X3N1cGVyX3Jvb3Q= [1]\n  mysql_zabbix_password: emFiYml4X3VzZXJfcGFzc3dvcmQ= [2]\n  mysql_zabbix_username: emFiYml4 [3]\ntype: Opaque\n```\nUsing MySQL root password (*mysqlrootpassword* [1]) Zabbix server / proxy will try to create MySQL database schema with grant permissions to *mysqlzabbixusername* [2] and *mysqlzabbixpassword* [3].\n### SSL certificates for HTTPS\n```\nkind: Secret\napiVersion: v1\nmetadata:\n  name: zabbix-web-sslsecret\ndata:\n  ssl.crt: >-\n   < ssl.crt data>\n  ssl.key: >-\n\t < ssl.key data >\n  dhparam.pem: >-\n   <  dhparam.pem data >\n```\nFiles *ssl.crt*, *ssl.key* and *dhparam.perm* are required for Zabbix web-interface for SSL support.\n",
      "csv_display_name": "Zabbix Operator",
      "csv_metadata_description": "Zabbix operator with multiple deployment variants and different components",
      "csv_name": "zabbix-operator-certified.v0.0.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:36:54.769000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "zabbix-operator-certified",
      "provided_apis": [
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixAgent",
          "version": "v1alpha1"
        },
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixAppliance",
          "version": "v1alpha1"
        },
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixFull",
          "version": "v1alpha1"
        },
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixProxyMysql",
          "version": "v1alpha1"
        },
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixProxySqlite",
          "version": "v1alpha1"
        },
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixServer",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:c2dee633a667191d3272bf1652412ac1077455f18b90168ddcaa2ac8882f0c66",
          "image": "registry.connect.redhat.com/zabbix/zabbixoperator-certified@sha256:c2dee633a667191d3272bf1652412ac1077455f18b90168ddcaa2ac8882f0c66",
          "name": "zabbixoperator-certified-c2dee633a667191d3272bf1652412ac1077455f18b90168ddcaa2ac8882f0c66-annotation"
        },
        {
          "digest": "sha256:c2dee633a667191d3272bf1652412ac1077455f18b90168ddcaa2ac8882f0c66",
          "image": "registry.connect.redhat.com/zabbix/zabbixoperator-certified@sha256:c2dee633a667191d3272bf1652412ac1077455f18b90168ddcaa2ac8882f0c66",
          "name": "ansible"
        },
        {
          "digest": "sha256:c2dee633a667191d3272bf1652412ac1077455f18b90168ddcaa2ac8882f0c66",
          "image": "registry.connect.redhat.com/zabbix/zabbixoperator-certified@sha256:c2dee633a667191d3272bf1652412ac1077455f18b90168ddcaa2ac8882f0c66",
          "name": "operator"
        },
        {
          "digest": "sha256:2f76e7cbece9d9366b613bcb1079b030ddbcc5e97b2f133b73bd0131f0869725",
          "image": "registry.connect.redhat.com/zabbix/zabbix-server-mysql-50@sha256:2f76e7cbece9d9366b613bcb1079b030ddbcc5e97b2f133b73bd0131f0869725",
          "name": "zbx_server_mysql"
        },
        {
          "digest": "sha256:9f3ba82445ea3d9754f016e21b2ea1c99c1958da928f49aee1b18377af78d365",
          "image": "registry.connect.redhat.com/zabbix/zabbix-web-mysql-50@sha256:9f3ba82445ea3d9754f016e21b2ea1c99c1958da928f49aee1b18377af78d365",
          "name": "zbx_web_mysql"
        },
        {
          "digest": "sha256:a216de448dc10b2797a70f4fc6664c2bd611840b7b6c26f066635d48c606bf06",
          "image": "registry.connect.redhat.com/zabbix/zabbix-java-gateway-50@sha256:a216de448dc10b2797a70f4fc6664c2bd611840b7b6c26f066635d48c606bf06",
          "name": "zbx_java_gateway"
        },
        {
          "digest": "sha256:054ad28ade616642fb50fd38a48df2d00a9c0c6a57df1e367caeceb6469f6c42",
          "image": "registry.connect.redhat.com/zabbix/zabbix-proxy-mysql-50@sha256:054ad28ade616642fb50fd38a48df2d00a9c0c6a57df1e367caeceb6469f6c42",
          "name": "zbx_proxy_mysql"
        },
        {
          "digest": "sha256:713a6223a01ee57efb719d6f491ef779d74104a1bc1b8599eade8b3f4a3318ed",
          "image": "registry.connect.redhat.com/zabbix/zabbix-proxy-sqlite-50@sha256:713a6223a01ee57efb719d6f491ef779d74104a1bc1b8599eade8b3f4a3318ed",
          "name": "zbx_proxy_sqlite"
        },
        {
          "digest": "sha256:229562a27ed45319ef17397fe81cac81129c84eccd2c14f6085531a86ef9b87d",
          "image": "registry.connect.redhat.com/zabbix/zabbix-agent-50@sha256:229562a27ed45319ef17397fe81cac81129c84eccd2c14f6085531a86ef9b87d",
          "name": "zbx_agent"
        },
        {
          "digest": "sha256:7236c68c494f572edf64ced85c3a083b7eafff1c6562e95bdc50e50c37e3e3bf",
          "image": "registry.connect.redhat.com/zabbix/zabbix-appliance-50@sha256:7236c68c494f572edf64ced85c3a083b7eafff1c6562e95bdc50e50c37e3e3bf",
          "name": "zbx_appliance"
        },
        {
          "digest": "sha256:e7541d9fbcb7a71ac8a68cc4efc1806bab74023961c7d3fb562ded320df90c43",
          "image": "registry.redhat.io/rhel8/mysql-80@sha256:e7541d9fbcb7a71ac8a68cc4efc1806bab74023961c7d3fb562ded320df90c43",
          "name": "db_mysql"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "0.0.2",
      "version_original": "0.0.2"
    },
    {
      "_id": "6234605006c5dada0193e08b",
      "alm_examples": [
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixAgent",
          "metadata": {
            "labels": {
              "app": "agent",
              "vendor": "zabbix"
            },
            "name": "zabbix-agent"
          },
          "spec": {
            "active_allow": true,
            "activeservers": "",
            "allow_key": "",
            "allow_privileged": true,
            "buffer#": 100,
            "buffer_send": 5,
            "debug_level": 3,
            "deny_key": "system.run[*]",
            "host_interface": "",
            "host_interface_item": "",
            "hostname": "",
            "hostname_item": "system.hostname",
            "load_module": "",
            "log_remote_commands": true,
            "max_lines_per_second": 20,
            "metadata": "",
            "metadata_item": "",
            "passive_allow": true,
            "passive_servers": "",
            "refresh_active_checks": 120,
            "server_host": "zabbix-server",
            "start_agents": 3,
            "timeout": 3,
            "tls_accept": "unencrypted",
            "tls_ca_file_name": "",
            "tls_cert_file_name": "",
            "tls_cipher_all": "",
            "tls_cipher_cert_13": "",
            "tls_cipher_psk": "",
            "tls_cipherall_13": "",
            "tls_connect": "unencrypted",
            "tls_crl_file_name": "",
            "tls_key_file_name": "",
            "tls_psk_file_name": "",
            "tls_psk_identity": "",
            "tls_server_cert_issuer": "",
            "tls_server_cert_subject": "",
            "tlsciphercert": "",
            "tlscipherpsk13": "",
            "unsafe_user_parameters": false
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixAppliance",
          "metadata": {
            "labels": {
              "app": "appliance",
              "vendor": "zabbix"
            },
            "name": "zabbix-appliance"
          },
          "spec": {
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher13": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_double_ieee754": true,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web_enable_route": true,
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "zabbix-mysql-secrets"
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixFull",
          "metadata": {
            "labels": {
              "app": "server",
              "vendor": "zabbix"
            },
            "name": "zabbix-full"
          },
          "spec": {
            "history_storage_url": "",
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlsciphercert": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_cipher_list": "",
              "db_double_ieee754": true,
              "db_encryption": false,
              "db_verify_host": false,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web#": 2,
            "web_enable_route": true,
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "zabbix-mysql-secrets"
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixProxyMysql",
          "metadata": {
            "labels": {
              "app": "proxy",
              "vendor": "zabbix"
            },
            "name": "zabbix-proxy-mysql"
          },
          "spec": {
            "db_server_port": 3306,
            "internal_db": true,
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "mysql_database": "zabbix_proxy",
            "proxy": {
              "cache#": "8M",
              "config_frequency": 3600,
              "data_sender_frequency": 1,
              "db_tls_cipher": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "enable_remote_commands": false,
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "hostname": "",
              "hostname_item": "system.hostname",
              "housekeeping_frequency": 1,
              "log_remote_commands": true,
              "log_slow_queries": 0,
              "proxy_heartbeat_frequency": 60,
              "proxy_local_buffer": 0,
              "proxy_mode": 0,
              "proxy_offline_buffer": 1,
              "server_host": "zabbix-server",
              "server_port": 10051,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "timeout": 4,
              "tls_accept": "unencrypted",
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_connect": "unencrypted",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tls_psk_file_name": "",
              "tls_psk_identity": "",
              "tls_server_cert_issuer": "",
              "tls_server_cert_subject": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "zabbix-mysql-secrets"
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixProxySqlite",
          "metadata": {
            "labels": {
              "app": "proxy",
              "vendor": "zabbix"
            },
            "name": "zabbix-proxy-sqlite"
          },
          "spec": {
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "proxy": {
              "cache#": "8M",
              "config_frequency": 3600,
              "data_sender_frequency": 1,
              "debug_level": 3,
              "enable_remote_commands": false,
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "hostname": "",
              "hostname_item": "system.hostname",
              "housekeeping_frequency": 1,
              "log_remote_commands": true,
              "log_slow_queries": 0,
              "proxy_heartbeat_frequency": 60,
              "proxy_local_buffer": 0,
              "proxy_mode": 0,
              "proxy_offline_buffer": 1,
              "server_host": "zabbix-server",
              "server_port": 10051,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "timeout": 4,
              "tls_accept": "unencrypted",
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_connect": "unencrypted",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tls_psk_file_name": "",
              "tls_psk_identity": "",
              "tls_server_cert_issuer": "",
              "tls_server_cert_subject": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "proxy#": 1
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixServer",
          "metadata": {
            "labels": {
              "app": "server",
              "vendor": "zabbix"
            },
            "name": "zabbix-server"
          },
          "spec": {
            "db_server_host": "mysql-server",
            "db_server_port": 3306,
            "history_storage_url": "",
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "mysql_database": "zabbix",
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher13": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_cipher_list": "",
              "db_double_ieee754": true,
              "db_encryption": false,
              "db_verify_host": false,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web#": 2,
            "web_enable_route": true,
            "zabbix_mysqlsecret": "zabbix-mysql-secrets"
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixAgent",
          "metadata": {
            "labels": {
              "app": "agent",
              "vendor": "zabbix"
            },
            "name": "zabbix-agent"
          },
          "spec": {
            "active_allow": true,
            "activeservers": "",
            "allow_key": "",
            "allow_privileged": true,
            "buffer#": 100,
            "buffer_send": 5,
            "debug_level": 3,
            "deny_key": "system.run[*]",
            "host_interface": "",
            "host_interface_item": "",
            "hostname": "",
            "hostname_item": "system.hostname",
            "load_module": "",
            "log_remote_commands": true,
            "max_lines_per_second": 20,
            "metadata": "",
            "metadata_item": "",
            "passive_allow": true,
            "passive_servers": "",
            "refresh_active_checks": 120,
            "server_host": "zabbix-server",
            "start_agents": 3,
            "timeout": 3,
            "tls_accept": "unencrypted",
            "tls_ca_file_name": "",
            "tls_cert_file_name": "",
            "tls_cipher_all": "",
            "tls_cipher_cert_13": "",
            "tls_cipher_psk": "",
            "tls_cipherall_13": "",
            "tls_connect": "unencrypted",
            "tls_crl_file_name": "",
            "tls_key_file_name": "",
            "tls_psk_file_name": "",
            "tls_psk_identity": "",
            "tls_server_cert_issuer": "",
            "tls_server_cert_subject": "",
            "tlsciphercert": "",
            "tlscipherpsk13": "",
            "unsafe_user_parameters": false
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixServer",
          "metadata": {
            "labels": {
              "app": "server",
              "vendor": "zabbix"
            },
            "name": "zabbix-server"
          },
          "spec": {
            "db_server_host": "mysql-server",
            "db_server_port": 3306,
            "history_storage_url": "",
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "mysql_database": "zabbix",
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher13": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_cipher_list": "",
              "db_double_ieee754": true,
              "db_encryption": false,
              "db_verify_host": false,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web#": 2,
            "web_enable_route": true,
            "zabbix_mysqlsecret": "mysql-secrets"
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixProxySqlite",
          "metadata": {
            "labels": {
              "app": "proxy",
              "vendor": "zabbix"
            },
            "name": "zabbix-proxy-sqlite"
          },
          "spec": {
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "proxy": {
              "cache#": "8M",
              "config_frequency": 3600,
              "data_sender_frequency": 1,
              "debug_level": 3,
              "enable_remote_commands": false,
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "hostname": "",
              "hostname_item": "system.hostname",
              "housekeeping_frequency": 1,
              "log_remote_commands": true,
              "log_slow_queries": 0,
              "proxy_heartbeat_frequency": 60,
              "proxy_local_buffer": 0,
              "proxy_mode": 0,
              "proxy_offline_buffer": 1,
              "server_host": "zabbix-server",
              "server_port": 10051,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "timeout": 4,
              "tls_accept": "unencrypted",
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_connect": "unencrypted",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tls_psk_file_name": "",
              "tls_psk_identity": "",
              "tls_server_cert_issuer": "",
              "tls_server_cert_subject": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "proxy#": 1
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixProxyMysql",
          "metadata": {
            "labels": {
              "app": "proxy",
              "vendor": "zabbix"
            },
            "name": "zabbix-proxy-mysql"
          },
          "spec": {
            "db_server_port": 3306,
            "internal_db": true,
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "mysql_database": "zabbix_proxy",
            "proxy": {
              "cache#": "8M",
              "config_frequency": 3600,
              "data_sender_frequency": 1,
              "db_tls_cipher": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "enable_remote_commands": false,
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "hostname": "",
              "hostname_item": "system.hostname",
              "housekeeping_frequency": 1,
              "log_remote_commands": true,
              "log_slow_queries": 0,
              "proxy_heartbeat_frequency": 60,
              "proxy_local_buffer": 0,
              "proxy_mode": 0,
              "proxy_offline_buffer": 1,
              "server_host": "zabbix-server",
              "server_port": 10051,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "timeout": 4,
              "tls_accept": "unencrypted",
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_connect": "unencrypted",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tls_psk_file_name": "",
              "tls_psk_identity": "",
              "tls_server_cert_issuer": "",
              "tls_server_cert_subject": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "zabbix-mysql-secrets"
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixFull",
          "metadata": {
            "labels": {
              "app": "server",
              "vendor": "zabbix"
            },
            "name": "zabbix-full"
          },
          "spec": {
            "history_storage_url": "",
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "java_gateway#": 1,
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_cipher_all": "",
              "tls_cipher_cert_13": "",
              "tls_cipher_psk": "",
              "tls_cipherall_13": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlsciphercert": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_cipher_list": "",
              "db_double_ieee754": true,
              "db_encryption": false,
              "db_verify_host": false,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web#": 2,
            "web_enable_route": true,
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "mysql-secrets"
          }
        },
        {
          "api_version": "kubernetes.zabbix.com/v1alpha1",
          "kind": "ZabbixAppliance",
          "metadata": {
            "labels": {
              "app": "appliance",
              "vendor": "zabbix"
            },
            "name": "zabbix-appliance"
          },
          "spec": {
            "java_gateway": {
              "debug_level": "info",
              "start_pollers": 5,
              "timeout": 3
            },
            "server": {
              "cache#": "8M",
              "cache_update_frequency": 60,
              "db_tls_cipher": "",
              "db_tls_cipher13": "",
              "db_tls_cipher_13": "",
              "db_tls_connect": "",
              "debug_level": 3,
              "export_file#": "",
              "history_cache#": "16M",
              "history_index_cache#": "4M",
              "history_storage_date_index": true,
              "history_storage_types": "",
              "housekeeping_frequency": 1,
              "load_module": "",
              "log_slow_queries": 0,
              "max_housekeeper_delete": 5000,
              "proxy_config_frequency": 3600,
              "proxy_data_frequency": 1,
              "start_alerters": 3,
              "start_db_syncers": 4,
              "start_discoverers": 1,
              "start_escalators": 1,
              "start_http_pollers": 1,
              "start_ipmi_pollers": 0,
              "start_java_pollers": 5,
              "start_lld_processors": 2,
              "start_pingers": 1,
              "start_pollers": 5,
              "start_pollers_unreachable": 1,
              "start_preprocessors": 3,
              "start_proxy_pollers": 0,
              "start_timers": 1,
              "start_trappers": 5,
              "start_vmware_collectors": 0,
              "stats_allowed_ip": "",
              "timeout": 4,
              "tls_ca_file_name": "",
              "tls_cert_file_name": "",
              "tls_crl_file_name": "",
              "tls_key_file_name": "",
              "tlscipherall": "",
              "tlscipherall13": "",
              "tlsciphercert": "",
              "tlsciphercert13": "",
              "tlscipherpsk": "",
              "tlscipherpsk13": "",
              "trapper_timeout": 300,
              "trend_cache#": "4M",
              "unavailable_delay": 60,
              "unreachable_delay": 15,
              "unreachable_period": 45,
              "value_cache#": "8M",
              "vmware_cache#": "8M",
              "vmware_frequency": 60,
              "vmware_perf_frequency": 60,
              "vmware_timeout": 10
            },
            "web": {
              "db_double_ieee754": true,
              "deny_gui_access": false,
              "enable_web_access_log": true,
              "gui_access_ip_range": "",
              "gui_warning_msg": "Zabbix is under maintenance.",
              "history_storage_types": "",
              "max_execution_time": 300,
              "max_input_time": 300,
              "memory_limit": "128M",
              "post_max#": "16M",
              "server_name": "Kubernetes installation",
              "session_name": "zbx_sessionid",
              "sso_settings": "",
              "timezone": "Europe/Riga",
              "upload_max_filesize": "2M"
            },
            "web_enable_route": true,
            "zabbix_mysql_volumeclaim": "mysql-volume-claim",
            "zabbix_mysqlsecret": "mysql-secrets"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/zabbix/zabbixoperator-certified-bundle@sha256:3351d4e9f8ddf2b4498852335ebd7197188ff3f167919c603c5dc77b08774091",
      "bundle_path_digest": "sha256:3351d4e9f8ddf2b4498852335ebd7197188ff3f167919c603c5dc77b08774091",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "lts",
      "creation_date": "2022-03-18T10:34:56.333000+00:00",
      "csv_description": "## About this Operator\n\nZabbix helps you to real-time monitoring of millions of metrics collected from tens of thousands of servers, virtual machines and network devices.\nThe Zabbix Operator allows users to easily deploy, manage, and maintain Zabbix deployments on OpenShift. By installing this integration you will be able to deploy Zabbix server / proxies and other components with a single command.\n## Supported Features\n* **Zabbix Server** - Simple Zabbix installation with included Zabbix server, Zabbix web-interface and Zabbix Java Gateway with MySQL database support. The feature does not provide MySQL service and requires an external MySQL database. \n* **Zabbix Server (Full)** - Zabbix installation with included Zabbix server, Zabbix web-interface, Zabbix Java Gateway and MySQL server instance.\n* **Zabbix proxy (SQLite3)** - Very simple way to gain power of Zabbix proxy. The feature has  SQLite3 support for Zabbix proxies and allow to specify amount of proxies. \n* **Zabbix proxy (MySQL)** - Another option of Zabbix proxy. The option support and deliver MySQL database.\n* **Zabbix agent** - Zabbix agent can be deployed on each available node for stability and performance monitoring on remote nodes. It allows to gather metrics with full automation!\n* **Zabbix Appliance** - Zabbix appliance very simple way to test and check Zabbix features. The option provides all core components in one solution. It includes Zabbix server, Zabbix Java Gateway, Zabbix web-interface and MySQL server in deployment. It is very useful for testing Zabbix features!\n## Prerequisites\nAll deployment options are require additional information during deployment. Please, check the following instructions and provide required configuration:\n* **Zabbix Server** - MySQL database host information and MySQL database credentials in specially formatted *Secret*. Additionally it is possible to specify SSL certificates for HTTPS support in *Secret*.\n* **Zabbix Server (Full)** - MySQL database credentials in specially formatted *Secret*. MySQL database volume name information. Additionally it is possible to specify SSL certificates for HTTPS support in *Secret*.\n* **Zabbix proxy (SQLite3)** - Zabbix server host information only.\n* **Zabbix proxy (MySQL)** - MySQL database credentials in specially formatted *Secrets* and Zabbix server host information.\n* **Zabbix agent** - Zabbix server host information only for outgoing and incoming connections. Zabbix agent uses \"privileged\" mode to monitor node resources! For example, running processes.\n* **Zabbix Appliance** - MySQL database credentials in specially formatted *Secret*. MySQL database volume name information. Additionally it is possible to specify SSL certificates for HTTPS support in *Secret*.\n### MySQL credentials\n```\nkind: Secret\napiVersion: v1\nmetadata:\n  name: zabbix-full-secrets\ndata:\n  mysql_root_password: emFiYml4X3N1cGVyX3Jvb3Q= [1]\n  mysql_zabbix_password: emFiYml4X3VzZXJfcGFzc3dvcmQ= [2]\n  mysql_zabbix_username: emFiYml4 [3]\ntype: Opaque\n```\nUsing MySQL root password (*mysqlrootpassword* [1]) Zabbix server / proxy will try to create MySQL database schema with grant permissions to *mysqlzabbixusername* [2] and *mysqlzabbixpassword* [3].\n### SSL certificates for HTTPS\n```\nkind: Secret\napiVersion: v1\nmetadata:\n  name: zabbix-web-sslsecret\ndata:\n  ssl.crt: >-\n   < ssl.crt data>\n  ssl.key: >-\n\t < ssl.key data >\n  dhparam.pem: >-\n   <  dhparam.pem data >\n```\nFiles *ssl.crt*, *ssl.key* and *dhparam.perm* are required for Zabbix web-interface for SSL support.\n",
      "csv_display_name": "Zabbix Operator",
      "csv_metadata_description": "Zabbix operator with multiple deployment variants and different components",
      "csv_name": "zabbix-operator-certified.v0.0.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:36:59.625000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "zabbix-operator-certified",
      "provided_apis": [
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixAgent",
          "version": "v1alpha1"
        },
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixAppliance",
          "version": "v1alpha1"
        },
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixFull",
          "version": "v1alpha1"
        },
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixProxyMysql",
          "version": "v1alpha1"
        },
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixProxySqlite",
          "version": "v1alpha1"
        },
        {
          "group": "kubernetes.zabbix.com",
          "kind": "ZabbixServer",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "0.0.3",
      "version_original": "0.0.3"
    },
    {
      "_id": "6235501b7bd6ce5a69d76fcf",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:d01e9da1a9897bb6f12ad4034bea571b53ea08d53d0fd7eebe30298a44ea4f65",
      "bundle_path_digest": "sha256:d01e9da1a9897bb6f12ad4034bea571b53ea08d53d0fd7eebe30298a44ea4f65",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-19T03:38:03.694000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.5.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T00:54:35.443000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator-e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47-annotation"
        },
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:fc69790f6713bd3f2f4d1cefd9eadac7ebe776cd0f83ae1ec523d80f2c276f59",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:fc69790f6713bd3f2f4d1cefd9eadac7ebe776cd0f83ae1ec523d80f2c276f59",
          "name": "kubeturbo"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "8.5.0",
      "version_original": "8.5.0"
    },
    {
      "_id": "623551829abee742b66cf953",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:d01e9da1a9897bb6f12ad4034bea571b53ea08d53d0fd7eebe30298a44ea4f65",
      "bundle_path_digest": "sha256:d01e9da1a9897bb6f12ad4034bea571b53ea08d53d0fd7eebe30298a44ea4f65",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-19T03:44:02.527000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.5.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:59:39.884000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator-e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47-annotation"
        },
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:fc69790f6713bd3f2f4d1cefd9eadac7ebe776cd0f83ae1ec523d80f2c276f59",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:fc69790f6713bd3f2f4d1cefd9eadac7ebe776cd0f83ae1ec523d80f2c276f59",
          "name": "kubeturbo"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "8.5.0",
      "version_original": "8.5.0"
    },
    {
      "_id": "623551e61c4a58a9993e9933",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:d01e9da1a9897bb6f12ad4034bea571b53ea08d53d0fd7eebe30298a44ea4f65",
      "bundle_path_digest": "sha256:d01e9da1a9897bb6f12ad4034bea571b53ea08d53d0fd7eebe30298a44ea4f65",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-19T03:45:42.893000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.5.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:04:25.886000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator-e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47-annotation"
        },
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:fc69790f6713bd3f2f4d1cefd9eadac7ebe776cd0f83ae1ec523d80f2c276f59",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:fc69790f6713bd3f2f4d1cefd9eadac7ebe776cd0f83ae1ec523d80f2c276f59",
          "name": "kubeturbo"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "8.5.0",
      "version_original": "8.5.0"
    },
    {
      "_id": "623552ae9abee742b66cf954",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:d01e9da1a9897bb6f12ad4034bea571b53ea08d53d0fd7eebe30298a44ea4f65",
      "bundle_path_digest": "sha256:d01e9da1a9897bb6f12ad4034bea571b53ea08d53d0fd7eebe30298a44ea4f65",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-19T03:49:02.240000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.5.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T02:03:32.167000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator-e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47-annotation"
        },
        {
          "digest": "sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:e5cdbdeeaf639afe9782fceb9bf32c5e06e2b6ed4ded41e06abe8f49bda7ac47",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:fc69790f6713bd3f2f4d1cefd9eadac7ebe776cd0f83ae1ec523d80f2c276f59",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:fc69790f6713bd3f2f4d1cefd9eadac7ebe776cd0f83ae1ec523d80f2c276f59",
          "name": "kubeturbo"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "8.5.0",
      "version_original": "8.5.0"
    },
    {
      "_id": "62360187314381d2b0756c96",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.5.0"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:29151a8d044e26f924430612ba7638acde109b3173ec6017d269e2c97f33bdc2",
      "bundle_path_digest": "sha256:29151a8d044e26f924430612ba7638acde109b3173ec6017d269e2c97f33bdc2",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-19T16:15:03.916000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.8.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:01:00.286000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:6b1353d252440681788b0b4b1f6cafc09a3bd6629396d5fdfa5a3618ce89eea4",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:6b1353d252440681788b0b4b1f6cafc09a3bd6629396d5fdfa5a3618ce89eea4",
          "name": "t8c-operator-6b1353d252440681788b0b4b1f6cafc09a3bd6629396d5fdfa5a3618ce89eea4-annotation"
        },
        {
          "digest": "sha256:6b1353d252440681788b0b4b1f6cafc09a3bd6629396d5fdfa5a3618ce89eea4",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:6b1353d252440681788b0b4b1f6cafc09a3bd6629396d5fdfa5a3618ce89eea4",
          "name": "t8c-operator"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "42.8.0",
      "version_original": "42.8.0"
    },
    {
      "_id": "623604425593ce895a7b54cf",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.5.0"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:29151a8d044e26f924430612ba7638acde109b3173ec6017d269e2c97f33bdc2",
      "bundle_path_digest": "sha256:29151a8d044e26f924430612ba7638acde109b3173ec6017d269e2c97f33bdc2",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-19T16:26:42.855000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.8.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T02:06:14.820000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:6b1353d252440681788b0b4b1f6cafc09a3bd6629396d5fdfa5a3618ce89eea4",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:6b1353d252440681788b0b4b1f6cafc09a3bd6629396d5fdfa5a3618ce89eea4",
          "name": "t8c-operator-6b1353d252440681788b0b4b1f6cafc09a3bd6629396d5fdfa5a3618ce89eea4-annotation"
        },
        {
          "digest": "sha256:6b1353d252440681788b0b4b1f6cafc09a3bd6629396d5fdfa5a3618ce89eea4",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:6b1353d252440681788b0b4b1f6cafc09a3bd6629396d5fdfa5a3618ce89eea4",
          "name": "t8c-operator"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "42.8.0",
      "version_original": "42.8.0"
    },
    {
      "_id": "62360466670f4cadbafad434",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.5.0"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:29151a8d044e26f924430612ba7638acde109b3173ec6017d269e2c97f33bdc2",
      "bundle_path_digest": "sha256:29151a8d044e26f924430612ba7638acde109b3173ec6017d269e2c97f33bdc2",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-19T16:27:18.933000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.8.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T00:59:43.440000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:6b1353d252440681788b0b4b1f6cafc09a3bd6629396d5fdfa5a3618ce89eea4",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:6b1353d252440681788b0b4b1f6cafc09a3bd6629396d5fdfa5a3618ce89eea4",
          "name": "t8c-operator-6b1353d252440681788b0b4b1f6cafc09a3bd6629396d5fdfa5a3618ce89eea4-annotation"
        },
        {
          "digest": "sha256:6b1353d252440681788b0b4b1f6cafc09a3bd6629396d5fdfa5a3618ce89eea4",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:6b1353d252440681788b0b4b1f6cafc09a3bd6629396d5fdfa5a3618ce89eea4",
          "name": "t8c-operator"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "42.8.0",
      "version_original": "42.8.0"
    },
    {
      "_id": "6236062406c5dada0193e21f",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.5.0"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:29151a8d044e26f924430612ba7638acde109b3173ec6017d269e2c97f33bdc2",
      "bundle_path_digest": "sha256:29151a8d044e26f924430612ba7638acde109b3173ec6017d269e2c97f33bdc2",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-19T16:34:44.089000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.8.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T02:11:35.292000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "plural": "xls",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:6b1353d252440681788b0b4b1f6cafc09a3bd6629396d5fdfa5a3618ce89eea4",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:6b1353d252440681788b0b4b1f6cafc09a3bd6629396d5fdfa5a3618ce89eea4",
          "name": "t8c-operator-6b1353d252440681788b0b4b1f6cafc09a3bd6629396d5fdfa5a3618ce89eea4-annotation"
        },
        {
          "digest": "sha256:6b1353d252440681788b0b4b1f6cafc09a3bd6629396d5fdfa5a3618ce89eea4",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:6b1353d252440681788b0b4b1f6cafc09a3bd6629396d5fdfa5a3618ce89eea4",
          "name": "t8c-operator"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "42.8.0",
      "version_original": "42.8.0"
    },
    {
      "_id": "6237b39adec8a38f7320b59b",
      "alm_examples": [
        {
          "api_version": "instana.io/v1",
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent": {
              "configuration_yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n",
              "endpointHost": "ingress-red-saas.instana.io",
              "endpointPort": "443",
              "env": {},
              "key": "replace-key"
            },
            "cluster": {
              "name": "my-cluster"
            },
            "zone": {
              "name": "edited-zone"
            }
          }
        },
        {
          "api_version": "instana.io/v1beta1",
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent.endpoint.host": "ingress-red-saas.instana.io",
            "agent.endpoint.port": 443,
            "agent.env": {
              "INSTANA_AGENT_TAGS": "example"
            },
            "agent.key": "replace-me",
            "agent.zone.name": "my-zone",
            "cluster.name": "replace-me",
            "config.files": {
              "configuration.yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/instana/instana-agent-operator-bundle@sha256:5aa72362012e1162708614b3dba4339797d757d04d22683f521328b63ed169d1",
      "bundle_path_digest": "sha256:5aa72362012e1162708614b3dba4339797d757d04d22683f521328b63ed169d1",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-20T23:07:06.622000+00:00",
      "csv_description": "# Instana\n\nInstana is an [APM solution](https://www.instana.com/product-overview/) built for microservices that enables IT Ops to build applications faster and deliver higher quality services by automating monitoring, tracing and root cause analysis. The solution is optimized for [Kubernetes](https://www.instana.com/automatic-kubernetes-monitoring/) and [OpenShift](https://www.instana.com/blog/automatic-root-cause-analysis-for-openshift-applications/).\n\n## Instana Agent Operator\n\nThis is the Kubernetes Operator for installing the Instana Agent on Kubernetes or OpenShift.\n\n## Prerequisites for OpenShift\n\nBefore the agent will be able to run in OpenShift, you need to perform a couple of extra configuration steps.\n\nYou need to set up a project for the Instana Agent and configure it's permissions.\n\nThe project you create here needs to be the namespace where you create the Instana Agent custom resource that the operator will use to deploy the agent.\n\nFor example, create the `instana-agent` project:\n\n    oc new-project instana-agent\n\nThen, ensure the `instana-agent` service account is in the privileged security context:\n\n    oc adm policy add-scc-to-user privileged -z instana-agent\n\nThis service account will be created by the operator.\n\nNow you can proceed with installing the operator for the Instana agent.\n\n## Installation and Configuration\n\nFirst, install this operator from [OperatorHub.io](https://operatorhub.io/), [OpenShift Container Platform](https://www.openshift.com/), or [OKD](https://www.okd.io/).\n\nSecond, create a custom resource with the agent configuration in the target namespace (for now, this MUST always be the `instana-agent` namespace). The operator will pick up the custom resource and install the Instana agent accordingly.\n\nThe following is a minimal template of the custom resource:\n\n```yaml\napiVersion: instana.io/v1\nkind: InstanaAgent\nmetadata:\n  name: instana-agent\n  namespace: instana-agent\nspec:\n  zone:\n    name: my-zone # (optional) name of the zone of the host\n  cluster:\n    name: replace-me # replace with the name of your Kubernetes cluster\n  agent:\n    key: replace-me # replace with your Instana agent key\n    endpointHost: ingress-red-saas.instana.io # the monitoring ingress endpoint\n    endpointPort: \"443\" # the monitoring ingress endpoint port, wrapped in quotes\n    env:\n      INSTANA_AGENT_TAGS: example\n    configuration_yaml: |\n      # You can leave this empty, or use this to configure your instana agent.\n      # See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n```\n\nSave the template in a file `instana-agent.yaml` and edit the following values:\n\n* If your target namespace is not `instana-agent`, replace the `namespace:` accordingly.\n* `agent.key` must be set with your Instana agent key.\n* `agent.endpointHost` must be set with the monitoring ingress endpoint, generally either `saas-us-west-2.instana.io` or `saas-eu-west-1.instana.io`.\n* `agent.endpointPort` must be set with the monitoring ingress port, generally \"443\" (wrapped in quotes).\n* `zone.name` should be set with the name of the Kubernetes cluster that is be displayed in Instana.\n\nFor advanced configuration, you can edit the contents of the `configuration.yaml` file. View documentation [here](https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/).\n\nApply the custom resource with `kubectl apply -f instana-agent.yaml`. After some time, you should see `instana-agent` Pods being created on each node of your cluster, and your cluster should show on the infrastructure map on your Instana Web interface.\n\n## Uninstalling\n\nIn order to uninstall the Instana agent, simply remove the custom resource with `kubectl delete -f instana-agent.yaml`.\n\n## Source Code\n\nThe Instana agent operator is an open source project hosted on [https://github.com/instana/instana-agent-operator](https://github.com/instana/instana-agent-operator/).\n",
      "csv_display_name": "Instana Agent Operator",
      "csv_metadata_description": "Fully automated Application Performance Monitoring (APM) for microservices.",
      "csv_name": "instana-agent-operator.v2.0.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T00:52:36.491000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "instana-agent-operator",
      "provided_apis": [
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1"
        },
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1beta1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "image": "instana/instana-agent-operator@sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "name": "instana-agent-operator"
        },
        {
          "digest": "sha256:3076921ebb8d3ff127511cc7289eacc2e0835ea88500bd4a2798ff2fdbe8b26a",
          "image": "instana/agent@sha256:3076921ebb8d3ff127511cc7289eacc2e0835ea88500bd4a2798ff2fdbe8b26a",
          "name": "instana-agent"
        },
        {
          "digest": "sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "image": "instana/instana-agent-operator@sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "name": "instana-agent-operator-abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2-annotation"
        },
        {
          "digest": "sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "image": "instana/instana-agent-operator@sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "name": "manager"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2.0.4",
      "version_original": "2.0.4"
    },
    {
      "_id": "6237b470dec8a38f7320b59c",
      "alm_examples": [
        {
          "api_version": "instana.io/v1",
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent": {
              "configuration_yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n",
              "endpointHost": "ingress-red-saas.instana.io",
              "endpointPort": "443",
              "env": {},
              "key": "replace-key"
            },
            "cluster": {
              "name": "my-cluster"
            },
            "zone": {
              "name": "edited-zone"
            }
          }
        },
        {
          "api_version": "instana.io/v1beta1",
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent.endpoint.host": "ingress-red-saas.instana.io",
            "agent.endpoint.port": 443,
            "agent.env": {
              "INSTANA_AGENT_TAGS": "example"
            },
            "agent.key": "replace-me",
            "agent.zone.name": "my-zone",
            "cluster.name": "replace-me",
            "config.files": {
              "configuration.yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/instana/instana-agent-operator-bundle@sha256:5aa72362012e1162708614b3dba4339797d757d04d22683f521328b63ed169d1",
      "bundle_path_digest": "sha256:5aa72362012e1162708614b3dba4339797d757d04d22683f521328b63ed169d1",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-20T23:10:40.464000+00:00",
      "csv_description": "# Instana\n\nInstana is an [APM solution](https://www.instana.com/product-overview/) built for microservices that enables IT Ops to build applications faster and deliver higher quality services by automating monitoring, tracing and root cause analysis. The solution is optimized for [Kubernetes](https://www.instana.com/automatic-kubernetes-monitoring/) and [OpenShift](https://www.instana.com/blog/automatic-root-cause-analysis-for-openshift-applications/).\n\n## Instana Agent Operator\n\nThis is the Kubernetes Operator for installing the Instana Agent on Kubernetes or OpenShift.\n\n## Prerequisites for OpenShift\n\nBefore the agent will be able to run in OpenShift, you need to perform a couple of extra configuration steps.\n\nYou need to set up a project for the Instana Agent and configure it's permissions.\n\nThe project you create here needs to be the namespace where you create the Instana Agent custom resource that the operator will use to deploy the agent.\n\nFor example, create the `instana-agent` project:\n\n    oc new-project instana-agent\n\nThen, ensure the `instana-agent` service account is in the privileged security context:\n\n    oc adm policy add-scc-to-user privileged -z instana-agent\n\nThis service account will be created by the operator.\n\nNow you can proceed with installing the operator for the Instana agent.\n\n## Installation and Configuration\n\nFirst, install this operator from [OperatorHub.io](https://operatorhub.io/), [OpenShift Container Platform](https://www.openshift.com/), or [OKD](https://www.okd.io/).\n\nSecond, create a custom resource with the agent configuration in the target namespace (for now, this MUST always be the `instana-agent` namespace). The operator will pick up the custom resource and install the Instana agent accordingly.\n\nThe following is a minimal template of the custom resource:\n\n```yaml\napiVersion: instana.io/v1\nkind: InstanaAgent\nmetadata:\n  name: instana-agent\n  namespace: instana-agent\nspec:\n  zone:\n    name: my-zone # (optional) name of the zone of the host\n  cluster:\n    name: replace-me # replace with the name of your Kubernetes cluster\n  agent:\n    key: replace-me # replace with your Instana agent key\n    endpointHost: ingress-red-saas.instana.io # the monitoring ingress endpoint\n    endpointPort: \"443\" # the monitoring ingress endpoint port, wrapped in quotes\n    env:\n      INSTANA_AGENT_TAGS: example\n    configuration_yaml: |\n      # You can leave this empty, or use this to configure your instana agent.\n      # See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n```\n\nSave the template in a file `instana-agent.yaml` and edit the following values:\n\n* If your target namespace is not `instana-agent`, replace the `namespace:` accordingly.\n* `agent.key` must be set with your Instana agent key.\n* `agent.endpointHost` must be set with the monitoring ingress endpoint, generally either `saas-us-west-2.instana.io` or `saas-eu-west-1.instana.io`.\n* `agent.endpointPort` must be set with the monitoring ingress port, generally \"443\" (wrapped in quotes).\n* `zone.name` should be set with the name of the Kubernetes cluster that is be displayed in Instana.\n\nFor advanced configuration, you can edit the contents of the `configuration.yaml` file. View documentation [here](https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/).\n\nApply the custom resource with `kubectl apply -f instana-agent.yaml`. After some time, you should see `instana-agent` Pods being created on each node of your cluster, and your cluster should show on the infrastructure map on your Instana Web interface.\n\n## Uninstalling\n\nIn order to uninstall the Instana agent, simply remove the custom resource with `kubectl delete -f instana-agent.yaml`.\n\n## Source Code\n\nThe Instana agent operator is an open source project hosted on [https://github.com/instana/instana-agent-operator](https://github.com/instana/instana-agent-operator/).\n",
      "csv_display_name": "Instana Agent Operator",
      "csv_metadata_description": "Fully automated Application Performance Monitoring (APM) for microservices.",
      "csv_name": "instana-agent-operator.v2.0.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T02:14:03.644000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "instana-agent-operator",
      "provided_apis": [
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1"
        },
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1beta1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "image": "instana/instana-agent-operator@sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "name": "instana-agent-operator"
        },
        {
          "digest": "sha256:3076921ebb8d3ff127511cc7289eacc2e0835ea88500bd4a2798ff2fdbe8b26a",
          "image": "instana/agent@sha256:3076921ebb8d3ff127511cc7289eacc2e0835ea88500bd4a2798ff2fdbe8b26a",
          "name": "instana-agent"
        },
        {
          "digest": "sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "image": "instana/instana-agent-operator@sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "name": "instana-agent-operator-abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2-annotation"
        },
        {
          "digest": "sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "image": "instana/instana-agent-operator@sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "name": "manager"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "2.0.4",
      "version_original": "2.0.4"
    },
    {
      "_id": "6237b48c7bd6ce5a69d76fef",
      "alm_examples": [
        {
          "api_version": "instana.io/v1",
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent": {
              "configuration_yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n",
              "endpointHost": "ingress-red-saas.instana.io",
              "endpointPort": "443",
              "env": {},
              "key": "replace-key"
            },
            "cluster": {
              "name": "my-cluster"
            },
            "zone": {
              "name": "edited-zone"
            }
          }
        },
        {
          "api_version": "instana.io/v1beta1",
          "kind": "InstanaAgent",
          "metadata": {
            "name": "instana-agent",
            "namespace": "instana-agent"
          },
          "spec": {
            "agent.endpoint.host": "ingress-red-saas.instana.io",
            "agent.endpoint.port": 443,
            "agent.env": {
              "INSTANA_AGENT_TAGS": "example"
            },
            "agent.key": "replace-me",
            "agent.zone.name": "my-zone",
            "cluster.name": "replace-me",
            "config.files": {
              "configuration.yaml": "# You can leave this empty, or use this to configure your instana agent.\n# See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/instana/instana-agent-operator-bundle@sha256:5aa72362012e1162708614b3dba4339797d757d04d22683f521328b63ed169d1",
      "bundle_path_digest": "sha256:5aa72362012e1162708614b3dba4339797d757d04d22683f521328b63ed169d1",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-20T23:11:08.760000+00:00",
      "csv_description": "# Instana\n\nInstana is an [APM solution](https://www.instana.com/product-overview/) built for microservices that enables IT Ops to build applications faster and deliver higher quality services by automating monitoring, tracing and root cause analysis. The solution is optimized for [Kubernetes](https://www.instana.com/automatic-kubernetes-monitoring/) and [OpenShift](https://www.instana.com/blog/automatic-root-cause-analysis-for-openshift-applications/).\n\n## Instana Agent Operator\n\nThis is the Kubernetes Operator for installing the Instana Agent on Kubernetes or OpenShift.\n\n## Prerequisites for OpenShift\n\nBefore the agent will be able to run in OpenShift, you need to perform a couple of extra configuration steps.\n\nYou need to set up a project for the Instana Agent and configure it's permissions.\n\nThe project you create here needs to be the namespace where you create the Instana Agent custom resource that the operator will use to deploy the agent.\n\nFor example, create the `instana-agent` project:\n\n    oc new-project instana-agent\n\nThen, ensure the `instana-agent` service account is in the privileged security context:\n\n    oc adm policy add-scc-to-user privileged -z instana-agent\n\nThis service account will be created by the operator.\n\nNow you can proceed with installing the operator for the Instana agent.\n\n## Installation and Configuration\n\nFirst, install this operator from [OperatorHub.io](https://operatorhub.io/), [OpenShift Container Platform](https://www.openshift.com/), or [OKD](https://www.okd.io/).\n\nSecond, create a custom resource with the agent configuration in the target namespace (for now, this MUST always be the `instana-agent` namespace). The operator will pick up the custom resource and install the Instana agent accordingly.\n\nThe following is a minimal template of the custom resource:\n\n```yaml\napiVersion: instana.io/v1\nkind: InstanaAgent\nmetadata:\n  name: instana-agent\n  namespace: instana-agent\nspec:\n  zone:\n    name: my-zone # (optional) name of the zone of the host\n  cluster:\n    name: replace-me # replace with the name of your Kubernetes cluster\n  agent:\n    key: replace-me # replace with your Instana agent key\n    endpointHost: ingress-red-saas.instana.io # the monitoring ingress endpoint\n    endpointPort: \"443\" # the monitoring ingress endpoint port, wrapped in quotes\n    env:\n      INSTANA_AGENT_TAGS: example\n    configuration_yaml: |\n      # You can leave this empty, or use this to configure your instana agent.\n      # See https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/\n```\n\nSave the template in a file `instana-agent.yaml` and edit the following values:\n\n* If your target namespace is not `instana-agent`, replace the `namespace:` accordingly.\n* `agent.key` must be set with your Instana agent key.\n* `agent.endpointHost` must be set with the monitoring ingress endpoint, generally either `saas-us-west-2.instana.io` or `saas-eu-west-1.instana.io`.\n* `agent.endpointPort` must be set with the monitoring ingress port, generally \"443\" (wrapped in quotes).\n* `zone.name` should be set with the name of the Kubernetes cluster that is be displayed in Instana.\n\nFor advanced configuration, you can edit the contents of the `configuration.yaml` file. View documentation [here](https://docs.instana.io/setup_and_manage/host_agent/on/kubernetes/).\n\nApply the custom resource with `kubectl apply -f instana-agent.yaml`. After some time, you should see `instana-agent` Pods being created on each node of your cluster, and your cluster should show on the infrastructure map on your Instana Web interface.\n\n## Uninstalling\n\nIn order to uninstall the Instana agent, simply remove the custom resource with `kubectl delete -f instana-agent.yaml`.\n\n## Source Code\n\nThe Instana agent operator is an open source project hosted on [https://github.com/instana/instana-agent-operator](https://github.com/instana/instana-agent-operator/).\n",
      "csv_display_name": "Instana Agent Operator",
      "csv_metadata_description": "Fully automated Application Performance Monitoring (APM) for microservices.",
      "csv_name": "instana-agent-operator.v2.0.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:13:20.307000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "instana-agent-operator",
      "provided_apis": [
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1"
        },
        {
          "group": "instana.io",
          "kind": "InstanaAgent",
          "plural": "agents",
          "version": "v1beta1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "image": "instana/instana-agent-operator@sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "name": "instana-agent-operator"
        },
        {
          "digest": "sha256:3076921ebb8d3ff127511cc7289eacc2e0835ea88500bd4a2798ff2fdbe8b26a",
          "image": "instana/agent@sha256:3076921ebb8d3ff127511cc7289eacc2e0835ea88500bd4a2798ff2fdbe8b26a",
          "name": "instana-agent"
        },
        {
          "digest": "sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "image": "instana/instana-agent-operator@sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "name": "instana-agent-operator-abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2-annotation"
        },
        {
          "digest": "sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "image": "instana/instana-agent-operator@sha256:abc4ae48ee97f907cee54b63130d07bfcdbc3223392db1abaad72c6c330893a2",
          "name": "manager"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "2.0.4",
      "version_original": "2.0.4"
    },
    {
      "_id": "623a088957d5e4fffe9893dd",
      "alm_examples": [
        {
          "api_version": "nvidia.com/v1",
          "kind": "ClusterPolicy",
          "metadata": {
            "name": "gpu-cluster-policy"
          },
          "spec": {
            "daemonsets": {},
            "dcgm": {
              "enabled": true
            },
            "dcgmExporter": {
              "config": {
                "name": ""
              }
            },
            "devicePlugin": {},
            "driver": {
              "certConfig": {
                "name": ""
              },
              "enabled": true,
              "kernelModuleConfig": {
                "name": ""
              },
              "licensingConfig": {
                "configMapName": "",
                "nlsEnabled": false
              },
              "repoConfig": {
                "configMapName": ""
              },
              "use_ocp_driver_toolkit": true,
              "virtualTopology": {
                "config": ""
              }
            },
            "gfd": {},
            "mig": {
              "strategy": "single"
            },
            "migManager": {
              "enabled": true
            },
            "nodeStatusExporter": {
              "enabled": true
            },
            "operator": {
              "defaultRuntime": "crio",
              "deployGFD": true,
              "initContainer": {}
            },
            "toolkit": {
              "enabled": true
            },
            "validator": {
              "plugin": {
                "env": [
                  {
                    "name": "WITH_WORKLOAD",
                    "value": "true"
                  }
                ]
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/nvidia/gpu-operator-bundle@sha256:4d1268054559b7678028a7a66e36567c55417b729101ef131dec8d989cbef1d3",
      "bundle_path_digest": "sha256:4d1268054559b7678028a7a66e36567c55417b729101ef131dec8d989cbef1d3",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-22T17:34:01.705000+00:00",
      "csv_description": "Kubernetes provides access to special hardware resources such as NVIDIA GPUs, NICs, Infiniband adapters and other devices through the [device plugin framework](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/). However, configuring and managing nodes with these hardware resources requires configuration of multiple software components such as drivers, container runtimes or other libraries which are difficult and prone to errors.\nThe NVIDIA GPU Operator uses the [operator framework](https://coreos.com/blog/introducing-operator-framework) within Kubernetes to automate the management of all NVIDIA software components needed to provision and monitor GPUs. These components include the NVIDIA drivers (to enable CUDA), Kubernetes device plugin for GPUs, the NVIDIA Container Runtime, automatic node labelling and NVIDIA DCGM exporter.\nVisit the official site of the [GPU Operator](https://github.com/NVIDIA/gpu-operator) for more information. For getting started with using the GPU Operator with OpenShift, see the instructions [here](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/contents.html).\n",
      "csv_display_name": "NVIDIA GPU Operator",
      "csv_metadata_description": "Automate the management and monitoring of NVIDIA GPUs.",
      "csv_name": "gpu-operator-certified.v1.10.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-06-17T00:47:12.944000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "gpu-operator-certified",
      "provided_apis": [
        {
          "group": "nvidia.com",
          "kind": "ClusterPolicy",
          "plural": "clusterpolicies",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "name": "gpu-operator-image"
        },
        {
          "digest": "sha256:67c48a8370c34f68b46eb57339e87d01c04198368a0423553fab7565c862c4df",
          "image": "nvcr.io/nvidia/k8s/dcgm-exporter@sha256:67c48a8370c34f68b46eb57339e87d01c04198368a0423553fab7565c862c4df",
          "name": "dcgm-exporter-image"
        },
        {
          "digest": "sha256:ac13256c295126b854a07421c45de0721e7a57974b38b3e66eb1fdc3a4e29f2e",
          "image": "nvcr.io/nvidia/cloud-native/dcgm@sha256:ac13256c295126b854a07421c45de0721e7a57974b38b3e66eb1fdc3a4e29f2e",
          "name": "dcgm-image"
        },
        {
          "digest": "sha256:9abb063e6b74085728fead5ed5bbe3bd7b3f57de60e87f6b964bba2d46f1bc67",
          "image": "nvcr.io/nvidia/k8s/container-toolkit@sha256:9abb063e6b74085728fead5ed5bbe3bd7b3f57de60e87f6b964bba2d46f1bc67",
          "name": "container-toolkit-image"
        },
        {
          "digest": "sha256:d46393d6bd5be020c78e1d45669d2bb3ac8681df13369ddbbbf90740e354c0cf",
          "image": "nvcr.io/nvidia/driver@sha256:d46393d6bd5be020c78e1d45669d2bb3ac8681df13369ddbbbf90740e354c0cf",
          "name": "driver-image"
        },
        {
          "digest": "sha256:aa95c16106280e36a5e32d2fe4c66e8b70f5a114860c6f4ed5b1a4085c63601b",
          "image": "nvcr.io/nvidia/k8s-device-plugin@sha256:aa95c16106280e36a5e32d2fe4c66e8b70f5a114860c6f4ed5b1a4085c63601b",
          "name": "device-plugin-image"
        },
        {
          "digest": "sha256:c2e3d0fe41a0d227dbb70caec03c780cc76317515e5ab3875f31d50c63f41c66",
          "image": "nvcr.io/nvidia/gpu-feature-discovery@sha256:c2e3d0fe41a0d227dbb70caec03c780cc76317515e5ab3875f31d50c63f41c66",
          "name": "gpu-feature-discovery-image"
        },
        {
          "digest": "sha256:e8f06ce53415e8572f633b2169289d973993cb1e49d4dcc686ac134194d88f33",
          "image": "nvcr.io/nvidia/cloud-native/k8s-mig-manager@sha256:e8f06ce53415e8572f633b2169289d973993cb1e49d4dcc686ac134194d88f33",
          "name": "mig-manager-image"
        },
        {
          "digest": "sha256:c7609c27c68ae6520ff21862665d10e1dd0dc99fe0615968310478632187341b",
          "image": "docker.io/nvidia/cuda@sha256:c7609c27c68ae6520ff21862665d10e1dd0dc99fe0615968310478632187341b",
          "name": "init-container-image"
        },
        {
          "digest": "sha256:6819f4c9136e82e44ec34b03ba71c72cbbeebe1db49c596a8bc245fea3bee596",
          "image": "nvcr.io/nvidia/cloud-native/gpu-operator-validator@sha256:6819f4c9136e82e44ec34b03ba71c72cbbeebe1db49c596a8bc245fea3bee596",
          "name": "gpu-operator-validator-image"
        },
        {
          "digest": "sha256:5b16056257acc51b517d9cdb1da3218693cefc214af93789e6e214fd2b4cacf1",
          "image": "nvcr.io/nvidia/cloud-native/k8s-driver-manager@sha256:5b16056257acc51b517d9cdb1da3218693cefc214af93789e6e214fd2b4cacf1",
          "name": "k8s-driver-manager-image"
        },
        {
          "digest": "sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "name": "gpu-operator-e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be-annotation"
        },
        {
          "digest": "sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "name": "gpu-operator"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.10.0",
      "version_original": "1.10.0"
    },
    {
      "_id": "623a088a5216f202c0697683",
      "alm_examples": [
        {
          "api_version": "nvidia.com/v1",
          "kind": "ClusterPolicy",
          "metadata": {
            "name": "gpu-cluster-policy"
          },
          "spec": {
            "daemonsets": {},
            "dcgm": {
              "enabled": true
            },
            "dcgmExporter": {
              "config": {
                "name": ""
              }
            },
            "devicePlugin": {},
            "driver": {
              "certConfig": {
                "name": ""
              },
              "enabled": true,
              "kernelModuleConfig": {
                "name": ""
              },
              "licensingConfig": {
                "configMapName": "",
                "nlsEnabled": false
              },
              "repoConfig": {
                "configMapName": ""
              },
              "use_ocp_driver_toolkit": true,
              "virtualTopology": {
                "config": ""
              }
            },
            "gfd": {},
            "mig": {
              "strategy": "single"
            },
            "migManager": {
              "enabled": true
            },
            "nodeStatusExporter": {
              "enabled": true
            },
            "operator": {
              "defaultRuntime": "crio",
              "deployGFD": true,
              "initContainer": {}
            },
            "toolkit": {
              "enabled": true
            },
            "validator": {
              "plugin": {
                "env": [
                  {
                    "name": "WITH_WORKLOAD",
                    "value": "true"
                  }
                ]
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/nvidia/gpu-operator-bundle@sha256:4d1268054559b7678028a7a66e36567c55417b729101ef131dec8d989cbef1d3",
      "bundle_path_digest": "sha256:4d1268054559b7678028a7a66e36567c55417b729101ef131dec8d989cbef1d3",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "v1.10",
      "creation_date": "2022-03-22T17:34:02.977000+00:00",
      "csv_description": "Kubernetes provides access to special hardware resources such as NVIDIA GPUs, NICs, Infiniband adapters and other devices through the [device plugin framework](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/). However, configuring and managing nodes with these hardware resources requires configuration of multiple software components such as drivers, container runtimes or other libraries which are difficult and prone to errors.\nThe NVIDIA GPU Operator uses the [operator framework](https://coreos.com/blog/introducing-operator-framework) within Kubernetes to automate the management of all NVIDIA software components needed to provision and monitor GPUs. These components include the NVIDIA drivers (to enable CUDA), Kubernetes device plugin for GPUs, the NVIDIA Container Runtime, automatic node labelling and NVIDIA DCGM exporter.\nVisit the official site of the [GPU Operator](https://github.com/NVIDIA/gpu-operator) for more information. For getting started with using the GPU Operator with OpenShift, see the instructions [here](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/contents.html).\n",
      "csv_display_name": "NVIDIA GPU Operator",
      "csv_metadata_description": "Automate the management and monitoring of NVIDIA GPUs.",
      "csv_name": "gpu-operator-certified.v1.10.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T00:47:16.525000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "gpu-operator-certified",
      "provided_apis": [
        {
          "group": "nvidia.com",
          "kind": "ClusterPolicy",
          "plural": "clusterpolicies",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "name": "gpu-operator-image"
        },
        {
          "digest": "sha256:67c48a8370c34f68b46eb57339e87d01c04198368a0423553fab7565c862c4df",
          "image": "nvcr.io/nvidia/k8s/dcgm-exporter@sha256:67c48a8370c34f68b46eb57339e87d01c04198368a0423553fab7565c862c4df",
          "name": "dcgm-exporter-image"
        },
        {
          "digest": "sha256:ac13256c295126b854a07421c45de0721e7a57974b38b3e66eb1fdc3a4e29f2e",
          "image": "nvcr.io/nvidia/cloud-native/dcgm@sha256:ac13256c295126b854a07421c45de0721e7a57974b38b3e66eb1fdc3a4e29f2e",
          "name": "dcgm-image"
        },
        {
          "digest": "sha256:9abb063e6b74085728fead5ed5bbe3bd7b3f57de60e87f6b964bba2d46f1bc67",
          "image": "nvcr.io/nvidia/k8s/container-toolkit@sha256:9abb063e6b74085728fead5ed5bbe3bd7b3f57de60e87f6b964bba2d46f1bc67",
          "name": "container-toolkit-image"
        },
        {
          "digest": "sha256:d46393d6bd5be020c78e1d45669d2bb3ac8681df13369ddbbbf90740e354c0cf",
          "image": "nvcr.io/nvidia/driver@sha256:d46393d6bd5be020c78e1d45669d2bb3ac8681df13369ddbbbf90740e354c0cf",
          "name": "driver-image"
        },
        {
          "digest": "sha256:aa95c16106280e36a5e32d2fe4c66e8b70f5a114860c6f4ed5b1a4085c63601b",
          "image": "nvcr.io/nvidia/k8s-device-plugin@sha256:aa95c16106280e36a5e32d2fe4c66e8b70f5a114860c6f4ed5b1a4085c63601b",
          "name": "device-plugin-image"
        },
        {
          "digest": "sha256:c2e3d0fe41a0d227dbb70caec03c780cc76317515e5ab3875f31d50c63f41c66",
          "image": "nvcr.io/nvidia/gpu-feature-discovery@sha256:c2e3d0fe41a0d227dbb70caec03c780cc76317515e5ab3875f31d50c63f41c66",
          "name": "gpu-feature-discovery-image"
        },
        {
          "digest": "sha256:e8f06ce53415e8572f633b2169289d973993cb1e49d4dcc686ac134194d88f33",
          "image": "nvcr.io/nvidia/cloud-native/k8s-mig-manager@sha256:e8f06ce53415e8572f633b2169289d973993cb1e49d4dcc686ac134194d88f33",
          "name": "mig-manager-image"
        },
        {
          "digest": "sha256:c7609c27c68ae6520ff21862665d10e1dd0dc99fe0615968310478632187341b",
          "image": "docker.io/nvidia/cuda@sha256:c7609c27c68ae6520ff21862665d10e1dd0dc99fe0615968310478632187341b",
          "name": "init-container-image"
        },
        {
          "digest": "sha256:6819f4c9136e82e44ec34b03ba71c72cbbeebe1db49c596a8bc245fea3bee596",
          "image": "nvcr.io/nvidia/cloud-native/gpu-operator-validator@sha256:6819f4c9136e82e44ec34b03ba71c72cbbeebe1db49c596a8bc245fea3bee596",
          "name": "gpu-operator-validator-image"
        },
        {
          "digest": "sha256:5b16056257acc51b517d9cdb1da3218693cefc214af93789e6e214fd2b4cacf1",
          "image": "nvcr.io/nvidia/cloud-native/k8s-driver-manager@sha256:5b16056257acc51b517d9cdb1da3218693cefc214af93789e6e214fd2b4cacf1",
          "name": "k8s-driver-manager-image"
        },
        {
          "digest": "sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "name": "gpu-operator-e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be-annotation"
        },
        {
          "digest": "sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "name": "gpu-operator"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.10.0",
      "version_original": "1.10.0"
    },
    {
      "_id": "623a0efc5216f202c0697686",
      "alm_examples": [
        {
          "api_version": "nvidia.com/v1",
          "kind": "ClusterPolicy",
          "metadata": {
            "name": "gpu-cluster-policy"
          },
          "spec": {
            "daemonsets": {},
            "dcgm": {
              "enabled": true
            },
            "dcgmExporter": {
              "config": {
                "name": ""
              }
            },
            "devicePlugin": {},
            "driver": {
              "certConfig": {
                "name": ""
              },
              "enabled": true,
              "kernelModuleConfig": {
                "name": ""
              },
              "licensingConfig": {
                "configMapName": "",
                "nlsEnabled": false
              },
              "repoConfig": {
                "configMapName": ""
              },
              "use_ocp_driver_toolkit": true,
              "virtualTopology": {
                "config": ""
              }
            },
            "gfd": {},
            "mig": {
              "strategy": "single"
            },
            "migManager": {
              "enabled": true
            },
            "nodeStatusExporter": {
              "enabled": true
            },
            "operator": {
              "defaultRuntime": "crio",
              "deployGFD": true,
              "initContainer": {}
            },
            "toolkit": {
              "enabled": true
            },
            "validator": {
              "plugin": {
                "env": [
                  {
                    "name": "WITH_WORKLOAD",
                    "value": "true"
                  }
                ]
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/nvidia/gpu-operator-bundle@sha256:4d1268054559b7678028a7a66e36567c55417b729101ef131dec8d989cbef1d3",
      "bundle_path_digest": "sha256:4d1268054559b7678028a7a66e36567c55417b729101ef131dec8d989cbef1d3",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-22T18:01:32.719000+00:00",
      "csv_description": "Kubernetes provides access to special hardware resources such as NVIDIA GPUs, NICs, Infiniband adapters and other devices through the [device plugin framework](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/). However, configuring and managing nodes with these hardware resources requires configuration of multiple software components such as drivers, container runtimes or other libraries which are difficult and prone to errors.\nThe NVIDIA GPU Operator uses the [operator framework](https://coreos.com/blog/introducing-operator-framework) within Kubernetes to automate the management of all NVIDIA software components needed to provision and monitor GPUs. These components include the NVIDIA drivers (to enable CUDA), Kubernetes device plugin for GPUs, the NVIDIA Container Runtime, automatic node labelling and NVIDIA DCGM exporter.\nVisit the official site of the [GPU Operator](https://github.com/NVIDIA/gpu-operator) for more information. For getting started with using the GPU Operator with OpenShift, see the instructions [here](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/contents.html).\n",
      "csv_display_name": "NVIDIA GPU Operator",
      "csv_metadata_description": "Automate the management and monitoring of NVIDIA GPUs.",
      "csv_name": "gpu-operator-certified.v1.10.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-06-17T00:50:21.667000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "gpu-operator-certified",
      "provided_apis": [
        {
          "group": "nvidia.com",
          "kind": "ClusterPolicy",
          "plural": "clusterpolicies",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "name": "gpu-operator-image"
        },
        {
          "digest": "sha256:67c48a8370c34f68b46eb57339e87d01c04198368a0423553fab7565c862c4df",
          "image": "nvcr.io/nvidia/k8s/dcgm-exporter@sha256:67c48a8370c34f68b46eb57339e87d01c04198368a0423553fab7565c862c4df",
          "name": "dcgm-exporter-image"
        },
        {
          "digest": "sha256:ac13256c295126b854a07421c45de0721e7a57974b38b3e66eb1fdc3a4e29f2e",
          "image": "nvcr.io/nvidia/cloud-native/dcgm@sha256:ac13256c295126b854a07421c45de0721e7a57974b38b3e66eb1fdc3a4e29f2e",
          "name": "dcgm-image"
        },
        {
          "digest": "sha256:9abb063e6b74085728fead5ed5bbe3bd7b3f57de60e87f6b964bba2d46f1bc67",
          "image": "nvcr.io/nvidia/k8s/container-toolkit@sha256:9abb063e6b74085728fead5ed5bbe3bd7b3f57de60e87f6b964bba2d46f1bc67",
          "name": "container-toolkit-image"
        },
        {
          "digest": "sha256:d46393d6bd5be020c78e1d45669d2bb3ac8681df13369ddbbbf90740e354c0cf",
          "image": "nvcr.io/nvidia/driver@sha256:d46393d6bd5be020c78e1d45669d2bb3ac8681df13369ddbbbf90740e354c0cf",
          "name": "driver-image"
        },
        {
          "digest": "sha256:aa95c16106280e36a5e32d2fe4c66e8b70f5a114860c6f4ed5b1a4085c63601b",
          "image": "nvcr.io/nvidia/k8s-device-plugin@sha256:aa95c16106280e36a5e32d2fe4c66e8b70f5a114860c6f4ed5b1a4085c63601b",
          "name": "device-plugin-image"
        },
        {
          "digest": "sha256:c2e3d0fe41a0d227dbb70caec03c780cc76317515e5ab3875f31d50c63f41c66",
          "image": "nvcr.io/nvidia/gpu-feature-discovery@sha256:c2e3d0fe41a0d227dbb70caec03c780cc76317515e5ab3875f31d50c63f41c66",
          "name": "gpu-feature-discovery-image"
        },
        {
          "digest": "sha256:e8f06ce53415e8572f633b2169289d973993cb1e49d4dcc686ac134194d88f33",
          "image": "nvcr.io/nvidia/cloud-native/k8s-mig-manager@sha256:e8f06ce53415e8572f633b2169289d973993cb1e49d4dcc686ac134194d88f33",
          "name": "mig-manager-image"
        },
        {
          "digest": "sha256:c7609c27c68ae6520ff21862665d10e1dd0dc99fe0615968310478632187341b",
          "image": "docker.io/nvidia/cuda@sha256:c7609c27c68ae6520ff21862665d10e1dd0dc99fe0615968310478632187341b",
          "name": "init-container-image"
        },
        {
          "digest": "sha256:6819f4c9136e82e44ec34b03ba71c72cbbeebe1db49c596a8bc245fea3bee596",
          "image": "nvcr.io/nvidia/cloud-native/gpu-operator-validator@sha256:6819f4c9136e82e44ec34b03ba71c72cbbeebe1db49c596a8bc245fea3bee596",
          "name": "gpu-operator-validator-image"
        },
        {
          "digest": "sha256:5b16056257acc51b517d9cdb1da3218693cefc214af93789e6e214fd2b4cacf1",
          "image": "nvcr.io/nvidia/cloud-native/k8s-driver-manager@sha256:5b16056257acc51b517d9cdb1da3218693cefc214af93789e6e214fd2b4cacf1",
          "name": "k8s-driver-manager-image"
        },
        {
          "digest": "sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "name": "gpu-operator-e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be-annotation"
        },
        {
          "digest": "sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "name": "gpu-operator"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.10.0",
      "version_original": "1.10.0"
    },
    {
      "_id": "623a0efef2605d1718604401",
      "alm_examples": [
        {
          "api_version": "nvidia.com/v1",
          "kind": "ClusterPolicy",
          "metadata": {
            "name": "gpu-cluster-policy"
          },
          "spec": {
            "daemonsets": {},
            "dcgm": {
              "enabled": true
            },
            "dcgmExporter": {
              "config": {
                "name": ""
              }
            },
            "devicePlugin": {},
            "driver": {
              "certConfig": {
                "name": ""
              },
              "enabled": true,
              "kernelModuleConfig": {
                "name": ""
              },
              "licensingConfig": {
                "configMapName": "",
                "nlsEnabled": false
              },
              "repoConfig": {
                "configMapName": ""
              },
              "use_ocp_driver_toolkit": true,
              "virtualTopology": {
                "config": ""
              }
            },
            "gfd": {},
            "mig": {
              "strategy": "single"
            },
            "migManager": {
              "enabled": true
            },
            "nodeStatusExporter": {
              "enabled": true
            },
            "operator": {
              "defaultRuntime": "crio",
              "deployGFD": true,
              "initContainer": {}
            },
            "toolkit": {
              "enabled": true
            },
            "validator": {
              "plugin": {
                "env": [
                  {
                    "name": "WITH_WORKLOAD",
                    "value": "true"
                  }
                ]
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/nvidia/gpu-operator-bundle@sha256:4d1268054559b7678028a7a66e36567c55417b729101ef131dec8d989cbef1d3",
      "bundle_path_digest": "sha256:4d1268054559b7678028a7a66e36567c55417b729101ef131dec8d989cbef1d3",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "v1.10",
      "creation_date": "2022-03-22T18:01:34.039000+00:00",
      "csv_description": "Kubernetes provides access to special hardware resources such as NVIDIA GPUs, NICs, Infiniband adapters and other devices through the [device plugin framework](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/). However, configuring and managing nodes with these hardware resources requires configuration of multiple software components such as drivers, container runtimes or other libraries which are difficult and prone to errors.\nThe NVIDIA GPU Operator uses the [operator framework](https://coreos.com/blog/introducing-operator-framework) within Kubernetes to automate the management of all NVIDIA software components needed to provision and monitor GPUs. These components include the NVIDIA drivers (to enable CUDA), Kubernetes device plugin for GPUs, the NVIDIA Container Runtime, automatic node labelling and NVIDIA DCGM exporter.\nVisit the official site of the [GPU Operator](https://github.com/NVIDIA/gpu-operator) for more information. For getting started with using the GPU Operator with OpenShift, see the instructions [here](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/contents.html).\n",
      "csv_display_name": "NVIDIA GPU Operator",
      "csv_metadata_description": "Automate the management and monitoring of NVIDIA GPUs.",
      "csv_name": "gpu-operator-certified.v1.10.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T00:50:26.023000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "gpu-operator-certified",
      "provided_apis": [
        {
          "group": "nvidia.com",
          "kind": "ClusterPolicy",
          "plural": "clusterpolicies",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "name": "gpu-operator-image"
        },
        {
          "digest": "sha256:67c48a8370c34f68b46eb57339e87d01c04198368a0423553fab7565c862c4df",
          "image": "nvcr.io/nvidia/k8s/dcgm-exporter@sha256:67c48a8370c34f68b46eb57339e87d01c04198368a0423553fab7565c862c4df",
          "name": "dcgm-exporter-image"
        },
        {
          "digest": "sha256:ac13256c295126b854a07421c45de0721e7a57974b38b3e66eb1fdc3a4e29f2e",
          "image": "nvcr.io/nvidia/cloud-native/dcgm@sha256:ac13256c295126b854a07421c45de0721e7a57974b38b3e66eb1fdc3a4e29f2e",
          "name": "dcgm-image"
        },
        {
          "digest": "sha256:9abb063e6b74085728fead5ed5bbe3bd7b3f57de60e87f6b964bba2d46f1bc67",
          "image": "nvcr.io/nvidia/k8s/container-toolkit@sha256:9abb063e6b74085728fead5ed5bbe3bd7b3f57de60e87f6b964bba2d46f1bc67",
          "name": "container-toolkit-image"
        },
        {
          "digest": "sha256:d46393d6bd5be020c78e1d45669d2bb3ac8681df13369ddbbbf90740e354c0cf",
          "image": "nvcr.io/nvidia/driver@sha256:d46393d6bd5be020c78e1d45669d2bb3ac8681df13369ddbbbf90740e354c0cf",
          "name": "driver-image"
        },
        {
          "digest": "sha256:aa95c16106280e36a5e32d2fe4c66e8b70f5a114860c6f4ed5b1a4085c63601b",
          "image": "nvcr.io/nvidia/k8s-device-plugin@sha256:aa95c16106280e36a5e32d2fe4c66e8b70f5a114860c6f4ed5b1a4085c63601b",
          "name": "device-plugin-image"
        },
        {
          "digest": "sha256:c2e3d0fe41a0d227dbb70caec03c780cc76317515e5ab3875f31d50c63f41c66",
          "image": "nvcr.io/nvidia/gpu-feature-discovery@sha256:c2e3d0fe41a0d227dbb70caec03c780cc76317515e5ab3875f31d50c63f41c66",
          "name": "gpu-feature-discovery-image"
        },
        {
          "digest": "sha256:e8f06ce53415e8572f633b2169289d973993cb1e49d4dcc686ac134194d88f33",
          "image": "nvcr.io/nvidia/cloud-native/k8s-mig-manager@sha256:e8f06ce53415e8572f633b2169289d973993cb1e49d4dcc686ac134194d88f33",
          "name": "mig-manager-image"
        },
        {
          "digest": "sha256:c7609c27c68ae6520ff21862665d10e1dd0dc99fe0615968310478632187341b",
          "image": "docker.io/nvidia/cuda@sha256:c7609c27c68ae6520ff21862665d10e1dd0dc99fe0615968310478632187341b",
          "name": "init-container-image"
        },
        {
          "digest": "sha256:6819f4c9136e82e44ec34b03ba71c72cbbeebe1db49c596a8bc245fea3bee596",
          "image": "nvcr.io/nvidia/cloud-native/gpu-operator-validator@sha256:6819f4c9136e82e44ec34b03ba71c72cbbeebe1db49c596a8bc245fea3bee596",
          "name": "gpu-operator-validator-image"
        },
        {
          "digest": "sha256:5b16056257acc51b517d9cdb1da3218693cefc214af93789e6e214fd2b4cacf1",
          "image": "nvcr.io/nvidia/cloud-native/k8s-driver-manager@sha256:5b16056257acc51b517d9cdb1da3218693cefc214af93789e6e214fd2b4cacf1",
          "name": "k8s-driver-manager-image"
        },
        {
          "digest": "sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "name": "gpu-operator-e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be-annotation"
        },
        {
          "digest": "sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "image": "nvcr.io/nvidia/gpu-operator@sha256:e2da1a42a885482a6b40b397397e79c037a10e71abd08e4658eb0b9fc2a761be",
          "name": "gpu-operator"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.10.0",
      "version_original": "1.10.0"
    },
    {
      "_id": "623d8a666d7cc84677b2e8b3",
      "alm_examples": [
        {
          "api_version": "ako.vmware.com/v1alpha1",
          "kind": "AKOConfig",
          "metadata": {
            "name": "ako-sample",
            "namespace": "avi-system"
          },
          "spec": {
            "akoSettings": {
              "apiServerPort": 8080,
              "clusterName": "my-cluster",
              "cniPlugin": "openshift",
              "deleteConfig": false,
              "disableStaticRouteSync": false,
              "enableEVH": false,
              "enableEvents": "true",
              "fullSyncFrequency": "1800",
              "layer7Only": false,
              "logLevel": "INFO",
              "namespaceSelector": {
                "labelKey": "",
                "labelValue": ""
              },
              "servicesAPI": false,
              "vipPerNamespace": "false"
            },
            "controllerSettings": {
              "cloudName": "Default-Cloud",
              "controllerHost": "",
              "controllerVersion": "20.1.5",
              "serviceEngineGroupName": "Default-Group",
              "tenantName": "admin",
              "tenantsPerCluster": "false"
            },
            "imagePullPolicy": "IfNotPresent",
            "imageRepository": "projects.registry.vmware.com/ako/ako-operator@sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
            "l4Settings": {
              "advancedL4": false,
              "autoFQDN": "default",
              "defaultDomain": ""
            },
            "l7Settings": {
              "defaultIngController": true,
              "noPGForSNI": false,
              "passthroughShardSize": "SMALL",
              "serviceType": "ClusterIP",
              "shardVSSize": "LARGE"
            },
            "logFile": "avi.log",
            "mountPath": "/log",
            "networkSettings": {
              "bgpPeerLabels": [],
              "enableRHI": false,
              "nodeNetworkList": [
                {
                  "cidrs": [],
                  "networkName": ""
                }
              ],
              "nsxtT1LR": "",
              "vipNetworkList": [
                {
                  "cidr": "",
                  "networkName": ""
                }
              ]
            },
            "nodePortSelector": {
              "key": "",
              "value": ""
            },
            "resources": {
              "limits": {
                "cpu": "250m",
                "memory": "300Mi"
              },
              "requests": {
                "cpu": "100m",
                "memory": "200Mi"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/wavefronthq/ako-operator-bundle@sha256:7b318b8ae2f90210bda94e4c88b1187a7e92b696dc00cbc3e894c0f285c83f9e",
      "bundle_path_digest": "sha256:7b318b8ae2f90210bda94e4c88b1187a7e92b696dc00cbc3e894c0f285c83f9e",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-25T09:24:54.092000+00:00",
      "csv_description": "Operator to manage the artifacts of the AKO Controller",
      "csv_display_name": "AKO Operator",
      "csv_metadata_description": "",
      "csv_name": "ako-operator.v1.6.3-stable",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:43:15.188000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "ako-operator",
      "provided_apis": [
        {
          "group": "ako.vmware.com",
          "kind": "AKOConfig",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "image": "projects.registry.vmware.com/ako/ako-operator@sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "name": "ako-operator"
        },
        {
          "digest": "sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "image": "projects.registry.vmware.com/ako/ako-operator@sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "name": "ako-operator-378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.6.3",
      "version_original": "1.6.3"
    },
    {
      "_id": "623d8c0cad5091e14e579f73",
      "alm_examples": [
        {
          "api_version": "ako.vmware.com/v1alpha1",
          "kind": "AKOConfig",
          "metadata": {
            "name": "ako-sample",
            "namespace": "avi-system"
          },
          "spec": {
            "akoSettings": {
              "apiServerPort": 8080,
              "clusterName": "my-cluster",
              "cniPlugin": "openshift",
              "deleteConfig": false,
              "disableStaticRouteSync": false,
              "enableEVH": false,
              "enableEvents": "true",
              "fullSyncFrequency": "1800",
              "layer7Only": false,
              "logLevel": "INFO",
              "namespaceSelector": {
                "labelKey": "",
                "labelValue": ""
              },
              "servicesAPI": false,
              "vipPerNamespace": "false"
            },
            "controllerSettings": {
              "cloudName": "Default-Cloud",
              "controllerHost": "",
              "controllerVersion": "20.1.5",
              "serviceEngineGroupName": "Default-Group",
              "tenantName": "admin",
              "tenantsPerCluster": "false"
            },
            "imagePullPolicy": "IfNotPresent",
            "imageRepository": "projects.registry.vmware.com/ako/ako-operator@sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
            "l4Settings": {
              "advancedL4": false,
              "autoFQDN": "default",
              "defaultDomain": ""
            },
            "l7Settings": {
              "defaultIngController": true,
              "noPGForSNI": false,
              "passthroughShardSize": "SMALL",
              "serviceType": "ClusterIP",
              "shardVSSize": "LARGE"
            },
            "logFile": "avi.log",
            "mountPath": "/log",
            "networkSettings": {
              "bgpPeerLabels": [],
              "enableRHI": false,
              "nodeNetworkList": [
                {
                  "cidrs": [],
                  "networkName": ""
                }
              ],
              "nsxtT1LR": "",
              "vipNetworkList": [
                {
                  "cidr": "",
                  "networkName": ""
                }
              ]
            },
            "nodePortSelector": {
              "key": "",
              "value": ""
            },
            "resources": {
              "limits": {
                "cpu": "250m",
                "memory": "300Mi"
              },
              "requests": {
                "cpu": "100m",
                "memory": "200Mi"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/wavefronthq/ako-operator-bundle@sha256:7b318b8ae2f90210bda94e4c88b1187a7e92b696dc00cbc3e894c0f285c83f9e",
      "bundle_path_digest": "sha256:7b318b8ae2f90210bda94e4c88b1187a7e92b696dc00cbc3e894c0f285c83f9e",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-25T09:31:56.260000+00:00",
      "csv_description": "Operator to manage the artifacts of the AKO Controller",
      "csv_display_name": "AKO Operator",
      "csv_metadata_description": "",
      "csv_name": "ako-operator.v1.6.3-stable",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T00:44:29.174000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "ako-operator",
      "provided_apis": [
        {
          "group": "ako.vmware.com",
          "kind": "AKOConfig",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "image": "projects.registry.vmware.com/ako/ako-operator@sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "name": "ako-operator"
        },
        {
          "digest": "sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "image": "projects.registry.vmware.com/ako/ako-operator@sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "name": "ako-operator-378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.6.3",
      "version_original": "1.6.3"
    },
    {
      "_id": "623d8eee6d7cc84677b2e8b4",
      "alm_examples": [
        {
          "api_version": "ako.vmware.com/v1alpha1",
          "kind": "AKOConfig",
          "metadata": {
            "name": "ako-sample",
            "namespace": "avi-system"
          },
          "spec": {
            "akoSettings": {
              "apiServerPort": 8080,
              "clusterName": "my-cluster",
              "cniPlugin": "openshift",
              "deleteConfig": false,
              "disableStaticRouteSync": false,
              "enableEVH": false,
              "enableEvents": "true",
              "fullSyncFrequency": "1800",
              "layer7Only": false,
              "logLevel": "INFO",
              "namespaceSelector": {
                "labelKey": "",
                "labelValue": ""
              },
              "servicesAPI": false,
              "vipPerNamespace": "false"
            },
            "controllerSettings": {
              "cloudName": "Default-Cloud",
              "controllerHost": "",
              "controllerVersion": "20.1.5",
              "serviceEngineGroupName": "Default-Group",
              "tenantName": "admin",
              "tenantsPerCluster": "false"
            },
            "imagePullPolicy": "IfNotPresent",
            "imageRepository": "projects.registry.vmware.com/ako/ako-operator@sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
            "l4Settings": {
              "advancedL4": false,
              "autoFQDN": "default",
              "defaultDomain": ""
            },
            "l7Settings": {
              "defaultIngController": true,
              "noPGForSNI": false,
              "passthroughShardSize": "SMALL",
              "serviceType": "ClusterIP",
              "shardVSSize": "LARGE"
            },
            "logFile": "avi.log",
            "mountPath": "/log",
            "networkSettings": {
              "bgpPeerLabels": [],
              "enableRHI": false,
              "nodeNetworkList": [
                {
                  "cidrs": [],
                  "networkName": ""
                }
              ],
              "nsxtT1LR": "",
              "vipNetworkList": [
                {
                  "cidr": "",
                  "networkName": ""
                }
              ]
            },
            "nodePortSelector": {
              "key": "",
              "value": ""
            },
            "resources": {
              "limits": {
                "cpu": "250m",
                "memory": "300Mi"
              },
              "requests": {
                "cpu": "100m",
                "memory": "200Mi"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/wavefronthq/ako-operator-bundle@sha256:7b318b8ae2f90210bda94e4c88b1187a7e92b696dc00cbc3e894c0f285c83f9e",
      "bundle_path_digest": "sha256:7b318b8ae2f90210bda94e4c88b1187a7e92b696dc00cbc3e894c0f285c83f9e",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-25T09:44:14.537000+00:00",
      "csv_description": "Operator to manage the artifacts of the AKO Controller",
      "csv_display_name": "AKO Operator",
      "csv_metadata_description": "",
      "csv_name": "ako-operator.v1.6.3-stable",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:44:15.444000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "ako-operator",
      "provided_apis": [
        {
          "group": "ako.vmware.com",
          "kind": "AKOConfig",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "image": "projects.registry.vmware.com/ako/ako-operator@sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "name": "ako-operator"
        },
        {
          "digest": "sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "image": "projects.registry.vmware.com/ako/ako-operator@sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "name": "ako-operator-378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.6.3",
      "version_original": "1.6.3"
    },
    {
      "_id": "623d8fcd37f345462469f62c",
      "alm_examples": [
        {
          "api_version": "ako.vmware.com/v1alpha1",
          "kind": "AKOConfig",
          "metadata": {
            "name": "ako-sample",
            "namespace": "avi-system"
          },
          "spec": {
            "akoSettings": {
              "apiServerPort": 8080,
              "clusterName": "my-cluster",
              "cniPlugin": "openshift",
              "deleteConfig": false,
              "disableStaticRouteSync": false,
              "enableEVH": false,
              "enableEvents": "true",
              "fullSyncFrequency": "1800",
              "layer7Only": false,
              "logLevel": "INFO",
              "namespaceSelector": {
                "labelKey": "",
                "labelValue": ""
              },
              "servicesAPI": false,
              "vipPerNamespace": "false"
            },
            "controllerSettings": {
              "cloudName": "Default-Cloud",
              "controllerHost": "",
              "controllerVersion": "20.1.5",
              "serviceEngineGroupName": "Default-Group",
              "tenantName": "admin",
              "tenantsPerCluster": "false"
            },
            "imagePullPolicy": "IfNotPresent",
            "imageRepository": "projects.registry.vmware.com/ako/ako-operator@sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
            "l4Settings": {
              "advancedL4": false,
              "autoFQDN": "default",
              "defaultDomain": ""
            },
            "l7Settings": {
              "defaultIngController": true,
              "noPGForSNI": false,
              "passthroughShardSize": "SMALL",
              "serviceType": "ClusterIP",
              "shardVSSize": "LARGE"
            },
            "logFile": "avi.log",
            "mountPath": "/log",
            "networkSettings": {
              "bgpPeerLabels": [],
              "enableRHI": false,
              "nodeNetworkList": [
                {
                  "cidrs": [],
                  "networkName": ""
                }
              ],
              "nsxtT1LR": "",
              "vipNetworkList": [
                {
                  "cidr": "",
                  "networkName": ""
                }
              ]
            },
            "nodePortSelector": {
              "key": "",
              "value": ""
            },
            "resources": {
              "limits": {
                "cpu": "250m",
                "memory": "300Mi"
              },
              "requests": {
                "cpu": "100m",
                "memory": "200Mi"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/wavefronthq/ako-operator-bundle@sha256:7b318b8ae2f90210bda94e4c88b1187a7e92b696dc00cbc3e894c0f285c83f9e",
      "bundle_path_digest": "sha256:7b318b8ae2f90210bda94e4c88b1187a7e92b696dc00cbc3e894c0f285c83f9e",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-25T09:47:57.153000+00:00",
      "csv_description": "Operator to manage the artifacts of the AKO Controller",
      "csv_display_name": "AKO Operator",
      "csv_metadata_description": "",
      "csv_name": "ako-operator.v1.6.3-stable",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:50:26.709000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "ako-operator",
      "provided_apis": [
        {
          "group": "ako.vmware.com",
          "kind": "AKOConfig",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "image": "projects.registry.vmware.com/ako/ako-operator@sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "name": "ako-operator"
        },
        {
          "digest": "sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "image": "projects.registry.vmware.com/ako/ako-operator@sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "name": "ako-operator-378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "1.6.3",
      "version_original": "1.6.3"
    },
    {
      "_id": "623d917f6d7cc84677b2e8b5",
      "alm_examples": [
        {
          "api_version": "ako.vmware.com/v1alpha1",
          "kind": "AKOConfig",
          "metadata": {
            "name": "ako-sample",
            "namespace": "avi-system"
          },
          "spec": {
            "akoSettings": {
              "apiServerPort": 8080,
              "clusterName": "my-cluster",
              "cniPlugin": "openshift",
              "deleteConfig": false,
              "disableStaticRouteSync": false,
              "enableEVH": false,
              "enableEvents": "true",
              "fullSyncFrequency": "1800",
              "layer7Only": false,
              "logLevel": "INFO",
              "namespaceSelector": {
                "labelKey": "",
                "labelValue": ""
              },
              "servicesAPI": false,
              "vipPerNamespace": "false"
            },
            "controllerSettings": {
              "cloudName": "Default-Cloud",
              "controllerHost": "",
              "controllerVersion": "20.1.5",
              "serviceEngineGroupName": "Default-Group",
              "tenantName": "admin",
              "tenantsPerCluster": "false"
            },
            "imagePullPolicy": "IfNotPresent",
            "imageRepository": "projects.registry.vmware.com/ako/ako-operator@sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
            "l4Settings": {
              "advancedL4": false,
              "autoFQDN": "default",
              "defaultDomain": ""
            },
            "l7Settings": {
              "defaultIngController": true,
              "noPGForSNI": false,
              "passthroughShardSize": "SMALL",
              "serviceType": "ClusterIP",
              "shardVSSize": "LARGE"
            },
            "logFile": "avi.log",
            "mountPath": "/log",
            "networkSettings": {
              "bgpPeerLabels": [],
              "enableRHI": false,
              "nodeNetworkList": [
                {
                  "cidrs": [],
                  "networkName": ""
                }
              ],
              "nsxtT1LR": "",
              "vipNetworkList": [
                {
                  "cidr": "",
                  "networkName": ""
                }
              ]
            },
            "nodePortSelector": {
              "key": "",
              "value": ""
            },
            "resources": {
              "limits": {
                "cpu": "250m",
                "memory": "300Mi"
              },
              "requests": {
                "cpu": "100m",
                "memory": "200Mi"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/wavefronthq/ako-operator-bundle@sha256:7b318b8ae2f90210bda94e4c88b1187a7e92b696dc00cbc3e894c0f285c83f9e",
      "bundle_path_digest": "sha256:7b318b8ae2f90210bda94e4c88b1187a7e92b696dc00cbc3e894c0f285c83f9e",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-25T09:55:11.976000+00:00",
      "csv_description": "Operator to manage the artifacts of the AKO Controller",
      "csv_display_name": "AKO Operator",
      "csv_metadata_description": "",
      "csv_name": "ako-operator.v1.6.3-stable",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:20:57.587000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "ako-operator",
      "provided_apis": [
        {
          "group": "ako.vmware.com",
          "kind": "AKOConfig",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "image": "projects.registry.vmware.com/ako/ako-operator@sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "name": "ako-operator"
        },
        {
          "digest": "sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "image": "projects.registry.vmware.com/ako/ako-operator@sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "name": "ako-operator-378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "1.6.3",
      "version_original": "1.6.3"
    },
    {
      "_id": "623d920f6d7cc84677b2e8b6",
      "alm_examples": [
        {
          "api_version": "ako.vmware.com/v1alpha1",
          "kind": "AKOConfig",
          "metadata": {
            "name": "ako-sample",
            "namespace": "avi-system"
          },
          "spec": {
            "akoSettings": {
              "apiServerPort": 8080,
              "clusterName": "my-cluster",
              "cniPlugin": "openshift",
              "deleteConfig": false,
              "disableStaticRouteSync": false,
              "enableEVH": false,
              "enableEvents": "true",
              "fullSyncFrequency": "1800",
              "layer7Only": false,
              "logLevel": "INFO",
              "namespaceSelector": {
                "labelKey": "",
                "labelValue": ""
              },
              "servicesAPI": false,
              "vipPerNamespace": "false"
            },
            "controllerSettings": {
              "cloudName": "Default-Cloud",
              "controllerHost": "",
              "controllerVersion": "20.1.5",
              "serviceEngineGroupName": "Default-Group",
              "tenantName": "admin",
              "tenantsPerCluster": "false"
            },
            "imagePullPolicy": "IfNotPresent",
            "imageRepository": "projects.registry.vmware.com/ako/ako-operator@sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
            "l4Settings": {
              "advancedL4": false,
              "autoFQDN": "default",
              "defaultDomain": ""
            },
            "l7Settings": {
              "defaultIngController": true,
              "noPGForSNI": false,
              "passthroughShardSize": "SMALL",
              "serviceType": "ClusterIP",
              "shardVSSize": "LARGE"
            },
            "logFile": "avi.log",
            "mountPath": "/log",
            "networkSettings": {
              "bgpPeerLabels": [],
              "enableRHI": false,
              "nodeNetworkList": [
                {
                  "cidrs": [],
                  "networkName": ""
                }
              ],
              "nsxtT1LR": "",
              "vipNetworkList": [
                {
                  "cidr": "",
                  "networkName": ""
                }
              ]
            },
            "nodePortSelector": {
              "key": "",
              "value": ""
            },
            "resources": {
              "limits": {
                "cpu": "250m",
                "memory": "300Mi"
              },
              "requests": {
                "cpu": "100m",
                "memory": "200Mi"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/wavefronthq/ako-operator-bundle@sha256:7b318b8ae2f90210bda94e4c88b1187a7e92b696dc00cbc3e894c0f285c83f9e",
      "bundle_path_digest": "sha256:7b318b8ae2f90210bda94e4c88b1187a7e92b696dc00cbc3e894c0f285c83f9e",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-25T09:57:35.638000+00:00",
      "csv_description": "Operator to manage the artifacts of the AKO Controller",
      "csv_display_name": "AKO Operator",
      "csv_metadata_description": "",
      "csv_name": "ako-operator.v1.6.3-stable",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T00:45:30.225000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "ako-operator",
      "provided_apis": [
        {
          "group": "ako.vmware.com",
          "kind": "AKOConfig",
          "plural": "akoconfigs",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "image": "projects.registry.vmware.com/ako/ako-operator@sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "name": "ako-operator"
        },
        {
          "digest": "sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "image": "projects.registry.vmware.com/ako/ako-operator@sha256:378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd",
          "name": "ako-operator-378c4bb64cfff509193930b7bdf981c299e306c4bebf6f5f3197255c5c0e38dd-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.6.3",
      "version_original": "1.6.3"
    },
    {
      "_id": "623dc670456d2e626dd77291",
      "alm_examples": [
        {
          "api_version": "manta.getmanta.com/v1alpha1",
          "kind": "MantaAuth",
          "metadata": {
            "name": "mantaauth-sample"
          },
          "spec": {
            "imagePullSecrets": "manta-registry-credentials",
            "imageRepoPrefix": "repo.getmanta.com/manta-ubi8/",
            "mantaFlowCredentials": "mantaflow-credentials",
            "mantaVersion": "35.1.0",
            "replicas": 1,
            "storageClassName": "ibmc-block-custom"
          }
        },
        {
          "api_version": "manta.getmanta.com/v1alpha1",
          "kind": "MantaFlow",
          "metadata": {
            "name": "mantaflow-sample"
          },
          "spec": {
            "connectors": {
              "wkc": {
                "enabled": false,
                "logInfo": true,
                "routeName": "cpd",
                "tlsSecretName": "internal-tls"
              }
            },
            "imagePullSecrets": "manta-registry-credentials",
            "imageRepoPrefix": "repo.getmanta.com/manta-ubi8/",
            "mantaFlowCredentials": "mantaflow-credentials",
            "mantaFlowKeys": "mantaflow-keys",
            "mantaVersion": "35.1.0",
            "replicas": 1,
            "storageClassName": "ibmc-block-custom"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/manta-ubi8/mantaflow-operator-bundle@sha256:5f437b941bfd25035b2776de0ec983f6f0cfecd183403379351a8f22d0e85691",
      "bundle_path_digest": "sha256:5f437b941bfd25035b2776de0ec983f6f0cfecd183403379351a8f22d0e85691",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-25T13:41:04.697000+00:00",
      "csv_description": "# MANTA Flow\nMANTA is a Unified Lineage Platform for Data Lineage.  MANTA performs code scanning for lineage that is illustrated to the detailed attribute level with transformations.   Extreme color coding and filtering to make lineage consumable.  Also includes time-slicing for historical lineage analysis.\n\n## Features\n* **Create/Destroy**: Launch MANTA Flow Container deployment.\n* **Scaling to zero**: Scale down the deployment (turn off the container).\n\n## Prerequisites and Requirements\n### MANTA Flow Namespace\nMANTA should be installed into its own namespace.\n\nFor additional installation documentation see a [MANTA Flow Container documentation](https://mantatools.atlassian.net/wiki/spaces/MTKB/pages/2450620467/MANTA+Flow+Container)\nin the MANTA Flow Knowledge Base.\n\n### MANTA Flow Operator\nThe MANTA Flow Operator is responsible for deployment and management of MANTA Flow container deployment.\n\n### Memory Considerations\nMANTA Flow is a memory intensive application. The MANTA Flow Container will specify the memory and cpu requirements for both request and limits. Also, the minimum storage requirements are specified for the persistent volumes (PVs).\n\n### MANTA Flow license.key\nValid license.key needs to be provided in order to successfully launch MANTA Flow Container.\n\n## MANTA Flow Deployment\n\n### Secrets\nCreate a secret for MANTA Flow license.key by:\n    \n    oc create secret generic mantaflow-keys --from-file=<path to license.key>/license.key\n\nCreate an initial admin credentials `username` and `password` and a MANTA master password, which is used for encryption of sensitive data in the persistent storage.\n\n    oc create secret generic mantaflow-credentials --from-literal=username=<manta admin username> --from-literal=password=<manta admin password> --from-literal=MANTA_MASTERPASSWORD=<password for encryption>\n\n### Create MANTA Auth Custom Resource\nCreate a MANTA Auth custom resource. Please use the default parameters provided by the operator and the name of the keys above.\n\n### Create MANTA Flow Custom Resource\nCreate a MANTA Flow custom resource. Please use the default parameters provided by the operator and the name of the keys above.\n\n## Scaling\nMANTA Flow currently supports scaling to zero. This means you can set `replicas: 0` in MANTA Flow Custom Resource Definition (CRD) and MANTA Flow container will be stopped.\n\nBy setting `replicas: 1` MANTA Flow will be scaled to be running on 1 container. All other values of `replicas` are considered invalid.\n",
      "csv_display_name": "MANTA Flow Operator",
      "csv_metadata_description": "",
      "csv_name": "mantaflow-operator.v35.1.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T00:55:17.649000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "mantaflow-operator",
      "provided_apis": [
        {
          "group": "manta.getmanta.com",
          "kind": "MantaFlow",
          "plural": "mantaflows",
          "version": "v1alpha1"
        },
        {
          "group": "manta.getmanta.com",
          "kind": "MantaAuth",
          "plural": "mantaauths",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:8c59b526db248c3b4cae700fa0ae7b87f47cf4134d5c377d0a9fc1e58f7989aa",
          "image": "repo.getmanta.com/manta-ubi8/mantaflow-operator@sha256:8c59b526db248c3b4cae700fa0ae7b87f47cf4134d5c377d0a9fc1e58f7989aa",
          "name": "mantaflow-operator-8c59b526db248c3b4cae700fa0ae7b87f47cf4134d5c377d0a9fc1e58f7989aa-annotation"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:8c59b526db248c3b4cae700fa0ae7b87f47cf4134d5c377d0a9fc1e58f7989aa",
          "image": "repo.getmanta.com/manta-ubi8/mantaflow-operator@sha256:8c59b526db248c3b4cae700fa0ae7b87f47cf4134d5c377d0a9fc1e58f7989aa",
          "name": "manager"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "35.1.1",
      "version_original": "35.1.1"
    },
    {
      "_id": "623dc708ca2c1e0c9df285aa",
      "alm_examples": [
        {
          "api_version": "manta.getmanta.com/v1alpha1",
          "kind": "MantaAuth",
          "metadata": {
            "name": "mantaauth-sample"
          },
          "spec": {
            "imagePullSecrets": "manta-registry-credentials",
            "imageRepoPrefix": "repo.getmanta.com/manta-ubi8/",
            "mantaFlowCredentials": "mantaflow-credentials",
            "mantaVersion": "35.1.0",
            "replicas": 1,
            "storageClassName": "ibmc-block-custom"
          }
        },
        {
          "api_version": "manta.getmanta.com/v1alpha1",
          "kind": "MantaFlow",
          "metadata": {
            "name": "mantaflow-sample"
          },
          "spec": {
            "connectors": {
              "wkc": {
                "enabled": false,
                "logInfo": true,
                "routeName": "cpd",
                "tlsSecretName": "internal-tls"
              }
            },
            "imagePullSecrets": "manta-registry-credentials",
            "imageRepoPrefix": "repo.getmanta.com/manta-ubi8/",
            "mantaFlowCredentials": "mantaflow-credentials",
            "mantaFlowKeys": "mantaflow-keys",
            "mantaVersion": "35.1.0",
            "replicas": 1,
            "storageClassName": "ibmc-block-custom"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/manta-ubi8/mantaflow-operator-bundle@sha256:5f437b941bfd25035b2776de0ec983f6f0cfecd183403379351a8f22d0e85691",
      "bundle_path_digest": "sha256:5f437b941bfd25035b2776de0ec983f6f0cfecd183403379351a8f22d0e85691",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-25T13:43:36.668000+00:00",
      "csv_description": "# MANTA Flow\nMANTA is a Unified Lineage Platform for Data Lineage.  MANTA performs code scanning for lineage that is illustrated to the detailed attribute level with transformations.   Extreme color coding and filtering to make lineage consumable.  Also includes time-slicing for historical lineage analysis.\n\n## Features\n* **Create/Destroy**: Launch MANTA Flow Container deployment.\n* **Scaling to zero**: Scale down the deployment (turn off the container).\n\n## Prerequisites and Requirements\n### MANTA Flow Namespace\nMANTA should be installed into its own namespace.\n\nFor additional installation documentation see a [MANTA Flow Container documentation](https://mantatools.atlassian.net/wiki/spaces/MTKB/pages/2450620467/MANTA+Flow+Container)\nin the MANTA Flow Knowledge Base.\n\n### MANTA Flow Operator\nThe MANTA Flow Operator is responsible for deployment and management of MANTA Flow container deployment.\n\n### Memory Considerations\nMANTA Flow is a memory intensive application. The MANTA Flow Container will specify the memory and cpu requirements for both request and limits. Also, the minimum storage requirements are specified for the persistent volumes (PVs).\n\n### MANTA Flow license.key\nValid license.key needs to be provided in order to successfully launch MANTA Flow Container.\n\n## MANTA Flow Deployment\n\n### Secrets\nCreate a secret for MANTA Flow license.key by:\n    \n    oc create secret generic mantaflow-keys --from-file=<path to license.key>/license.key\n\nCreate an initial admin credentials `username` and `password` and a MANTA master password, which is used for encryption of sensitive data in the persistent storage.\n\n    oc create secret generic mantaflow-credentials --from-literal=username=<manta admin username> --from-literal=password=<manta admin password> --from-literal=MANTA_MASTERPASSWORD=<password for encryption>\n\n### Create MANTA Auth Custom Resource\nCreate a MANTA Auth custom resource. Please use the default parameters provided by the operator and the name of the keys above.\n\n### Create MANTA Flow Custom Resource\nCreate a MANTA Flow custom resource. Please use the default parameters provided by the operator and the name of the keys above.\n\n## Scaling\nMANTA Flow currently supports scaling to zero. This means you can set `replicas: 0` in MANTA Flow Custom Resource Definition (CRD) and MANTA Flow container will be stopped.\n\nBy setting `replicas: 1` MANTA Flow will be scaled to be running on 1 container. All other values of `replicas` are considered invalid.\n",
      "csv_display_name": "MANTA Flow Operator",
      "csv_metadata_description": "",
      "csv_name": "mantaflow-operator.v35.1.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T02:07:06.743000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "mantaflow-operator",
      "provided_apis": [
        {
          "group": "manta.getmanta.com",
          "kind": "MantaAuth",
          "plural": "mantaauths",
          "version": "v1alpha1"
        },
        {
          "group": "manta.getmanta.com",
          "kind": "MantaFlow",
          "plural": "mantaflows",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:8c59b526db248c3b4cae700fa0ae7b87f47cf4134d5c377d0a9fc1e58f7989aa",
          "image": "repo.getmanta.com/manta-ubi8/mantaflow-operator@sha256:8c59b526db248c3b4cae700fa0ae7b87f47cf4134d5c377d0a9fc1e58f7989aa",
          "name": "mantaflow-operator-8c59b526db248c3b4cae700fa0ae7b87f47cf4134d5c377d0a9fc1e58f7989aa-annotation"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:8c59b526db248c3b4cae700fa0ae7b87f47cf4134d5c377d0a9fc1e58f7989aa",
          "image": "repo.getmanta.com/manta-ubi8/mantaflow-operator@sha256:8c59b526db248c3b4cae700fa0ae7b87f47cf4134d5c377d0a9fc1e58f7989aa",
          "name": "manager"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "35.1.1",
      "version_original": "35.1.1"
    },
    {
      "_id": "623dc7ce456d2e626dd77292",
      "alm_examples": [
        {
          "api_version": "manta.getmanta.com/v1alpha1",
          "kind": "MantaAuth",
          "metadata": {
            "name": "mantaauth-sample"
          },
          "spec": {
            "imagePullSecrets": "manta-registry-credentials",
            "imageRepoPrefix": "repo.getmanta.com/manta-ubi8/",
            "mantaFlowCredentials": "mantaflow-credentials",
            "mantaVersion": "35.1.0",
            "replicas": 1,
            "storageClassName": "ibmc-block-custom"
          }
        },
        {
          "api_version": "manta.getmanta.com/v1alpha1",
          "kind": "MantaFlow",
          "metadata": {
            "name": "mantaflow-sample"
          },
          "spec": {
            "connectors": {
              "wkc": {
                "enabled": false,
                "logInfo": true,
                "routeName": "cpd",
                "tlsSecretName": "internal-tls"
              }
            },
            "imagePullSecrets": "manta-registry-credentials",
            "imageRepoPrefix": "repo.getmanta.com/manta-ubi8/",
            "mantaFlowCredentials": "mantaflow-credentials",
            "mantaFlowKeys": "mantaflow-keys",
            "mantaVersion": "35.1.0",
            "replicas": 1,
            "storageClassName": "ibmc-block-custom"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/manta-ubi8/mantaflow-operator-bundle@sha256:5f437b941bfd25035b2776de0ec983f6f0cfecd183403379351a8f22d0e85691",
      "bundle_path_digest": "sha256:5f437b941bfd25035b2776de0ec983f6f0cfecd183403379351a8f22d0e85691",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-25T13:46:54.943000+00:00",
      "csv_description": "# MANTA Flow\nMANTA is a Unified Lineage Platform for Data Lineage.  MANTA performs code scanning for lineage that is illustrated to the detailed attribute level with transformations.   Extreme color coding and filtering to make lineage consumable.  Also includes time-slicing for historical lineage analysis.\n\n## Features\n* **Create/Destroy**: Launch MANTA Flow Container deployment.\n* **Scaling to zero**: Scale down the deployment (turn off the container).\n\n## Prerequisites and Requirements\n### MANTA Flow Namespace\nMANTA should be installed into its own namespace.\n\nFor additional installation documentation see a [MANTA Flow Container documentation](https://mantatools.atlassian.net/wiki/spaces/MTKB/pages/2450620467/MANTA+Flow+Container)\nin the MANTA Flow Knowledge Base.\n\n### MANTA Flow Operator\nThe MANTA Flow Operator is responsible for deployment and management of MANTA Flow container deployment.\n\n### Memory Considerations\nMANTA Flow is a memory intensive application. The MANTA Flow Container will specify the memory and cpu requirements for both request and limits. Also, the minimum storage requirements are specified for the persistent volumes (PVs).\n\n### MANTA Flow license.key\nValid license.key needs to be provided in order to successfully launch MANTA Flow Container.\n\n## MANTA Flow Deployment\n\n### Secrets\nCreate a secret for MANTA Flow license.key by:\n    \n    oc create secret generic mantaflow-keys --from-file=<path to license.key>/license.key\n\nCreate an initial admin credentials `username` and `password` and a MANTA master password, which is used for encryption of sensitive data in the persistent storage.\n\n    oc create secret generic mantaflow-credentials --from-literal=username=<manta admin username> --from-literal=password=<manta admin password> --from-literal=MANTA_MASTERPASSWORD=<password for encryption>\n\n### Create MANTA Auth Custom Resource\nCreate a MANTA Auth custom resource. Please use the default parameters provided by the operator and the name of the keys above.\n\n### Create MANTA Flow Custom Resource\nCreate a MANTA Flow custom resource. Please use the default parameters provided by the operator and the name of the keys above.\n\n## Scaling\nMANTA Flow currently supports scaling to zero. This means you can set `replicas: 0` in MANTA Flow Custom Resource Definition (CRD) and MANTA Flow container will be stopped.\n\nBy setting `replicas: 1` MANTA Flow will be scaled to be running on 1 container. All other values of `replicas` are considered invalid.\n",
      "csv_display_name": "MANTA Flow Operator",
      "csv_metadata_description": "",
      "csv_name": "mantaflow-operator.v35.1.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T02:00:24.840000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "mantaflow-operator",
      "provided_apis": [
        {
          "group": "manta.getmanta.com",
          "kind": "MantaAuth",
          "plural": "mantaauths",
          "version": "v1alpha1"
        },
        {
          "group": "manta.getmanta.com",
          "kind": "MantaFlow",
          "plural": "mantaflows",
          "version": "v1alpha1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:8c59b526db248c3b4cae700fa0ae7b87f47cf4134d5c377d0a9fc1e58f7989aa",
          "image": "repo.getmanta.com/manta-ubi8/mantaflow-operator@sha256:8c59b526db248c3b4cae700fa0ae7b87f47cf4134d5c377d0a9fc1e58f7989aa",
          "name": "mantaflow-operator-8c59b526db248c3b4cae700fa0ae7b87f47cf4134d5c377d0a9fc1e58f7989aa-annotation"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:8c59b526db248c3b4cae700fa0ae7b87f47cf4134d5c377d0a9fc1e58f7989aa",
          "image": "repo.getmanta.com/manta-ubi8/mantaflow-operator@sha256:8c59b526db248c3b4cae700fa0ae7b87f47cf4134d5c377d0a9fc1e58f7989aa",
          "name": "manager"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "35.1.1",
      "version_original": "35.1.1"
    },
    {
      "_id": "623e5d5e6d7cc84677b2e8e6",
      "alm_examples": [
        {
          "api_version": "rc.app.stacks/v1beta2",
          "kind": "RuntimeComponent",
          "metadata": {
            "name": "runtimecomponent-sample"
          },
          "spec": {
            "applicationImage": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
            "expose": true,
            "replicas": 1,
            "service": {
              "port": 9080
            }
          }
        },
        {
          "api_version": "rc.app.stacks/v1beta2",
          "kind": "RuntimeOperation",
          "metadata": {
            "name": "runtimeoperation-sample"
          },
          "spec": {
            "command": [
              "./your_script.sh"
            ],
            "containerName": "app",
            "podName": "Specify_Pod_Name_Here"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/runtime-component-operator-bundle@sha256:4603bf04e53ce948bbf0ee5d239d5e265b40598044ef9e1f4539f4e466e59cb2",
      "bundle_path_digest": "sha256:4603bf04e53ce948bbf0ee5d239d5e265b40598044ef9e1f4539f4e466e59cb2",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "beta2",
      "creation_date": "2022-03-26T00:25:02.009000+00:00",
      "csv_description": "This advanced Operator is capable of deploying any runtime component image with consistent, production-grade QoS. It enables enterprise architects to govern the way their applications get deployed & managed in the cluster, while dramatically reducing the learning curve for developers to deploy into Kubernetes - allowing them to focus on writing the code!\nHere are some key features:\n\n#### Application Lifecyle\nYou can deploy your runtime component container by either pointing to a container image, or an OpenShift ImageStream. When using an ImageStream the Operator will watch for any updates and will re-deploy the modified image.\n\n#### Custom RBAC\nThis Operator is capable of using a custom ServiceAccount from the caller, allowing it to follow RBAC restrictions. By default it creates a ServiceAccount if one is not specified, which can also be bound with specific roles.\n\n#### Environment Configuration\nYou can configure a variety of artifacts with your deployment, such as: labels, annotations, and environment variables from a ConfigMap, a Secret or a value.\n\n#### Routing\nExpose your application to external users via a single toggle to create a Route on OpenShift or an Ingress on other Kubernetes environments. Advanced configuration, such as TLS settings, are also easily enabled.\n\n#### High Availability via Horizontal Pod Autoscaling\nRun multiple instances of your application for high availability. Either specify a static number of replicas or easily configure horizontal auto scaling to create (and delete) instances based on resource consumption.\n\n#### Persistence and advanced storage\nEnable persistence for your application by specifying simple requirements: just tell us the size of the storage and where you would like it to be mounted and we will create and manage that storage for you.\nThis toggles a StatefulSet resource instead of a Deployment resource, so your container can recover transactions and state upon a pod restart.\nWe offer an advanced mode where you can specify a built-in PersistentVolumeClaim, allowing you to configure many details of the persistent volume, such as its storage class and access mode.\n\n#### Service Binding\nYour runtime components can expose services by a simple toggle. We take care of the heavy lifting such as creating kubernetes Secrets with information other services can use to bind. We also keep the bindable information synchronized, so your applications can dynamically reconnect to its required services without any intervention or interruption.\n\n#### Exposing metrics to Prometheus\nThe Runtime Component Operator exposes the runtime container's metrics via the Prometheus Operator.\nYou can pick between a basic mode, where you simply specify the label that Prometheus is watching to scrape the metrics from the container, or you can specify the full `ServiceMonitor` spec embedded into the RuntimeComponent's `spec.monitoring` field to control configurations such as the poll interval and security credentials.\n\n#### Easily mount logs and transaction directories\nIf you need to mount the logs and transaction data from your runtime component to an external volume such as NFS (or any storage supported in your cluster), simply add the following (to specify the volume size and the location to persist) to your RuntimeComponent CR:\n``` storage: size: 2Gi mountPath: \"/logs\" ```\n\n#### Integration with OpenShift Serverless\nDeploy your serverless runtime component using a single toggle.  The Operator will convert all of its generated resources into [Knative](https://knative.dev) resources, allowing your pod to automatically scale to 0 when it is idle.\n\n#### Integration with OpenShift's Topology UI\nWe set the corresponding labels to support OpenShift's Developer Topology UI, which allows you to visualize your entire set of deployments and how they are connected.\n\nSee our [**documentation**](https://github.com/application-stacks/runtime-component-operator/tree/main/doc/) for more information.\n",
      "csv_display_name": "Runtime Component",
      "csv_metadata_description": "Deploys any runtime component with dynamic and auto-tuning configuration",
      "csv_name": "runtime-component.v0.8.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:41:12.325000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "runtime-component-operator-certified",
      "provided_apis": [
        {
          "group": "rc.app.stacks",
          "kind": "RuntimeComponent",
          "version": "v1beta2"
        },
        {
          "group": "rc.app.stacks",
          "kind": "RuntimeOperation",
          "version": "v1beta2"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "image": "registry.connect.redhat.com/ibm/runtime-component-operator@sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "name": "runtime-component-operator-d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d-annotation"
        },
        {
          "digest": "sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "image": "registry.connect.redhat.com/ibm/runtime-component-operator@sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "name": "manager"
        },
        {
          "digest": "sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "image": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "name": "open-liberty-samples-8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "<0.8.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "0.8.1",
      "version_original": "0.8.1"
    },
    {
      "_id": "623e5ff88dcbcc3f5ae16321",
      "alm_examples": [
        {
          "api_version": "rc.app.stacks/v1beta2",
          "kind": "RuntimeComponent",
          "metadata": {
            "name": "runtimecomponent-sample"
          },
          "spec": {
            "applicationImage": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
            "expose": true,
            "replicas": 1,
            "service": {
              "port": 9080
            }
          }
        },
        {
          "api_version": "rc.app.stacks/v1beta2",
          "kind": "RuntimeOperation",
          "metadata": {
            "name": "runtimeoperation-sample"
          },
          "spec": {
            "command": [
              "./your_script.sh"
            ],
            "containerName": "app",
            "podName": "Specify_Pod_Name_Here"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/runtime-component-operator-bundle@sha256:4603bf04e53ce948bbf0ee5d239d5e265b40598044ef9e1f4539f4e466e59cb2",
      "bundle_path_digest": "sha256:4603bf04e53ce948bbf0ee5d239d5e265b40598044ef9e1f4539f4e466e59cb2",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "beta2",
      "creation_date": "2022-03-26T00:36:08.781000+00:00",
      "csv_description": "This advanced Operator is capable of deploying any runtime component image with consistent, production-grade QoS. It enables enterprise architects to govern the way their applications get deployed & managed in the cluster, while dramatically reducing the learning curve for developers to deploy into Kubernetes - allowing them to focus on writing the code!\nHere are some key features:\n\n#### Application Lifecyle\nYou can deploy your runtime component container by either pointing to a container image, or an OpenShift ImageStream. When using an ImageStream the Operator will watch for any updates and will re-deploy the modified image.\n\n#### Custom RBAC\nThis Operator is capable of using a custom ServiceAccount from the caller, allowing it to follow RBAC restrictions. By default it creates a ServiceAccount if one is not specified, which can also be bound with specific roles.\n\n#### Environment Configuration\nYou can configure a variety of artifacts with your deployment, such as: labels, annotations, and environment variables from a ConfigMap, a Secret or a value.\n\n#### Routing\nExpose your application to external users via a single toggle to create a Route on OpenShift or an Ingress on other Kubernetes environments. Advanced configuration, such as TLS settings, are also easily enabled.\n\n#### High Availability via Horizontal Pod Autoscaling\nRun multiple instances of your application for high availability. Either specify a static number of replicas or easily configure horizontal auto scaling to create (and delete) instances based on resource consumption.\n\n#### Persistence and advanced storage\nEnable persistence for your application by specifying simple requirements: just tell us the size of the storage and where you would like it to be mounted and we will create and manage that storage for you.\nThis toggles a StatefulSet resource instead of a Deployment resource, so your container can recover transactions and state upon a pod restart.\nWe offer an advanced mode where you can specify a built-in PersistentVolumeClaim, allowing you to configure many details of the persistent volume, such as its storage class and access mode.\n\n#### Service Binding\nYour runtime components can expose services by a simple toggle. We take care of the heavy lifting such as creating kubernetes Secrets with information other services can use to bind. We also keep the bindable information synchronized, so your applications can dynamically reconnect to its required services without any intervention or interruption.\n\n#### Exposing metrics to Prometheus\nThe Runtime Component Operator exposes the runtime container's metrics via the Prometheus Operator.\nYou can pick between a basic mode, where you simply specify the label that Prometheus is watching to scrape the metrics from the container, or you can specify the full `ServiceMonitor` spec embedded into the RuntimeComponent's `spec.monitoring` field to control configurations such as the poll interval and security credentials.\n\n#### Easily mount logs and transaction directories\nIf you need to mount the logs and transaction data from your runtime component to an external volume such as NFS (or any storage supported in your cluster), simply add the following (to specify the volume size and the location to persist) to your RuntimeComponent CR:\n``` storage: size: 2Gi mountPath: \"/logs\" ```\n\n#### Integration with OpenShift Serverless\nDeploy your serverless runtime component using a single toggle.  The Operator will convert all of its generated resources into [Knative](https://knative.dev) resources, allowing your pod to automatically scale to 0 when it is idle.\n\n#### Integration with OpenShift's Topology UI\nWe set the corresponding labels to support OpenShift's Developer Topology UI, which allows you to visualize your entire set of deployments and how they are connected.\n\nSee our [**documentation**](https://github.com/application-stacks/runtime-component-operator/tree/main/doc/) for more information.\n",
      "csv_display_name": "Runtime Component",
      "csv_metadata_description": "Deploys any runtime component with dynamic and auto-tuning configuration",
      "csv_name": "runtime-component.v0.8.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T00:53:34.611000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "runtime-component-operator-certified",
      "provided_apis": [
        {
          "group": "rc.app.stacks",
          "kind": "RuntimeComponent",
          "plural": "runtimecomponents",
          "version": "v1beta2"
        },
        {
          "group": "rc.app.stacks",
          "kind": "RuntimeOperation",
          "plural": "runtimeoperations",
          "version": "v1beta2"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "image": "registry.connect.redhat.com/ibm/runtime-component-operator@sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "name": "runtime-component-operator-d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d-annotation"
        },
        {
          "digest": "sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "image": "registry.connect.redhat.com/ibm/runtime-component-operator@sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "name": "manager"
        },
        {
          "digest": "sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "image": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "name": "open-liberty-samples-8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "<0.8.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "0.8.1",
      "version_original": "0.8.1"
    },
    {
      "_id": "623e605b8dcbcc3f5ae16322",
      "alm_examples": [
        {
          "api_version": "rc.app.stacks/v1beta2",
          "kind": "RuntimeComponent",
          "metadata": {
            "name": "runtimecomponent-sample"
          },
          "spec": {
            "applicationImage": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
            "expose": true,
            "replicas": 1,
            "service": {
              "port": 9080
            }
          }
        },
        {
          "api_version": "rc.app.stacks/v1beta2",
          "kind": "RuntimeOperation",
          "metadata": {
            "name": "runtimeoperation-sample"
          },
          "spec": {
            "command": [
              "./your_script.sh"
            ],
            "containerName": "app",
            "podName": "Specify_Pod_Name_Here"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/runtime-component-operator-bundle@sha256:4603bf04e53ce948bbf0ee5d239d5e265b40598044ef9e1f4539f4e466e59cb2",
      "bundle_path_digest": "sha256:4603bf04e53ce948bbf0ee5d239d5e265b40598044ef9e1f4539f4e466e59cb2",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "beta2",
      "creation_date": "2022-03-26T00:37:47.851000+00:00",
      "csv_description": "This advanced Operator is capable of deploying any runtime component image with consistent, production-grade QoS. It enables enterprise architects to govern the way their applications get deployed & managed in the cluster, while dramatically reducing the learning curve for developers to deploy into Kubernetes - allowing them to focus on writing the code!\nHere are some key features:\n\n#### Application Lifecyle\nYou can deploy your runtime component container by either pointing to a container image, or an OpenShift ImageStream. When using an ImageStream the Operator will watch for any updates and will re-deploy the modified image.\n\n#### Custom RBAC\nThis Operator is capable of using a custom ServiceAccount from the caller, allowing it to follow RBAC restrictions. By default it creates a ServiceAccount if one is not specified, which can also be bound with specific roles.\n\n#### Environment Configuration\nYou can configure a variety of artifacts with your deployment, such as: labels, annotations, and environment variables from a ConfigMap, a Secret or a value.\n\n#### Routing\nExpose your application to external users via a single toggle to create a Route on OpenShift or an Ingress on other Kubernetes environments. Advanced configuration, such as TLS settings, are also easily enabled.\n\n#### High Availability via Horizontal Pod Autoscaling\nRun multiple instances of your application for high availability. Either specify a static number of replicas or easily configure horizontal auto scaling to create (and delete) instances based on resource consumption.\n\n#### Persistence and advanced storage\nEnable persistence for your application by specifying simple requirements: just tell us the size of the storage and where you would like it to be mounted and we will create and manage that storage for you.\nThis toggles a StatefulSet resource instead of a Deployment resource, so your container can recover transactions and state upon a pod restart.\nWe offer an advanced mode where you can specify a built-in PersistentVolumeClaim, allowing you to configure many details of the persistent volume, such as its storage class and access mode.\n\n#### Service Binding\nYour runtime components can expose services by a simple toggle. We take care of the heavy lifting such as creating kubernetes Secrets with information other services can use to bind. We also keep the bindable information synchronized, so your applications can dynamically reconnect to its required services without any intervention or interruption.\n\n#### Exposing metrics to Prometheus\nThe Runtime Component Operator exposes the runtime container's metrics via the Prometheus Operator.\nYou can pick between a basic mode, where you simply specify the label that Prometheus is watching to scrape the metrics from the container, or you can specify the full `ServiceMonitor` spec embedded into the RuntimeComponent's `spec.monitoring` field to control configurations such as the poll interval and security credentials.\n\n#### Easily mount logs and transaction directories\nIf you need to mount the logs and transaction data from your runtime component to an external volume such as NFS (or any storage supported in your cluster), simply add the following (to specify the volume size and the location to persist) to your RuntimeComponent CR:\n``` storage: size: 2Gi mountPath: \"/logs\" ```\n\n#### Integration with OpenShift Serverless\nDeploy your serverless runtime component using a single toggle.  The Operator will convert all of its generated resources into [Knative](https://knative.dev) resources, allowing your pod to automatically scale to 0 when it is idle.\n\n#### Integration with OpenShift's Topology UI\nWe set the corresponding labels to support OpenShift's Developer Topology UI, which allows you to visualize your entire set of deployments and how they are connected.\n\nSee our [**documentation**](https://github.com/application-stacks/runtime-component-operator/tree/main/doc/) for more information.\n",
      "csv_display_name": "Runtime Component",
      "csv_metadata_description": "Deploys any runtime component with dynamic and auto-tuning configuration",
      "csv_name": "runtime-component.v0.8.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:00:05.015000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "runtime-component-operator-certified",
      "provided_apis": [
        {
          "group": "rc.app.stacks",
          "kind": "RuntimeComponent",
          "plural": "runtimecomponents",
          "version": "v1beta2"
        },
        {
          "group": "rc.app.stacks",
          "kind": "RuntimeOperation",
          "plural": "runtimeoperations",
          "version": "v1beta2"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "image": "registry.connect.redhat.com/ibm/runtime-component-operator@sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "name": "runtime-component-operator-d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d-annotation"
        },
        {
          "digest": "sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "image": "registry.connect.redhat.com/ibm/runtime-component-operator@sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "name": "manager"
        },
        {
          "digest": "sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "image": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "name": "open-liberty-samples-8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "<0.8.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "0.8.1",
      "version_original": "0.8.1"
    },
    {
      "_id": "623e60ee37f345462469f654",
      "alm_examples": [
        {
          "api_version": "rc.app.stacks/v1beta2",
          "kind": "RuntimeComponent",
          "metadata": {
            "name": "runtimecomponent-sample"
          },
          "spec": {
            "applicationImage": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
            "expose": true,
            "replicas": 1,
            "service": {
              "port": 9080
            }
          }
        },
        {
          "api_version": "rc.app.stacks/v1beta2",
          "kind": "RuntimeOperation",
          "metadata": {
            "name": "runtimeoperation-sample"
          },
          "spec": {
            "command": [
              "./your_script.sh"
            ],
            "containerName": "app",
            "podName": "Specify_Pod_Name_Here"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/runtime-component-operator-bundle@sha256:4603bf04e53ce948bbf0ee5d239d5e265b40598044ef9e1f4539f4e466e59cb2",
      "bundle_path_digest": "sha256:4603bf04e53ce948bbf0ee5d239d5e265b40598044ef9e1f4539f4e466e59cb2",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "beta2",
      "creation_date": "2022-03-26T00:40:14.909000+00:00",
      "csv_description": "This advanced Operator is capable of deploying any runtime component image with consistent, production-grade QoS. It enables enterprise architects to govern the way their applications get deployed & managed in the cluster, while dramatically reducing the learning curve for developers to deploy into Kubernetes - allowing them to focus on writing the code!\nHere are some key features:\n\n#### Application Lifecyle\nYou can deploy your runtime component container by either pointing to a container image, or an OpenShift ImageStream. When using an ImageStream the Operator will watch for any updates and will re-deploy the modified image.\n\n#### Custom RBAC\nThis Operator is capable of using a custom ServiceAccount from the caller, allowing it to follow RBAC restrictions. By default it creates a ServiceAccount if one is not specified, which can also be bound with specific roles.\n\n#### Environment Configuration\nYou can configure a variety of artifacts with your deployment, such as: labels, annotations, and environment variables from a ConfigMap, a Secret or a value.\n\n#### Routing\nExpose your application to external users via a single toggle to create a Route on OpenShift or an Ingress on other Kubernetes environments. Advanced configuration, such as TLS settings, are also easily enabled.\n\n#### High Availability via Horizontal Pod Autoscaling\nRun multiple instances of your application for high availability. Either specify a static number of replicas or easily configure horizontal auto scaling to create (and delete) instances based on resource consumption.\n\n#### Persistence and advanced storage\nEnable persistence for your application by specifying simple requirements: just tell us the size of the storage and where you would like it to be mounted and we will create and manage that storage for you.\nThis toggles a StatefulSet resource instead of a Deployment resource, so your container can recover transactions and state upon a pod restart.\nWe offer an advanced mode where you can specify a built-in PersistentVolumeClaim, allowing you to configure many details of the persistent volume, such as its storage class and access mode.\n\n#### Service Binding\nYour runtime components can expose services by a simple toggle. We take care of the heavy lifting such as creating kubernetes Secrets with information other services can use to bind. We also keep the bindable information synchronized, so your applications can dynamically reconnect to its required services without any intervention or interruption.\n\n#### Exposing metrics to Prometheus\nThe Runtime Component Operator exposes the runtime container's metrics via the Prometheus Operator.\nYou can pick between a basic mode, where you simply specify the label that Prometheus is watching to scrape the metrics from the container, or you can specify the full `ServiceMonitor` spec embedded into the RuntimeComponent's `spec.monitoring` field to control configurations such as the poll interval and security credentials.\n\n#### Easily mount logs and transaction directories\nIf you need to mount the logs and transaction data from your runtime component to an external volume such as NFS (or any storage supported in your cluster), simply add the following (to specify the volume size and the location to persist) to your RuntimeComponent CR:\n``` storage: size: 2Gi mountPath: \"/logs\" ```\n\n#### Integration with OpenShift Serverless\nDeploy your serverless runtime component using a single toggle.  The Operator will convert all of its generated resources into [Knative](https://knative.dev) resources, allowing your pod to automatically scale to 0 when it is idle.\n\n#### Integration with OpenShift's Topology UI\nWe set the corresponding labels to support OpenShift's Developer Topology UI, which allows you to visualize your entire set of deployments and how they are connected.\n\nSee our [**documentation**](https://github.com/application-stacks/runtime-component-operator/tree/main/doc/) for more information.\n",
      "csv_display_name": "Runtime Component",
      "csv_metadata_description": "Deploys any runtime component with dynamic and auto-tuning configuration",
      "csv_name": "runtime-component.v0.8.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T02:02:46.954000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "runtime-component-operator-certified",
      "provided_apis": [
        {
          "group": "rc.app.stacks",
          "kind": "RuntimeOperation",
          "plural": "runtimeoperations",
          "version": "v1beta2"
        },
        {
          "group": "rc.app.stacks",
          "kind": "RuntimeComponent",
          "plural": "runtimecomponents",
          "version": "v1beta2"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "image": "registry.connect.redhat.com/ibm/runtime-component-operator@sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "name": "runtime-component-operator-d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d-annotation"
        },
        {
          "digest": "sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "image": "registry.connect.redhat.com/ibm/runtime-component-operator@sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "name": "manager"
        },
        {
          "digest": "sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "image": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "name": "open-liberty-samples-8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "<0.8.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "0.8.1",
      "version_original": "0.8.1"
    },
    {
      "_id": "623e610a37f345462469f655",
      "alm_examples": [
        {
          "api_version": "rc.app.stacks/v1beta2",
          "kind": "RuntimeComponent",
          "metadata": {
            "name": "runtimecomponent-sample"
          },
          "spec": {
            "applicationImage": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
            "expose": true,
            "replicas": 1,
            "service": {
              "port": 9080
            }
          }
        },
        {
          "api_version": "rc.app.stacks/v1beta2",
          "kind": "RuntimeOperation",
          "metadata": {
            "name": "runtimeoperation-sample"
          },
          "spec": {
            "command": [
              "./your_script.sh"
            ],
            "containerName": "app",
            "podName": "Specify_Pod_Name_Here"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/runtime-component-operator-bundle@sha256:4603bf04e53ce948bbf0ee5d239d5e265b40598044ef9e1f4539f4e466e59cb2",
      "bundle_path_digest": "sha256:4603bf04e53ce948bbf0ee5d239d5e265b40598044ef9e1f4539f4e466e59cb2",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "beta2",
      "creation_date": "2022-03-26T00:40:42.064000+00:00",
      "csv_description": "This advanced Operator is capable of deploying any runtime component image with consistent, production-grade QoS. It enables enterprise architects to govern the way their applications get deployed & managed in the cluster, while dramatically reducing the learning curve for developers to deploy into Kubernetes - allowing them to focus on writing the code!\nHere are some key features:\n\n#### Application Lifecyle\nYou can deploy your runtime component container by either pointing to a container image, or an OpenShift ImageStream. When using an ImageStream the Operator will watch for any updates and will re-deploy the modified image.\n\n#### Custom RBAC\nThis Operator is capable of using a custom ServiceAccount from the caller, allowing it to follow RBAC restrictions. By default it creates a ServiceAccount if one is not specified, which can also be bound with specific roles.\n\n#### Environment Configuration\nYou can configure a variety of artifacts with your deployment, such as: labels, annotations, and environment variables from a ConfigMap, a Secret or a value.\n\n#### Routing\nExpose your application to external users via a single toggle to create a Route on OpenShift or an Ingress on other Kubernetes environments. Advanced configuration, such as TLS settings, are also easily enabled.\n\n#### High Availability via Horizontal Pod Autoscaling\nRun multiple instances of your application for high availability. Either specify a static number of replicas or easily configure horizontal auto scaling to create (and delete) instances based on resource consumption.\n\n#### Persistence and advanced storage\nEnable persistence for your application by specifying simple requirements: just tell us the size of the storage and where you would like it to be mounted and we will create and manage that storage for you.\nThis toggles a StatefulSet resource instead of a Deployment resource, so your container can recover transactions and state upon a pod restart.\nWe offer an advanced mode where you can specify a built-in PersistentVolumeClaim, allowing you to configure many details of the persistent volume, such as its storage class and access mode.\n\n#### Service Binding\nYour runtime components can expose services by a simple toggle. We take care of the heavy lifting such as creating kubernetes Secrets with information other services can use to bind. We also keep the bindable information synchronized, so your applications can dynamically reconnect to its required services without any intervention or interruption.\n\n#### Exposing metrics to Prometheus\nThe Runtime Component Operator exposes the runtime container's metrics via the Prometheus Operator.\nYou can pick between a basic mode, where you simply specify the label that Prometheus is watching to scrape the metrics from the container, or you can specify the full `ServiceMonitor` spec embedded into the RuntimeComponent's `spec.monitoring` field to control configurations such as the poll interval and security credentials.\n\n#### Easily mount logs and transaction directories\nIf you need to mount the logs and transaction data from your runtime component to an external volume such as NFS (or any storage supported in your cluster), simply add the following (to specify the volume size and the location to persist) to your RuntimeComponent CR:\n``` storage: size: 2Gi mountPath: \"/logs\" ```\n\n#### Integration with OpenShift Serverless\nDeploy your serverless runtime component using a single toggle.  The Operator will convert all of its generated resources into [Knative](https://knative.dev) resources, allowing your pod to automatically scale to 0 when it is idle.\n\n#### Integration with OpenShift's Topology UI\nWe set the corresponding labels to support OpenShift's Developer Topology UI, which allows you to visualize your entire set of deployments and how they are connected.\n\nSee our [**documentation**](https://github.com/application-stacks/runtime-component-operator/tree/main/doc/) for more information.\n",
      "csv_display_name": "Runtime Component",
      "csv_metadata_description": "Deploys any runtime component with dynamic and auto-tuning configuration",
      "csv_name": "runtime-component.v0.8.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:26:41.370000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "runtime-component-operator-certified",
      "provided_apis": [
        {
          "group": "rc.app.stacks",
          "kind": "RuntimeComponent",
          "plural": "runtimecomponents",
          "version": "v1beta2"
        },
        {
          "group": "rc.app.stacks",
          "kind": "RuntimeOperation",
          "plural": "runtimeoperations",
          "version": "v1beta2"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "image": "registry.connect.redhat.com/ibm/runtime-component-operator@sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "name": "runtime-component-operator-d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d-annotation"
        },
        {
          "digest": "sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "image": "registry.connect.redhat.com/ibm/runtime-component-operator@sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "name": "manager"
        },
        {
          "digest": "sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "image": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "name": "open-liberty-samples-8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "<0.8.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "0.8.1",
      "version_original": "0.8.1"
    },
    {
      "_id": "623e6161ad5091e14e579fae",
      "alm_examples": [
        {
          "api_version": "rc.app.stacks/v1beta2",
          "kind": "RuntimeComponent",
          "metadata": {
            "name": "runtimecomponent-sample"
          },
          "spec": {
            "applicationImage": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
            "expose": true,
            "replicas": 1,
            "service": {
              "port": 9080
            }
          }
        },
        {
          "api_version": "rc.app.stacks/v1beta2",
          "kind": "RuntimeOperation",
          "metadata": {
            "name": "runtimeoperation-sample"
          },
          "spec": {
            "command": [
              "./your_script.sh"
            ],
            "containerName": "app",
            "podName": "Specify_Pod_Name_Here"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/runtime-component-operator-bundle@sha256:4603bf04e53ce948bbf0ee5d239d5e265b40598044ef9e1f4539f4e466e59cb2",
      "bundle_path_digest": "sha256:4603bf04e53ce948bbf0ee5d239d5e265b40598044ef9e1f4539f4e466e59cb2",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "beta2",
      "creation_date": "2022-03-26T00:42:09.882000+00:00",
      "csv_description": "This advanced Operator is capable of deploying any runtime component image with consistent, production-grade QoS. It enables enterprise architects to govern the way their applications get deployed & managed in the cluster, while dramatically reducing the learning curve for developers to deploy into Kubernetes - allowing them to focus on writing the code!\nHere are some key features:\n\n#### Application Lifecyle\nYou can deploy your runtime component container by either pointing to a container image, or an OpenShift ImageStream. When using an ImageStream the Operator will watch for any updates and will re-deploy the modified image.\n\n#### Custom RBAC\nThis Operator is capable of using a custom ServiceAccount from the caller, allowing it to follow RBAC restrictions. By default it creates a ServiceAccount if one is not specified, which can also be bound with specific roles.\n\n#### Environment Configuration\nYou can configure a variety of artifacts with your deployment, such as: labels, annotations, and environment variables from a ConfigMap, a Secret or a value.\n\n#### Routing\nExpose your application to external users via a single toggle to create a Route on OpenShift or an Ingress on other Kubernetes environments. Advanced configuration, such as TLS settings, are also easily enabled.\n\n#### High Availability via Horizontal Pod Autoscaling\nRun multiple instances of your application for high availability. Either specify a static number of replicas or easily configure horizontal auto scaling to create (and delete) instances based on resource consumption.\n\n#### Persistence and advanced storage\nEnable persistence for your application by specifying simple requirements: just tell us the size of the storage and where you would like it to be mounted and we will create and manage that storage for you.\nThis toggles a StatefulSet resource instead of a Deployment resource, so your container can recover transactions and state upon a pod restart.\nWe offer an advanced mode where you can specify a built-in PersistentVolumeClaim, allowing you to configure many details of the persistent volume, such as its storage class and access mode.\n\n#### Service Binding\nYour runtime components can expose services by a simple toggle. We take care of the heavy lifting such as creating kubernetes Secrets with information other services can use to bind. We also keep the bindable information synchronized, so your applications can dynamically reconnect to its required services without any intervention or interruption.\n\n#### Exposing metrics to Prometheus\nThe Runtime Component Operator exposes the runtime container's metrics via the Prometheus Operator.\nYou can pick between a basic mode, where you simply specify the label that Prometheus is watching to scrape the metrics from the container, or you can specify the full `ServiceMonitor` spec embedded into the RuntimeComponent's `spec.monitoring` field to control configurations such as the poll interval and security credentials.\n\n#### Easily mount logs and transaction directories\nIf you need to mount the logs and transaction data from your runtime component to an external volume such as NFS (or any storage supported in your cluster), simply add the following (to specify the volume size and the location to persist) to your RuntimeComponent CR:\n``` storage: size: 2Gi mountPath: \"/logs\" ```\n\n#### Integration with OpenShift Serverless\nDeploy your serverless runtime component using a single toggle.  The Operator will convert all of its generated resources into [Knative](https://knative.dev) resources, allowing your pod to automatically scale to 0 when it is idle.\n\n#### Integration with OpenShift's Topology UI\nWe set the corresponding labels to support OpenShift's Developer Topology UI, which allows you to visualize your entire set of deployments and how they are connected.\n\nSee our [**documentation**](https://github.com/application-stacks/runtime-component-operator/tree/main/doc/) for more information.\n",
      "csv_display_name": "Runtime Component",
      "csv_metadata_description": "Deploys any runtime component with dynamic and auto-tuning configuration",
      "csv_name": "runtime-component.v0.8.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:44:30.703000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "runtime-component-operator-certified",
      "provided_apis": [
        {
          "group": "rc.app.stacks",
          "kind": "RuntimeComponent",
          "plural": "runtimecomponents",
          "version": "v1beta2"
        },
        {
          "group": "rc.app.stacks",
          "kind": "RuntimeOperation",
          "plural": "runtimeoperations",
          "version": "v1beta2"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "image": "registry.connect.redhat.com/ibm/runtime-component-operator@sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "name": "runtime-component-operator-d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d-annotation"
        },
        {
          "digest": "sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "image": "registry.connect.redhat.com/ibm/runtime-component-operator@sha256:d37b3f62575c9ad1ffcb22c89e2c3886275c326bf27aa49fb1808acba475853d",
          "name": "manager"
        },
        {
          "digest": "sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "image": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "name": "open-liberty-samples-8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "<0.8.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "0.8.1",
      "version_original": "0.8.1"
    },
    {
      "_id": "623e983d6d7cc84677b2e8f4",
      "alm_examples": [
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyApplication",
          "metadata": {
            "name": "openliberty-app-sample"
          },
          "spec": {
            "applicationImage": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
            "expose": true,
            "replicas": 1
          }
        },
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyDump",
          "metadata": {
            "name": "openliberty-dump-sample"
          },
          "spec": {
            "include": [
              "thread",
              "heap"
            ],
            "podName": "Specify_Pod_Name_Here"
          }
        },
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyTrace",
          "metadata": {
            "name": "openliberty-trace-sample"
          },
          "spec": {
            "maxFileSize": 20,
            "maxFiles": 5,
            "podName": "Specify_Pod_Name_Here",
            "traceSpecification": "*=info:com.ibm.ws.webcontainer*=all"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/open-liberty-operator-bundle@sha256:591fc4b5867dff26df1952653423b33889c0f56ba3f756057694d4c0e396eeb0",
      "bundle_path_digest": "sha256:591fc4b5867dff26df1952653423b33889c0f56ba3f756057694d4c0e396eeb0",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "beta2",
      "creation_date": "2022-03-26T04:36:13.663000+00:00",
      "csv_description": "This advanced Operator can be used to deploy and manage Open Liberty applications with consistent, production-grade QoS. This operator is based on the [Runtime Component Operator](https://github.com/application-stacks/runtime-component-operator) and provides all of its capabilities in addition to Open Liberty specific features such as gathering traces and dumps (Day-2 operations) and easily configuring and managing the single sign-on information for your Open Liberty applications.\n\nOpen Liberty Operator enables enterprise architects to govern the way their applications get deployed & managed in the cluster, while dramatically reducing the learning curve for developers to deploy into Kubernetes - allowing them to focus on writing the code!\n\nHere are some key features:\n\n#### Application Lifecyle\nYou can deploy your Open Liberty application container by either pointing to a container image, or an OpenShift ImageStream. When using an ImageStream the Operator will watch for any updates and will re-deploy the modified image.\n\n#### Custom RBAC\nThis Operator is capable of using a custom ServiceAccount from the caller, allowing it to follow RBAC restrictions. By default it creates a ServiceAccount if one is not specified, which can also be bound with specific roles.\n\n#### Environment Configuration\nYou can configure a variety of artifacts with your deployment, such as: labels, annotations, and environment variables from a ConfigMap, a Secret or a value.\n\n#### Routing\nExpose your application to external users via a single toggle to create a Route on OpenShift or an Ingress on other Kubernetes environments. Advanced configuration, such as TLS settings, are also easily enabled.\n\n#### High Availability via Horizontal Pod Autoscaling\nRun multiple instances of your application for high availability. Either specify a static number of replicas or easily configure horizontal auto scaling to create (and delete) instances based on resource consumption.\n\n#### Persistence and advanced storage\nEnable persistence for your application by specifying simple requirements: just tell us the size of the storage and where you would like it to be mounted and we will create and manage that storage for you.\nThis toggles a StatefulSet resource instead of a Deployment resource, so your container can recover transactions and state upon a pod restart.\nWe offer an advanced mode where you can specify a built-in PersistentVolumeClaim, allowing you to configure many details of the persistent volume, such as its storage class and access mode.\nYou can also easily configure and use a single storage for serviceability related Day-2 operations, such as gatherig server traces and dumps.\n\n#### Service Binding\nYour runtime components can expose services by a simple toggle. We take care of the heavy lifting such as creating kubernetes Secrets with information other services can use to bind. We also keep the bindable information synchronized, so your applications can dynamically reconnect to its required services without any intervention or interruption.\n\n#### Single Sign-On (SSO)\nOpen Liberty provides capabilities to delegate authentication to external providers. Your application users can log in using their existing social media credentials from providers such as Google, Facebook, LinkedIn, Twitter, GitHub, and any OpenID Connect (OIDC) or OAuth 2.0 clients. Open Liberty Operator allows to easily configure and manage the single sign-on information for your applications.\n\n#### Exposing metrics to Prometheus\nExpose the Open Liberty application's metrics via the Prometheus Operator.\nYou can pick between a basic mode, where you simply specify the label that Prometheus is watching to scrape the metrics from the container, or you can specify the full `ServiceMonitor` spec embedded into the OpenLibertyApplication's `spec.monitoring` field to control configurations such as poll interval and security credentials.\n\n#### Easily mount logs and transaction directories\nDo you need to mount the logs and transaction data from your application to an external volume such as NFS (or any storage supported in your cluster)? Simply add the following configuration (to specify the volume size and the location to persist) to your OpenLibertyApplication CR:\n``` storage: size: 2Gi mountPath: \"/logs\" ```\n\n#### Integration with OpenShift Serverless\nDeploy your serverless runtime component using a single toggle.  The Operator will convert all of its generated resources into [Knative](https://knative.dev) resources, allowing your pod to automatically scale to 0 when it is idle.\n\n#### Integration with OpenShift's Topology UI\nWe set the corresponding labels to support OpenShift's Developer Topology UI, which allows you to visualize your entire set of deployments and how they are connected.\n\nSee our [**documentation**](https://github.com/OpenLiberty/open-liberty-operator/tree/main/doc/) for more information.\n",
      "csv_display_name": "Open Liberty",
      "csv_metadata_description": "Deploy and manage applications running on Liberty",
      "csv_name": "open-liberty-operator.v0.8.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T00:51:29.985000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "open-liberty-certified",
      "provided_apis": [
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyApplication",
          "plural": "openlibertyapplications",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyDump",
          "plural": "openlibertydumps",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyTrace",
          "plural": "openlibertytraces",
          "version": "v1beta2"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "name": "open-liberty-operator-controller-18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db-annotation"
        },
        {
          "digest": "sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "name": "manager"
        },
        {
          "digest": "sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "image": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "name": "open-liberty-samples-8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "<0.8.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "0.8.1",
      "version_original": "0.8.1"
    },
    {
      "_id": "623e9869ad5091e14e579fbc",
      "alm_examples": [
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyApplication",
          "metadata": {
            "name": "openliberty-app-sample"
          },
          "spec": {
            "applicationImage": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
            "expose": true,
            "replicas": 1
          }
        },
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyDump",
          "metadata": {
            "name": "openliberty-dump-sample"
          },
          "spec": {
            "include": [
              "thread",
              "heap"
            ],
            "podName": "Specify_Pod_Name_Here"
          }
        },
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyTrace",
          "metadata": {
            "name": "openliberty-trace-sample"
          },
          "spec": {
            "maxFileSize": 20,
            "maxFiles": 5,
            "podName": "Specify_Pod_Name_Here",
            "traceSpecification": "*=info:com.ibm.ws.webcontainer*=all"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/open-liberty-operator-bundle@sha256:591fc4b5867dff26df1952653423b33889c0f56ba3f756057694d4c0e396eeb0",
      "bundle_path_digest": "sha256:591fc4b5867dff26df1952653423b33889c0f56ba3f756057694d4c0e396eeb0",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "beta2",
      "creation_date": "2022-03-26T04:36:57.541000+00:00",
      "csv_description": "This advanced Operator can be used to deploy and manage Open Liberty applications with consistent, production-grade QoS. This operator is based on the [Runtime Component Operator](https://github.com/application-stacks/runtime-component-operator) and provides all of its capabilities in addition to Open Liberty specific features such as gathering traces and dumps (Day-2 operations) and easily configuring and managing the single sign-on information for your Open Liberty applications.\n\nOpen Liberty Operator enables enterprise architects to govern the way their applications get deployed & managed in the cluster, while dramatically reducing the learning curve for developers to deploy into Kubernetes - allowing them to focus on writing the code!\n\nHere are some key features:\n\n#### Application Lifecyle\nYou can deploy your Open Liberty application container by either pointing to a container image, or an OpenShift ImageStream. When using an ImageStream the Operator will watch for any updates and will re-deploy the modified image.\n\n#### Custom RBAC\nThis Operator is capable of using a custom ServiceAccount from the caller, allowing it to follow RBAC restrictions. By default it creates a ServiceAccount if one is not specified, which can also be bound with specific roles.\n\n#### Environment Configuration\nYou can configure a variety of artifacts with your deployment, such as: labels, annotations, and environment variables from a ConfigMap, a Secret or a value.\n\n#### Routing\nExpose your application to external users via a single toggle to create a Route on OpenShift or an Ingress on other Kubernetes environments. Advanced configuration, such as TLS settings, are also easily enabled.\n\n#### High Availability via Horizontal Pod Autoscaling\nRun multiple instances of your application for high availability. Either specify a static number of replicas or easily configure horizontal auto scaling to create (and delete) instances based on resource consumption.\n\n#### Persistence and advanced storage\nEnable persistence for your application by specifying simple requirements: just tell us the size of the storage and where you would like it to be mounted and we will create and manage that storage for you.\nThis toggles a StatefulSet resource instead of a Deployment resource, so your container can recover transactions and state upon a pod restart.\nWe offer an advanced mode where you can specify a built-in PersistentVolumeClaim, allowing you to configure many details of the persistent volume, such as its storage class and access mode.\nYou can also easily configure and use a single storage for serviceability related Day-2 operations, such as gatherig server traces and dumps.\n\n#### Service Binding\nYour runtime components can expose services by a simple toggle. We take care of the heavy lifting such as creating kubernetes Secrets with information other services can use to bind. We also keep the bindable information synchronized, so your applications can dynamically reconnect to its required services without any intervention or interruption.\n\n#### Single Sign-On (SSO)\nOpen Liberty provides capabilities to delegate authentication to external providers. Your application users can log in using their existing social media credentials from providers such as Google, Facebook, LinkedIn, Twitter, GitHub, and any OpenID Connect (OIDC) or OAuth 2.0 clients. Open Liberty Operator allows to easily configure and manage the single sign-on information for your applications.\n\n#### Exposing metrics to Prometheus\nExpose the Open Liberty application's metrics via the Prometheus Operator.\nYou can pick between a basic mode, where you simply specify the label that Prometheus is watching to scrape the metrics from the container, or you can specify the full `ServiceMonitor` spec embedded into the OpenLibertyApplication's `spec.monitoring` field to control configurations such as poll interval and security credentials.\n\n#### Easily mount logs and transaction directories\nDo you need to mount the logs and transaction data from your application to an external volume such as NFS (or any storage supported in your cluster)? Simply add the following configuration (to specify the volume size and the location to persist) to your OpenLibertyApplication CR:\n``` storage: size: 2Gi mountPath: \"/logs\" ```\n\n#### Integration with OpenShift Serverless\nDeploy your serverless runtime component using a single toggle.  The Operator will convert all of its generated resources into [Knative](https://knative.dev) resources, allowing your pod to automatically scale to 0 when it is idle.\n\n#### Integration with OpenShift's Topology UI\nWe set the corresponding labels to support OpenShift's Developer Topology UI, which allows you to visualize your entire set of deployments and how they are connected.\n\nSee our [**documentation**](https://github.com/OpenLiberty/open-liberty-operator/tree/main/doc/) for more information.\n",
      "csv_display_name": "Open Liberty",
      "csv_metadata_description": "Deploy and manage applications running on Liberty",
      "csv_name": "open-liberty-operator.v0.8.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T00:57:19.387000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "open-liberty-certified",
      "provided_apis": [
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyApplication",
          "plural": "openlibertyapplications",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyDump",
          "plural": "openlibertydumps",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyTrace",
          "plural": "openlibertytraces",
          "version": "v1beta2"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "name": "open-liberty-operator-controller-18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db-annotation"
        },
        {
          "digest": "sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "name": "manager"
        },
        {
          "digest": "sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "image": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "name": "open-liberty-samples-8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "<0.8.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "0.8.1",
      "version_original": "0.8.1"
    },
    {
      "_id": "623e98758dcbcc3f5ae1633b",
      "alm_examples": [
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyApplication",
          "metadata": {
            "name": "openliberty-app-sample"
          },
          "spec": {
            "applicationImage": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
            "expose": true,
            "replicas": 1
          }
        },
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyDump",
          "metadata": {
            "name": "openliberty-dump-sample"
          },
          "spec": {
            "include": [
              "thread",
              "heap"
            ],
            "podName": "Specify_Pod_Name_Here"
          }
        },
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyTrace",
          "metadata": {
            "name": "openliberty-trace-sample"
          },
          "spec": {
            "maxFileSize": 20,
            "maxFiles": 5,
            "podName": "Specify_Pod_Name_Here",
            "traceSpecification": "*=info:com.ibm.ws.webcontainer*=all"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/open-liberty-operator-bundle@sha256:591fc4b5867dff26df1952653423b33889c0f56ba3f756057694d4c0e396eeb0",
      "bundle_path_digest": "sha256:591fc4b5867dff26df1952653423b33889c0f56ba3f756057694d4c0e396eeb0",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "beta2",
      "creation_date": "2022-03-26T04:37:09.494000+00:00",
      "csv_description": "This advanced Operator can be used to deploy and manage Open Liberty applications with consistent, production-grade QoS. This operator is based on the [Runtime Component Operator](https://github.com/application-stacks/runtime-component-operator) and provides all of its capabilities in addition to Open Liberty specific features such as gathering traces and dumps (Day-2 operations) and easily configuring and managing the single sign-on information for your Open Liberty applications.\n\nOpen Liberty Operator enables enterprise architects to govern the way their applications get deployed & managed in the cluster, while dramatically reducing the learning curve for developers to deploy into Kubernetes - allowing them to focus on writing the code!\n\nHere are some key features:\n\n#### Application Lifecyle\nYou can deploy your Open Liberty application container by either pointing to a container image, or an OpenShift ImageStream. When using an ImageStream the Operator will watch for any updates and will re-deploy the modified image.\n\n#### Custom RBAC\nThis Operator is capable of using a custom ServiceAccount from the caller, allowing it to follow RBAC restrictions. By default it creates a ServiceAccount if one is not specified, which can also be bound with specific roles.\n\n#### Environment Configuration\nYou can configure a variety of artifacts with your deployment, such as: labels, annotations, and environment variables from a ConfigMap, a Secret or a value.\n\n#### Routing\nExpose your application to external users via a single toggle to create a Route on OpenShift or an Ingress on other Kubernetes environments. Advanced configuration, such as TLS settings, are also easily enabled.\n\n#### High Availability via Horizontal Pod Autoscaling\nRun multiple instances of your application for high availability. Either specify a static number of replicas or easily configure horizontal auto scaling to create (and delete) instances based on resource consumption.\n\n#### Persistence and advanced storage\nEnable persistence for your application by specifying simple requirements: just tell us the size of the storage and where you would like it to be mounted and we will create and manage that storage for you.\nThis toggles a StatefulSet resource instead of a Deployment resource, so your container can recover transactions and state upon a pod restart.\nWe offer an advanced mode where you can specify a built-in PersistentVolumeClaim, allowing you to configure many details of the persistent volume, such as its storage class and access mode.\nYou can also easily configure and use a single storage for serviceability related Day-2 operations, such as gatherig server traces and dumps.\n\n#### Service Binding\nYour runtime components can expose services by a simple toggle. We take care of the heavy lifting such as creating kubernetes Secrets with information other services can use to bind. We also keep the bindable information synchronized, so your applications can dynamically reconnect to its required services without any intervention or interruption.\n\n#### Single Sign-On (SSO)\nOpen Liberty provides capabilities to delegate authentication to external providers. Your application users can log in using their existing social media credentials from providers such as Google, Facebook, LinkedIn, Twitter, GitHub, and any OpenID Connect (OIDC) or OAuth 2.0 clients. Open Liberty Operator allows to easily configure and manage the single sign-on information for your applications.\n\n#### Exposing metrics to Prometheus\nExpose the Open Liberty application's metrics via the Prometheus Operator.\nYou can pick between a basic mode, where you simply specify the label that Prometheus is watching to scrape the metrics from the container, or you can specify the full `ServiceMonitor` spec embedded into the OpenLibertyApplication's `spec.monitoring` field to control configurations such as poll interval and security credentials.\n\n#### Easily mount logs and transaction directories\nDo you need to mount the logs and transaction data from your application to an external volume such as NFS (or any storage supported in your cluster)? Simply add the following configuration (to specify the volume size and the location to persist) to your OpenLibertyApplication CR:\n``` storage: size: 2Gi mountPath: \"/logs\" ```\n\n#### Integration with OpenShift Serverless\nDeploy your serverless runtime component using a single toggle.  The Operator will convert all of its generated resources into [Knative](https://knative.dev) resources, allowing your pod to automatically scale to 0 when it is idle.\n\n#### Integration with OpenShift's Topology UI\nWe set the corresponding labels to support OpenShift's Developer Topology UI, which allows you to visualize your entire set of deployments and how they are connected.\n\nSee our [**documentation**](https://github.com/OpenLiberty/open-liberty-operator/tree/main/doc/) for more information.\n",
      "csv_display_name": "Open Liberty",
      "csv_metadata_description": "Deploy and manage applications running on Liberty",
      "csv_name": "open-liberty-operator.v0.8.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:44:20.156000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "open-liberty-certified",
      "provided_apis": [
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyApplication",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyDump",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyTrace",
          "version": "v1beta2"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "name": "open-liberty-operator-controller-18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db-annotation"
        },
        {
          "digest": "sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "name": "manager"
        },
        {
          "digest": "sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "image": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "name": "open-liberty-samples-8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "<0.8.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "0.8.1",
      "version_original": "0.8.1"
    },
    {
      "_id": "623e9933ad5091e14e579fbd",
      "alm_examples": [
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyApplication",
          "metadata": {
            "name": "openliberty-app-sample"
          },
          "spec": {
            "applicationImage": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
            "expose": true,
            "replicas": 1
          }
        },
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyDump",
          "metadata": {
            "name": "openliberty-dump-sample"
          },
          "spec": {
            "include": [
              "thread",
              "heap"
            ],
            "podName": "Specify_Pod_Name_Here"
          }
        },
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyTrace",
          "metadata": {
            "name": "openliberty-trace-sample"
          },
          "spec": {
            "maxFileSize": 20,
            "maxFiles": 5,
            "podName": "Specify_Pod_Name_Here",
            "traceSpecification": "*=info:com.ibm.ws.webcontainer*=all"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/open-liberty-operator-bundle@sha256:591fc4b5867dff26df1952653423b33889c0f56ba3f756057694d4c0e396eeb0",
      "bundle_path_digest": "sha256:591fc4b5867dff26df1952653423b33889c0f56ba3f756057694d4c0e396eeb0",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "beta2",
      "creation_date": "2022-03-26T04:40:19.106000+00:00",
      "csv_description": "This advanced Operator can be used to deploy and manage Open Liberty applications with consistent, production-grade QoS. This operator is based on the [Runtime Component Operator](https://github.com/application-stacks/runtime-component-operator) and provides all of its capabilities in addition to Open Liberty specific features such as gathering traces and dumps (Day-2 operations) and easily configuring and managing the single sign-on information for your Open Liberty applications.\n\nOpen Liberty Operator enables enterprise architects to govern the way their applications get deployed & managed in the cluster, while dramatically reducing the learning curve for developers to deploy into Kubernetes - allowing them to focus on writing the code!\n\nHere are some key features:\n\n#### Application Lifecyle\nYou can deploy your Open Liberty application container by either pointing to a container image, or an OpenShift ImageStream. When using an ImageStream the Operator will watch for any updates and will re-deploy the modified image.\n\n#### Custom RBAC\nThis Operator is capable of using a custom ServiceAccount from the caller, allowing it to follow RBAC restrictions. By default it creates a ServiceAccount if one is not specified, which can also be bound with specific roles.\n\n#### Environment Configuration\nYou can configure a variety of artifacts with your deployment, such as: labels, annotations, and environment variables from a ConfigMap, a Secret or a value.\n\n#### Routing\nExpose your application to external users via a single toggle to create a Route on OpenShift or an Ingress on other Kubernetes environments. Advanced configuration, such as TLS settings, are also easily enabled.\n\n#### High Availability via Horizontal Pod Autoscaling\nRun multiple instances of your application for high availability. Either specify a static number of replicas or easily configure horizontal auto scaling to create (and delete) instances based on resource consumption.\n\n#### Persistence and advanced storage\nEnable persistence for your application by specifying simple requirements: just tell us the size of the storage and where you would like it to be mounted and we will create and manage that storage for you.\nThis toggles a StatefulSet resource instead of a Deployment resource, so your container can recover transactions and state upon a pod restart.\nWe offer an advanced mode where you can specify a built-in PersistentVolumeClaim, allowing you to configure many details of the persistent volume, such as its storage class and access mode.\nYou can also easily configure and use a single storage for serviceability related Day-2 operations, such as gatherig server traces and dumps.\n\n#### Service Binding\nYour runtime components can expose services by a simple toggle. We take care of the heavy lifting such as creating kubernetes Secrets with information other services can use to bind. We also keep the bindable information synchronized, so your applications can dynamically reconnect to its required services without any intervention or interruption.\n\n#### Single Sign-On (SSO)\nOpen Liberty provides capabilities to delegate authentication to external providers. Your application users can log in using their existing social media credentials from providers such as Google, Facebook, LinkedIn, Twitter, GitHub, and any OpenID Connect (OIDC) or OAuth 2.0 clients. Open Liberty Operator allows to easily configure and manage the single sign-on information for your applications.\n\n#### Exposing metrics to Prometheus\nExpose the Open Liberty application's metrics via the Prometheus Operator.\nYou can pick between a basic mode, where you simply specify the label that Prometheus is watching to scrape the metrics from the container, or you can specify the full `ServiceMonitor` spec embedded into the OpenLibertyApplication's `spec.monitoring` field to control configurations such as poll interval and security credentials.\n\n#### Easily mount logs and transaction directories\nDo you need to mount the logs and transaction data from your application to an external volume such as NFS (or any storage supported in your cluster)? Simply add the following configuration (to specify the volume size and the location to persist) to your OpenLibertyApplication CR:\n``` storage: size: 2Gi mountPath: \"/logs\" ```\n\n#### Integration with OpenShift Serverless\nDeploy your serverless runtime component using a single toggle.  The Operator will convert all of its generated resources into [Knative](https://knative.dev) resources, allowing your pod to automatically scale to 0 when it is idle.\n\n#### Integration with OpenShift's Topology UI\nWe set the corresponding labels to support OpenShift's Developer Topology UI, which allows you to visualize your entire set of deployments and how they are connected.\n\nSee our [**documentation**](https://github.com/OpenLiberty/open-liberty-operator/tree/main/doc/) for more information.\n",
      "csv_display_name": "Open Liberty",
      "csv_metadata_description": "Deploy and manage applications running on Liberty",
      "csv_name": "open-liberty-operator.v0.8.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T02:04:44.830000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "open-liberty-certified",
      "provided_apis": [
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyDump",
          "plural": "openlibertydumps",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyTrace",
          "plural": "openlibertytraces",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyApplication",
          "plural": "openlibertyapplications",
          "version": "v1beta2"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "name": "open-liberty-operator-controller-18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db-annotation"
        },
        {
          "digest": "sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "name": "manager"
        },
        {
          "digest": "sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "image": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "name": "open-liberty-samples-8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "<0.8.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "0.8.1",
      "version_original": "0.8.1"
    },
    {
      "_id": "623e99828dcbcc3f5ae1633c",
      "alm_examples": [
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyApplication",
          "metadata": {
            "name": "openliberty-app-sample"
          },
          "spec": {
            "applicationImage": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
            "expose": true,
            "replicas": 1
          }
        },
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyDump",
          "metadata": {
            "name": "openliberty-dump-sample"
          },
          "spec": {
            "include": [
              "thread",
              "heap"
            ],
            "podName": "Specify_Pod_Name_Here"
          }
        },
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyTrace",
          "metadata": {
            "name": "openliberty-trace-sample"
          },
          "spec": {
            "maxFileSize": 20,
            "maxFiles": 5,
            "podName": "Specify_Pod_Name_Here",
            "traceSpecification": "*=info:com.ibm.ws.webcontainer*=all"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/open-liberty-operator-bundle@sha256:591fc4b5867dff26df1952653423b33889c0f56ba3f756057694d4c0e396eeb0",
      "bundle_path_digest": "sha256:591fc4b5867dff26df1952653423b33889c0f56ba3f756057694d4c0e396eeb0",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "beta2",
      "creation_date": "2022-03-26T04:41:38.562000+00:00",
      "csv_description": "This advanced Operator can be used to deploy and manage Open Liberty applications with consistent, production-grade QoS. This operator is based on the [Runtime Component Operator](https://github.com/application-stacks/runtime-component-operator) and provides all of its capabilities in addition to Open Liberty specific features such as gathering traces and dumps (Day-2 operations) and easily configuring and managing the single sign-on information for your Open Liberty applications.\n\nOpen Liberty Operator enables enterprise architects to govern the way their applications get deployed & managed in the cluster, while dramatically reducing the learning curve for developers to deploy into Kubernetes - allowing them to focus on writing the code!\n\nHere are some key features:\n\n#### Application Lifecyle\nYou can deploy your Open Liberty application container by either pointing to a container image, or an OpenShift ImageStream. When using an ImageStream the Operator will watch for any updates and will re-deploy the modified image.\n\n#### Custom RBAC\nThis Operator is capable of using a custom ServiceAccount from the caller, allowing it to follow RBAC restrictions. By default it creates a ServiceAccount if one is not specified, which can also be bound with specific roles.\n\n#### Environment Configuration\nYou can configure a variety of artifacts with your deployment, such as: labels, annotations, and environment variables from a ConfigMap, a Secret or a value.\n\n#### Routing\nExpose your application to external users via a single toggle to create a Route on OpenShift or an Ingress on other Kubernetes environments. Advanced configuration, such as TLS settings, are also easily enabled.\n\n#### High Availability via Horizontal Pod Autoscaling\nRun multiple instances of your application for high availability. Either specify a static number of replicas or easily configure horizontal auto scaling to create (and delete) instances based on resource consumption.\n\n#### Persistence and advanced storage\nEnable persistence for your application by specifying simple requirements: just tell us the size of the storage and where you would like it to be mounted and we will create and manage that storage for you.\nThis toggles a StatefulSet resource instead of a Deployment resource, so your container can recover transactions and state upon a pod restart.\nWe offer an advanced mode where you can specify a built-in PersistentVolumeClaim, allowing you to configure many details of the persistent volume, such as its storage class and access mode.\nYou can also easily configure and use a single storage for serviceability related Day-2 operations, such as gatherig server traces and dumps.\n\n#### Service Binding\nYour runtime components can expose services by a simple toggle. We take care of the heavy lifting such as creating kubernetes Secrets with information other services can use to bind. We also keep the bindable information synchronized, so your applications can dynamically reconnect to its required services without any intervention or interruption.\n\n#### Single Sign-On (SSO)\nOpen Liberty provides capabilities to delegate authentication to external providers. Your application users can log in using their existing social media credentials from providers such as Google, Facebook, LinkedIn, Twitter, GitHub, and any OpenID Connect (OIDC) or OAuth 2.0 clients. Open Liberty Operator allows to easily configure and manage the single sign-on information for your applications.\n\n#### Exposing metrics to Prometheus\nExpose the Open Liberty application's metrics via the Prometheus Operator.\nYou can pick between a basic mode, where you simply specify the label that Prometheus is watching to scrape the metrics from the container, or you can specify the full `ServiceMonitor` spec embedded into the OpenLibertyApplication's `spec.monitoring` field to control configurations such as poll interval and security credentials.\n\n#### Easily mount logs and transaction directories\nDo you need to mount the logs and transaction data from your application to an external volume such as NFS (or any storage supported in your cluster)? Simply add the following configuration (to specify the volume size and the location to persist) to your OpenLibertyApplication CR:\n``` storage: size: 2Gi mountPath: \"/logs\" ```\n\n#### Integration with OpenShift Serverless\nDeploy your serverless runtime component using a single toggle.  The Operator will convert all of its generated resources into [Knative](https://knative.dev) resources, allowing your pod to automatically scale to 0 when it is idle.\n\n#### Integration with OpenShift's Topology UI\nWe set the corresponding labels to support OpenShift's Developer Topology UI, which allows you to visualize your entire set of deployments and how they are connected.\n\nSee our [**documentation**](https://github.com/OpenLiberty/open-liberty-operator/tree/main/doc/) for more information.\n",
      "csv_display_name": "Open Liberty",
      "csv_metadata_description": "Deploy and manage applications running on Liberty",
      "csv_name": "open-liberty-operator.v0.8.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T02:07:37.472000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "open-liberty-certified",
      "provided_apis": [
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyApplication",
          "plural": "openlibertyapplications",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyDump",
          "plural": "openlibertydumps",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyTrace",
          "plural": "openlibertytraces",
          "version": "v1beta2"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "name": "open-liberty-operator-controller-18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db-annotation"
        },
        {
          "digest": "sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "name": "manager"
        },
        {
          "digest": "sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "image": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "name": "open-liberty-samples-8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "<0.8.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "0.8.1",
      "version_original": "0.8.1"
    },
    {
      "_id": "623e9c8737f345462469f66a",
      "alm_examples": [
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyApplication",
          "metadata": {
            "name": "openliberty-app-sample"
          },
          "spec": {
            "applicationImage": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
            "expose": true,
            "replicas": 1
          }
        },
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyDump",
          "metadata": {
            "name": "openliberty-dump-sample"
          },
          "spec": {
            "include": [
              "thread",
              "heap"
            ],
            "podName": "Specify_Pod_Name_Here"
          }
        },
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyTrace",
          "metadata": {
            "name": "openliberty-trace-sample"
          },
          "spec": {
            "maxFileSize": 20,
            "maxFiles": 5,
            "podName": "Specify_Pod_Name_Here",
            "traceSpecification": "*=info:com.ibm.ws.webcontainer*=all"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/open-liberty-operator-bundle@sha256:591fc4b5867dff26df1952653423b33889c0f56ba3f756057694d4c0e396eeb0",
      "bundle_path_digest": "sha256:591fc4b5867dff26df1952653423b33889c0f56ba3f756057694d4c0e396eeb0",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "beta2",
      "creation_date": "2022-03-26T04:54:31.335000+00:00",
      "csv_description": "This advanced Operator can be used to deploy and manage Open Liberty applications with consistent, production-grade QoS. This operator is based on the [Runtime Component Operator](https://github.com/application-stacks/runtime-component-operator) and provides all of its capabilities in addition to Open Liberty specific features such as gathering traces and dumps (Day-2 operations) and easily configuring and managing the single sign-on information for your Open Liberty applications.\n\nOpen Liberty Operator enables enterprise architects to govern the way their applications get deployed & managed in the cluster, while dramatically reducing the learning curve for developers to deploy into Kubernetes - allowing them to focus on writing the code!\n\nHere are some key features:\n\n#### Application Lifecyle\nYou can deploy your Open Liberty application container by either pointing to a container image, or an OpenShift ImageStream. When using an ImageStream the Operator will watch for any updates and will re-deploy the modified image.\n\n#### Custom RBAC\nThis Operator is capable of using a custom ServiceAccount from the caller, allowing it to follow RBAC restrictions. By default it creates a ServiceAccount if one is not specified, which can also be bound with specific roles.\n\n#### Environment Configuration\nYou can configure a variety of artifacts with your deployment, such as: labels, annotations, and environment variables from a ConfigMap, a Secret or a value.\n\n#### Routing\nExpose your application to external users via a single toggle to create a Route on OpenShift or an Ingress on other Kubernetes environments. Advanced configuration, such as TLS settings, are also easily enabled.\n\n#### High Availability via Horizontal Pod Autoscaling\nRun multiple instances of your application for high availability. Either specify a static number of replicas or easily configure horizontal auto scaling to create (and delete) instances based on resource consumption.\n\n#### Persistence and advanced storage\nEnable persistence for your application by specifying simple requirements: just tell us the size of the storage and where you would like it to be mounted and we will create and manage that storage for you.\nThis toggles a StatefulSet resource instead of a Deployment resource, so your container can recover transactions and state upon a pod restart.\nWe offer an advanced mode where you can specify a built-in PersistentVolumeClaim, allowing you to configure many details of the persistent volume, such as its storage class and access mode.\nYou can also easily configure and use a single storage for serviceability related Day-2 operations, such as gatherig server traces and dumps.\n\n#### Service Binding\nYour runtime components can expose services by a simple toggle. We take care of the heavy lifting such as creating kubernetes Secrets with information other services can use to bind. We also keep the bindable information synchronized, so your applications can dynamically reconnect to its required services without any intervention or interruption.\n\n#### Single Sign-On (SSO)\nOpen Liberty provides capabilities to delegate authentication to external providers. Your application users can log in using their existing social media credentials from providers such as Google, Facebook, LinkedIn, Twitter, GitHub, and any OpenID Connect (OIDC) or OAuth 2.0 clients. Open Liberty Operator allows to easily configure and manage the single sign-on information for your applications.\n\n#### Exposing metrics to Prometheus\nExpose the Open Liberty application's metrics via the Prometheus Operator.\nYou can pick between a basic mode, where you simply specify the label that Prometheus is watching to scrape the metrics from the container, or you can specify the full `ServiceMonitor` spec embedded into the OpenLibertyApplication's `spec.monitoring` field to control configurations such as poll interval and security credentials.\n\n#### Easily mount logs and transaction directories\nDo you need to mount the logs and transaction data from your application to an external volume such as NFS (or any storage supported in your cluster)? Simply add the following configuration (to specify the volume size and the location to persist) to your OpenLibertyApplication CR:\n``` storage: size: 2Gi mountPath: \"/logs\" ```\n\n#### Integration with OpenShift Serverless\nDeploy your serverless runtime component using a single toggle.  The Operator will convert all of its generated resources into [Knative](https://knative.dev) resources, allowing your pod to automatically scale to 0 when it is idle.\n\n#### Integration with OpenShift's Topology UI\nWe set the corresponding labels to support OpenShift's Developer Topology UI, which allows you to visualize your entire set of deployments and how they are connected.\n\nSee our [**documentation**](https://github.com/OpenLiberty/open-liberty-operator/tree/main/doc/) for more information.\n",
      "csv_display_name": "Open Liberty",
      "csv_metadata_description": "Deploy and manage applications running on Liberty",
      "csv_name": "open-liberty-operator.v0.8.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T01:06:49.553000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "open-liberty-certified",
      "provided_apis": [
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyApplication",
          "plural": "openlibertyapplications",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyDump",
          "plural": "openlibertydumps",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyTrace",
          "plural": "openlibertytraces",
          "version": "v1beta2"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "name": "open-liberty-operator-controller-18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db-annotation"
        },
        {
          "digest": "sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "name": "manager"
        },
        {
          "digest": "sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "image": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "name": "open-liberty-samples-8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "<0.8.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "0.8.1",
      "version_original": "0.8.1"
    },
    {
      "_id": "624249ae37f345462469f876",
      "alm_examples": [
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseCluster",
          "metadata": {
            "name": "cb-example"
          },
          "spec": {
            "backup": {
              "image": "registry.connect.redhat.com/couchbase/operator-backup@sha256:c0ab51854294d117c4ecf867b541ed6dc67410294d72f560cc33b038d98e4b76",
              "managed": false,
              "selector": {
                "matchLabels": {
                  "cluster": "cb-example"
                }
              },
              "serviceAccountName": "couchbase-backup"
            },
            "buckets": {
              "managed": true,
              "selector": {
                "matchLabels": {
                  "cluster": "cb-example"
                }
              }
            },
            "cluster": {
              "analyticsServiceMemoryQuota": "1Gi",
              "autoCompaction": {
                "databaseFragmentationThreshold": {
                  "percent": 30,
                  "size": "1Gi"
                },
                "parallelCompaction": false,
                "timeWindow": {
                  "abortCompactionOutsideWindow": true,
                  "end": "06:00",
                  "start": "02:00"
                },
                "tombstonePurgeInterval": "72h",
                "viewFragmentationThreshold": {
                  "percent": 30,
                  "size": "1Gi"
                }
              },
              "autoFailoverMaxCount": 3,
              "autoFailoverOnDataDiskIssues": true,
              "autoFailoverOnDataDiskIssuesTimePeriod": "120s",
              "autoFailoverServerGroup": false,
              "autoFailoverTimeout": "120s",
              "clusterName": "cb-example",
              "dataServiceMemoryQuota": "256Mi",
              "eventingServiceMemoryQuota": "256Mi",
              "indexServiceMemoryQuota": "256Mi",
              "indexStorageSetting": "memory_optimized",
              "searchServiceMemoryQuota": "256Mi"
            },
            "enablePreviewScaling": false,
            "hibernate": false,
            "hibernationStrategy": "Immediate",
            "image": "registry.connect.redhat.com/couchbase/server@sha256:187046a848f32233e7e92705c57fa864b1d373c2078a92b51c9706bec6e372e5",
            "logRetentionCount": 20,
            "logRetentionTime": "604800s",
            "monitoring": {
              "prometheus": {
                "enabled": false,
                "image": "registry.connect.redhat.com/couchbase/exporter@sha256:b9ff3aec88f42f8e6164d61a1c5f845b4c3dd3f606ac552170d5c61311ce5784"
              }
            },
            "networking": {
              "adminConsoleServiceType": "NodePort",
              "adminConsoleServices": [
                "data"
              ],
              "exposeAdminConsole": true,
              "exposedFeatureServiceType": "NodePort",
              "exposedFeatures": [
                "xdcr"
              ]
            },
            "recoveryPolicy": "PrioritizeDataIntegrity",
            "security": {
              "adminSecret": "cb-example-auth",
              "rbac": {
                "managed": true,
                "selector": {
                  "matchLabels": {
                    "cluster": "cb-example"
                  }
                }
              }
            },
            "servers": [
              {
                "name": "all_services",
                "services": [
                  "data",
                  "index",
                  "query",
                  "search",
                  "eventing",
                  "analytics"
                ],
                "size": 3
              }
            ],
            "upgradeStrategy": "RollingUpgrade",
            "xdcr": {
              "managed": false,
              "selector": {
                "matchLabels": {
                  "cluster": "cb-example"
                }
              }
            }
          }
        },
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseBucket",
          "metadata": {
            "labels": {
              "cluster": "cb-example"
            },
            "name": "default"
          },
          "spec": {
            "compressionMode": "passive",
            "conflictResolution": "lww",
            "enableFlush": false,
            "enableIndexReplica": true,
            "evictionPolicy": "valueOnly",
            "ioPriority": "low",
            "memoryQuota": "100Mi",
            "replicas": 2
          }
        },
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseEphemeralBucket",
          "metadata": {
            "labels": {
              "cluster": "cb-example"
            },
            "name": "ephemeral-bucket"
          },
          "spec": {
            "compressionMode": "passive",
            "conflictResolution": "lww",
            "enableFlush": false,
            "evictionPolicy": "noEviction",
            "ioPriority": "low",
            "memoryQuota": "100Mi",
            "replicas": 2
          }
        },
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseMemcachedBucket",
          "metadata": {
            "labels": {
              "cluster": "cb-example"
            },
            "name": "memcached-bucket"
          },
          "spec": {
            "enableFlush": false,
            "memoryQuota": "100Mi"
          }
        },
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseUser",
          "metadata": {
            "labels": {
              "cluster": "cb-example"
            },
            "name": "my-user"
          },
          "spec": {
            "authDomain": "local",
            "authSecret": "cb-example-auth",
            "fullName": "My User"
          }
        },
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseGroup",
          "metadata": {
            "labels": {
              "cluster": "cb-example"
            },
            "name": "my-group"
          },
          "spec": {
            "roles": [
              {
                "bucket": "default",
                "name": "bucket_admin"
              }
            ]
          }
        },
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseRoleBinding",
          "metadata": {
            "name": "my-role-binding"
          },
          "spec": {
            "roleRef": {
              "kind": "CouchbaseGroup",
              "name": "my-group"
            },
            "subjects": [
              {
                "kind": "CouchbaseUser",
                "name": "my-user"
              }
            ]
          }
        },
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseReplication",
          "metadata": {
            "labels": {
              "cluster": "cb-example"
            },
            "name": "my-replication"
          },
          "spec": {
            "bucket": "default",
            "compressionType": "Snappy",
            "filterExpression": "",
            "paused": false,
            "remoteBucket": "default"
          }
        },
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseBackup",
          "metadata": {
            "labels": {
              "cluster": "cb-example"
            },
            "name": "cb-backup"
          },
          "spec": {
            "backOffLimit": 2,
            "backupRetention": "24h",
            "failedJobsHistoryLimit": 3,
            "full": {
              "schedule": "0 3 * * 6"
            },
            "incremental": {
              "schedule": "0 3 * * 1-6"
            },
            "logRetention": "24h",
            "size": "5Gi",
            "strategy": "full_incremental",
            "successfulJobsHistoryLimit": 1
          }
        },
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseBackupRestore",
          "metadata": {
            "labels": {
              "cluster": "cb-example"
            },
            "name": "cb-restore"
          },
          "spec": {
            "backOffLimit": 2,
            "backup": "cb-backup",
            "end": {
              "int": 1
            },
            "logRetention": "24h",
            "repo": "cb-example-2020-10-29T19_00_03",
            "start": {
              "int": 1
            }
          }
        },
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseAutoscaler",
          "metadata": {
            "name": "do.not.create.internal.only"
          },
          "spec": {
            "servers": "internal",
            "size": 2
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/couchbase/operator-bundle@sha256:52e1e4883957b89af73807fc4e34cbda84997d42fb76f598bb40eaf77bba572b",
      "bundle_path_digest": "sha256:52e1e4883957b89af73807fc4e34cbda84997d42fb76f598bb40eaf77bba572b",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-28T23:50:06.431000+00:00",
      "csv_description": "The Couchbase Autonomous Operator allows users to easily deploy, manage, and maintain Couchbase deployments on OpenShift. By installing this integration you will be able to deply Couchbase Server clusters with a single command.\n\n## Supported Features\n\n* **Automated cluster provisioning** - Deploying a Couchbase Cluster has never been easier. Fill out a Couchbase specific configuration and let the Couchbase Operator take care of provisioning nodes and setting up cluster to your exact specification.\n\n* **On-demand scalability** - Automatically scale your cluster up or down by changing a simple configuration parameter and let the Couchbase Operator handle provisioning of new nodes and joining them into the cluster.\n\n* **Auto-recovery** - Detect Couchbase node failures, rebalance out bad nodes, and bring the cluster back up to the desired capacity. Auto-recovery is completely automated so you can sleep easy through the night knowing that the Couchbase Operator will handle any failures.\n\n* **Geo-distribution** - Replicate your data between datacenters to move data closer to the users who consume it and protect against disaster scenarios where an entire datacenter becomes unavailable.\n\n* **Persistent storage** - Define persistent network-attached storage for each node in your cluster to allow pods to be recovered even if the node they were running on is no longer available.\n\n* **Rack/zone awareness** - Tell the Couchbase Operator about availability zones in your datacenter and let the operator take care of ensuring that nodes in your cluster are deployed equally across each zone.\n\n* **Supportability** - When things go wrong, use the cbopinfo tool provided with the Couchbase Operator to collect relevant data about your Couchbase deployment so that you can quickly address issues.\n\n* **Centralized configuration management** - Manage your configuration centrally with OpenShift. Updates to the configuration are watched by the Couchbase Operator and actions are taken to make the target cluster match the desired configuration.\n## Required Parameters\n* `authSecret` - provide the name of a secret that contains two keys for the `username` and `password` of the super user ([documentation](https://docs.couchbase.com/operator/1.2/couchbase-cluster-config.html))\n\n## About Couchbase Server\n\nBuilt on the most powerful NoSQL technology, Couchbase Server delivers unparalleled performance at scale, in any cloud. With features like memory-first architecture, geo-distributed deployments, and workload isolation, Couchbase Server excels at supporting mission-critical applications at scale while maintaining submillisecond latencies and 99.999% availability. Plus, with the most comprehensive SQL-compatible query language (N1QL), migrating from RDBMS to Couchbase Server is easy with ANSI joins.\n",
      "csv_display_name": "Couchbase Operator",
      "csv_metadata_description": "The Couchbase Autonomous Operator allows users to easily deploy, manage, and maintain Couchbase deployments",
      "csv_name": "couchbase-operator.v2.2.2-1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T00:48:15.974000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "couchbase-enterprise-certified",
      "provided_apis": [
        {
          "group": "couchbase.com",
          "kind": "CouchbaseReplication",
          "plural": "couchbasereplications",
          "version": "v2"
        },
        {
          "group": "couchbase.com",
          "kind": "CouchbaseRoleBinding",
          "plural": "couchbaserolebindings",
          "version": "v2"
        },
        {
          "group": "couchbase.com",
          "kind": "CouchbaseUser",
          "plural": "couchbaseusers",
          "version": "v2"
        },
        {
          "group": "couchbase.com",
          "kind": "CouchbaseBucket",
          "plural": "couchbasebuckets",
          "version": "v2"
        },
        {
          "group": "couchbase.com",
          "kind": "CouchbaseAutoscaler",
          "plural": "couchbaseautoscalers",
          "version": "v2"
        },
        {
          "group": "couchbase.com",
          "kind": "CouchbaseBackupRestore",
          "plural": "couchbasebackuprestores",
          "version": "v2"
        },
        {
          "group": "couchbase.com",
          "kind": "CouchbaseMemcachedBucket",
          "plural": "couchbasememcachedbuckets",
          "version": "v2"
        },
        {
          "group": "couchbase.com",
          "kind": "CouchbaseEphemeralBucket",
          "plural": "couchbaseephemeralbuckets",
          "version": "v2"
        },
        {
          "group": "couchbase.com",
          "kind": "CouchbaseGroup",
          "plural": "couchbasegroups",
          "version": "v2"
        },
        {
          "group": "couchbase.com",
          "kind": "CouchbaseBackup",
          "plural": "couchbasebackups",
          "version": "v2"
        },
        {
          "group": "couchbase.com",
          "kind": "CouchbaseCluster",
          "plural": "couchbaseclusters",
          "version": "v2"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:0d6dd6456959b1b9e58c088a94818dfe0917782d1dcb19410d40c95615ae74be",
          "image": "registry.connect.redhat.com/couchbase/operator@sha256:0d6dd6456959b1b9e58c088a94818dfe0917782d1dcb19410d40c95615ae74be",
          "name": "couchbase-operator"
        },
        {
          "digest": "sha256:187046a848f32233e7e92705c57fa864b1d373c2078a92b51c9706bec6e372e5",
          "image": "registry.connect.redhat.com/couchbase/server@sha256:187046a848f32233e7e92705c57fa864b1d373c2078a92b51c9706bec6e372e5",
          "name": "couchbase-server"
        },
        {
          "digest": "sha256:c0ab51854294d117c4ecf867b541ed6dc67410294d72f560cc33b038d98e4b76",
          "image": "registry.connect.redhat.com/couchbase/operator-backup@sha256:c0ab51854294d117c4ecf867b541ed6dc67410294d72f560cc33b038d98e4b76",
          "name": "couchbase-backup"
        },
        {
          "digest": "sha256:b9ff3aec88f42f8e6164d61a1c5f845b4c3dd3f606ac552170d5c61311ce5784",
          "image": "registry.connect.redhat.com/couchbase/exporter@sha256:b9ff3aec88f42f8e6164d61a1c5f845b4c3dd3f606ac552170d5c61311ce5784",
          "name": "couchbase-metrics"
        },
        {
          "digest": "sha256:187046a848f32233e7e92705c57fa864b1d373c2078a92b51c9706bec6e372e5",
          "image": "registry.connect.redhat.com/couchbase/server@sha256:187046a848f32233e7e92705c57fa864b1d373c2078a92b51c9706bec6e372e5",
          "name": "couchbase_server"
        },
        {
          "digest": "sha256:c0ab51854294d117c4ecf867b541ed6dc67410294d72f560cc33b038d98e4b76",
          "image": "registry.connect.redhat.com/couchbase/operator-backup@sha256:c0ab51854294d117c4ecf867b541ed6dc67410294d72f560cc33b038d98e4b76",
          "name": "couchbase_backup"
        },
        {
          "digest": "sha256:b9ff3aec88f42f8e6164d61a1c5f845b4c3dd3f606ac552170d5c61311ce5784",
          "image": "registry.connect.redhat.com/couchbase/exporter@sha256:b9ff3aec88f42f8e6164d61a1c5f845b4c3dd3f606ac552170d5c61311ce5784",
          "name": "couchbase_metrics"
        },
        {
          "digest": "sha256:b9ff3aec88f42f8e6164d61a1c5f845b4c3dd3f606ac552170d5c61311ce5784",
          "image": "registry.connect.redhat.com/couchbase/exporter@sha256:b9ff3aec88f42f8e6164d61a1c5f845b4c3dd3f606ac552170d5c61311ce5784",
          "name": "exporter-b9ff3aec88f42f8e6164d61a1c5f845b4c3dd3f606ac552170d5c61311ce5784-annotation"
        },
        {
          "digest": "sha256:c0ab51854294d117c4ecf867b541ed6dc67410294d72f560cc33b038d98e4b76",
          "image": "registry.connect.redhat.com/couchbase/operator-backup@sha256:c0ab51854294d117c4ecf867b541ed6dc67410294d72f560cc33b038d98e4b76",
          "name": "operator-backup-c0ab51854294d117c4ecf867b541ed6dc67410294d72f560cc33b038d98e4b76-annotation"
        },
        {
          "digest": "sha256:187046a848f32233e7e92705c57fa864b1d373c2078a92b51c9706bec6e372e5",
          "image": "registry.connect.redhat.com/couchbase/server@sha256:187046a848f32233e7e92705c57fa864b1d373c2078a92b51c9706bec6e372e5",
          "name": "server-187046a848f32233e7e92705c57fa864b1d373c2078a92b51c9706bec6e372e5-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2.2.2-1",
      "version_original": "2.2.2-1"
    },
    {
      "_id": "62424b7c8dcbcc3f5ae16571",
      "alm_examples": [
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseCluster",
          "metadata": {
            "name": "cb-example"
          },
          "spec": {
            "backup": {
              "image": "registry.connect.redhat.com/couchbase/operator-backup@sha256:c0ab51854294d117c4ecf867b541ed6dc67410294d72f560cc33b038d98e4b76",
              "managed": false,
              "selector": {
                "matchLabels": {
                  "cluster": "cb-example"
                }
              },
              "serviceAccountName": "couchbase-backup"
            },
            "buckets": {
              "managed": true,
              "selector": {
                "matchLabels": {
                  "cluster": "cb-example"
                }
              }
            },
            "cluster": {
              "analyticsServiceMemoryQuota": "1Gi",
              "autoCompaction": {
                "databaseFragmentationThreshold": {
                  "percent": 30,
                  "size": "1Gi"
                },
                "parallelCompaction": false,
                "timeWindow": {
                  "abortCompactionOutsideWindow": true,
                  "end": "06:00",
                  "start": "02:00"
                },
                "tombstonePurgeInterval": "72h",
                "viewFragmentationThreshold": {
                  "percent": 30,
                  "size": "1Gi"
                }
              },
              "autoFailoverMaxCount": 3,
              "autoFailoverOnDataDiskIssues": true,
              "autoFailoverOnDataDiskIssuesTimePeriod": "120s",
              "autoFailoverServerGroup": false,
              "autoFailoverTimeout": "120s",
              "clusterName": "cb-example",
              "dataServiceMemoryQuota": "256Mi",
              "eventingServiceMemoryQuota": "256Mi",
              "indexServiceMemoryQuota": "256Mi",
              "indexStorageSetting": "memory_optimized",
              "searchServiceMemoryQuota": "256Mi"
            },
            "enablePreviewScaling": false,
            "hibernate": false,
            "hibernationStrategy": "Immediate",
            "image": "registry.connect.redhat.com/couchbase/server@sha256:187046a848f32233e7e92705c57fa864b1d373c2078a92b51c9706bec6e372e5",
            "logRetentionCount": 20,
            "logRetentionTime": "604800s",
            "monitoring": {
              "prometheus": {
                "enabled": false,
                "image": "registry.connect.redhat.com/couchbase/exporter@sha256:b9ff3aec88f42f8e6164d61a1c5f845b4c3dd3f606ac552170d5c61311ce5784"
              }
            },
            "networking": {
              "adminConsoleServiceType": "NodePort",
              "adminConsoleServices": [
                "data"
              ],
              "exposeAdminConsole": true,
              "exposedFeatureServiceType": "NodePort",
              "exposedFeatures": [
                "xdcr"
              ]
            },
            "recoveryPolicy": "PrioritizeDataIntegrity",
            "security": {
              "adminSecret": "cb-example-auth",
              "rbac": {
                "managed": true,
                "selector": {
                  "matchLabels": {
                    "cluster": "cb-example"
                  }
                }
              }
            },
            "servers": [
              {
                "name": "all_services",
                "services": [
                  "data",
                  "index",
                  "query",
                  "search",
                  "eventing",
                  "analytics"
                ],
                "size": 3
              }
            ],
            "upgradeStrategy": "RollingUpgrade",
            "xdcr": {
              "managed": false,
              "selector": {
                "matchLabels": {
                  "cluster": "cb-example"
                }
              }
            }
          }
        },
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseBucket",
          "metadata": {
            "labels": {
              "cluster": "cb-example"
            },
            "name": "default"
          },
          "spec": {
            "compressionMode": "passive",
            "conflictResolution": "lww",
            "enableFlush": false,
            "enableIndexReplica": true,
            "evictionPolicy": "valueOnly",
            "ioPriority": "low",
            "memoryQuota": "100Mi",
            "replicas": 2
          }
        },
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseEphemeralBucket",
          "metadata": {
            "labels": {
              "cluster": "cb-example"
            },
            "name": "ephemeral-bucket"
          },
          "spec": {
            "compressionMode": "passive",
            "conflictResolution": "lww",
            "enableFlush": false,
            "evictionPolicy": "noEviction",
            "ioPriority": "low",
            "memoryQuota": "100Mi",
            "replicas": 2
          }
        },
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseMemcachedBucket",
          "metadata": {
            "labels": {
              "cluster": "cb-example"
            },
            "name": "memcached-bucket"
          },
          "spec": {
            "enableFlush": false,
            "memoryQuota": "100Mi"
          }
        },
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseUser",
          "metadata": {
            "labels": {
              "cluster": "cb-example"
            },
            "name": "my-user"
          },
          "spec": {
            "authDomain": "local",
            "authSecret": "cb-example-auth",
            "fullName": "My User"
          }
        },
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseGroup",
          "metadata": {
            "labels": {
              "cluster": "cb-example"
            },
            "name": "my-group"
          },
          "spec": {
            "roles": [
              {
                "bucket": "default",
                "name": "bucket_admin"
              }
            ]
          }
        },
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseRoleBinding",
          "metadata": {
            "name": "my-role-binding"
          },
          "spec": {
            "roleRef": {
              "kind": "CouchbaseGroup",
              "name": "my-group"
            },
            "subjects": [
              {
                "kind": "CouchbaseUser",
                "name": "my-user"
              }
            ]
          }
        },
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseReplication",
          "metadata": {
            "labels": {
              "cluster": "cb-example"
            },
            "name": "my-replication"
          },
          "spec": {
            "bucket": "default",
            "compressionType": "Snappy",
            "filterExpression": "",
            "paused": false,
            "remoteBucket": "default"
          }
        },
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseBackup",
          "metadata": {
            "labels": {
              "cluster": "cb-example"
            },
            "name": "cb-backup"
          },
          "spec": {
            "backOffLimit": 2,
            "backupRetention": "24h",
            "failedJobsHistoryLimit": 3,
            "full": {
              "schedule": "0 3 * * 6"
            },
            "incremental": {
              "schedule": "0 3 * * 1-6"
            },
            "logRetention": "24h",
            "size": "5Gi",
            "strategy": "full_incremental",
            "successfulJobsHistoryLimit": 1
          }
        },
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseBackupRestore",
          "metadata": {
            "labels": {
              "cluster": "cb-example"
            },
            "name": "cb-restore"
          },
          "spec": {
            "backOffLimit": 2,
            "backup": "cb-backup",
            "end": {
              "int": 1
            },
            "logRetention": "24h",
            "repo": "cb-example-2020-10-29T19_00_03",
            "start": {
              "int": 1
            }
          }
        },
        {
          "api_version": "couchbase.com/v2",
          "kind": "CouchbaseAutoscaler",
          "metadata": {
            "name": "do.not.create.internal.only"
          },
          "spec": {
            "servers": "internal",
            "size": 2
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/couchbase/operator-bundle@sha256:52e1e4883957b89af73807fc4e34cbda84997d42fb76f598bb40eaf77bba572b",
      "bundle_path_digest": "sha256:52e1e4883957b89af73807fc4e34cbda84997d42fb76f598bb40eaf77bba572b",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-03-28T23:57:48.178000+00:00",
      "csv_description": "The Couchbase Autonomous Operator allows users to easily deploy, manage, and maintain Couchbase deployments on OpenShift. By installing this integration you will be able to deply Couchbase Server clusters with a single command.\n\n## Supported Features\n\n* **Automated cluster provisioning** - Deploying a Couchbase Cluster has never been easier. Fill out a Couchbase specific configuration and let the Couchbase Operator take care of provisioning nodes and setting up cluster to your exact specification.\n\n* **On-demand scalability** - Automatically scale your cluster up or down by changing a simple configuration parameter and let the Couchbase Operator handle provisioning of new nodes and joining them into the cluster.\n\n* **Auto-recovery** - Detect Couchbase node failures, rebalance out bad nodes, and bring the cluster back up to the desired capacity. Auto-recovery is completely automated so you can sleep easy through the night knowing that the Couchbase Operator will handle any failures.\n\n* **Geo-distribution** - Replicate your data between datacenters to move data closer to the users who consume it and protect against disaster scenarios where an entire datacenter becomes unavailable.\n\n* **Persistent storage** - Define persistent network-attached storage for each node in your cluster to allow pods to be recovered even if the node they were running on is no longer available.\n\n* **Rack/zone awareness** - Tell the Couchbase Operator about availability zones in your datacenter and let the operator take care of ensuring that nodes in your cluster are deployed equally across each zone.\n\n* **Supportability** - When things go wrong, use the cbopinfo tool provided with the Couchbase Operator to collect relevant data about your Couchbase deployment so that you can quickly address issues.\n\n* **Centralized configuration management** - Manage your configuration centrally with OpenShift. Updates to the configuration are watched by the Couchbase Operator and actions are taken to make the target cluster match the desired configuration.\n## Required Parameters\n* `authSecret` - provide the name of a secret that contains two keys for the `username` and `password` of the super user ([documentation](https://docs.couchbase.com/operator/1.2/couchbase-cluster-config.html))\n\n## About Couchbase Server\n\nBuilt on the most powerful NoSQL technology, Couchbase Server delivers unparalleled performance at scale, in any cloud. With features like memory-first architecture, geo-distributed deployments, and workload isolation, Couchbase Server excels at supporting mission-critical applications at scale while maintaining submillisecond latencies and 99.999% availability. Plus, with the most comprehensive SQL-compatible query language (N1QL), migrating from RDBMS to Couchbase Server is easy with ANSI joins.\n",
      "csv_display_name": "Couchbase Operator",
      "csv_metadata_description": "The Couchbase Autonomous Operator allows users to easily deploy, manage, and maintain Couchbase deployments",
      "csv_name": "couchbase-operator.v2.2.2-1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T02:15:03.991000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "couchbase-enterprise-certified",
      "provided_apis": [
        {
          "group": "couchbase.com",
          "kind": "CouchbaseAutoscaler",
          "plural": "couchbaseautoscalers",
          "version": "v2"
        },
        {
          "group": "couchbase.com",
          "kind": "CouchbaseCluster",
          "plural": "couchbaseclusters",
          "version": "v2"
        },
        {
          "group": "couchbase.com",
          "kind": "CouchbaseEphemeralBucket",
          "plural": "couchbaseephemeralbuckets",
          "version": "v2"
        },
        {
          "group": "couchbase.com",
          "kind": "CouchbaseRoleBinding",
          "plural": "couchbaserolebindings",
          "version": "v2"
        },
        {
          "group": "couchbase.com",
          "kind": "CouchbaseBackup",
          "plural": "couchbasebackups",
          "version": "v2"
        },
        {
          "group": "couchbase.com",
          "kind": "CouchbaseGroup",
          "plural": "couchbasegroups",
          "version": "v2"
        },
        {
          "group": "couchbase.com",
          "kind": "CouchbaseMemcachedBucket",
          "plural": "couchbasememcachedbuckets",
          "version": "v2"
        },
        {
          "group": "couchbase.com",
          "kind": "CouchbaseBackupRestore",
          "plural": "couchbasebackuprestores",
          "version": "v2"
        },
        {
          "group": "couchbase.com",
          "kind": "CouchbaseReplication",
          "plural": "couchbasereplications",
          "version": "v2"
        },
        {
          "group": "couchbase.com",
          "kind": "CouchbaseBucket",
          "plural": "couchbasebuckets",
          "version": "v2"
        },
        {
          "group": "couchbase.com",
          "kind": "CouchbaseUser",
          "plural": "couchbaseusers",
          "version": "v2"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:0d6dd6456959b1b9e58c088a94818dfe0917782d1dcb19410d40c95615ae74be",
          "image": "registry.connect.redhat.com/couchbase/operator@sha256:0d6dd6456959b1b9e58c088a94818dfe0917782d1dcb19410d40c95615ae74be",
          "name": "couchbase-operator"
        },
        {
          "digest": "sha256:187046a848f32233e7e92705c57fa864b1d373c2078a92b51c9706bec6e372e5",
          "image": "registry.connect.redhat.com/couchbase/server@sha256:187046a848f32233e7e92705c57fa864b1d373c2078a92b51c9706bec6e372e5",
          "name": "couchbase-server"
        },
        {
          "digest": "sha256:c0ab51854294d117c4ecf867b541ed6dc67410294d72f560cc33b038d98e4b76",
          "image": "registry.connect.redhat.com/couchbase/operator-backup@sha256:c0ab51854294d117c4ecf867b541ed6dc67410294d72f560cc33b038d98e4b76",
          "name": "couchbase-backup"
        },
        {
          "digest": "sha256:b9ff3aec88f42f8e6164d61a1c5f845b4c3dd3f606ac552170d5c61311ce5784",
          "image": "registry.connect.redhat.com/couchbase/exporter@sha256:b9ff3aec88f42f8e6164d61a1c5f845b4c3dd3f606ac552170d5c61311ce5784",
          "name": "couchbase-metrics"
        },
        {
          "digest": "sha256:187046a848f32233e7e92705c57fa864b1d373c2078a92b51c9706bec6e372e5",
          "image": "registry.connect.redhat.com/couchbase/server@sha256:187046a848f32233e7e92705c57fa864b1d373c2078a92b51c9706bec6e372e5",
          "name": "couchbase_server"
        },
        {
          "digest": "sha256:c0ab51854294d117c4ecf867b541ed6dc67410294d72f560cc33b038d98e4b76",
          "image": "registry.connect.redhat.com/couchbase/operator-backup@sha256:c0ab51854294d117c4ecf867b541ed6dc67410294d72f560cc33b038d98e4b76",
          "name": "couchbase_backup"
        },
        {
          "digest": "sha256:b9ff3aec88f42f8e6164d61a1c5f845b4c3dd3f606ac552170d5c61311ce5784",
          "image": "registry.connect.redhat.com/couchbase/exporter@sha256:b9ff3aec88f42f8e6164d61a1c5f845b4c3dd3f606ac552170d5c61311ce5784",
          "name": "couchbase_metrics"
        },
        {
          "digest": "sha256:b9ff3aec88f42f8e6164d61a1c5f845b4c3dd3f606ac552170d5c61311ce5784",
          "image": "registry.connect.redhat.com/couchbase/exporter@sha256:b9ff3aec88f42f8e6164d61a1c5f845b4c3dd3f606ac552170d5c61311ce5784",
          "name": "exporter-b9ff3aec88f42f8e6164d61a1c5f845b4c3dd3f606ac552170d5c61311ce5784-annotation"
        },
        {
          "digest": "sha256:c0ab51854294d117c4ecf867b541ed6dc67410294d72f560cc33b038d98e4b76",
          "image": "registry.connect.redhat.com/couchbase/operator-backup@sha256:c0ab51854294d117c4ecf867b541ed6dc67410294d72f560cc33b038d98e4b76",
          "name": "operator-backup-c0ab51854294d117c4ecf867b541ed6dc67410294d72f560cc33b038d98e4b76-annotation"
        },
        {
          "digest": "sha256:187046a848f32233e7e92705c57fa864b1d373c2078a92b51c9706bec6e372e5",
          "image": "registry.connect.redhat.com/couchbase/server@sha256:187046a848f32233e7e92705c57fa864b1d373c2078a92b51c9706bec6e372e5",
          "name": "server-187046a848f32233e7e92705c57fa864b1d373c2078a92b51c9706bec6e372e5-annotation"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2.2.2-1",
      "version_original": "2.2.2-1"
    },
    {
      "_id": "62475306a44a9962be01bd2f",
      "alm_examples": [
        {
          "api_version": "ibm.com/v1",
          "kind": "IBMApplicationGateway",
          "metadata": {
            "name": "iag-instance"
          },
          "spec": {
            "configuration": [
              {
                "dataKey": "config",
                "name": "test-config",
                "type": "configmap"
              },
              {
                "discoveryEndpoint": "https://isam.mmfa.ibm.com/mga/sps/oauth/oauth20/metadata/test",
                "postData": [
                  {
                    "name": "redirect_uris",
                    "values": [
                      "https://isam.mmfa.ibm.com/pkmsoidc"
                    ]
                  },
                  {
                    "name": "client_name",
                    "value": "OperatorTest"
                  },
                  {
                    "name": "enforce_pkce",
                    "value": "false"
                  },
                  {
                    "name": "all_users_entitled",
                    "value": "true"
                  },
                  {
                    "name": "consent_action",
                    "value": "never_prompt"
                  }
                ],
                "secret": "oidc-client",
                "type": "oidc_registration"
              },
              {
                "headers": [
                  {
                    "name": "Authorization",
                    "secretKey": "value",
                    "type": "secret",
                    "value": "githubsecret"
                  }
                ],
                "type": "web",
                "url": "https://raw.github.com/ibm-security/iag-config/master/test/sample1.yaml"
              },
              {
                "type": "literal",
                "value": "version: \"21.12\"\n\nserver:\n  local_applications:\n    cred_viewer:\n      path_segment: creds\n      enable_html: true\n\nidentity:\n  oidc:\n    discovery_endpoint: \"https://iag-dev.ibmcloudsecurity.com/oidc/endpoint/default/.well-known/openid-configuration\"\n    client_id: 1cbfe647-9e5f-4d99-8e05-8ed1c862eb47\n    client_secret: uPP8rM7N0e\n"
              }
            ],
            "deployment": {
              "image": "ibmcom/ibm-application-gateway@sha256:410fc5d3bc187c01e5ea699ce5023a24a9eb8309902fe513900286ecce5af99f",
              "imagePullPolicy": "Always",
              "imagePullSecrets": [
                {
                  "name": "regcred"
                }
              ],
              "lang": "C",
              "livenessProbe": {
                "failureThreshold": 6,
                "initialDelaySeconds": 8,
                "periodSeconds": 9,
                "successThreshold": 7,
                "timeoutSeconds": 1
              },
              "readinessProbe": {
                "failureThreshold": 2,
                "initialDelaySeconds": 7,
                "periodSeconds": 8,
                "successThreshold": 4,
                "timeoutSeconds": 5
              },
              "serviceAccountName": "iag"
            },
            "replicas": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/ibm-application-gateway-operator-bundle@sha256:7737a7c6d8eaf495367265c6b482f5ac9f5cc2dfe6320e1a0ed2f9eed15ce03a",
      "bundle_path_digest": "sha256:7737a7c6d8eaf495367265c6b482f5ac9f5cc2dfe6320e1a0ed2f9eed15ce03a",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-04-01T19:31:18.879000+00:00",
      "csv_description": "The [IBM Application Gateway (IAG)](https://ibm.biz/ibm-app-gateway) image provides a containerized secure Web Reverse proxy which is designed to sit in front of your application, seamlessly adding authentication and authorization protection to your application.\n\nAn IAG instance deployed on Kubernetes can be a complex deployment.  In particular the configuration can be defined externally in one or more locations, and changes to this configuration may require all instances to be reloaded for the changes to take effect. \n\nThe internal Kubernetes deployment controller does not have any knowledge of how an IBM Application Gateway instance should behave when the configuration changes. As such this IBM Application Gateway specific Kubernetes operator is available to be deployed. Once deployed the operator can manage the lifecycle of the IBM Application Gateway instances.\n\nSee the project [Readme](https://github.com/IBM-Security/ibm-application-gateway-operator/blob/master/README.md) for further information and details.\n\n",
      "csv_display_name": "IBM Application Gateway Operator",
      "csv_metadata_description": "The IBM Application Gateway operator manages the lifecycle of IBM Application Gateway containers.",
      "csv_name": "ibm-application-gateway-operator.v22.3.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-06-17T00:51:36.495000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "ibm-application-gateway-operator",
      "provided_apis": [
        {
          "group": "ibm.com",
          "kind": "IBMApplicationGateway",
          "version": "v1"
        }
      ],
      "provider": null,
      "related_images": [
        {
          "digest": "sha256:2c7bf8032867f6e401a8a83c0cab14a61a3a3191ece9c9bf5b16426c97e37ebf",
          "image": "ibmcom/ibm-application-gateway-operator@sha256:2c7bf8032867f6e401a8a83c0cab14a61a3a3191ece9c9bf5b16426c97e37ebf",
          "name": "ibm-application-gateway-operator"
        },
        {
          "digest": "sha256:2c7bf8032867f6e401a8a83c0cab14a61a3a3191ece9c9bf5b16426c97e37ebf",
          "image": "ibmcom/ibm-application-gateway-operator@sha256:2c7bf8032867f6e401a8a83c0cab14a61a3a3191ece9c9bf5b16426c97e37ebf",
          "name": "ibm-application-gateway-operator-2c7bf8032867f6e401a8a83c0cab14a61a3a3191ece9c9bf5b16426c97e37ebf-annotation"
        },
        {
          "digest": "sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:db06cc4c084dd0253134f156dddaaf53ef1c3fb3cc809e5d81711baa4029ea4c",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:2c7bf8032867f6e401a8a83c0cab14a61a3a3191ece9c9bf5b16426c97e37ebf",
          "image": "ibmcom/ibm-application-gateway-operator@sha256:2c7bf8032867f6e401a8a83c0cab14a61a3a3191ece9c9bf5b16426c97e37ebf",
          "name": "manager"
        }
      ],
      "replaces": "",
      "skip_range": "",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "22.3.0",
      "version_original": "22.3.0"
    }
  ],
  "page": 23,
  "page_size": 100,
  "total": 3969
}
