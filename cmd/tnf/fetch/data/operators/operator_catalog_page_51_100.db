{
  "data": [
    {
      "_id": "63284298d1a8ccdba1fb075c",
      "alm_examples": [
        {
          "api_version": "app.joget.com/v1alpha1",
          "kind": "JogetDX",
          "metadata": {
            "name": "example-joget"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/joget/joget-dx-operator-bundle@sha256:3720a367fd6301f7e541bbdb5eaf291641caa834fd6f93cc8b99f2a22f4dd422",
      "bundle_path_digest": "sha256:3720a367fd6301f7e541bbdb5eaf291641caa834fd6f93cc8b99f2a22f4dd422",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:21:12.029000+00:00",
      "csv_description": "Joget DX is the next generation open source no-code / low-code application platform that combines the best of Rapid Application Development, Business Process Automation and Workflow Management. \nJoget DX empowers business users, non-coders or coders with a single platform to easily build, deliver, monitor and maintain enterprise applications.\n\nThis operator installs a Joget DX cluster running on JBoss EAP 7.\n\n### Features\n* Build full-fledged apps e.g. CRM, HR, Healthcare, etc\n* Drag and drop forms, lists, UI\n* Add workflow to automate processes\n* Extend via plugins\n* Apps are mobile optimized and cloud ready\n* Download ready-made apps from the Joget Marketplace\n\n### Before You Start\nDeploy a [MySQL](https://docs.openshift.com/online/pro/using_images/db_images/mysql.html) or [MariaDB](https://docs.openshift.com/online/pro/using_images/db_images/mariadb.html) database.\n\n### Post Deployment\nAccess the service URL and complete the one-time [Database Setup](https://dev.joget.org/community/display/DX7/Setting+Up+Database)\n\n### More Information\nMore information about Joget DX on JBoss EAP 7 is available in the [Joget Knowledge Base](https://dev.joget.org/community/display/DX7/Automated+Deployment+on+Red+Hat+OpenShift+with+the+Joget+Operator)\n",
      "csv_display_name": "Joget DX Operator",
      "csv_metadata_description": "No-code/low-code application platform to visually build, run and maintain apps",
      "csv_name": "joget-dx-openshift-operator.v0.0.31",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:25:45.027000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "joget-dx-operator",
      "provided_apis": [
        {
          "group": "app.joget.com",
          "kind": "JogetDX",
          "version": "v1alpha1"
        }
      ],
      "provider": "Joget, Inc",
      "related_images": [
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "joget-dx-operator-79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749-annotation"
        },
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "operator"
        },
        {
          "digest": "sha256:56dcccccbce154c2b91f4857e78edc3e736234058a03adadeb46823dd3997d63",
          "image": "registry.connect.redhat.com/joget/joget-dx7-eap7@sha256:56dcccccbce154c2b91f4857e78edc3e736234058a03adadeb46823dd3997d63",
          "name": "joget"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "0.0.31",
      "version_original": "0.0.31"
    },
    {
      "_id": "6328429a316b8eb377f076e0",
      "alm_examples": [
        {
          "api_version": "app.joget.com/v1alpha1",
          "kind": "JogetDX",
          "metadata": {
            "name": "example-joget"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/joget/joget-dx-operator-bundle@sha256:b0e763b8e865c832348cc4a883a99af0be4b657f0b44b4419ca4d6066a3c7bed",
      "bundle_path_digest": "sha256:b0e763b8e865c832348cc4a883a99af0be4b657f0b44b4419ca4d6066a3c7bed",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:21:14.684000+00:00",
      "csv_description": "Joget DX is the next generation open source no-code / low-code application platform that combines the best of Rapid Application Development, Business Process Automation and Workflow Management. \nJoget DX empowers business users, non-coders or coders with a single platform to easily build, deliver, monitor and maintain enterprise applications.\n\nThis operator installs a Joget DX cluster running on JBoss EAP 7.\n\n### Features\n* Build full-fledged apps e.g. CRM, HR, Healthcare, etc\n* Drag and drop forms, lists, UI\n* Add workflow to automate processes\n* Extend via plugins\n* Apps are mobile optimized and cloud ready\n* Download ready-made apps from the Joget Marketplace\n\n### Before You Start\nDeploy a [MySQL](https://docs.openshift.com/online/pro/using_images/db_images/mysql.html) or [MariaDB](https://docs.openshift.com/online/pro/using_images/db_images/mariadb.html) database.\n\n### Post Deployment\nAccess the service URL and complete the one-time [Database Setup](https://dev.joget.org/community/display/DX7/Setting+Up+Database)\n\n### More Information\nMore information about Joget DX on JBoss EAP 7 is available in the [Joget Knowledge Base](https://dev.joget.org/community/display/DX7/Automated+Deployment+on+Red+Hat+OpenShift+with+the+Joget+Operator)\n",
      "csv_display_name": "Joget DX Operator",
      "csv_metadata_description": "No-code/low-code application platform to visually build, run and maintain apps",
      "csv_name": "joget-dx-openshift-operator.v0.0.20",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:25:50.199000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "joget-dx-operator",
      "provided_apis": [
        {
          "group": "app.joget.com",
          "kind": "JogetDX",
          "version": "v1alpha1"
        }
      ],
      "provider": "Joget, Inc",
      "related_images": [
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "joget-dx-operator-79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749-annotation"
        },
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "operator"
        },
        {
          "digest": "sha256:dffc105b4cf03f0b4f15c90786505ba5d660bf703bf11e19e80c90d93fece559",
          "image": "registry.connect.redhat.com/joget/joget-dx7-eap7@sha256:dffc105b4cf03f0b4f15c90786505ba5d660bf703bf11e19e80c90d93fece559",
          "name": "joget"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "0.0.20",
      "version_original": "0.0.20"
    },
    {
      "_id": "6328429da9c6e63893ae52f5",
      "alm_examples": [
        {
          "api_version": "app.joget.com/v1alpha1",
          "kind": "JogetDX",
          "metadata": {
            "name": "example-joget"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/joget/joget-dx-operator-bundle@sha256:58e3af46a8b343a8a899cea5c01061f9fb3530713d7786cca289b198d72bacf6",
      "bundle_path_digest": "sha256:58e3af46a8b343a8a899cea5c01061f9fb3530713d7786cca289b198d72bacf6",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:21:17.952000+00:00",
      "csv_description": "Joget DX is the next generation open source no-code / low-code application platform that combines the best of Rapid Application Development, Business Process Automation and Workflow Management. \nJoget DX empowers business users, non-coders or coders with a single platform to easily build, deliver, monitor and maintain enterprise applications.\n\nThis operator installs a Joget DX cluster running on JBoss EAP 7.\n\n### Features\n* Build full-fledged apps e.g. CRM, HR, Healthcare, etc\n* Drag and drop forms, lists, UI\n* Add workflow to automate processes\n* Extend via plugins\n* Apps are mobile optimized and cloud ready\n* Download ready-made apps from the Joget Marketplace\n\n### Before You Start\nDeploy a [MySQL](https://docs.openshift.com/online/pro/using_images/db_images/mysql.html) or [MariaDB](https://docs.openshift.com/online/pro/using_images/db_images/mariadb.html) database.\n\n### Post Deployment\nAccess the service URL and complete the one-time [Database Setup](https://dev.joget.org/community/display/DX7/Setting+Up+Database)\n\n### More Information\nMore information about Joget DX on JBoss EAP 7 is available in the [Joget Knowledge Base](https://dev.joget.org/community/display/DX7/Automated+Deployment+on+Red+Hat+OpenShift+with+the+Joget+Operator)\n",
      "csv_display_name": "Joget DX Operator",
      "csv_metadata_description": "No-code/low-code application platform to visually build, run and maintain apps",
      "csv_name": "joget-dx-openshift-operator.v0.0.21",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:25:18.751000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "joget-dx-operator",
      "provided_apis": [
        {
          "group": "app.joget.com",
          "kind": "JogetDX",
          "version": "v1alpha1"
        }
      ],
      "provider": "Joget, Inc",
      "related_images": [
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "joget-dx-operator-79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749-annotation"
        },
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "operator"
        },
        {
          "digest": "sha256:326789849a178bdea0e57f1b4649a4e92a2590579902e899932c733bc24409d3",
          "image": "registry.connect.redhat.com/joget/joget-dx7-eap7@sha256:326789849a178bdea0e57f1b4649a4e92a2590579902e899932c733bc24409d3",
          "name": "joget"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "0.0.21",
      "version_original": "0.0.21"
    },
    {
      "_id": "632842a11fe6c3c921e6b2ad",
      "alm_examples": [
        {
          "api_version": "app.joget.com/v1alpha1",
          "kind": "JogetDX",
          "metadata": {
            "name": "example-joget"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/joget/joget-dx-operator-bundle@sha256:d778e1d70bee8e4a17cac2ea9b04c82c747fd1d1f3859e846626f581f58f1ae3",
      "bundle_path_digest": "sha256:d778e1d70bee8e4a17cac2ea9b04c82c747fd1d1f3859e846626f581f58f1ae3",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:21:21.092000+00:00",
      "csv_description": "Joget DX is the next generation open source no-code / low-code application platform that combines the best of Rapid Application Development, Business Process Automation and Workflow Management. \nJoget DX empowers business users, non-coders or coders with a single platform to easily build, deliver, monitor and maintain enterprise applications.\n\nThis operator installs a Joget DX cluster running on JBoss EAP 7.\n\n### Features\n* Build full-fledged apps e.g. CRM, HR, Healthcare, etc\n* Drag and drop forms, lists, UI\n* Add workflow to automate processes\n* Extend via plugins\n* Apps are mobile optimized and cloud ready\n* Download ready-made apps from the Joget Marketplace\n\n### Before You Start\nDeploy a [MySQL](https://docs.openshift.com/online/pro/using_images/db_images/mysql.html) or [MariaDB](https://docs.openshift.com/online/pro/using_images/db_images/mariadb.html) database.\n\n### Post Deployment\nAccess the service URL and complete the one-time [Database Setup](https://dev.joget.org/community/display/DX7/Setting+Up+Database)\n\n### More Information\nMore information about Joget DX on JBoss EAP 7 is available in the [Joget Knowledge Base](https://dev.joget.org/community/display/DX7/Automated+Deployment+on+Red+Hat+OpenShift+with+the+Joget+Operator)\n",
      "csv_display_name": "Joget DX Operator",
      "csv_metadata_description": "No-code/low-code application platform to visually build, run and maintain apps",
      "csv_name": "joget-dx-openshift-operator.v0.0.22",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:25:24.806000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "joget-dx-operator",
      "provided_apis": [
        {
          "group": "app.joget.com",
          "kind": "JogetDX",
          "version": "v1alpha1"
        }
      ],
      "provider": "Joget, Inc",
      "related_images": [
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "joget-dx-operator-79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749-annotation"
        },
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "operator"
        },
        {
          "digest": "sha256:f839152251e021fe0ae1d4bd9e5374c2a2fb3c01da4381ba4c01afcbaadbf8bd",
          "image": "registry.connect.redhat.com/joget/joget-dx7-eap7@sha256:f839152251e021fe0ae1d4bd9e5374c2a2fb3c01da4381ba4c01afcbaadbf8bd",
          "name": "joget"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "0.0.22",
      "version_original": "0.0.22"
    },
    {
      "_id": "632842a4316b8eb377f076eb",
      "alm_examples": [
        {
          "api_version": "app.joget.com/v1alpha1",
          "kind": "JogetDX",
          "metadata": {
            "name": "example-joget"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/joget/joget-dx-operator-bundle@sha256:b0429d13d8f0146a431bb9a009b1c1c691ec0afea12c23547f46c73f7e116a38",
      "bundle_path_digest": "sha256:b0429d13d8f0146a431bb9a009b1c1c691ec0afea12c23547f46c73f7e116a38",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:21:24.408000+00:00",
      "csv_description": "Joget DX is the next generation open source no-code / low-code application platform that combines the best of Rapid Application Development, Business Process Automation and Workflow Management. \nJoget DX empowers business users, non-coders or coders with a single platform to easily build, deliver, monitor and maintain enterprise applications.\n\nThis operator installs a Joget DX cluster running on JBoss EAP 7.\n\n### Features\n* Build full-fledged apps e.g. CRM, HR, Healthcare, etc\n* Drag and drop forms, lists, UI\n* Add workflow to automate processes\n* Extend via plugins\n* Apps are mobile optimized and cloud ready\n* Download ready-made apps from the Joget Marketplace\n\n### Before You Start\nDeploy a [MySQL](https://docs.openshift.com/online/pro/using_images/db_images/mysql.html) or [MariaDB](https://docs.openshift.com/online/pro/using_images/db_images/mariadb.html) database.\n\n### Post Deployment\nAccess the service URL and complete the one-time [Database Setup](https://dev.joget.org/community/display/DX7/Setting+Up+Database)\n\n### More Information\nMore information about Joget DX on JBoss EAP 7 is available in the [Joget Knowledge Base](https://dev.joget.org/community/display/DX7/Automated+Deployment+on+Red+Hat+OpenShift+with+the+Joget+Operator)\n",
      "csv_display_name": "Joget DX Operator",
      "csv_metadata_description": "No-code/low-code application platform to visually build, run and maintain apps",
      "csv_name": "joget-dx-openshift-operator.v0.0.23",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:25:29.985000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "joget-dx-operator",
      "provided_apis": [
        {
          "group": "app.joget.com",
          "kind": "JogetDX",
          "version": "v1alpha1"
        }
      ],
      "provider": "Joget, Inc",
      "related_images": [
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "joget-dx-operator-79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749-annotation"
        },
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "operator"
        },
        {
          "digest": "sha256:20361ef412dab120fe6ac4793db463e9e32cdaca348791c97043af874e8326d2",
          "image": "registry.connect.redhat.com/joget/joget-dx7-eap7@sha256:20361ef412dab120fe6ac4793db463e9e32cdaca348791c97043af874e8326d2",
          "name": "joget"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "0.0.23",
      "version_original": "0.0.23"
    },
    {
      "_id": "632842a88454bee1cb723a9d",
      "alm_examples": [
        {
          "api_version": "app.joget.com/v1alpha1",
          "kind": "JogetDX",
          "metadata": {
            "name": "example-joget"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/joget/joget-dx-operator-bundle@sha256:2c1d558f9e8253d1573cbb36f3a5254a6d87041b2bf1ad9a69b23b81e2bc67e2",
      "bundle_path_digest": "sha256:2c1d558f9e8253d1573cbb36f3a5254a6d87041b2bf1ad9a69b23b81e2bc67e2",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:21:28.041000+00:00",
      "csv_description": "Joget DX is the next generation open source no-code / low-code application platform that combines the best of Rapid Application Development, Business Process Automation and Workflow Management. \nJoget DX empowers business users, non-coders or coders with a single platform to easily build, deliver, monitor and maintain enterprise applications.\n\nThis operator installs a Joget DX cluster running on JBoss EAP 7.\n\n### Features\n* Build full-fledged apps e.g. CRM, HR, Healthcare, etc\n* Drag and drop forms, lists, UI\n* Add workflow to automate processes\n* Extend via plugins\n* Apps are mobile optimized and cloud ready\n* Download ready-made apps from the Joget Marketplace\n\n### Before You Start\nDeploy a [MySQL](https://docs.openshift.com/online/pro/using_images/db_images/mysql.html) or [MariaDB](https://docs.openshift.com/online/pro/using_images/db_images/mariadb.html) database.\n\n### Post Deployment\nAccess the service URL and complete the one-time [Database Setup](https://dev.joget.org/community/display/DX7/Setting+Up+Database)\n\n### More Information\nMore information about Joget DX on JBoss EAP 7 is available in the [Joget Knowledge Base](https://dev.joget.org/community/display/DX7/Automated+Deployment+on+Red+Hat+OpenShift+with+the+Joget+Operator)\n",
      "csv_display_name": "Joget DX Operator",
      "csv_metadata_description": "No-code/low-code application platform to visually build, run and maintain apps",
      "csv_name": "joget-dx-openshift-operator.v0.0.32",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:25:39.247000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "joget-dx-operator",
      "provided_apis": [
        {
          "group": "app.joget.com",
          "kind": "JogetDX",
          "version": "v1alpha1"
        }
      ],
      "provider": "Joget, Inc",
      "related_images": [
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "joget-dx-operator-79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749-annotation"
        },
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "operator"
        },
        {
          "digest": "sha256:5956e2fb7bd8f177e5997fb3ef57ae16ce8b793ad2c90b7d2902222bab896e2d",
          "image": "registry.connect.redhat.com/joget/joget-dx7-eap7@sha256:5956e2fb7bd8f177e5997fb3ef57ae16ce8b793ad2c90b7d2902222bab896e2d",
          "name": "joget"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "0.0.32",
      "version_original": "0.0.32"
    },
    {
      "_id": "632842ab2dd1cd9660afba61",
      "alm_examples": [
        {
          "api_version": "app.joget.com/v1alpha1",
          "kind": "JogetDX",
          "metadata": {
            "name": "example-joget"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/joget/joget-dx-operator-bundle@sha256:e95e296f6633c6154f21dfabd0caf27fd0db871fe4ed987b5415f6f9b62ac230",
      "bundle_path_digest": "sha256:e95e296f6633c6154f21dfabd0caf27fd0db871fe4ed987b5415f6f9b62ac230",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:21:31.534000+00:00",
      "csv_description": "Joget DX is the next generation open source no-code / low-code application platform that combines the best of Rapid Application Development, Business Process Automation and Workflow Management. \nJoget DX empowers business users, non-coders or coders with a single platform to easily build, deliver, monitor and maintain enterprise applications.\n\nThis operator installs a Joget DX cluster running on JBoss EAP 7.\n\n### Features\n* Build full-fledged apps e.g. CRM, HR, Healthcare, etc\n* Drag and drop forms, lists, UI\n* Add workflow to automate processes\n* Extend via plugins\n* Apps are mobile optimized and cloud ready\n* Download ready-made apps from the Joget Marketplace\n\n### Before You Start\nDeploy a [MySQL](https://docs.openshift.com/online/pro/using_images/db_images/mysql.html) or [MariaDB](https://docs.openshift.com/online/pro/using_images/db_images/mariadb.html) database.\n\n### Post Deployment\nAccess the service URL and complete the one-time [Database Setup](https://dev.joget.org/community/display/DX7/Setting+Up+Database)\n\n### More Information\nMore information about Joget DX on JBoss EAP 7 is available in the [Joget Knowledge Base](https://dev.joget.org/community/display/DX7/Automated+Deployment+on+Red+Hat+OpenShift+with+the+Joget+Operator)\n",
      "csv_display_name": "Joget DX Operator",
      "csv_metadata_description": "No-code/low-code application platform to visually build, run and maintain apps",
      "csv_name": "joget-dx-openshift-operator.v0.0.26",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:25:03.446000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "joget-dx-operator",
      "provided_apis": [
        {
          "group": "app.joget.com",
          "kind": "JogetDX",
          "version": "v1alpha1"
        }
      ],
      "provider": "Joget, Inc",
      "related_images": [
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "joget-dx-operator-79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749-annotation"
        },
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "operator"
        },
        {
          "digest": "sha256:46a5da986ccec2377cf27b6d7220dade459b534c69030162dbbd544a560a2c5e",
          "image": "registry.connect.redhat.com/joget/joget-dx7-eap7@sha256:46a5da986ccec2377cf27b6d7220dade459b534c69030162dbbd544a560a2c5e",
          "name": "joget"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "0.0.26",
      "version_original": "0.0.26"
    },
    {
      "_id": "632842af703b1887dc1c74cd",
      "alm_examples": [
        {
          "api_version": "app.joget.com/v1alpha1",
          "kind": "JogetDX",
          "metadata": {
            "name": "example-joget"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/joget/joget-dx-operator-bundle@sha256:1a7445f65072dc48009b174bc8bd66de5c2d18d98c235c1fa9b3af2dda6de6ce",
      "bundle_path_digest": "sha256:1a7445f65072dc48009b174bc8bd66de5c2d18d98c235c1fa9b3af2dda6de6ce",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:21:35.058000+00:00",
      "csv_description": "Joget DX is the next generation open source no-code / low-code application platform that combines the best of Rapid Application Development, Business Process Automation and Workflow Management. \nJoget DX empowers business users, non-coders or coders with a single platform to easily build, deliver, monitor and maintain enterprise applications.\n\nThis operator installs a Joget DX cluster running on JBoss EAP 7.\n\n### Features\n* Build full-fledged apps e.g. CRM, HR, Healthcare, etc\n* Drag and drop forms, lists, UI\n* Add workflow to automate processes\n* Extend via plugins\n* Apps are mobile optimized and cloud ready\n* Download ready-made apps from the Joget Marketplace\n\n### Before You Start\nDeploy a [MySQL](https://docs.openshift.com/online/pro/using_images/db_images/mysql.html) or [MariaDB](https://docs.openshift.com/online/pro/using_images/db_images/mariadb.html) database.\n\n### Post Deployment\nAccess the service URL and complete the one-time [Database Setup](https://dev.joget.org/community/display/DX7/Setting+Up+Database)\n\n### More Information\nMore information about Joget DX on JBoss EAP 7 is available in the [Joget Knowledge Base](https://dev.joget.org/community/display/DX7/Automated+Deployment+on+Red+Hat+OpenShift+with+the+Joget+Operator)\n",
      "csv_display_name": "Joget DX Operator",
      "csv_metadata_description": "No-code/low-code application platform to visually build, run and maintain apps",
      "csv_name": "joget-dx-openshift-operator.v0.0.27",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:26:06.698000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "joget-dx-operator",
      "provided_apis": [
        {
          "group": "app.joget.com",
          "kind": "JogetDX",
          "version": "v1alpha1"
        }
      ],
      "provider": "Joget, Inc",
      "related_images": [
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "joget-dx-operator-79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749-annotation"
        },
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "operator"
        },
        {
          "digest": "sha256:73f7a5500e2af1c40506fb43d7150988c665fab8f1d0df8cc75b5d7c0b325007",
          "image": "registry.connect.redhat.com/joget/joget-dx7-eap7@sha256:73f7a5500e2af1c40506fb43d7150988c665fab8f1d0df8cc75b5d7c0b325007",
          "name": "joget"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "0.0.27",
      "version_original": "0.0.27"
    },
    {
      "_id": "632842b1a1826a2016e6feba",
      "alm_examples": [
        {
          "api_version": "app.joget.com/v1alpha1",
          "kind": "JogetDX",
          "metadata": {
            "name": "example-joget"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/joget/joget-dx-operator-bundle@sha256:37008543a382b540053595c4210bed1ee3062128be472eeade9b037528192092",
      "bundle_path_digest": "sha256:37008543a382b540053595c4210bed1ee3062128be472eeade9b037528192092",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:21:37.771000+00:00",
      "csv_description": "Joget DX is the next generation open source no-code / low-code application platform that combines the best of Rapid Application Development, Business Process Automation and Workflow Management. \nJoget DX empowers business users, non-coders or coders with a single platform to easily build, deliver, monitor and maintain enterprise applications.\n\nThis operator installs a Joget DX cluster running on JBoss EAP 7.\n\n### Features\n* Build full-fledged apps e.g. CRM, HR, Healthcare, etc\n* Drag and drop forms, lists, UI\n* Add workflow to automate processes\n* Extend via plugins\n* Apps are mobile optimized and cloud ready\n* Download ready-made apps from the Joget Marketplace\n\n### Before You Start\nDeploy a [MySQL](https://docs.openshift.com/online/pro/using_images/db_images/mysql.html) or [MariaDB](https://docs.openshift.com/online/pro/using_images/db_images/mariadb.html) database.\n\n### Post Deployment\nAccess the service URL and complete the one-time [Database Setup](https://dev.joget.org/community/display/DX7/Setting+Up+Database)\n\n### More Information\nMore information about Joget DX on JBoss EAP 7 is available in the [Joget Knowledge Base](https://dev.joget.org/community/display/DX7/Automated+Deployment+on+Red+Hat+OpenShift+with+the+Joget+Operator)\n",
      "csv_display_name": "Joget DX Operator",
      "csv_metadata_description": "No-code/low-code application platform to visually build, run and maintain apps",
      "csv_name": "joget-dx-openshift-operator.v0.0.29",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:25:08.451000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "joget-dx-operator",
      "provided_apis": [
        {
          "group": "app.joget.com",
          "kind": "JogetDX",
          "version": "v1alpha1"
        }
      ],
      "provider": "Joget, Inc",
      "related_images": [
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "joget-dx-operator-79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749-annotation"
        },
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "operator"
        },
        {
          "digest": "sha256:9db5627766c81e99d6ef6cb40b6532a766b991881d8197ab543a35d5c6e3a87a",
          "image": "registry.connect.redhat.com/joget/joget-dx7-eap7@sha256:9db5627766c81e99d6ef6cb40b6532a766b991881d8197ab543a35d5c6e3a87a",
          "name": "joget"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "0.0.29",
      "version_original": "0.0.29"
    },
    {
      "_id": "632842b4eb69678e80bd1ea5",
      "alm_examples": [
        {
          "api_version": "app.joget.com/v1alpha1",
          "kind": "JogetDX",
          "metadata": {
            "name": "example-joget"
          },
          "spec": {
            "size": 1
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/joget/joget-dx-operator-bundle@sha256:f9c5556854d4c2d1b32b57ebc096b6b525cecd5e801da2cf15a9fed2dfa0d7c3",
      "bundle_path_digest": "sha256:f9c5556854d4c2d1b32b57ebc096b6b525cecd5e801da2cf15a9fed2dfa0d7c3",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:21:40.683000+00:00",
      "csv_description": "Joget DX is the next generation open source no-code / low-code application platform that combines the best of Rapid Application Development, Business Process Automation and Workflow Management. \nJoget DX empowers business users, non-coders or coders with a single platform to easily build, deliver, monitor and maintain enterprise applications.\n\nThis operator installs a Joget DX cluster running on JBoss EAP 7.\n\n### Features\n* Build full-fledged apps e.g. CRM, HR, Healthcare, etc\n* Drag and drop forms, lists, UI\n* Add workflow to automate processes\n* Extend via plugins\n* Apps are mobile optimized and cloud ready\n* Download ready-made apps from the Joget Marketplace\n\n### Before You Start\nDeploy a [MySQL](https://docs.openshift.com/online/pro/using_images/db_images/mysql.html) or [MariaDB](https://docs.openshift.com/online/pro/using_images/db_images/mariadb.html) database.\n\n### Post Deployment\nAccess the service URL and complete the one-time [Database Setup](https://dev.joget.org/community/display/DX7/Setting+Up+Database)\n\n### More Information\nMore information about Joget DX on JBoss EAP 7 is available in the [Joget Knowledge Base](https://dev.joget.org/community/display/DX7/Automated+Deployment+on+Red+Hat+OpenShift+with+the+Joget+Operator)\n",
      "csv_display_name": "Joget DX Operator",
      "csv_metadata_description": "No-code/low-code application platform to visually build, run and maintain apps",
      "csv_name": "joget-dx-openshift-operator.v0.0.25",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:26:01.377000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "joget-dx-operator",
      "provided_apis": [
        {
          "group": "app.joget.com",
          "kind": "JogetDX",
          "version": "v1alpha1"
        }
      ],
      "provider": "Joget, Inc",
      "related_images": [
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "joget-dx-operator-79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749-annotation"
        },
        {
          "digest": "sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "image": "registry.connect.redhat.com/joget/joget-dx-operator@sha256:79856e88008da33fc0323e197819fec39fbd6b6bf2b03a0bf799b517bcf8e749",
          "name": "operator"
        },
        {
          "digest": "sha256:d2c8ad6be94b49b9e679025d60ddafd3c4f2261e08b30785157f9039ca05f289",
          "image": "registry.connect.redhat.com/joget/joget-dx7-eap7@sha256:d2c8ad6be94b49b9e679025d60ddafd3c4f2261e08b30785157f9039ca05f289",
          "name": "joget"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "0.0.25",
      "version_original": "0.0.25"
    },
    {
      "_id": "632842b6a9c6e63893ae5306",
      "alm_examples": [
        {
          "api_version": "operator.smilecdr.com/v1alpha1",
          "kind": "Smilecdr",
          "metadata": {
            "name": "smilecdr"
          },
          "spec": {
            "labels": {
              "application": "smilecdr",
              "client": "smilecdr",
              "env": "dev",
              "version": "one"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/smilecdr/smilecdr@sha256:c44f5661a598aa18c4c10372918a45edb0f26d7d2772c47a55c66e4ff874cb5f",
      "bundle_path_digest": "sha256:c44f5661a598aa18c4c10372918a45edb0f26d7d2772c47a55c66e4ff874cb5f",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:21:42.377000+00:00",
      "csv_description": "Smilecdr Operator description. TODO.",
      "csv_display_name": "Smilecdr Operator",
      "csv_metadata_description": "",
      "csv_name": "smilecdr-operator.v0.0.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:33:40.927000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "smilecdr-operator",
      "provided_apis": [
        {
          "group": "operator.smilecdr.com",
          "kind": "Smilecdr",
          "version": "v1alpha1"
        }
      ],
      "provider": "Provider Name",
      "related_images": [
        {
          "digest": "sha256:5e33f9d095952866b9743cc8268fb740cce6d93439f00ce333a2de1e5974837e",
          "image": "quay.io/jibran_shaukat/ose-kube-rbac-proxy@sha256:5e33f9d095952866b9743cc8268fb740cce6d93439f00ce333a2de1e5974837e",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:cd6b2cec6f5b9ad9e0f0434532f8fb00b6919fcd840e686d96ce08874f2154db",
          "image": "quay.io/jibran_shaukat/smilecdr@sha256:cd6b2cec6f5b9ad9e0f0434532f8fb00b6919fcd840e686d96ce08874f2154db",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "0.0.1",
      "version_original": "0.0.1"
    },
    {
      "_id": "632842b8eb69678e80bd1ea8",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1alpha1",
          "kind": "OpenshiftArtifactoryHa",
          "metadata": {
            "name": "openshiftartifactoryha"
          },
          "spec": {
            "artifactory-ha": {
              "artifactory": {
                "image": {
                  "registry": "registry.connect.redhat.com",
                  "repository": "jfrog/artifactory-pro",
                  "tag": "7.25.7-2"
                },
                "joinKey": "OVERRIDE",
                "masterKey": "OVERRIDE",
                "node": {
                  "replicaCount": 2,
                  "waitForPrimaryStartup": {
                    "enabled": false
                  }
                },
                "uid": "1000721030"
              },
              "database": {
                "driver": "OVERRIDE",
                "password": "OVERRIDE",
                "type": "OVERRIDE",
                "url": "OVERRIDE",
                "user": "OVERRIDE"
              },
              "databaseUpgradeReady": true,
              "initContainerImage": "registry.connect.redhat.com/jfrog/init@sha256:175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03",
              "nginx": {
                "gid": "1000720107",
                "http": {
                  "externalPort": 80,
                  "internalPort": 8080
                },
                "https": {
                  "externalPort": 443,
                  "internalPort": 8443
                },
                "image": {
                  "registry": "registry.redhat.io",
                  "repository": "rhel8/nginx-116",
                  "tag": "latest"
                },
                "service": {
                  "ssloffload": false
                },
                "tlsSecretName": "OVERRIDE",
                "uid": "1000720104"
              },
              "postgresql": {
                "enabled": false
              },
              "waitForDatabase": true
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/jfrog/artifactory-operator-bundle@sha256:49229329083f8836be365b25beda86290cf8c6985dbeb1c46991c2121b54dda9",
      "bundle_path_digest": "sha256:49229329083f8836be365b25beda86290cf8c6985dbeb1c46991c2121b54dda9",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:21:44.206000+00:00",
      "csv_description": " ## Breaking change\nPlease update to version 1.1.10 of the operator.\nVersion 1.1.8 and 1.1.9 have issues. Please skip these versions.\n\n## Overview\nOpenshift Operator to deploy JFrog Artifactory Enterprise into your Openshift cluster.\n## Security Context Constraints\nTo deploy this helm chart you will need to be a cluster admin w/ access to the anyuid scc and add the operator service account to the anyuid scc.\n```\noc adm policy add-scc-to-user anyuid -z artifactory-ha-operator -n openshift-operators\n```\nAdd the service account for the Artifactory chart to deploy successfully:\n``` oc adm policy add-scc-to-user anyuid -z openshiftartifactoryha-artifactory-ha -n artifactory ```\n### Usage\n\nAn external DB is required. The operator will not deploy a DB but will require you to specify the configuration values to connect to it.\n\nSearch for JFrog and click JFrog Artifactory Enterprise Operator to install.\n\nGo to the Installed Operators.\n\nWait for the JFrog Artifactory Enterprise Operator to complete the installation.\n\nOpen the Operator and click on the provided API: Artifactory HA.\n\nClick Create New Instance and provide the following parameters for your DB configuration:\n\n```\nDATABASE_TYPE\nDATABASE_DRIVER\nDATABASE_URL\nDATABASE_USER\nDATABASE_PASSWORD\n```\nMaster key and Join key must be supplied. To generate a new key for each run the command below:\n\n```\n# Create a key\nexport JOIN_KEY=$(openssl rand -hex 32)\necho ${JOIN_KEY}\n```\n\nTo use TLS you will need to first create a k8s tls secret to store your .crt and .key file into.\nThen supply the value of this k8s secret into the TLS_SECRET field.\n``` oc create secret tls my_tls_secret --cert=tls.crt --key=tls.key --namespace=my_namespace ```\nClick Create for Artifactory Enterprise to deploy into OpenShift and connect to it on the external IP exposed by the load balancer.\n### Create a route\nTo expose Artifactory from Openshift we recommend you create a new route in Openshift.\nYou can either use the oc command line tool or the Openshift web console to generate a new route.\nDepending upon where you terminate TLS you will need to either specify pass through or edge.\nCommand Line (Edge):\n``` oc create route edge --service=openshiftartifactory-ha --cert=tls.crt --key=tls.key --ca-cert=ca.crt --hostname=www.example.com ```\nOr for more information visit the official Openshift documentation on routes here:\nhttps://docs.openshift.com/container-platform/4.6/networking/routes/route-configuration.html\n\n",
      "csv_display_name": "JFrog Artifactory Enterprise Operator",
      "csv_metadata_description": "JFrog Artifactory Enterprise deploys Artifactory in a high availability environment across multiple pods",
      "csv_name": "artifactory-ha-operator.v1.1.14",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:32:37.036000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "openshiftartifactoryha-operator",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "OpenshiftArtifactoryHa",
          "version": "v1alpha1"
        }
      ],
      "provider": "JFrog",
      "related_images": [
        {
          "digest": "sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "name": "artifactory-operator-9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4-annotation"
        },
        {
          "digest": "sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "name": "artifactory-ha-operator"
        },
        {
          "digest": "sha256:abd96a07bbeffcdcdf69b5998b9256b684e72bcecb9b94b9a623a0c02b276322",
          "image": "registry.connect.redhat.com/jfrog/artifactory-pro@sha256:abd96a07bbeffcdcdf69b5998b9256b684e72bcecb9b94b9a623a0c02b276322",
          "name": "artifactory_image_repository"
        },
        {
          "digest": "sha256:225b9d8cac2b4d3a1d193782f4bba749194048b87bf31dcd12ea88422e6350c8",
          "image": "registry.redhat.io/rhel8/nginx-116@sha256:225b9d8cac2b4d3a1d193782f4bba749194048b87bf31dcd12ea88422e6350c8",
          "name": "nginx_image_repository"
        },
        {
          "digest": "sha256:175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03",
          "image": "registry.connect.redhat.com/jfrog/init@sha256:175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03",
          "name": "init-175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.1.14",
      "version_original": "1.1.14"
    },
    {
      "_id": "632842baa9c6e63893ae530b",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1alpha1",
          "kind": "OpenshiftArtifactoryHa",
          "metadata": {
            "name": "openshiftartifactoryha"
          },
          "spec": {
            "artifactory-ha": {
              "artifactory": {
                "image": {
                  "registry": "registry.connect.redhat.com",
                  "repository": "jfrog/artifactory-pro",
                  "tag": "7.25.7-2"
                },
                "joinKey": "OVERRIDE",
                "masterKey": "OVERRIDE",
                "node": {
                  "replicaCount": 2,
                  "waitForPrimaryStartup": {
                    "enabled": false
                  }
                },
                "uid": "1000721030"
              },
              "database": {
                "driver": "OVERRIDE",
                "password": "OVERRIDE",
                "type": "OVERRIDE",
                "url": "OVERRIDE",
                "user": "OVERRIDE"
              },
              "databaseUpgradeReady": true,
              "initContainerImage": "registry.connect.redhat.com/jfrog/init@sha256:175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03",
              "nginx": {
                "gid": "1000720107",
                "http": {
                  "externalPort": 80,
                  "internalPort": 8080
                },
                "https": {
                  "externalPort": 443,
                  "internalPort": 8443
                },
                "image": {
                  "registry": "registry.redhat.io",
                  "repository": "rhel8/nginx-116",
                  "tag": "latest"
                },
                "service": {
                  "ssloffload": false
                },
                "tlsSecretName": "OVERRIDE",
                "uid": "1000720104"
              },
              "postgresql": {
                "enabled": false
              },
              "waitForDatabase": true
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/jfrog/artifactory-operator-bundle@sha256:55712df39fd00efa21711d24459e5a0610d9d2221af37a893fd80f7951838fab",
      "bundle_path_digest": "sha256:55712df39fd00efa21711d24459e5a0610d9d2221af37a893fd80f7951838fab",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:21:46.435000+00:00",
      "csv_description": " ## Breaking change\nPlease update to version 1.1.10 of the operator.\nVersion 1.1.8 and 1.1.9 have issues. Please skip these versions.\n\n## Overview\nOpenshift Operator to deploy JFrog Artifactory Enterprise into your Openshift cluster.\n## Security Context Constraints\nTo deploy this helm chart you will need to be a cluster admin w/ access to the anyuid scc and add the operator service account to the anyuid scc.\n```\noc adm policy add-scc-to-user anyuid -z artifactory-ha-operator -n openshift-operators\n```\nAdd the service account for the Artifactory chart to deploy successfully:\n``` oc adm policy add-scc-to-user anyuid -z openshiftartifactoryha-artifactory-ha -n artifactory ```\n### Usage\n\nAn external DB is required. The operator will not deploy a DB but will require you to specify the configuration values to connect to it.\n\nSearch for JFrog and click JFrog Artifactory Enterprise Operator to install.\n\nGo to the Installed Operators.\n\nWait for the JFrog Artifactory Enterprise Operator to complete the installation.\n\nOpen the Operator and click on the provided API: Artifactory HA.\n\nClick Create New Instance and provide the following parameters for your DB configuration:\n\n```\nDATABASE_TYPE\nDATABASE_DRIVER\nDATABASE_URL\nDATABASE_USER\nDATABASE_PASSWORD\n```\nMaster key and Join key must be supplied. To generate a new key for each run the command below:\n\n```\n# Create a key\nexport JOIN_KEY=$(openssl rand -hex 32)\necho ${JOIN_KEY}\n```\n\nTo use TLS you will need to first create a k8s tls secret to store your .crt and .key file into.\nThen supply the value of this k8s secret into the TLS_SECRET field.\n``` oc create secret tls my_tls_secret --cert=tls.crt --key=tls.key --namespace=my_namespace ```\nClick Create for Artifactory Enterprise to deploy into OpenShift and connect to it on the external IP exposed by the load balancer.\n### Create a route\nTo expose Artifactory from Openshift we recommend you create a new route in Openshift.\nYou can either use the oc command line tool or the Openshift web console to generate a new route.\nDepending upon where you terminate TLS you will need to either specify pass through or edge.\nCommand Line (Edge):\n``` oc create route edge --service=openshiftartifactory-ha --cert=tls.crt --key=tls.key --ca-cert=ca.crt --hostname=www.example.com ```\nOr for more information visit the official Openshift documentation on routes here:\nhttps://docs.openshift.com/container-platform/4.6/networking/routes/route-configuration.html\n\n",
      "csv_display_name": "JFrog Artifactory Enterprise Operator",
      "csv_metadata_description": "JFrog Artifactory Enterprise deploys Artifactory in a high availability environment across multiple pods",
      "csv_name": "artifactory-ha-operator.v1.1.15",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:32:40.306000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "openshiftartifactoryha-operator",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "OpenshiftArtifactoryHa",
          "version": "v1alpha1"
        }
      ],
      "provider": "JFrog",
      "related_images": [
        {
          "digest": "sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "name": "artifactory-operator-9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4-annotation"
        },
        {
          "digest": "sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "name": "artifactory-ha-operator"
        },
        {
          "digest": "sha256:abd96a07bbeffcdcdf69b5998b9256b684e72bcecb9b94b9a623a0c02b276322",
          "image": "registry.connect.redhat.com/jfrog/artifactory-pro@sha256:abd96a07bbeffcdcdf69b5998b9256b684e72bcecb9b94b9a623a0c02b276322",
          "name": "artifactory_image_repository"
        },
        {
          "digest": "sha256:d71d368d6094a5777000a8d99164959ccb97fca355e855e24bd92c13a8df04f6",
          "image": "registry.redhat.io/rhel8/nginx-116@sha256:d71d368d6094a5777000a8d99164959ccb97fca355e855e24bd92c13a8df04f6",
          "name": "nginx_image_repository"
        },
        {
          "digest": "sha256:175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03",
          "image": "registry.connect.redhat.com/jfrog/init@sha256:175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03",
          "name": "init-175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.1.15",
      "version_original": "1.1.15"
    },
    {
      "_id": "632842bc5ec32701224aa65b",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "OpenshiftArtifactoryHa",
          "metadata": {
            "name": "openshiftartifactoryha"
          },
          "spec": {
            "artifactory-ha": {
              "artifactory": {
                "image": {
                  "registry": "registry.connect.redhat.com",
                  "repository": "jfrog/artifactory-pro",
                  "tag": "7.27.3-1"
                },
                "joinKey": "OVERRIDE",
                "masterKey": "OVERRIDE",
                "node": {
                  "replicaCount": 2,
                  "waitForPrimaryStartup": {
                    "enabled": false
                  }
                },
                "uid": "1000721030"
              },
              "database": {
                "driver": "OVERRIDE",
                "password": "OVERRIDE",
                "type": "OVERRIDE",
                "url": "OVERRIDE",
                "user": "OVERRIDE"
              },
              "databaseUpgradeReady": true,
              "initContainerImage": "registry.connect.redhat.com/jfrog/init@sha256:164b41720a37f75c6129c8a28d05cc56f821022313d44ff918cce4a2146d93e8",
              "nginx": {
                "gid": "1000720107",
                "http": {
                  "externalPort": 80,
                  "internalPort": 8080
                },
                "https": {
                  "externalPort": 443,
                  "internalPort": 8443
                },
                "image": {
                  "registry": "registry.redhat.io",
                  "repository": "rhel8/nginx-116",
                  "tag": "latest"
                },
                "service": {
                  "ssloffload": false
                },
                "tlsSecretName": "OVERRIDE",
                "uid": "1000720104"
              },
              "postgresql": {
                "enabled": false
              },
              "waitForDatabase": true
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/jfrog/artifactory-operator-bundle@sha256:3c12c9d9537b12f610b9f759ad0a94ed465608f69e6bd1cd175a8c3d177151b8",
      "bundle_path_digest": "sha256:3c12c9d9537b12f610b9f759ad0a94ed465608f69e6bd1cd175a8c3d177151b8",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:21:48.432000+00:00",
      "csv_description": " ## Breaking change\nPlease update to version 1.1.10 of the operator.\nVersion 1.1.8 and 1.1.9 have issues. Please skip these versions.\n\n## Overview\nOpenshift Operator to deploy JFrog Artifactory Enterprise into your Openshift cluster.\n## Security Context Constraints\nTo deploy this helm chart you will need to be a cluster admin w/ access to the anyuid scc and add the operator service account to the anyuid scc.\n```\noc adm policy add-scc-to-user anyuid -z artifactory-ha-operator -n openshift-operators\n```\nAdd the service account for the Artifactory chart to deploy successfully:\n``` oc adm policy add-scc-to-user anyuid -z openshiftartifactoryha-artifactory-ha -n artifactory ```\n### Usage\n\nAn external DB is required. The operator will not deploy a DB but will require you to specify the configuration values to connect to it.\n\nSearch for JFrog and click JFrog Artifactory Enterprise Operator to install.\n\nGo to the Installed Operators.\n\nWait for the JFrog Artifactory Enterprise Operator to complete the installation.\n\nOpen the Operator and click on the provided API: Artifactory HA.\n\nClick Create New Instance and provide the following parameters for your DB configuration:\n\n```\nDATABASE_TYPE\nDATABASE_DRIVER\nDATABASE_URL\nDATABASE_USER\nDATABASE_PASSWORD\n```\nMaster key and Join key must be supplied. To generate a new key for each run the command below:\n\n```\n# Create a key\nexport JOIN_KEY=$(openssl rand -hex 32)\necho ${JOIN_KEY}\n```\n\nTo use TLS you will need to first create a k8s tls secret to store your .crt and .key file into.\nThen supply the value of this k8s secret into the TLS_SECRET field.\n``` oc create secret tls my_tls_secret --cert=tls.crt --key=tls.key --namespace=my_namespace ```\nClick Create for Artifactory Enterprise to deploy into OpenShift and connect to it on the external IP exposed by the load balancer.\n### Create a route\nTo expose Artifactory from Openshift we recommend you create a new route in Openshift.\nYou can either use the oc command line tool or the Openshift web console to generate a new route.\nDepending upon where you terminate TLS you will need to either specify pass through or edge.\nCommand Line (Edge):\n``` oc create route edge --service=openshiftartifactory-ha --cert=tls.crt --key=tls.key --ca-cert=ca.crt --hostname=www.example.com ```\nOr for more information visit the official Openshift documentation on routes here:\nhttps://docs.openshift.com/container-platform/4.6/networking/routes/route-configuration.html\n\n",
      "csv_display_name": "JFrog Artifactory Enterprise Operator",
      "csv_metadata_description": "JFrog Artifactory Enterprise deploys Artifactory in a high availability environment across multiple pods",
      "csv_name": "artifactory-ha-operator.v1.1.20",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:32:34.506000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "openshiftartifactoryha-operator",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "OpenshiftArtifactoryHa",
          "version": "v1"
        }
      ],
      "provider": "JFrog",
      "related_images": [
        {
          "digest": "sha256:29dad888f9b74b2c19f221aa6634c94dcd2144237dc039157056a77cbb0c74a4",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:29dad888f9b74b2c19f221aa6634c94dcd2144237dc039157056a77cbb0c74a4",
          "name": "artifactory-operator-29dad888f9b74b2c19f221aa6634c94dcd2144237dc039157056a77cbb0c74a4-annotation"
        },
        {
          "digest": "sha256:29dad888f9b74b2c19f221aa6634c94dcd2144237dc039157056a77cbb0c74a4",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:29dad888f9b74b2c19f221aa6634c94dcd2144237dc039157056a77cbb0c74a4",
          "name": "artifactory-ha-operator"
        },
        {
          "digest": "sha256:7289dde95d1e4d8e161a28cffd9c4a0cc96f92f7536d069ab63ec304a92254fd",
          "image": "registry.connect.redhat.com/jfrog/artifactory-pro@sha256:7289dde95d1e4d8e161a28cffd9c4a0cc96f92f7536d069ab63ec304a92254fd",
          "name": "artifactory_image_repository"
        },
        {
          "digest": "sha256:d71d368d6094a5777000a8d99164959ccb97fca355e855e24bd92c13a8df04f6",
          "image": "registry.redhat.io/rhel8/nginx-116@sha256:d71d368d6094a5777000a8d99164959ccb97fca355e855e24bd92c13a8df04f6",
          "name": "nginx_image_repository"
        },
        {
          "digest": "sha256:164b41720a37f75c6129c8a28d05cc56f821022313d44ff918cce4a2146d93e8",
          "image": "registry.connect.redhat.com/jfrog/init@sha256:164b41720a37f75c6129c8a28d05cc56f821022313d44ff918cce4a2146d93e8",
          "name": "init-164b41720a37f75c6129c8a28d05cc56f821022313d44ff918cce4a2146d93e8-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.1.20",
      "version_original": "1.1.20"
    },
    {
      "_id": "632842be1fe6c3c921e6b2c5",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1alpha1",
          "kind": "OpenshiftArtifactoryHa",
          "metadata": {
            "name": "openshiftartifactoryha"
          },
          "spec": {
            "artifactory-ha": {
              "artifactory": {
                "image": {
                  "registry": "registry.connect.redhat.com",
                  "repository": "jfrog/artifactory-pro",
                  "tag": "7.25.7-2"
                },
                "joinKey": "OVERRIDE",
                "masterKey": "OVERRIDE",
                "node": {
                  "replicaCount": 2,
                  "waitForPrimaryStartup": {
                    "enabled": false
                  }
                },
                "uid": "1000721030"
              },
              "database": {
                "driver": "OVERRIDE",
                "password": "OVERRIDE",
                "type": "OVERRIDE",
                "url": "OVERRIDE",
                "user": "OVERRIDE"
              },
              "databaseUpgradeReady": true,
              "initContainerImage": "registry.connect.redhat.com/jfrog/init@sha256:175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03",
              "nginx": {
                "gid": "1000720107",
                "http": {
                  "externalPort": 80,
                  "internalPort": 8080
                },
                "https": {
                  "externalPort": 443,
                  "internalPort": 8443
                },
                "image": {
                  "registry": "registry.redhat.io",
                  "repository": "rhel8/nginx-116",
                  "tag": "latest"
                },
                "service": {
                  "ssloffload": false
                },
                "tlsSecretName": "OVERRIDE",
                "uid": "1000720104"
              },
              "postgresql": {
                "enabled": false
              },
              "waitForDatabase": true
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/jfrog/artifactory-operator-bundle@sha256:49229329083f8836be365b25beda86290cf8c6985dbeb1c46991c2121b54dda9",
      "bundle_path_digest": "sha256:49229329083f8836be365b25beda86290cf8c6985dbeb1c46991c2121b54dda9",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T10:21:50.739000+00:00",
      "csv_description": " ## Breaking change\nPlease update to version 1.1.10 of the operator.\nVersion 1.1.8 and 1.1.9 have issues. Please skip these versions.\n\n## Overview\nOpenshift Operator to deploy JFrog Artifactory Enterprise into your Openshift cluster.\n## Security Context Constraints\nTo deploy this helm chart you will need to be a cluster admin w/ access to the anyuid scc and add the operator service account to the anyuid scc.\n```\noc adm policy add-scc-to-user anyuid -z artifactory-ha-operator -n openshift-operators\n```\nAdd the service account for the Artifactory chart to deploy successfully:\n``` oc adm policy add-scc-to-user anyuid -z openshiftartifactoryha-artifactory-ha -n artifactory ```\n### Usage\n\nAn external DB is required. The operator will not deploy a DB but will require you to specify the configuration values to connect to it.\n\nSearch for JFrog and click JFrog Artifactory Enterprise Operator to install.\n\nGo to the Installed Operators.\n\nWait for the JFrog Artifactory Enterprise Operator to complete the installation.\n\nOpen the Operator and click on the provided API: Artifactory HA.\n\nClick Create New Instance and provide the following parameters for your DB configuration:\n\n```\nDATABASE_TYPE\nDATABASE_DRIVER\nDATABASE_URL\nDATABASE_USER\nDATABASE_PASSWORD\n```\nMaster key and Join key must be supplied. To generate a new key for each run the command below:\n\n```\n# Create a key\nexport JOIN_KEY=$(openssl rand -hex 32)\necho ${JOIN_KEY}\n```\n\nTo use TLS you will need to first create a k8s tls secret to store your .crt and .key file into.\nThen supply the value of this k8s secret into the TLS_SECRET field.\n``` oc create secret tls my_tls_secret --cert=tls.crt --key=tls.key --namespace=my_namespace ```\nClick Create for Artifactory Enterprise to deploy into OpenShift and connect to it on the external IP exposed by the load balancer.\n### Create a route\nTo expose Artifactory from Openshift we recommend you create a new route in Openshift.\nYou can either use the oc command line tool or the Openshift web console to generate a new route.\nDepending upon where you terminate TLS you will need to either specify pass through or edge.\nCommand Line (Edge):\n``` oc create route edge --service=openshiftartifactory-ha --cert=tls.crt --key=tls.key --ca-cert=ca.crt --hostname=www.example.com ```\nOr for more information visit the official Openshift documentation on routes here:\nhttps://docs.openshift.com/container-platform/4.6/networking/routes/route-configuration.html\n\n",
      "csv_display_name": "JFrog Artifactory Enterprise Operator",
      "csv_metadata_description": "JFrog Artifactory Enterprise deploys Artifactory in a high availability environment across multiple pods",
      "csv_name": "artifactory-ha-operator.v1.1.14",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-09-19T12:32:42.973000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "openshiftartifactoryha-operator",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "OpenshiftArtifactoryHa",
          "version": "v1alpha1"
        }
      ],
      "provider": "JFrog",
      "related_images": [
        {
          "digest": "sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "name": "artifactory-operator-9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4-annotation"
        },
        {
          "digest": "sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:9b0b59194a052c63fa0d54d47220b7d2154ac38272694e54492cf2c029043cc4",
          "name": "artifactory-ha-operator"
        },
        {
          "digest": "sha256:abd96a07bbeffcdcdf69b5998b9256b684e72bcecb9b94b9a623a0c02b276322",
          "image": "registry.connect.redhat.com/jfrog/artifactory-pro@sha256:abd96a07bbeffcdcdf69b5998b9256b684e72bcecb9b94b9a623a0c02b276322",
          "name": "artifactory_image_repository"
        },
        {
          "digest": "sha256:225b9d8cac2b4d3a1d193782f4bba749194048b87bf31dcd12ea88422e6350c8",
          "image": "registry.redhat.io/rhel8/nginx-116@sha256:225b9d8cac2b4d3a1d193782f4bba749194048b87bf31dcd12ea88422e6350c8",
          "name": "nginx_image_repository"
        },
        {
          "digest": "sha256:175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03",
          "image": "registry.connect.redhat.com/jfrog/init@sha256:175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03",
          "name": "init-175efbb8c51f0c50c4d32e876b20083b92ec5a04bab94e93cb3cb92d86164d03-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.1.14",
      "version_original": "1.1.14"
    },
    {
      "_id": "632842c1eb69678e80bd1eba",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "OpenshiftArtifactoryHa",
          "metadata": {
            "name": "openshiftartifactoryha"
          },
          "spec": {
            "artifactory-ha": {
              "artifactory": {
                "image": {
                  "registry": "registry.connect.redhat.com",
                  "repository": "jfrog/artifactory-pro",
                  "tag": "7.27.3-1"
                },
                "joinKey": "OVERRIDE",
                "masterKey": "OVERRIDE",
                "node": {
                  "replicaCount": 2,
                  "waitForPrimaryStartup": {
                    "enabled": false
                  }
                },
                "uid": "1000721030"
              },
              "database": {
                "driver": "OVERRIDE",
                "password": "OVERRIDE",
                "type": "OVERRIDE",
                "url": "OVERRIDE",
                "user": "OVERRIDE"
              },
              "databaseUpgradeReady": true,
              "initContainerImage": "registry.connect.redhat.com/jfrog/init@sha256:164b41720a37f75c6129c8a28d05cc56f821022313d44ff918cce4a2146d93e8",
              "nginx": {
                "gid": "1000720107",
                "http": {
                  "externalPort": 80,
                  "internalPort": 8080
                },
                "https": {
                  "externalPort": 443,
                  "internalPort": 8443
                },
                "image": {
                  "registry": "registry.redhat.io",
                  "repository": "rhel8/nginx-116",
                  "tag": "latest"
                },
                "service": {
                  "ssloffload": false
                },
                "tlsSecretName": "OVERRIDE",
                "uid": "1000720104"
              },
              "postgresql": {
                "enabled": false
              },
              "waitForDatabase": true
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/jfrog/artifactory-operator-bundle@sha256:fc374491270b9566b0a5c80f3dd665b2227b1e8fb224eada7e5c98c82926ae08",
      "bundle_path_digest": "sha256:fc374491270b9566b0a5c80f3dd665b2227b1e8fb224eada7e5c98c82926ae08",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T10:21:53.853000+00:00",
      "csv_description": " ## Breaking change\nPlease update to version 1.1.10 of the operator.\nVersion 1.1.8 and 1.1.9 have issues. Please skip these versions.\n\n## Overview\nOpenshift Operator to deploy JFrog Artifactory Enterprise into your Openshift cluster.\n## Security Context Constraints\nTo deploy this helm chart you will need to be a cluster admin w/ access to the anyuid scc and add the operator service account to the anyuid scc.\n```\noc adm policy add-scc-to-user anyuid -z artifactory-ha-operator -n openshift-operators\n```\nAdd the service account for the Artifactory chart to deploy successfully:\n``` oc adm policy add-scc-to-user anyuid -z openshiftartifactoryha-artifactory-ha -n artifactory ```\n### Usage\n\nAn external DB is required. The operator will not deploy a DB but will require you to specify the configuration values to connect to it.\n\nSearch for JFrog and click JFrog Artifactory Enterprise Operator to install.\n\nGo to the Installed Operators.\n\nWait for the JFrog Artifactory Enterprise Operator to complete the installation.\n\nOpen the Operator and click on the provided API: Artifactory HA.\n\nClick Create New Instance and provide the following parameters for your DB configuration:\n\n```\nDATABASE_TYPE\nDATABASE_DRIVER\nDATABASE_URL\nDATABASE_USER\nDATABASE_PASSWORD\n```\nMaster key and Join key must be supplied. To generate a new key for each run the command below:\n\n```\n# Create a key\nexport JOIN_KEY=$(openssl rand -hex 32)\necho ${JOIN_KEY}\n```\n\nTo use TLS you will need to first create a k8s tls secret to store your .crt and .key file into.\nThen supply the value of this k8s secret into the TLS_SECRET field.\n``` oc create secret tls my_tls_secret --cert=tls.crt --key=tls.key --namespace=my_namespace ```\nClick Create for Artifactory Enterprise to deploy into OpenShift and connect to it on the external IP exposed by the load balancer.\n### Create a route\nTo expose Artifactory from Openshift we recommend you create a new route in Openshift.\nYou can either use the oc command line tool or the Openshift web console to generate a new route.\nDepending upon where you terminate TLS you will need to either specify pass through or edge.\nCommand Line (Edge):\n``` oc create route edge --service=openshiftartifactory-ha --cert=tls.crt --key=tls.key --ca-cert=ca.crt --hostname=www.example.com ```\nOr for more information visit the official Openshift documentation on routes here:\nhttps://docs.openshift.com/container-platform/4.6/networking/routes/route-configuration.html\n\n",
      "csv_display_name": "JFrog Artifactory Enterprise Operator",
      "csv_metadata_description": "JFrog Artifactory Enterprise deploys Artifactory in a high availability environment across multiple pods",
      "csv_name": "artifactory-ha-operator.v1.1.18",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-09-19T12:32:46.116000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "openshiftartifactoryha-operator",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "OpenshiftArtifactoryHa",
          "version": "v1"
        }
      ],
      "provider": "JFrog",
      "related_images": [
        {
          "digest": "sha256:e292553e1b6e792ff19276c7f6565d7ed61dd95289eb176066329954bc93e371",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:e292553e1b6e792ff19276c7f6565d7ed61dd95289eb176066329954bc93e371",
          "name": "artifactory-operator-e292553e1b6e792ff19276c7f6565d7ed61dd95289eb176066329954bc93e371-annotation"
        },
        {
          "digest": "sha256:e292553e1b6e792ff19276c7f6565d7ed61dd95289eb176066329954bc93e371",
          "image": "registry.connect.redhat.com/jfrog/artifactory-operator@sha256:e292553e1b6e792ff19276c7f6565d7ed61dd95289eb176066329954bc93e371",
          "name": "artifactory-ha-operator"
        },
        {
          "digest": "sha256:7289dde95d1e4d8e161a28cffd9c4a0cc96f92f7536d069ab63ec304a92254fd",
          "image": "registry.connect.redhat.com/jfrog/artifactory-pro@sha256:7289dde95d1e4d8e161a28cffd9c4a0cc96f92f7536d069ab63ec304a92254fd",
          "name": "artifactory_image_repository"
        },
        {
          "digest": "sha256:d71d368d6094a5777000a8d99164959ccb97fca355e855e24bd92c13a8df04f6",
          "image": "registry.redhat.io/rhel8/nginx-116@sha256:d71d368d6094a5777000a8d99164959ccb97fca355e855e24bd92c13a8df04f6",
          "name": "nginx_image_repository"
        },
        {
          "digest": "sha256:164b41720a37f75c6129c8a28d05cc56f821022313d44ff918cce4a2146d93e8",
          "image": "registry.connect.redhat.com/jfrog/init@sha256:164b41720a37f75c6129c8a28d05cc56f821022313d44ff918cce4a2146d93e8",
          "name": "init-164b41720a37f75c6129c8a28d05cc56f821022313d44ff918cce4a2146d93e8-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.1.18",
      "version_original": "1.1.18"
    },
    {
      "_id": "632842c4703b1887dc1c74e6",
      "alm_examples": [
        {
          "api_version": "infoscale.veritas.com/v1",
          "kind": "DNS",
          "metadata": {
            "name": "test-dns"
          },
          "spec": {
            "domain": "vcslnxdns.com",
            "resRecord": {
              "abc": "r7515-054-vm9",
              "r7515-054-vm10": "10.221.85.83",
              "r7515-054-vm8": "10.221.85.81",
              "r7515-054-vm9": "10.221.85.82",
              "www": "r7515-054-vm8",
              "xyz": "r7515-054-vm10"
            },
            "stealthMasters": [
              "1.2.3.4"
            ],
            "tsigKeyFile": "/Kvcslnxdns.com.+157+10641.private"
          }
        },
        {
          "api_version": "infoscale.veritas.com/v1",
          "kind": "DataReplication",
          "metadata": {
            "name": "test-datareplication"
          },
          "spec": {
            "currentPrimary": "Clus1",
            "force": false,
            "localHostAddress": "10.0.0.1",
            "localNIC": "eth0",
            "localNetMask": "255.255.240.0",
            "remoteClusterDetails": [
              {
                "bandwidthLimit": "N/A",
                "clusterName": "Clus2",
                "latencyProtection": "fail",
                "logProtection": "autodcm",
                "networkTransportProtocol": "TCP",
                "remoteHostAddress": "10.0.0.2",
                "remoteNIC": "eth0",
                "remoteNetMask": "255.255.240.0",
                "replicationState": "start",
                "replicationType": "async"
              }
            ],
            "selector": {
              "namespace": "mysql"
            }
          }
        },
        {
          "api_version": "infoscale.veritas.com/v1",
          "kind": "DisasterRecoveryPlan",
          "metadata": {
            "name": "test-disaster-recovery-plan"
          },
          "spec": {
            "clusterFailOverPolicy": "Manual",
            "dataReplicationPointer": "test-datareplication",
            "force": false,
            "preferredClusterList": [
              "Clus1",
              "Clus2"
            ],
            "primaryCluster": "Clus1",
            "selector": {
              "namespace": "mysql"
            }
          }
        },
        {
          "api_version": "infoscale.veritas.com/v1",
          "kind": "GlobalClusterMembership",
          "metadata": {
            "name": "global-cluster-membership"
          },
          "spec": {
            "backupClusterScopeCRD": true,
            "counterMissTolerance": 5,
            "datarepRefreshStatusFrequency": 10,
            "globalClusterOperation": "none",
            "globalMemberClusters": [
              {
                "clusterID": "Clus1",
                "drControllerAddress": "10.0.10.1",
                "drControllerPort": "8080"
              },
              {
                "clusterID": "Clus2",
                "drControllerAddress": "10.0.10.2",
                "drControllerPort": "9090"
              }
            ],
            "localClusterName": "Clus1",
            "metadataBackupInterval": 15
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/veritas-technologies/infoscale-dr-manager-bundle@sha256:71ff93b137b6569f8fdefbd446cf12cd95477e4294bdea98fb5318e5d7d1cdd6",
      "bundle_path_digest": "sha256:71ff93b137b6569f8fdefbd446cf12cd95477e4294bdea98fb5318e5d7d1cdd6",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T10:21:56.720000+00:00",
      "csv_description": "## InfoScale\u2122 DR Manager\n\nInfoScale\u2122 DR Manager manages the Disaster Recovery operations of InfoScale\u2122 for container environment\n\n## Overview\n\n- Disaster Recovery(DR) is provided to applications hosted in container ecosystems. Native container HA capabilities provide high availability to application components within a cluster. However, DR functionality provides disaster recovery in the event of a entire cluster failure and application components can be restored on another peer cluster in membership.\n- You can form a logical notion called 'Global Cluster' comprising clusters that can be used to migrate DR-enabled objects. DR-enabled objects migrate to peer cluster in case of a disaster like entire cluster going down, loss of connectivity with a particular cluster, user-initiated planned migration across cluster.\n\n---\n\n## Pre-requisites\n\n**1.** InfoScale must be installed and InfoScale pods must be configured on the clusters. [[More Details](https://www.veritas.com/content/support/en_US/doc/155483965-155483981-0/v155481520-155483981)]\n\n**2.** Create storage class with name, which must always be **`infoscale-dr-csi-sc`.**\n\n```\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: infoscale-dr-csi-sc\nparameters:\n  fstype: vxfs\n  layout: mirror\nallowVolumeExpansion: true\nprovisioner: org.veritas.infoscale\nreclaimPolicy: Delete\n\n```\n\n**3.** Create persistent volume claim with name, which must always be **`infoscale-dr-meta-bkp-pvc`.**\n\n```\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: infoscale-dr-meta-bkp-pvc\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 4Gi\n  storageClassName: infoscale-dr-csi-sc\n  volumeMode: Filesystem\n\n```\n\n- **Note:** User must use InfoScale\u2122 CSI provisioned storage.\n\n- [For more details, please refer to 'Installing InfoScale DR Manager on openshift' section from official documentation](https://www.veritas.com/content/support/en_US/doc/155483965-155483981-0/v151984431-155483981)\n\n## InfoScale\u2122 DR Manager custom resources\n\n- **Note:** InfoScale\u2122 DR Manager custom resources must be created only in the following order\n\n**1. Global Cluster Membership:**\n\n```\napiVersion: infoscale.veritas.com/v1\nkind: GlobalClusterMembership\nmetadata:\n  name: global-cluster-membership\nspec:\n  # Local cluster name in the global membership\n  localClusterName: Clus1\n\n  globalMemberClusters:\n      # Cluster ID of member of global cluster membershrip\n    - clusterID: Clus1\n\n      # Address Used For Communicating With Peer Cluster's DR Controller\n      drControllerAddress: \"10.0.10.1\"\n\n      # Port used for DR controller\n      drControllerPort: \"8080\"\n\n      # Cluster ID of member of global cluster membershrip\n    - clusterID: Clus2\n\n      # Address Used For Communicating With Peer Cluster's DR Controller\n      drControllerAddress: \"10.0.10.2\"\n\n      # Port used for DR controller\n      drControllerPort: \"9090\"\n\n```\n\n**2. Data Replication:**\n\n```\napiVersion: infoscale.veritas.com/v1\nkind: DataReplication\nmetadata:\n  name: test-datareplication\nspec:\n  # Primary cluster details\n\n  # Virtual IP address to configure VVR\n  localHostAddress: 10.0.0.1\n\n  # Corresponding netmask to configure VVR\n  localNetMask: 255.255.240.0\n\n  # Corresponding network interface to configure VVR (If NIC name is identical for all nodes)\n  localNIC: eth0\n\n  # Namespace and optional labels for which you want to configure data replication\n  selector:\n    namespace: mysql\n    #labels:\n    #  app: db\n\n  # Current primary cluster name - Name of the cluster you want to back up\n  currentPrimary: Clus1\n\n  # Secondary cluster details\n  remoteClusterDetails:\n      # ID of the Cluster to be used for a backup\n    - clusterName: Clus2\n\n      # Virtual IP address for VVR configuration of this cluster\n      remoteHostAddress: 10.0.0.2\n\n      # Corresponsding Netmask of this cluster\n      remoteNetMask: 255.255.240.0\n\n      # Corresponding Network interface of this cluster\n      remoteNIC: eth0\n\n      # (optional) replication type can be sync or async.\n      # default value will be async if not specified.\n      replicationType: async\n\n```\n**3. Disaster Recovery Plan:**\n\n```\napiVersion: infoscale.veritas.com/v1\nkind: DisasterRecoveryPlan\nmetadata:\n  name: test-disaster-recovery-plan\nspec:\n  # Name of cluster that should be treated as primary for this DR plan\n  primaryCluster: Clus1\n\n  # (optional) Set force to True if peer cluster(s) is not reachable and local cluster needs to perform takeover\n  force: false\n\n  # List of member cluster(s) where this DRPlan can failover.\n  # Sequence of MemberCluster specified in this list denotes relative preference of member cluster(s)\n  # Must be subset of Global Cluster Membership\n  preferredClusterList: [\"Clus1\", \"Clus2\"]\n\n  # Kind of corrective action in case of disaster\n  # default value will be \"Manual\" if not specified\n  clusterFailOverPolicy: Manual\n\n  # Specify namespace and optional labels to decide what all needs to be part of the disaster recovery plan\n  selector:\n    namespace: mysql\n    #labels:\n    #  app: db\n\n  # (optional) Pointer to manage data replication\n  dataReplicationPointer: test-datareplication\n\n```\n",
      "csv_display_name": "InfoScale\u2122 DR Manager",
      "csv_metadata_description": "InfoScale\u2122 DR Manager manages the Disaster Recovery operations of InfoScale\u2122 for container environment",
      "csv_name": "infoscale-dr-manager.v8.0.100",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:26:11.955000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "infoscale-dr-manager",
      "provided_apis": [
        {
          "group": "infoscale.veritas.com",
          "kind": "DNS",
          "version": "v1"
        },
        {
          "group": "infoscale.veritas.com",
          "kind": "DataReplication",
          "version": "v1"
        },
        {
          "group": "infoscale.veritas.com",
          "kind": "DisasterRecoveryPlan",
          "version": "v1"
        },
        {
          "group": "infoscale.veritas.com",
          "kind": "GlobalClusterMembership",
          "version": "v1"
        }
      ],
      "provider": "Veritas Technologies LLC",
      "related_images": [
        {
          "digest": "sha256:eb999187a1f9a9ce5566089e24adf598b1c229d31c5e57ddcfe4439ba25e97dc",
          "image": "registry.connect.redhat.com/veritas-technologies/infoscale-dr-manager@sha256:eb999187a1f9a9ce5566089e24adf598b1c229d31c5e57ddcfe4439ba25e97dc",
          "name": "manager"
        },
        {
          "digest": "sha256:eb999187a1f9a9ce5566089e24adf598b1c229d31c5e57ddcfe4439ba25e97dc",
          "image": "registry.connect.redhat.com/veritas-technologies/infoscale-dr-manager@sha256:eb999187a1f9a9ce5566089e24adf598b1c229d31c5e57ddcfe4439ba25e97dc",
          "name": "pre-manager"
        },
        {
          "digest": "sha256:eb999187a1f9a9ce5566089e24adf598b1c229d31c5e57ddcfe4439ba25e97dc",
          "image": "registry.connect.redhat.com/veritas-technologies/infoscale-dr-manager@sha256:eb999187a1f9a9ce5566089e24adf598b1c229d31c5e57ddcfe4439ba25e97dc",
          "name": "infoscale-dr-manager-eb999187a1f9a9ce5566089e24adf598b1c229d31c5e57ddcfe4439ba25e97dc-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "8.0.100",
      "version_original": "8.0.100"
    },
    {
      "_id": "632842c6a1826a2016e6fed0",
      "alm_examples": [
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageCluster",
          "metadata": {
            "annotations": {
              "portworx.io/is-openshift": "true"
            },
            "name": "portworx",
            "namespace": "test-operator"
          },
          "spec": {}
        },
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageNode",
          "metadata": {
            "name": "example",
            "namespace": "test-operator"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/portworx/portworx-certified-bundle@sha256:2a717d5d940a152105e8f5dd46b3e527c19132fec7eb0982955f52c46166dfca",
      "bundle_path_digest": "sha256:2a717d5d940a152105e8f5dd46b3e527c19132fec7eb0982955f52c46166dfca",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:21:58.937000+00:00",
      "csv_description": "Portworx-Enterprise is the most widely-used and reliable cloud-native\nstorage solution for production workloads and provides high-availability,\ndata protection and security for containerized applications.\n\nPortworx Enterprise enables you to migrate entire applications, including\ndata, between clusters in a single data center or cloud, or between clouds,\nwith a single kubectl command.\n\nThe cloud native storage and data management platform that enterprises trust\nto manage data in containers now has an operator which simplifies the install,\nconfiguration, upgrades and manages the Portworx Enterprise cluster lifecycle.\n\nLearn more about the Portworx Enterprise\n[the data platform for Kubernetes](https://portworx.com/products/introduction)\n\nTo learn more about the platform features, please visit our\n[product features page](https://portworx.com/products/features)\n\n### About Portworx\n\nPortworx is the solution for running stateful containers in production,\ndesigned with DevOps in mind. With Portworx, users can manage any database\nor stateful service on any infrastructure using any container scheduler,\nincluding Kubernetes, Mesosphere DC/OS, and Docker Swarm. Portworx solves\nthe five most common problems DevOps teams encounter when running stateful\nservices in production: persistence, high availability, data automation,\nsecurity, and support for multiple data stores and infrastructure.\n\n### How to install StorageCluster\n\nTo customize your cluster's configuration (specification), use the\n[Spec Generator](https://central.portworx.com/) from PX-Central.\n\n### Prerequisite\n\nEnsure ports 17001-17020 on worker nodes are reachable from master and other worker nodes.\n\n### Tutorials\n\n* [Portworx Enterprise on Openshift](https://portworx.com/openshift)\n\n* [Stateful applications on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes/application-install-with-kubernetes)\n\n* [Portworx Enterprise on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes)\n\n* [Kafka on Kubernetes](https://portworx.com/kafka-kubernetes)\n\n* [Elastisearch on Kubernetes](https://portworx.com/elasticsearch-kubernetes)\n\n* [PostgreSQL on Kubernetes](https://portworx.com/postgres-kubernetes/)\n\n* [MongoDB on Kubernetes](https://portworx.com/mongodb-kubernetes/)\n\n* [Cassandra on Kubernetes](https://portworx.com/cassandra-kubernetes/)\n\n* [Kubernetes backup and recovery](https://portworx.com/kubernetes-backup/)\n\n* [Disaster Recovery for Kubernetes](https://portworx.com/kubernetes-disaster-recovery/)\n\n### Uninstall\n\nDeleting the StorageCluster object for Portworx cluster does not stop Portworx\nservice running on the nodes, to avoid application downtime.\n\nTo uninstall Portworx completely without wiping the data, you should add the\nfollowing delete strategy to the StorageCluster spec:\n```\nspec:\n  deleteStrategy:\n    type: Uninstall\n```\n**Caution:** To uninstall Portworx and **wipe all the data**, you should use the following\ndelete strategy:\n```\nspec:\n  deleteStrategy:\n    type: UninstallAndWipe\n```\n",
      "csv_display_name": "Portworx Enterprise",
      "csv_metadata_description": "Cloud native storage solution for production workloads",
      "csv_name": "portworx-operator.v1.8.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-09-19T12:27:22.741000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "portworx-certified",
      "provided_apis": [
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1alpha1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1alpha1"
        }
      ],
      "provider": "Portworx",
      "related_images": [
        {
          "digest": "sha256:bb93cb53d57ed8277480f5cfb827b6b2041e639c8fceae2e501e91c201d7e0d9",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:bb93cb53d57ed8277480f5cfb827b6b2041e639c8fceae2e501e91c201d7e0d9",
          "name": "openstorage-operator-bb93cb53d57ed8277480f5cfb827b6b2041e639c8fceae2e501e91c201d7e0d9-annotation"
        },
        {
          "digest": "sha256:bb93cb53d57ed8277480f5cfb827b6b2041e639c8fceae2e501e91c201d7e0d9",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:bb93cb53d57ed8277480f5cfb827b6b2041e639c8fceae2e501e91c201d7e0d9",
          "name": "portworx-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.8.1",
      "version_original": "1.8.1"
    },
    {
      "_id": "632842c9d1a8ccdba1fb0795",
      "alm_examples": [
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageCluster",
          "metadata": {
            "annotations": {
              "portworx.io/is-openshift": "true"
            },
            "name": "portworx",
            "namespace": "test-operator"
          },
          "spec": {}
        },
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageNode",
          "metadata": {
            "name": "example",
            "namespace": "test-operator"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/portworx/portworx-certified-bundle@sha256:b2f671e9b067f3b74de9b7422ac5d73a4251003758431b99133c2f7b905c14dc",
      "bundle_path_digest": "sha256:b2f671e9b067f3b74de9b7422ac5d73a4251003758431b99133c2f7b905c14dc",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:22:01.031000+00:00",
      "csv_description": "Portworx-Enterprise is the most widely-used and reliable cloud-native\nstorage solution for production workloads and provides high-availability,\ndata protection and security for containerized applications.\n\nPortworx Enterprise enables you to migrate entire applications, including\ndata, between clusters in a single data center or cloud, or between clouds,\nwith a single kubectl command.\n\nThe cloud native storage and data management platform that enterprises trust\nto manage data in containers now has an operator which simplifies the install,\nconfiguration, upgrades and manages the Portworx Enterprise cluster lifecycle.\n\nLearn more about the Portworx Enterprise\n[the data platform for Kubernetes](https://portworx.com/products/introduction)\n\nTo learn more about the platform features, please visit our\n[product features page](https://portworx.com/products/features)\n\n### About Portworx\n\nPortworx is the solution for running stateful containers in production,\ndesigned with DevOps in mind. With Portworx, users can manage any database\nor stateful service on any infrastructure using any container scheduler,\nincluding Kubernetes, Mesosphere DC/OS, and Docker Swarm. Portworx solves\nthe five most common problems DevOps teams encounter when running stateful\nservices in production: persistence, high availability, data automation,\nsecurity, and support for multiple data stores and infrastructure.\n\n### How to install StorageCluster\n\nTo customize your cluster's configuration (specification), use the\n[Spec Generator](https://central.portworx.com/) from PX-Central.\n\n### Prerequisite\n\nEnsure ports 17001-17020 on worker nodes are reachable from master and other worker nodes.\n\n### Tutorials\n\n* [Portworx Enterprise on Openshift](https://portworx.com/openshift)\n\n* [Stateful applications on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes/application-install-with-kubernetes)\n\n* [Portworx Enterprise on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes)\n\n* [Kafka on Kubernetes](https://portworx.com/kafka-kubernetes)\n\n* [Elastisearch on Kubernetes](https://portworx.com/elasticsearch-kubernetes)\n\n* [PostgreSQL on Kubernetes](https://portworx.com/postgres-kubernetes/)\n\n* [MongoDB on Kubernetes](https://portworx.com/mongodb-kubernetes/)\n\n* [Cassandra on Kubernetes](https://portworx.com/cassandra-kubernetes/)\n\n* [Kubernetes backup and recovery](https://portworx.com/kubernetes-backup/)\n\n* [Disaster Recovery for Kubernetes](https://portworx.com/kubernetes-disaster-recovery/)\n\n### Uninstall\n\nDeleting the StorageCluster object for Portworx cluster does not stop Portworx\nservice running on the nodes, to avoid application downtime.\n\nTo uninstall Portworx completely without wiping the data, you should add the\nfollowing delete strategy to the StorageCluster spec:\n```\nspec:\n  deleteStrategy:\n    type: Uninstall\n```\n**Caution:** To uninstall Portworx and **wipe all the data**, you should use the following\ndelete strategy:\n```\nspec:\n  deleteStrategy:\n    type: UninstallAndWipe\n```\n",
      "csv_display_name": "Portworx Enterprise",
      "csv_metadata_description": "Cloud native storage solution for production workloads",
      "csv_name": "portworx-operator.v1.9.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-09-19T12:27:28.711000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "portworx-certified",
      "provided_apis": [
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1alpha1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1alpha1"
        }
      ],
      "provider": "Portworx",
      "related_images": [
        {
          "digest": "sha256:c1e25a64fd2fe5ca974182b316f6b4677b190ba292a1535af581cb286574703c",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:c1e25a64fd2fe5ca974182b316f6b4677b190ba292a1535af581cb286574703c",
          "name": "openstorage-operator-c1e25a64fd2fe5ca974182b316f6b4677b190ba292a1535af581cb286574703c-annotation"
        },
        {
          "digest": "sha256:c1e25a64fd2fe5ca974182b316f6b4677b190ba292a1535af581cb286574703c",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:c1e25a64fd2fe5ca974182b316f6b4677b190ba292a1535af581cb286574703c",
          "name": "portworx-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.9.0",
      "version_original": "1.9.0"
    },
    {
      "_id": "632842cb5ec32701224aa669",
      "alm_examples": [
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageCluster",
          "metadata": {
            "annotations": {
              "portworx.io/is-openshift": "true"
            },
            "name": "portworx",
            "namespace": "test-operator"
          },
          "spec": {}
        },
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageNode",
          "metadata": {
            "name": "example",
            "namespace": "test-operator"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/portworx/portworx-certified-bundle@sha256:d5ac56a6085190ca9ce357395a84e588b0551e6d0a8af46264c91126b1f1e230",
      "bundle_path_digest": "sha256:d5ac56a6085190ca9ce357395a84e588b0551e6d0a8af46264c91126b1f1e230",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:22:03.655000+00:00",
      "csv_description": "Portworx-Enterprise is the most widely-used and reliable cloud-native\nstorage solution for production workloads and provides high-availability,\ndata protection and security for containerized applications.\n\nPortworx Enterprise enables you to migrate entire applications, including\ndata, between clusters in a single data center or cloud, or between clouds,\nwith a single kubectl command.\n\nThe cloud native storage and data management platform that enterprises trust\nto manage data in containers now has an operator which simplifies the install,\nconfiguration, upgrades and manages the Portworx Enterprise cluster lifecycle.\n\nLearn more about the Portworx Enterprise\n[the data platform for Kubernetes](https://portworx.com/products/introduction)\n\nTo learn more about the platform features, please visit our\n[product features page](https://portworx.com/products/features)\n\n### About Portworx\n\nPortworx is the solution for running stateful containers in production,\ndesigned with DevOps in mind. With Portworx, users can manage any database\nor stateful service on any infrastructure using any container scheduler,\nincluding Kubernetes, Mesosphere DC/OS, and Docker Swarm. Portworx solves\nthe five most common problems DevOps teams encounter when running stateful\nservices in production: persistence, high availability, data automation,\nsecurity, and support for multiple data stores and infrastructure.\n\n### How to install StorageCluster\n\nTo customize your cluster's configuration (specification), use the\n[Spec Generator](https://central.portworx.com/) from PX-Central.\n\n### Prerequisite\n\nEnsure ports 17001-17020 on worker nodes are reachable from master and other worker nodes.\n\n### Tutorials\n\n* [Portworx Enterprise on Openshift](https://portworx.com/openshift)\n\n* [Stateful applications on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes/application-install-with-kubernetes)\n\n* [Portworx Enterprise on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes)\n\n* [Kafka on Kubernetes](https://portworx.com/kafka-kubernetes)\n\n* [Elastisearch on Kubernetes](https://portworx.com/elasticsearch-kubernetes)\n\n* [PostgreSQL on Kubernetes](https://portworx.com/postgres-kubernetes/)\n\n* [MongoDB on Kubernetes](https://portworx.com/mongodb-kubernetes/)\n\n* [Cassandra on Kubernetes](https://portworx.com/cassandra-kubernetes/)\n\n* [Kubernetes backup and recovery](https://portworx.com/kubernetes-backup/)\n\n* [Disaster Recovery for Kubernetes](https://portworx.com/kubernetes-disaster-recovery/)\n\n### Uninstall\n\nDeleting the StorageCluster object for Portworx cluster does not stop Portworx\nservice running on the nodes, to avoid application downtime.\n\nTo uninstall Portworx completely without wiping the data, you should add the\nfollowing delete strategy to the StorageCluster spec:\n```\nspec:\n  deleteStrategy:\n    type: Uninstall\n```\n**Caution:** To uninstall Portworx and **wipe all the data**, you should use the following\ndelete strategy:\n```\nspec:\n  deleteStrategy:\n    type: UninstallAndWipe\n```\n",
      "csv_display_name": "Portworx Enterprise",
      "csv_metadata_description": "Cloud native storage solution for production workloads",
      "csv_name": "portworx-operator.v1.9.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-09-19T12:27:02.058000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "portworx-certified",
      "provided_apis": [
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1alpha1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1alpha1"
        }
      ],
      "provider": "Portworx",
      "related_images": [
        {
          "digest": "sha256:9971d9ddce03e9c174dbd2acd6904c89b0bdba4a9c61ea5223569bcd2972b089",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:9971d9ddce03e9c174dbd2acd6904c89b0bdba4a9c61ea5223569bcd2972b089",
          "name": "openstorage-operator-9971d9ddce03e9c174dbd2acd6904c89b0bdba4a9c61ea5223569bcd2972b089-annotation"
        },
        {
          "digest": "sha256:9971d9ddce03e9c174dbd2acd6904c89b0bdba4a9c61ea5223569bcd2972b089",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:9971d9ddce03e9c174dbd2acd6904c89b0bdba4a9c61ea5223569bcd2972b089",
          "name": "portworx-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.9.1",
      "version_original": "1.9.1"
    },
    {
      "_id": "632842cd703b1887dc1c74f4",
      "alm_examples": [
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageCluster",
          "metadata": {
            "annotations": {
              "portworx.io/is-openshift": "true"
            },
            "name": "portworx",
            "namespace": "test-operator"
          },
          "spec": {}
        },
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageNode",
          "metadata": {
            "name": "example",
            "namespace": "test-operator"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/portworx/portworx-certified-bundle@sha256:45853a8612cc9da123094499ac975eb2bc943346a0092fe9d892c5942170e77f",
      "bundle_path_digest": "sha256:45853a8612cc9da123094499ac975eb2bc943346a0092fe9d892c5942170e77f",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:22:05.828000+00:00",
      "csv_description": "Portworx-Enterprise is the most widely-used and reliable cloud-native\nstorage solution for production workloads and provides high-availability,\ndata protection and security for containerized applications.\n\nPortworx Enterprise enables you to migrate entire applications, including\ndata, between clusters in a single data center or cloud, or between clouds,\nwith a single kubectl command.\n\nThe cloud native storage and data management platform that enterprises trust\nto manage data in containers now has an operator which simplifies the install,\nconfiguration, upgrades and manages the Portworx Enterprise cluster lifecycle.\n\nLearn more about the Portworx Enterprise\n[the data platform for Kubernetes](https://portworx.com/products/introduction)\n\nTo learn more about the platform features, please visit our\n[product features page](https://portworx.com/products/features)\n\n### About Portworx\n\nPortworx is the solution for running stateful containers in production,\ndesigned with DevOps in mind. With Portworx, users can manage any database\nor stateful service on any infrastructure using any container scheduler,\nincluding Kubernetes, Mesosphere DC/OS, and Docker Swarm. Portworx solves\nthe five most common problems DevOps teams encounter when running stateful\nservices in production: persistence, high availability, data automation,\nsecurity, and support for multiple data stores and infrastructure.\n\n### How to install StorageCluster\n\nTo customize your cluster's configuration (specification), use the\n[Spec Generator](https://central.portworx.com/) from PX-Central.\n\n### Prerequisite\n\nEnsure ports 17001-17020 on worker nodes are reachable from master and other worker nodes.\n\n### Tutorials\n\n* [Portworx Enterprise on Openshift](https://portworx.com/openshift)\n\n* [Stateful applications on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes/application-install-with-kubernetes)\n\n* [Portworx Enterprise on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes)\n\n* [Kafka on Kubernetes](https://portworx.com/kafka-kubernetes)\n\n* [Elastisearch on Kubernetes](https://portworx.com/elasticsearch-kubernetes)\n\n* [PostgreSQL on Kubernetes](https://portworx.com/postgres-kubernetes/)\n\n* [MongoDB on Kubernetes](https://portworx.com/mongodb-kubernetes/)\n\n* [Cassandra on Kubernetes](https://portworx.com/cassandra-kubernetes/)\n\n* [Kubernetes backup and recovery](https://portworx.com/kubernetes-backup/)\n\n* [Disaster Recovery for Kubernetes](https://portworx.com/kubernetes-disaster-recovery/)\n\n### Uninstall\n\nDeleting the StorageCluster object for Portworx cluster does not stop Portworx\nservice running on the nodes, to avoid application downtime.\n\nTo uninstall Portworx completely without wiping the data, you should add the\nfollowing delete strategy to the StorageCluster spec:\n```\nspec:\n  deleteStrategy:\n    type: Uninstall\n```\n**Caution:** To uninstall Portworx and **wipe all the data**, you should use the following\ndelete strategy:\n```\nspec:\n  deleteStrategy:\n    type: UninstallAndWipe\n```\n",
      "csv_display_name": "Portworx Enterprise",
      "csv_metadata_description": "Cloud native storage solution for production workloads",
      "csv_name": "portworx-operator.v1.6.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-09-19T12:27:06.987000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "portworx-certified",
      "provided_apis": [
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1alpha1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1alpha1"
        }
      ],
      "provider": "Portworx",
      "related_images": [
        {
          "digest": "sha256:5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47",
          "name": "openstorage-operator-5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47-annotation"
        },
        {
          "digest": "sha256:5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47",
          "name": "portworx-operator"
        }
      ],
      "replaces": null,
      "skip_range": "<1.6.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.6.1",
      "version_original": "1.6.1"
    },
    {
      "_id": "632842cfa9c6e63893ae5321",
      "alm_examples": [
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageCluster",
          "metadata": {
            "annotations": {
              "portworx.io/is-openshift": "true"
            },
            "name": "portworx",
            "namespace": "test-operator"
          },
          "spec": {}
        },
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageNode",
          "metadata": {
            "name": "example",
            "namespace": "test-operator"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/portworx/portworx-certified-bundle@sha256:6b840a6631b9f345d9a66dc3b57568d2528d08dd78fdd0f5c027bdb49c97a3bd",
      "bundle_path_digest": "sha256:6b840a6631b9f345d9a66dc3b57568d2528d08dd78fdd0f5c027bdb49c97a3bd",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:22:07.915000+00:00",
      "csv_description": "Portworx-Enterprise is the most widely-used and reliable cloud-native\nstorage solution for production workloads and provides high-availability,\ndata protection and security for containerized applications.\n\nPortworx Enterprise enables you to migrate entire applications, including\ndata, between clusters in a single data center or cloud, or between clouds,\nwith a single kubectl command.\n\nThe cloud native storage and data management platform that enterprises trust\nto manage data in containers now has an operator which simplifies the install,\nconfiguration, upgrades and manages the Portworx Enterprise cluster lifecycle.\n\nLearn more about the Portworx Enterprise\n[the data platform for Kubernetes](https://portworx.com/products/introduction)\n\nTo learn more about the platform features, please visit our\n[product features page](https://portworx.com/products/features)\n\n### About Portworx\n\nPortworx is the solution for running stateful containers in production,\ndesigned with DevOps in mind. With Portworx, users can manage any database\nor stateful service on any infrastructure using any container scheduler,\nincluding Kubernetes, Mesosphere DC/OS, and Docker Swarm. Portworx solves\nthe five most common problems DevOps teams encounter when running stateful\nservices in production: persistence, high availability, data automation,\nsecurity, and support for multiple data stores and infrastructure.\n\n### How to install StorageCluster\n\nTo customize your cluster's configuration (specification), use the\n[Spec Generator](https://central.portworx.com/) from PX-Central.\n\n### Prerequisite\n\nEnsure ports 17001-17020 on worker nodes are reachable from master and other worker nodes.\n\n### Tutorials\n\n* [Portworx Enterprise on Openshift](https://portworx.com/openshift)\n\n* [Stateful applications on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes/application-install-with-kubernetes)\n\n* [Portworx Enterprise on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes)\n\n* [Kafka on Kubernetes](https://portworx.com/kafka-kubernetes)\n\n* [Elastisearch on Kubernetes](https://portworx.com/elasticsearch-kubernetes)\n\n* [PostgreSQL on Kubernetes](https://portworx.com/postgres-kubernetes/)\n\n* [MongoDB on Kubernetes](https://portworx.com/mongodb-kubernetes/)\n\n* [Cassandra on Kubernetes](https://portworx.com/cassandra-kubernetes/)\n\n* [Kubernetes backup and recovery](https://portworx.com/kubernetes-backup/)\n\n* [Disaster Recovery for Kubernetes](https://portworx.com/kubernetes-disaster-recovery/)\n\n### Uninstall\n\nDeleting the StorageCluster object for Portworx cluster does not stop Portworx\nservice running on the nodes, to avoid application downtime.\n\nTo uninstall Portworx completely without wiping the data, you should add the\nfollowing delete strategy to the StorageCluster spec:\n```\nspec:\n  deleteStrategy:\n    type: Uninstall\n```\n**Caution:** To uninstall Portworx and **wipe all the data**, you should use the following\ndelete strategy:\n```\nspec:\n  deleteStrategy:\n    type: UninstallAndWipe\n```\n",
      "csv_display_name": "Portworx Enterprise",
      "csv_metadata_description": "Cloud native storage solution for production workloads",
      "csv_name": "portworx-operator.v1.7.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-09-19T12:27:12.607000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "portworx-certified",
      "provided_apis": [
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1alpha1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1alpha1"
        }
      ],
      "provider": "Portworx",
      "related_images": [
        {
          "digest": "sha256:c4ba573632798d9d78b069a0e396e434e5209abaa4ad82be106c12ad91bb162c",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:c4ba573632798d9d78b069a0e396e434e5209abaa4ad82be106c12ad91bb162c",
          "name": "openstorage-operator-c4ba573632798d9d78b069a0e396e434e5209abaa4ad82be106c12ad91bb162c-annotation"
        },
        {
          "digest": "sha256:c4ba573632798d9d78b069a0e396e434e5209abaa4ad82be106c12ad91bb162c",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:c4ba573632798d9d78b069a0e396e434e5209abaa4ad82be106c12ad91bb162c",
          "name": "portworx-operator"
        }
      ],
      "replaces": null,
      "skip_range": "=1.7.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.7.1",
      "version_original": "1.7.1"
    },
    {
      "_id": "632842d32dd1cd9660afba8d",
      "alm_examples": [
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageCluster",
          "metadata": {
            "annotations": {
              "portworx.io/is-openshift": "true"
            },
            "name": "portworx",
            "namespace": "test-operator"
          },
          "spec": {}
        },
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageNode",
          "metadata": {
            "name": "example",
            "namespace": "test-operator"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/portworx/portworx-certified-bundle@sha256:b2c3acedb686c82ba2fd2ea828a841639e063b8f9a054411f4e75b9eaf70a11b",
      "bundle_path_digest": "sha256:b2c3acedb686c82ba2fd2ea828a841639e063b8f9a054411f4e75b9eaf70a11b",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:22:11.155000+00:00",
      "csv_description": "Portworx-Enterprise is the most widely-used and reliable cloud-native\nstorage solution for production workloads and provides high-availability,\ndata protection and security for containerized applications.\n\nPortworx Enterprise enables you to migrate entire applications, including\ndata, between clusters in a single data center or cloud, or between clouds,\nwith a single kubectl command.\n\nThe cloud native storage and data management platform that enterprises trust\nto manage data in containers now has an operator which simplifies the install,\nconfiguration, upgrades and manages the Portworx Enterprise cluster lifecycle.\n\nLearn more about the Portworx Enterprise\n[the data platform for Kubernetes](https://portworx.com/products/introduction)\n\nTo learn more about the platform features, please visit our\n[product features page](https://portworx.com/products/features)\n\n### About Portworx\n\nPortworx is the solution for running stateful containers in production,\ndesigned with DevOps in mind. With Portworx, users can manage any database\nor stateful service on any infrastructure using any container scheduler,\nincluding Kubernetes, Mesosphere DC/OS, and Docker Swarm. Portworx solves\nthe five most common problems DevOps teams encounter when running stateful\nservices in production: persistence, high availability, data automation,\nsecurity, and support for multiple data stores and infrastructure.\n\n### How to install StorageCluster\n\nTo customize your cluster's configuration (specification), use the\n[Spec Generator](https://central.portworx.com/) from PX-Central.\n\n### Prerequisite\n\nEnsure ports 17001-17020 on worker nodes are reachable from master and other worker nodes.\n\n### Tutorials\n\n* [Portworx Enterprise on Openshift](https://portworx.com/openshift)\n\n* [Stateful applications on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes/application-install-with-kubernetes)\n\n* [Portworx Enterprise on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes)\n\n* [Kafka on Kubernetes](https://portworx.com/kafka-kubernetes)\n\n* [Elastisearch on Kubernetes](https://portworx.com/elasticsearch-kubernetes)\n\n* [PostgreSQL on Kubernetes](https://portworx.com/postgres-kubernetes/)\n\n* [MongoDB on Kubernetes](https://portworx.com/mongodb-kubernetes/)\n\n* [Cassandra on Kubernetes](https://portworx.com/cassandra-kubernetes/)\n\n* [Kubernetes backup and recovery](https://portworx.com/kubernetes-backup/)\n\n* [Disaster Recovery for Kubernetes](https://portworx.com/kubernetes-disaster-recovery/)\n\n### Uninstall\n\nDeleting the StorageCluster object for Portworx cluster does not stop Portworx\nservice running on the nodes, to avoid application downtime.\n\nTo uninstall Portworx completely without wiping the data, you should add the\nfollowing delete strategy to the StorageCluster spec:\n```\nspec:\n  deleteStrategy:\n    type: Uninstall\n```\n**Caution:** To uninstall Portworx and **wipe all the data**, you should use the following\ndelete strategy:\n```\nspec:\n  deleteStrategy:\n    type: UninstallAndWipe\n```\n",
      "csv_display_name": "Portworx Enterprise",
      "csv_metadata_description": "Cloud native storage solution for production workloads",
      "csv_name": "portworx-operator.v1.8.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-09-19T12:27:17.215000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "portworx-certified",
      "provided_apis": [
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1alpha1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1alpha1"
        }
      ],
      "provider": "Portworx",
      "related_images": [
        {
          "digest": "sha256:f1772c36f53aef2748bde670b5aac7fd778a09d0d2b74e7c6287eb5e8fe2873a",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:f1772c36f53aef2748bde670b5aac7fd778a09d0d2b74e7c6287eb5e8fe2873a",
          "name": "openstorage-operator-f1772c36f53aef2748bde670b5aac7fd778a09d0d2b74e7c6287eb5e8fe2873a-annotation"
        },
        {
          "digest": "sha256:f1772c36f53aef2748bde670b5aac7fd778a09d0d2b74e7c6287eb5e8fe2873a",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:f1772c36f53aef2748bde670b5aac7fd778a09d0d2b74e7c6287eb5e8fe2873a",
          "name": "portworx-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.8.0",
      "version_original": "1.8.0"
    },
    {
      "_id": "632842d5316b8eb377f07722",
      "alm_examples": [
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageCluster",
          "metadata": {
            "annotations": {
              "portworx.io/is-openshift": "true"
            },
            "name": "portworx",
            "namespace": "test-operator"
          },
          "spec": {}
        },
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageNode",
          "metadata": {
            "name": "example",
            "namespace": "test-operator"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/portworx/portworx-certified-bundle@sha256:b2c3acedb686c82ba2fd2ea828a841639e063b8f9a054411f4e75b9eaf70a11b",
      "bundle_path_digest": "sha256:b2c3acedb686c82ba2fd2ea828a841639e063b8f9a054411f4e75b9eaf70a11b",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T10:22:13.135000+00:00",
      "csv_description": "Portworx-Enterprise is the most widely-used and reliable cloud-native\nstorage solution for production workloads and provides high-availability,\ndata protection and security for containerized applications.\n\nPortworx Enterprise enables you to migrate entire applications, including\ndata, between clusters in a single data center or cloud, or between clouds,\nwith a single kubectl command.\n\nThe cloud native storage and data management platform that enterprises trust\nto manage data in containers now has an operator which simplifies the install,\nconfiguration, upgrades and manages the Portworx Enterprise cluster lifecycle.\n\nLearn more about the Portworx Enterprise\n[the data platform for Kubernetes](https://portworx.com/products/introduction)\n\nTo learn more about the platform features, please visit our\n[product features page](https://portworx.com/products/features)\n\n### About Portworx\n\nPortworx is the solution for running stateful containers in production,\ndesigned with DevOps in mind. With Portworx, users can manage any database\nor stateful service on any infrastructure using any container scheduler,\nincluding Kubernetes, Mesosphere DC/OS, and Docker Swarm. Portworx solves\nthe five most common problems DevOps teams encounter when running stateful\nservices in production: persistence, high availability, data automation,\nsecurity, and support for multiple data stores and infrastructure.\n\n### How to install StorageCluster\n\nTo customize your cluster's configuration (specification), use the\n[Spec Generator](https://central.portworx.com/) from PX-Central.\n\n### Prerequisite\n\nEnsure ports 17001-17020 on worker nodes are reachable from master and other worker nodes.\n\n### Tutorials\n\n* [Portworx Enterprise on Openshift](https://portworx.com/openshift)\n\n* [Stateful applications on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes/application-install-with-kubernetes)\n\n* [Portworx Enterprise on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes)\n\n* [Kafka on Kubernetes](https://portworx.com/kafka-kubernetes)\n\n* [Elastisearch on Kubernetes](https://portworx.com/elasticsearch-kubernetes)\n\n* [PostgreSQL on Kubernetes](https://portworx.com/postgres-kubernetes/)\n\n* [MongoDB on Kubernetes](https://portworx.com/mongodb-kubernetes/)\n\n* [Cassandra on Kubernetes](https://portworx.com/cassandra-kubernetes/)\n\n* [Kubernetes backup and recovery](https://portworx.com/kubernetes-backup/)\n\n* [Disaster Recovery for Kubernetes](https://portworx.com/kubernetes-disaster-recovery/)\n\n### Uninstall\n\nDeleting the StorageCluster object for Portworx cluster does not stop Portworx\nservice running on the nodes, to avoid application downtime.\n\nTo uninstall Portworx completely without wiping the data, you should add the\nfollowing delete strategy to the StorageCluster spec:\n```\nspec:\n  deleteStrategy:\n    type: Uninstall\n```\n**Caution:** To uninstall Portworx and **wipe all the data**, you should use the following\ndelete strategy:\n```\nspec:\n  deleteStrategy:\n    type: UninstallAndWipe\n```\n",
      "csv_display_name": "Portworx Enterprise",
      "csv_metadata_description": "Cloud native storage solution for production workloads",
      "csv_name": "portworx-operator.v1.8.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:27:44.487000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "portworx-certified",
      "provided_apis": [
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1alpha1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1alpha1"
        }
      ],
      "provider": "Portworx",
      "related_images": [
        {
          "digest": "sha256:f1772c36f53aef2748bde670b5aac7fd778a09d0d2b74e7c6287eb5e8fe2873a",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:f1772c36f53aef2748bde670b5aac7fd778a09d0d2b74e7c6287eb5e8fe2873a",
          "name": "openstorage-operator-f1772c36f53aef2748bde670b5aac7fd778a09d0d2b74e7c6287eb5e8fe2873a-annotation"
        },
        {
          "digest": "sha256:f1772c36f53aef2748bde670b5aac7fd778a09d0d2b74e7c6287eb5e8fe2873a",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:f1772c36f53aef2748bde670b5aac7fd778a09d0d2b74e7c6287eb5e8fe2873a",
          "name": "portworx-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.8.0",
      "version_original": "1.8.0"
    },
    {
      "_id": "632842d78454bee1cb723abe",
      "alm_examples": [
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageCluster",
          "metadata": {
            "annotations": {
              "portworx.io/is-openshift": "true"
            },
            "name": "portworx",
            "namespace": "test-operator"
          },
          "spec": {}
        },
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageNode",
          "metadata": {
            "name": "example",
            "namespace": "test-operator"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/portworx/portworx-certified-bundle@sha256:2a717d5d940a152105e8f5dd46b3e527c19132fec7eb0982955f52c46166dfca",
      "bundle_path_digest": "sha256:2a717d5d940a152105e8f5dd46b3e527c19132fec7eb0982955f52c46166dfca",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T10:22:15.257000+00:00",
      "csv_description": "Portworx-Enterprise is the most widely-used and reliable cloud-native\nstorage solution for production workloads and provides high-availability,\ndata protection and security for containerized applications.\n\nPortworx Enterprise enables you to migrate entire applications, including\ndata, between clusters in a single data center or cloud, or between clouds,\nwith a single kubectl command.\n\nThe cloud native storage and data management platform that enterprises trust\nto manage data in containers now has an operator which simplifies the install,\nconfiguration, upgrades and manages the Portworx Enterprise cluster lifecycle.\n\nLearn more about the Portworx Enterprise\n[the data platform for Kubernetes](https://portworx.com/products/introduction)\n\nTo learn more about the platform features, please visit our\n[product features page](https://portworx.com/products/features)\n\n### About Portworx\n\nPortworx is the solution for running stateful containers in production,\ndesigned with DevOps in mind. With Portworx, users can manage any database\nor stateful service on any infrastructure using any container scheduler,\nincluding Kubernetes, Mesosphere DC/OS, and Docker Swarm. Portworx solves\nthe five most common problems DevOps teams encounter when running stateful\nservices in production: persistence, high availability, data automation,\nsecurity, and support for multiple data stores and infrastructure.\n\n### How to install StorageCluster\n\nTo customize your cluster's configuration (specification), use the\n[Spec Generator](https://central.portworx.com/) from PX-Central.\n\n### Prerequisite\n\nEnsure ports 17001-17020 on worker nodes are reachable from master and other worker nodes.\n\n### Tutorials\n\n* [Portworx Enterprise on Openshift](https://portworx.com/openshift)\n\n* [Stateful applications on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes/application-install-with-kubernetes)\n\n* [Portworx Enterprise on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes)\n\n* [Kafka on Kubernetes](https://portworx.com/kafka-kubernetes)\n\n* [Elastisearch on Kubernetes](https://portworx.com/elasticsearch-kubernetes)\n\n* [PostgreSQL on Kubernetes](https://portworx.com/postgres-kubernetes/)\n\n* [MongoDB on Kubernetes](https://portworx.com/mongodb-kubernetes/)\n\n* [Cassandra on Kubernetes](https://portworx.com/cassandra-kubernetes/)\n\n* [Kubernetes backup and recovery](https://portworx.com/kubernetes-backup/)\n\n* [Disaster Recovery for Kubernetes](https://portworx.com/kubernetes-disaster-recovery/)\n\n### Uninstall\n\nDeleting the StorageCluster object for Portworx cluster does not stop Portworx\nservice running on the nodes, to avoid application downtime.\n\nTo uninstall Portworx completely without wiping the data, you should add the\nfollowing delete strategy to the StorageCluster spec:\n```\nspec:\n  deleteStrategy:\n    type: Uninstall\n```\n**Caution:** To uninstall Portworx and **wipe all the data**, you should use the following\ndelete strategy:\n```\nspec:\n  deleteStrategy:\n    type: UninstallAndWipe\n```\n",
      "csv_display_name": "Portworx Enterprise",
      "csv_metadata_description": "Cloud native storage solution for production workloads",
      "csv_name": "portworx-operator.v1.8.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:27:49.476000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "portworx-certified",
      "provided_apis": [
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1alpha1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1alpha1"
        }
      ],
      "provider": "Portworx",
      "related_images": [
        {
          "digest": "sha256:bb93cb53d57ed8277480f5cfb827b6b2041e639c8fceae2e501e91c201d7e0d9",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:bb93cb53d57ed8277480f5cfb827b6b2041e639c8fceae2e501e91c201d7e0d9",
          "name": "openstorage-operator-bb93cb53d57ed8277480f5cfb827b6b2041e639c8fceae2e501e91c201d7e0d9-annotation"
        },
        {
          "digest": "sha256:bb93cb53d57ed8277480f5cfb827b6b2041e639c8fceae2e501e91c201d7e0d9",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:bb93cb53d57ed8277480f5cfb827b6b2041e639c8fceae2e501e91c201d7e0d9",
          "name": "portworx-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.8.1",
      "version_original": "1.8.1"
    },
    {
      "_id": "632842da8454bee1cb723ac3",
      "alm_examples": [
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageCluster",
          "metadata": {
            "annotations": {
              "portworx.io/is-openshift": "true"
            },
            "name": "portworx",
            "namespace": "test-operator"
          },
          "spec": {}
        },
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageNode",
          "metadata": {
            "name": "example",
            "namespace": "test-operator"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/portworx/portworx-certified-bundle@sha256:b2f671e9b067f3b74de9b7422ac5d73a4251003758431b99133c2f7b905c14dc",
      "bundle_path_digest": "sha256:b2f671e9b067f3b74de9b7422ac5d73a4251003758431b99133c2f7b905c14dc",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T10:22:18.666000+00:00",
      "csv_description": "Portworx-Enterprise is the most widely-used and reliable cloud-native\nstorage solution for production workloads and provides high-availability,\ndata protection and security for containerized applications.\n\nPortworx Enterprise enables you to migrate entire applications, including\ndata, between clusters in a single data center or cloud, or between clouds,\nwith a single kubectl command.\n\nThe cloud native storage and data management platform that enterprises trust\nto manage data in containers now has an operator which simplifies the install,\nconfiguration, upgrades and manages the Portworx Enterprise cluster lifecycle.\n\nLearn more about the Portworx Enterprise\n[the data platform for Kubernetes](https://portworx.com/products/introduction)\n\nTo learn more about the platform features, please visit our\n[product features page](https://portworx.com/products/features)\n\n### About Portworx\n\nPortworx is the solution for running stateful containers in production,\ndesigned with DevOps in mind. With Portworx, users can manage any database\nor stateful service on any infrastructure using any container scheduler,\nincluding Kubernetes, Mesosphere DC/OS, and Docker Swarm. Portworx solves\nthe five most common problems DevOps teams encounter when running stateful\nservices in production: persistence, high availability, data automation,\nsecurity, and support for multiple data stores and infrastructure.\n\n### How to install StorageCluster\n\nTo customize your cluster's configuration (specification), use the\n[Spec Generator](https://central.portworx.com/) from PX-Central.\n\n### Prerequisite\n\nEnsure ports 17001-17020 on worker nodes are reachable from master and other worker nodes.\n\n### Tutorials\n\n* [Portworx Enterprise on Openshift](https://portworx.com/openshift)\n\n* [Stateful applications on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes/application-install-with-kubernetes)\n\n* [Portworx Enterprise on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes)\n\n* [Kafka on Kubernetes](https://portworx.com/kafka-kubernetes)\n\n* [Elastisearch on Kubernetes](https://portworx.com/elasticsearch-kubernetes)\n\n* [PostgreSQL on Kubernetes](https://portworx.com/postgres-kubernetes/)\n\n* [MongoDB on Kubernetes](https://portworx.com/mongodb-kubernetes/)\n\n* [Cassandra on Kubernetes](https://portworx.com/cassandra-kubernetes/)\n\n* [Kubernetes backup and recovery](https://portworx.com/kubernetes-backup/)\n\n* [Disaster Recovery for Kubernetes](https://portworx.com/kubernetes-disaster-recovery/)\n\n### Uninstall\n\nDeleting the StorageCluster object for Portworx cluster does not stop Portworx\nservice running on the nodes, to avoid application downtime.\n\nTo uninstall Portworx completely without wiping the data, you should add the\nfollowing delete strategy to the StorageCluster spec:\n```\nspec:\n  deleteStrategy:\n    type: Uninstall\n```\n**Caution:** To uninstall Portworx and **wipe all the data**, you should use the following\ndelete strategy:\n```\nspec:\n  deleteStrategy:\n    type: UninstallAndWipe\n```\n",
      "csv_display_name": "Portworx Enterprise",
      "csv_metadata_description": "Cloud native storage solution for production workloads",
      "csv_name": "portworx-operator.v1.9.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:27:54.595000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "portworx-certified",
      "provided_apis": [
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1alpha1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1alpha1"
        }
      ],
      "provider": "Portworx",
      "related_images": [
        {
          "digest": "sha256:c1e25a64fd2fe5ca974182b316f6b4677b190ba292a1535af581cb286574703c",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:c1e25a64fd2fe5ca974182b316f6b4677b190ba292a1535af581cb286574703c",
          "name": "openstorage-operator-c1e25a64fd2fe5ca974182b316f6b4677b190ba292a1535af581cb286574703c-annotation"
        },
        {
          "digest": "sha256:c1e25a64fd2fe5ca974182b316f6b4677b190ba292a1535af581cb286574703c",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:c1e25a64fd2fe5ca974182b316f6b4677b190ba292a1535af581cb286574703c",
          "name": "portworx-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.9.0",
      "version_original": "1.9.0"
    },
    {
      "_id": "632842dd1fe6c3c921e6b2e2",
      "alm_examples": [
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageCluster",
          "metadata": {
            "annotations": {
              "portworx.io/is-openshift": "true"
            },
            "name": "portworx",
            "namespace": "test-operator"
          },
          "spec": {}
        },
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageNode",
          "metadata": {
            "name": "example",
            "namespace": "test-operator"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/portworx/portworx-certified-bundle@sha256:d5ac56a6085190ca9ce357395a84e588b0551e6d0a8af46264c91126b1f1e230",
      "bundle_path_digest": "sha256:d5ac56a6085190ca9ce357395a84e588b0551e6d0a8af46264c91126b1f1e230",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T10:22:21.688000+00:00",
      "csv_description": "Portworx-Enterprise is the most widely-used and reliable cloud-native\nstorage solution for production workloads and provides high-availability,\ndata protection and security for containerized applications.\n\nPortworx Enterprise enables you to migrate entire applications, including\ndata, between clusters in a single data center or cloud, or between clouds,\nwith a single kubectl command.\n\nThe cloud native storage and data management platform that enterprises trust\nto manage data in containers now has an operator which simplifies the install,\nconfiguration, upgrades and manages the Portworx Enterprise cluster lifecycle.\n\nLearn more about the Portworx Enterprise\n[the data platform for Kubernetes](https://portworx.com/products/introduction)\n\nTo learn more about the platform features, please visit our\n[product features page](https://portworx.com/products/features)\n\n### About Portworx\n\nPortworx is the solution for running stateful containers in production,\ndesigned with DevOps in mind. With Portworx, users can manage any database\nor stateful service on any infrastructure using any container scheduler,\nincluding Kubernetes, Mesosphere DC/OS, and Docker Swarm. Portworx solves\nthe five most common problems DevOps teams encounter when running stateful\nservices in production: persistence, high availability, data automation,\nsecurity, and support for multiple data stores and infrastructure.\n\n### How to install StorageCluster\n\nTo customize your cluster's configuration (specification), use the\n[Spec Generator](https://central.portworx.com/) from PX-Central.\n\n### Prerequisite\n\nEnsure ports 17001-17020 on worker nodes are reachable from master and other worker nodes.\n\n### Tutorials\n\n* [Portworx Enterprise on Openshift](https://portworx.com/openshift)\n\n* [Stateful applications on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes/application-install-with-kubernetes)\n\n* [Portworx Enterprise on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes)\n\n* [Kafka on Kubernetes](https://portworx.com/kafka-kubernetes)\n\n* [Elastisearch on Kubernetes](https://portworx.com/elasticsearch-kubernetes)\n\n* [PostgreSQL on Kubernetes](https://portworx.com/postgres-kubernetes/)\n\n* [MongoDB on Kubernetes](https://portworx.com/mongodb-kubernetes/)\n\n* [Cassandra on Kubernetes](https://portworx.com/cassandra-kubernetes/)\n\n* [Kubernetes backup and recovery](https://portworx.com/kubernetes-backup/)\n\n* [Disaster Recovery for Kubernetes](https://portworx.com/kubernetes-disaster-recovery/)\n\n### Uninstall\n\nDeleting the StorageCluster object for Portworx cluster does not stop Portworx\nservice running on the nodes, to avoid application downtime.\n\nTo uninstall Portworx completely without wiping the data, you should add the\nfollowing delete strategy to the StorageCluster spec:\n```\nspec:\n  deleteStrategy:\n    type: Uninstall\n```\n**Caution:** To uninstall Portworx and **wipe all the data**, you should use the following\ndelete strategy:\n```\nspec:\n  deleteStrategy:\n    type: UninstallAndWipe\n```\n",
      "csv_display_name": "Portworx Enterprise",
      "csv_metadata_description": "Cloud native storage solution for production workloads",
      "csv_name": "portworx-operator.v1.9.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:28:00.874000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "portworx-certified",
      "provided_apis": [
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1alpha1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1alpha1"
        }
      ],
      "provider": "Portworx",
      "related_images": [
        {
          "digest": "sha256:9971d9ddce03e9c174dbd2acd6904c89b0bdba4a9c61ea5223569bcd2972b089",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:9971d9ddce03e9c174dbd2acd6904c89b0bdba4a9c61ea5223569bcd2972b089",
          "name": "openstorage-operator-9971d9ddce03e9c174dbd2acd6904c89b0bdba4a9c61ea5223569bcd2972b089-annotation"
        },
        {
          "digest": "sha256:9971d9ddce03e9c174dbd2acd6904c89b0bdba4a9c61ea5223569bcd2972b089",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:9971d9ddce03e9c174dbd2acd6904c89b0bdba4a9c61ea5223569bcd2972b089",
          "name": "portworx-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.9.1",
      "version_original": "1.9.1"
    },
    {
      "_id": "632842e0a9c6e63893ae5330",
      "alm_examples": [
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageCluster",
          "metadata": {
            "annotations": {
              "portworx.io/is-openshift": "true"
            },
            "name": "portworx",
            "namespace": "test-operator"
          },
          "spec": {}
        },
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageNode",
          "metadata": {
            "name": "example",
            "namespace": "test-operator"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/portworx/portworx-certified-bundle@sha256:45853a8612cc9da123094499ac975eb2bc943346a0092fe9d892c5942170e77f",
      "bundle_path_digest": "sha256:45853a8612cc9da123094499ac975eb2bc943346a0092fe9d892c5942170e77f",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T10:22:24.183000+00:00",
      "csv_description": "Portworx-Enterprise is the most widely-used and reliable cloud-native\nstorage solution for production workloads and provides high-availability,\ndata protection and security for containerized applications.\n\nPortworx Enterprise enables you to migrate entire applications, including\ndata, between clusters in a single data center or cloud, or between clouds,\nwith a single kubectl command.\n\nThe cloud native storage and data management platform that enterprises trust\nto manage data in containers now has an operator which simplifies the install,\nconfiguration, upgrades and manages the Portworx Enterprise cluster lifecycle.\n\nLearn more about the Portworx Enterprise\n[the data platform for Kubernetes](https://portworx.com/products/introduction)\n\nTo learn more about the platform features, please visit our\n[product features page](https://portworx.com/products/features)\n\n### About Portworx\n\nPortworx is the solution for running stateful containers in production,\ndesigned with DevOps in mind. With Portworx, users can manage any database\nor stateful service on any infrastructure using any container scheduler,\nincluding Kubernetes, Mesosphere DC/OS, and Docker Swarm. Portworx solves\nthe five most common problems DevOps teams encounter when running stateful\nservices in production: persistence, high availability, data automation,\nsecurity, and support for multiple data stores and infrastructure.\n\n### How to install StorageCluster\n\nTo customize your cluster's configuration (specification), use the\n[Spec Generator](https://central.portworx.com/) from PX-Central.\n\n### Prerequisite\n\nEnsure ports 17001-17020 on worker nodes are reachable from master and other worker nodes.\n\n### Tutorials\n\n* [Portworx Enterprise on Openshift](https://portworx.com/openshift)\n\n* [Stateful applications on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes/application-install-with-kubernetes)\n\n* [Portworx Enterprise on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes)\n\n* [Kafka on Kubernetes](https://portworx.com/kafka-kubernetes)\n\n* [Elastisearch on Kubernetes](https://portworx.com/elasticsearch-kubernetes)\n\n* [PostgreSQL on Kubernetes](https://portworx.com/postgres-kubernetes/)\n\n* [MongoDB on Kubernetes](https://portworx.com/mongodb-kubernetes/)\n\n* [Cassandra on Kubernetes](https://portworx.com/cassandra-kubernetes/)\n\n* [Kubernetes backup and recovery](https://portworx.com/kubernetes-backup/)\n\n* [Disaster Recovery for Kubernetes](https://portworx.com/kubernetes-disaster-recovery/)\n\n### Uninstall\n\nDeleting the StorageCluster object for Portworx cluster does not stop Portworx\nservice running on the nodes, to avoid application downtime.\n\nTo uninstall Portworx completely without wiping the data, you should add the\nfollowing delete strategy to the StorageCluster spec:\n```\nspec:\n  deleteStrategy:\n    type: Uninstall\n```\n**Caution:** To uninstall Portworx and **wipe all the data**, you should use the following\ndelete strategy:\n```\nspec:\n  deleteStrategy:\n    type: UninstallAndWipe\n```\n",
      "csv_display_name": "Portworx Enterprise",
      "csv_metadata_description": "Cloud native storage solution for production workloads",
      "csv_name": "portworx-operator.v1.6.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:27:33.799000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "portworx-certified",
      "provided_apis": [
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1alpha1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1alpha1"
        }
      ],
      "provider": "Portworx",
      "related_images": [
        {
          "digest": "sha256:5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47",
          "name": "openstorage-operator-5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47-annotation"
        },
        {
          "digest": "sha256:5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:5d156a64d4ba9aba18cbd6b3c717049e903aac65b6db32189500d50898ca2b47",
          "name": "portworx-operator"
        }
      ],
      "replaces": null,
      "skip_range": "<1.6.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.6.1",
      "version_original": "1.6.1"
    },
    {
      "_id": "632842e2a1826a2016e6fee8",
      "alm_examples": [
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageCluster",
          "metadata": {
            "annotations": {
              "portworx.io/is-openshift": "true"
            },
            "name": "portworx",
            "namespace": "test-operator"
          },
          "spec": {}
        },
        {
          "api_version": "core.libopenstorage.org/v1",
          "kind": "StorageNode",
          "metadata": {
            "name": "example",
            "namespace": "test-operator"
          },
          "spec": {}
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/portworx/portworx-certified-bundle@sha256:6b840a6631b9f345d9a66dc3b57568d2528d08dd78fdd0f5c027bdb49c97a3bd",
      "bundle_path_digest": "sha256:6b840a6631b9f345d9a66dc3b57568d2528d08dd78fdd0f5c027bdb49c97a3bd",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T10:22:26.440000+00:00",
      "csv_description": "Portworx-Enterprise is the most widely-used and reliable cloud-native\nstorage solution for production workloads and provides high-availability,\ndata protection and security for containerized applications.\n\nPortworx Enterprise enables you to migrate entire applications, including\ndata, between clusters in a single data center or cloud, or between clouds,\nwith a single kubectl command.\n\nThe cloud native storage and data management platform that enterprises trust\nto manage data in containers now has an operator which simplifies the install,\nconfiguration, upgrades and manages the Portworx Enterprise cluster lifecycle.\n\nLearn more about the Portworx Enterprise\n[the data platform for Kubernetes](https://portworx.com/products/introduction)\n\nTo learn more about the platform features, please visit our\n[product features page](https://portworx.com/products/features)\n\n### About Portworx\n\nPortworx is the solution for running stateful containers in production,\ndesigned with DevOps in mind. With Portworx, users can manage any database\nor stateful service on any infrastructure using any container scheduler,\nincluding Kubernetes, Mesosphere DC/OS, and Docker Swarm. Portworx solves\nthe five most common problems DevOps teams encounter when running stateful\nservices in production: persistence, high availability, data automation,\nsecurity, and support for multiple data stores and infrastructure.\n\n### How to install StorageCluster\n\nTo customize your cluster's configuration (specification), use the\n[Spec Generator](https://central.portworx.com/) from PX-Central.\n\n### Prerequisite\n\nEnsure ports 17001-17020 on worker nodes are reachable from master and other worker nodes.\n\n### Tutorials\n\n* [Portworx Enterprise on Openshift](https://portworx.com/openshift)\n\n* [Stateful applications on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes/application-install-with-kubernetes)\n\n* [Portworx Enterprise on Kubernetes](https://docs.portworx.com/portworx-install-with-kubernetes)\n\n* [Kafka on Kubernetes](https://portworx.com/kafka-kubernetes)\n\n* [Elastisearch on Kubernetes](https://portworx.com/elasticsearch-kubernetes)\n\n* [PostgreSQL on Kubernetes](https://portworx.com/postgres-kubernetes/)\n\n* [MongoDB on Kubernetes](https://portworx.com/mongodb-kubernetes/)\n\n* [Cassandra on Kubernetes](https://portworx.com/cassandra-kubernetes/)\n\n* [Kubernetes backup and recovery](https://portworx.com/kubernetes-backup/)\n\n* [Disaster Recovery for Kubernetes](https://portworx.com/kubernetes-disaster-recovery/)\n\n### Uninstall\n\nDeleting the StorageCluster object for Portworx cluster does not stop Portworx\nservice running on the nodes, to avoid application downtime.\n\nTo uninstall Portworx completely without wiping the data, you should add the\nfollowing delete strategy to the StorageCluster spec:\n```\nspec:\n  deleteStrategy:\n    type: Uninstall\n```\n**Caution:** To uninstall Portworx and **wipe all the data**, you should use the following\ndelete strategy:\n```\nspec:\n  deleteStrategy:\n    type: UninstallAndWipe\n```\n",
      "csv_display_name": "Portworx Enterprise",
      "csv_metadata_description": "Cloud native storage solution for production workloads",
      "csv_name": "portworx-operator.v1.7.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:27:38.271000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "portworx-certified",
      "provided_apis": [
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageCluster",
          "version": "v1alpha1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1"
        },
        {
          "group": "core.libopenstorage.org",
          "kind": "StorageNode",
          "version": "v1alpha1"
        }
      ],
      "provider": "Portworx",
      "related_images": [
        {
          "digest": "sha256:c4ba573632798d9d78b069a0e396e434e5209abaa4ad82be106c12ad91bb162c",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:c4ba573632798d9d78b069a0e396e434e5209abaa4ad82be106c12ad91bb162c",
          "name": "openstorage-operator-c4ba573632798d9d78b069a0e396e434e5209abaa4ad82be106c12ad91bb162c-annotation"
        },
        {
          "digest": "sha256:c4ba573632798d9d78b069a0e396e434e5209abaa4ad82be106c12ad91bb162c",
          "image": "registry.connect.redhat.com/portworx/openstorage-operator@sha256:c4ba573632798d9d78b069a0e396e434e5209abaa4ad82be106c12ad91bb162c",
          "name": "portworx-operator"
        }
      ],
      "replaces": null,
      "skip_range": "=1.7.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.7.1",
      "version_original": "1.7.1"
    },
    {
      "_id": "632842e4a9c6e63893ae5337",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.5.1"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:73f1f2b6eed8d8653314178f809f6c8028aa4b470d1a441c90b68589abb0d0e7",
      "bundle_path_digest": "sha256:73f1f2b6eed8d8653314178f809f6c8028aa4b470d1a441c90b68589abb0d0e7",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T10:22:28.908000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.9.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:36:07.775000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:11a147d1e8e869a066180dffdcdd629610be81c419c3fda90ab6f3f4fa84453f",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:11a147d1e8e869a066180dffdcdd629610be81c419c3fda90ab6f3f4fa84453f",
          "name": "t8c-operator-11a147d1e8e869a066180dffdcdd629610be81c419c3fda90ab6f3f4fa84453f-annotation"
        },
        {
          "digest": "sha256:11a147d1e8e869a066180dffdcdd629610be81c419c3fda90ab6f3f4fa84453f",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:11a147d1e8e869a066180dffdcdd629610be81c419c3fda90ab6f3f4fa84453f",
          "name": "t8c-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "42.9.0",
      "version_original": "42.9.0"
    },
    {
      "_id": "632842e85ec32701224aa686",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.5.3"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:de272015802808cfe5784f1d1326ccce008179d35f39793bb4a6b92d914bf72f",
      "bundle_path_digest": "sha256:de272015802808cfe5784f1d1326ccce008179d35f39793bb4a6b92d914bf72f",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T10:22:32.257000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.10.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:36:10.202000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "name": "t8c-operator-5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6-annotation"
        },
        {
          "digest": "sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:5721ddea33cb3cdb4562f9f8867fb1a2de8c7bc51db077459054557bd094dfa6",
          "name": "t8c-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "42.10.0",
      "version_original": "42.10.0"
    },
    {
      "_id": "632842ea1fe6c3c921e6b2ef",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.5.7"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:141434b2abef8988f9adb2e07c4674b2beee71041015145b9ffa60de6ca332de",
      "bundle_path_digest": "sha256:141434b2abef8988f9adb2e07c4674b2beee71041015145b9ffa60de6ca332de",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T10:22:34.942000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.12.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:36:13.506000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:d4e3a78203a8afefd98f08d3f339cf66c689eba5e43fdd51a08b6ad1df8c4ca3",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:d4e3a78203a8afefd98f08d3f339cf66c689eba5e43fdd51a08b6ad1df8c4ca3",
          "name": "t8c-operator-d4e3a78203a8afefd98f08d3f339cf66c689eba5e43fdd51a08b6ad1df8c4ca3-annotation"
        },
        {
          "digest": "sha256:d4e3a78203a8afefd98f08d3f339cf66c689eba5e43fdd51a08b6ad1df8c4ca3",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:d4e3a78203a8afefd98f08d3f339cf66c689eba5e43fdd51a08b6ad1df8c4ca3",
          "name": "t8c-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "42.12.0",
      "version_original": "42.12.0"
    },
    {
      "_id": "632842eda9c6e63893ae5343",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Xl",
          "metadata": {
            "name": "xl-release"
          },
          "spec": {
            "global": {
              "customImageNames": false,
              "repository": "registry.connect.redhat.com/turbonomic",
              "tag": "8.5.7"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/t8c-operator-bundle@sha256:c5c898eff1a7189cd0e748bdcc08a40b5a05d23cd69d86a9716c0435b8719ec9",
      "bundle_path_digest": "sha256:c5c898eff1a7189cd0e748bdcc08a40b5a05d23cd69d86a9716c0435b8719ec9",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T10:22:37.724000+00:00",
      "csv_description": "### Realtime Decision Automation for Multicloud Applications\nTurbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints:\n* Continuous placement of workload across multiple clouds both on-prem and public clouds providers.\n* Continuous scaling for applications and the underlying infrastructure.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a public APIs already exposed by application and infrastructure instrumentation to discover and monitor your environment.\nTurbonomic determines the right actions that drive continuous health, including continuous placement and continuous scaling for applications and the underlying cluster.\nTurbonomic leverages the built-on orchestration provided by the application and infrastructure deployment tools and automates the execution of these actions to continiously meet the respective service level objective of each application service.",
      "csv_display_name": "Turbonomic Platform Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "t8c-operator.v42.13.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-21T21:33:32.813000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "t8c-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Xl",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:ecf118a07bd533a95e93c67b48aaa0ba442be529c23af50e7a835ab710696195",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:ecf118a07bd533a95e93c67b48aaa0ba442be529c23af50e7a835ab710696195",
          "name": "t8c-operator-ecf118a07bd533a95e93c67b48aaa0ba442be529c23af50e7a835ab710696195-annotation"
        },
        {
          "digest": "sha256:ecf118a07bd533a95e93c67b48aaa0ba442be529c23af50e7a835ab710696195",
          "image": "registry.connect.redhat.com/turbonomic/t8c-operator@sha256:ecf118a07bd533a95e93c67b48aaa0ba442be529c23af50e7a835ab710696195",
          "name": "t8c-operator"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "42.13.0",
      "version_original": "42.13.0"
    },
    {
      "_id": "632842f0703b1887dc1c7517",
      "alm_examples": [
        {
          "api_version": "ezmeral.hpe.com/v1",
          "kind": "HPEEzmeralCSIDriver",
          "metadata": {
            "name": "hpeezmeralcsidriver"
          },
          "spec": {
            "controllerImage": "registry.connect.redhat.com/maprtech/csi-kdfprovisioner@sha256:89a397c26960ba05542ac069e3a47059bced2bc958cfff4aa0f1eb081fab5d42",
            "nodeImage": "registry.connect.redhat.com/maprtech/csi-kdfplugin@sha256:480b6fb8b2501caa76013c94feac91bef7f9b5ae6ad0b286ec621fd6a9ce4bef",
            "pullPolicy": "Always"
          }
        },
        {
          "api_version": "ezmeral.hpe.com/v1",
          "kind": "HPEEzmeralNFSCSIDriver",
          "metadata": {
            "name": "hpeezmeralnfscsidriver"
          },
          "spec": {
            "controllerImage": "registry.connect.redhat.com/maprtech/csi-kdfprovisioner@sha256:89a397c26960ba05542ac069e3a47059bced2bc958cfff4aa0f1eb081fab5d42",
            "nodeImage": "registry.connect.redhat.com/maprtech/csi-nfsplugin@sha256:35c275363a6949fed56b8ddfe3886ed42a6267fb07271494d8367abbd4d8c822",
            "pullPolicy": "Always"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/maprtech/hpe-ezmeral-csi-operator-bundle@sha256:b23ef079d0bcbeaa227a0d759c900c103f97310ad2e00a566a74b100f95a37ff",
      "bundle_path_digest": "sha256:b23ef079d0bcbeaa227a0d759c900c103f97310ad2e00a566a74b100f95a37ff",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T10:22:40.908000+00:00",
      "csv_description": "The HPE Ezmeral CSI Operator for Kubernetes packages, deploys, manages, upgrades the HPE Ezmeral CSI Driver on Kubernetes and OpenShift for dynamic provisioning of persistent volumes on HPE Ezmeral Data Fabric platform.\nThe HPE Ezmeral CSI Driver for Kubernetes leverages HPE Ezmeral Data Fabric platform to provide scalable and persistent storage for stateful applications. Please refer to our CSI driver [documentation](https://docs.datafabric.hpe.com/home/CSIdriver/csi_overview.html) for full list of supported CSI features.\n## Installation\nRefer to the HPE Ezmeral CSI Operator for Kubernetes [documentation](https://docs.datafabric.hpe.com/home/CSIdriver/csi_installing_operator.html)\n",
      "csv_display_name": "HPE Ezmeral Data Fabric CSI Operator for Kubernetes",
      "csv_metadata_description": "A Container Storage Interface (CSI) driver for HPE Ezmeral Data Fabric platform. The CSI driver allows you to use HPE Ezmeral Data Fabric with your preferred container orchestrator.",
      "csv_name": "hpe-ezmeral-csi-operator.v1.0.9",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:33:43.391000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "hpe-ezmeral-csi-operator",
      "provided_apis": [
        {
          "group": "ezmeral.hpe.com",
          "kind": "HPEEzmeralCSIDriver",
          "version": "v1"
        },
        {
          "group": "ezmeral.hpe.com",
          "kind": "HPEEzmeralNFSCSIDriver",
          "version": "v1"
        }
      ],
      "provider": "HPE Ezmeral",
      "related_images": [
        {
          "digest": "sha256:82f52179dcd59a1e16f249bcd21f7aae22c09e84f24b479a923fef2adee45c7f",
          "image": "registry.connect.redhat.com/maprtech/hpe-ezmeral-csi-operator@sha256:82f52179dcd59a1e16f249bcd21f7aae22c09e84f24b479a923fef2adee45c7f",
          "name": "hpe-ezmeral-csi-operator-82f52179dcd59a1e16f249bcd21f7aae22c09e84f24b479a923fef2adee45c7f-annotation"
        },
        {
          "digest": "sha256:82f52179dcd59a1e16f249bcd21f7aae22c09e84f24b479a923fef2adee45c7f",
          "image": "registry.connect.redhat.com/maprtech/hpe-ezmeral-csi-operator@sha256:82f52179dcd59a1e16f249bcd21f7aae22c09e84f24b479a923fef2adee45c7f",
          "name": "hpe-ezmeral-csi-operator"
        },
        {
          "digest": "sha256:35c275363a6949fed56b8ddfe3886ed42a6267fb07271494d8367abbd4d8c822",
          "image": "registry.connect.redhat.com/maprtech/csi-nfsplugin@sha256:35c275363a6949fed56b8ddfe3886ed42a6267fb07271494d8367abbd4d8c822",
          "name": "csi-nfsplugin-35c275363a6949fed56b8ddfe3886ed42a6267fb07271494d8367abbd4d8c822-annotation"
        },
        {
          "digest": "sha256:89a397c26960ba05542ac069e3a47059bced2bc958cfff4aa0f1eb081fab5d42",
          "image": "registry.connect.redhat.com/maprtech/csi-kdfprovisioner@sha256:89a397c26960ba05542ac069e3a47059bced2bc958cfff4aa0f1eb081fab5d42",
          "name": "csi-kdfprovisioner-89a397c26960ba05542ac069e3a47059bced2bc958cfff4aa0f1eb081fab5d42-annotation"
        },
        {
          "digest": "sha256:480b6fb8b2501caa76013c94feac91bef7f9b5ae6ad0b286ec621fd6a9ce4bef",
          "image": "registry.connect.redhat.com/maprtech/csi-kdfplugin@sha256:480b6fb8b2501caa76013c94feac91bef7f9b5ae6ad0b286ec621fd6a9ce4bef",
          "name": "csi-kdfplugin-480b6fb8b2501caa76013c94feac91bef7f9b5ae6ad0b286ec621fd6a9ce4bef-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.0.9",
      "version_original": "1.0.9"
    },
    {
      "_id": "632842f4eb69678e80bd1eea",
      "alm_examples": [
        {
          "api_version": "modelbuilder.com/v1alpha1",
          "kind": "Modelbuilder",
          "metadata": {
            "name": "modelbuilder-sample"
          },
          "spec": {
            "backup_storage": {
              "storage#": "20G",
              "storage_class": "ibmc-file-gold-gid"
            },
            "email_notification": {
              "accept": true,
              "vm_mail_recipient": ""
            },
            "env_type": "prod",
            "in_memory_storage": {
              "storage#": "20G",
              "storage_class": "ibmc-file-gold-gid"
            },
            "license": {
              "accept": false
            },
            "metadata_storage": {
              "storage#": "20G",
              "storage_class": "ibmc-block-bronze"
            },
            "photo_storage": {
              "storage#": "500G",
              "storage_class": "ibmc-file-gold-gid"
            },
            "vm_request_method": "dynamic"
          }
        },
        {
          "api_version": "modelbuilder.com/v1alpha1",
          "kind": "ModelbuilderAWS",
          "metadata": {
            "name": "modelbuilder-aws-sample"
          },
          "spec": {
            "email_notification": {
              "accept": true,
              "vm_mail_recipient": ""
            },
            "env_type": "prod",
            "license": {
              "accept": false
            },
            "postgres": {
              "backup_storage#": "20G",
              "storage#": "20G",
              "storage_class": "gp2"
            },
            "vm_request_method": "dynamic"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/modelbuilder-bundle@sha256:4940d853ba477aeeec99550c35c132b69bab8bd7b6fbc1a2fe118c828c7ba088",
      "bundle_path_digest": "sha256:4940d853ba477aeeec99550c35c132b69bab8bd7b6fbc1a2fe118c828c7ba088",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T10:22:44.246000+00:00",
      "csv_description": "IBM Services Software Model Builder for Vision is an AI training platform that can use the capabilities of IBM Cloud and Amazon Web Services and their GPUs to quickly train computer vision models for compatible mobile apps. IBM Services Software Inspection Workbench iOS and iPadOS app will be used as the exclusive UI for labeling and training. Specifically, IBM Model Builder for Vision will train computer vision models that can then be deployed for use on the IBM Services Software Inspector Portable , IBM Services Software Inspector Wearable and the IBM Maximo Visual Inspection Mobile apps.",
      "csv_display_name": "IBM Model Builder for Vision",
      "csv_metadata_description": "",
      "csv_name": "ibm-modelbuilder-for-vision.v1.0.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:30:43.062000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "model-builder-for-vision-certified",
      "provided_apis": [
        {
          "group": "modelbuilder.com",
          "kind": "Modelbuilder",
          "version": "v1alpha1"
        },
        {
          "group": "modelbuilder.com",
          "kind": "ModelbuilderAWS",
          "version": "v1alpha1"
        }
      ],
      "provider": "IBM",
      "related_images": [
        {
          "digest": "sha256:96f4c45f82152ebbdd2b067a6dd8749c5572e00106142725a16ae30a3e09d2d0",
          "image": "registry.connect.redhat.com/ibm/modelbuilder-operator@sha256:96f4c45f82152ebbdd2b067a6dd8749c5572e00106142725a16ae30a3e09d2d0",
          "name": "modelbuilder-operator-96f4c45f82152ebbdd2b067a6dd8749c5572e00106142725a16ae30a3e09d2d0-annotation"
        },
        {
          "digest": "sha256:96f4c45f82152ebbdd2b067a6dd8749c5572e00106142725a16ae30a3e09d2d0",
          "image": "registry.connect.redhat.com/ibm/modelbuilder-operator@sha256:96f4c45f82152ebbdd2b067a6dd8749c5572e00106142725a16ae30a3e09d2d0",
          "name": "modelbuilder"
        },
        {
          "digest": "sha256:d4c60531f59953f399c6a2b0f8239128cdc2640f72f2d1e9ac4d6add618f9f01",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:d4c60531f59953f399c6a2b0f8239128cdc2640f72f2d1e9ac4d6add618f9f01",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:82d171ab0ce78a0157408662155b53d4f637947a303bfecb684f6132f5f468be",
          "image": "registry.redhat.io/rhel8/postgresql-12@sha256:82d171ab0ce78a0157408662155b53d4f637947a303bfecb684f6132f5f468be",
          "name": "postgres_cli"
        },
        {
          "digest": "sha256:ef5d0dde3eb334d919c2773af63007f1ef5e735ae040ef77fffe3440f854f068",
          "image": "registry.connect.redhat.com/ibm/modelbuilder-augmentor@sha256:ef5d0dde3eb334d919c2773af63007f1ef5e735ae040ef77fffe3440f854f068",
          "name": "coreml_augmentor"
        },
        {
          "digest": "sha256:ecdb665af651417c50335e7259b89ef8096521abec431976bd7abe4c1edc49d6",
          "image": "registry.connect.redhat.com/ibm/modelbuilder-image-server@sha256:ecdb665af651417c50335e7259b89ef8096521abec431976bd7abe4c1edc49d6",
          "name": "nginx"
        },
        {
          "digest": "sha256:f96b444fdcf7781775c9eba942bcc5e5ebdcf5f50820447f5eb26061c4c674cd",
          "image": "registry.connect.redhat.com/ibm/modelbuilder-auth-service@sha256:f96b444fdcf7781775c9eba942bcc5e5ebdcf5f50820447f5eb26061c4c674cd",
          "name": "mb_auth_coreml"
        },
        {
          "digest": "sha256:c3c9080b08b87022c784fd98ac3e2774ec89ce29a2dd19d91dee039e3fdb2b36",
          "image": "registry.connect.redhat.com/ibm/modelbuilder-cv-training-service@sha256:c3c9080b08b87022c784fd98ac3e2774ec89ce29a2dd19d91dee039e3fdb2b36",
          "name": "mb_service_coreml"
        },
        {
          "digest": "sha256:2f65f46b25d84a3cb41a6a10f93786bcab47b7354ca9ac13a8e602ea833eba60",
          "image": "registry.redhat.io/rhel8/redis-6@sha256:2f65f46b25d84a3cb41a6a10f93786bcab47b7354ca9ac13a8e602ea833eba60",
          "name": "redis"
        },
        {
          "digest": "sha256:0ec55c7f25c24f786978e045e8a67facb965a08dd519d06c82de05dd15e0f4a1",
          "image": "registry.connect.redhat.com/ibm/modelbuilder-util@sha256:0ec55c7f25c24f786978e045e8a67facb965a08dd519d06c82de05dd15e0f4a1",
          "name": "util"
        }
      ],
      "replaces": null,
      "skip_range": "<1.0.3",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.0.3",
      "version_original": "1.0.3"
    },
    {
      "_id": "632842f62dd1cd9660afbab9",
      "alm_examples": [
        {
          "api_version": "triliovault.trilio.io/v1",
          "kind": "License",
          "metadata": {
            "name": "tvk-license-one",
            "namespace": "openshift-marketplace"
          },
          "spec": {
            "key": "xLkNDgwKD3jafZJNb8IwDIbv+RWRdo6Uj5a2SD1MwKRtjE0bsLOTuiISpFWaovHv145NQy3iPcb249d27j6xoE/tnkpJOZ/KaBrFVHLJycwjBFu5OQSk/8r7IOMJk5IsCttn0IHyB4+49hb2BEywR6SjjOBbJHtr0DW4Rd9cUnJJXsC6gA6cwcVXbf3pbKLvrRhPmersVYca3GlEfsdiB4Gs2oNG/1pumo5+EWaCfKA/on+cDysh5gWokjOjU8WEQGBaQMSM0DrDiTKTpCterOgV5d07+wXIm4Dleehh+3y9vd8s138MdduEqWq8YsLBAZsaDBbkudW4Gc1Ic56ITHMwrEwTwSIlY5bqLGGGx1kW6QQzUZKfncPotJfrf2u92UGDN37HDDorNgxPlAtOe3d0VRXYfAMj8ZzrMEYCIQCVaI/QJN+2M/QJWimd28dWOi/6o5s5I5+z30JrmzwGnQIhAKrSu8NeUIqXGEBTQvPKe3n2U0LNPht/ZAQIs5CZNeWlX02gk"
          }
        },
        {
          "api_version": "triliovault.trilio.io/v1",
          "kind": "Target",
          "metadata": {
            "labels": {
              "app": "triliovault"
            },
            "name": "triliovault-target",
            "namespace": "openshift-marketplace"
          },
          "spec": {
            "nfsCredentials": {
              "nfsExport": "00.00.00.00:/src/nfs/kubedata",
              "nfsOptions": "nfsvers=4"
            },
            "type": "NFS",
            "vendor": "Other"
          }
        },
        {
          "api_version": "triliovault.trilio.io/v1",
          "kind": "BackupPlan",
          "metadata": {
            "name": "tvk-backupplan"
          },
          "spec": {
            "backupConfig": {
              "retentionPolicy": {
                "name": "retention-policy",
                "namespace": "openshift-marketplace"
              },
              "schedulePolicy": {
                "fullBackupPolicy": {
                  "name": "full-bp-policy",
                  "namespace": "openshift-marketplace"
                },
                "incrementalBackupPolicy": {
                  "name": "inc-bp-policy",
                  "namespace": "openshift-marketplace"
                }
              },
              "target": {
                "name": "triliovault-target",
                "namespace": "openshift-marketplace"
              }
            },
            "backupPlanComponents": {
              "custom": [
                {
                  "matchLabels": {
                    "app": "nginx"
                  }
                }
              ],
              "helmReleases": [
                "sample-release"
              ],
              "operators": [
                {
                  "applicationResourceSelector": [
                    {
                      "matchLabels": {
                        "app": "etcd"
                      }
                    }
                  ],
                  "customResources": [
                    {
                      "groupVersionKind": {
                        "group": "etcd.database.coreos.com",
                        "kind": "EtcdCluster",
                        "version": "v1beta2"
                      },
                      "objects": [
                        "demo-etcd-cluster"
                      ]
                    }
                  ],
                  "operatorId": "demo-etcd-cluster",
                  "operatorResourceSelector": [
                    {
                      "matchLabels": {
                        "release": "demo-etcd-operator"
                      }
                    }
                  ]
                }
              ]
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [
        "ppc64le"
      ],
      "bundle_path": "registry.connect.redhat.com/trilio/k8s-triliovault-ibm@sha256:85bdda572f98163d5e84adddb0ca47fb183ecd2cbeaa2ff0e905387c4d8f3d2d",
      "bundle_path_digest": "sha256:85bdda572f98163d5e84adddb0ca47fb183ecd2cbeaa2ff0e905387c4d8f3d2d",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T10:22:46.991000+00:00",
      "csv_description": "TrilioVault for Kubernetes is an enterprise-grade, cloud-native platform purpose built for data protection and management of Kubernetes applications for IT managers, administrators and developers. TrilioVault supports upstream Kubernetes and OpenShift environments and offers the following features:\n  * Application-Centric - protects both data and metadata for Helm, Operator or custom Label based applications.\n  * Red Hat Certified - first backup and recovery solution with OpenShift Operator Certification.\n  * Native to Kubernetes & OpenShift: Packaged and deployed as an Operator, integrated via Kubernetes API and with all features that it provides.\n  * Infrastructure Agnostic: Compatible with any Storage (CSI, NFS, S3), or any Cloud (Private or Public).\n  * Application Deployment & Tooling: Helm, Operators, Labels, Prometheus, Fluentd.\nTutorials\n------------\nPlease click the link below to access the TrilioVault for Kubernetes \"How-To\" series for deployment, best practice and use-case videos\n<a href=\"https://www.trilio.io/triliovault-for-kubernetes\">TrilioVault for Kubernetes - Tutorials and How-To </a>\u201d\nLicensing\n--------\nCustomers can download a 30-day Free Trial or a 10-node Basic Edition at no cost.  You can also connect with the Trilio team for an Enterprise Edition license with no limitations and Premium Support.\nFor more information on license plans please vist:\n<a href=\"www.trilio.io/plans\"> Trilio Vault for Kubernetes licensing and plans </a>\nAbout Trilio\n----------------\nTrilio is trusted by global cloud infrastructure operators to deliver data protection, application resiliency, infrastructure migration and infrastructure version management. Our TrilioVault technology supports Kubernetes, OpenStack and Virtualization environments to recover from disasters, migrate tenant workloads, move workloads to new infrastructures and migrate to new infrastructure software distributions. www.trilio.io and @triliodata on Twitter.",
      "csv_display_name": "TrilioVault for Kubernetes",
      "csv_metadata_description": "Cloud-Native Data Protection for Kubernetes",
      "csv_name": "k8s-triliovault-ibm-stable.2.7.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:26:51.212000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "k8s-triliovault-ibm",
      "provided_apis": [
        {
          "group": "triliovault.trilio.io",
          "kind": "Backup",
          "version": "v1"
        },
        {
          "group": "triliovault.trilio.io",
          "kind": "BackupPlan",
          "version": "v1"
        },
        {
          "group": "triliovault.trilio.io",
          "kind": "ClusterBackup",
          "version": "v1"
        },
        {
          "group": "triliovault.trilio.io",
          "kind": "ClusterBackupPlan",
          "version": "v1"
        },
        {
          "group": "triliovault.trilio.io",
          "kind": "ClusterRestore",
          "version": "v1"
        },
        {
          "group": "triliovault.trilio.io",
          "kind": "Hook",
          "version": "v1"
        },
        {
          "group": "triliovault.trilio.io",
          "kind": "License",
          "version": "v1"
        },
        {
          "group": "triliovault.trilio.io",
          "kind": "Policy",
          "version": "v1"
        },
        {
          "group": "triliovault.trilio.io",
          "kind": "Restore",
          "version": "v1"
        },
        {
          "group": "triliovault.trilio.io",
          "kind": "Target",
          "version": "v1"
        }
      ],
      "provider": "Trilio",
      "related_images": [
        {
          "digest": "sha256:1eea5404a92bf1a408559d3b7f7ac700f4df5559ce5e4737db866804930d720a",
          "image": "eu.gcr.io/amazing-chalice-243510/control-plane@sha256:1eea5404a92bf1a408559d3b7f7ac700f4df5559ce5e4737db866804930d720a",
          "name": "control-plane-1eea5404a92bf1a408559d3b7f7ac700f4df5559ce5e4737db866804930d720a-annotation"
        },
        {
          "digest": "sha256:1eea5404a92bf1a408559d3b7f7ac700f4df5559ce5e4737db866804930d720a",
          "image": "eu.gcr.io/amazing-chalice-243510/control-plane@sha256:1eea5404a92bf1a408559d3b7f7ac700f4df5559ce5e4737db866804930d720a",
          "name": "k8s-triliovault-control-plane"
        },
        {
          "digest": "sha256:8a1f8d4ef507034e9210f49cf6d20a42e18a480bff9974ac73efd35438610ba8",
          "image": "eu.gcr.io/amazing-chalice-243510/analyzer@sha256:8a1f8d4ef507034e9210f49cf6d20a42e18a480bff9974ac73efd35438610ba8",
          "name": "k8s-triliovault-analyzer"
        },
        {
          "digest": "sha256:b1318b3e0ee719ae183a48a1876f158862f958e9c85fadb672ccab3de5593311",
          "image": "eu.gcr.io/amazing-chalice-243510/trilio-admission-webhook@sha256:b1318b3e0ee719ae183a48a1876f158862f958e9c85fadb672ccab3de5593311",
          "name": "triliovault-admission-webhook"
        },
        {
          "digest": "sha256:3900293f0afbd3c594136768b89b3233611b115918ede5834eb8eab7ac5c3f70",
          "image": "eu.gcr.io/amazing-chalice-243510/exporter@sha256:3900293f0afbd3c594136768b89b3233611b115918ede5834eb8eab7ac5c3f70",
          "name": "triliovault-exporter"
        },
        {
          "digest": "sha256:0c0691485ff10b2318ce378fcb37a77130db556d8cba9f895a6bf6814774b604",
          "image": "eu.gcr.io/amazing-chalice-243510/web@sha256:0c0691485ff10b2318ce378fcb37a77130db556d8cba9f895a6bf6814774b604",
          "name": "triliovault-web"
        },
        {
          "digest": "sha256:c66c43fde40f9bf910b56c519d09cea3509de03973c6962ae57ceb3e924a9542",
          "image": "eu.gcr.io/amazing-chalice-243510/web-backend@sha256:c66c43fde40f9bf910b56c519d09cea3509de03973c6962ae57ceb3e924a9542",
          "name": "triliovault-web-backend"
        },
        {
          "digest": "sha256:040caf348ac11511b63271dd473bf31bf1d96d3e0fcbfc40e6d1bf4df2bb0f76",
          "image": "eu.gcr.io/amazing-chalice-243510/dex@sha256:040caf348ac11511b63271dd473bf31bf1d96d3e0fcbfc40e6d1bf4df2bb0f76",
          "name": "triliovault-dex"
        },
        {
          "digest": "sha256:73dd29b19b61a8fea3c4b94c7e479a5bc4546abf00deb35d47341b83246abf62",
          "image": "eu.gcr.io/amazing-chalice-243510/trilio-init@sha256:73dd29b19b61a8fea3c4b94c7e479a5bc4546abf00deb35d47341b83246abf62",
          "name": "webhook-init"
        },
        {
          "digest": "sha256:73dd29b19b61a8fea3c4b94c7e479a5bc4546abf00deb35d47341b83246abf62",
          "image": "eu.gcr.io/amazing-chalice-243510/trilio-init@sha256:73dd29b19b61a8fea3c4b94c7e479a5bc4546abf00deb35d47341b83246abf62",
          "name": "dex-init"
        },
        {
          "digest": "sha256:dc868ce5d6aa0f0fb194af84951f3e22922aa523f17ca1d7174441d72022cb77",
          "image": "eu.gcr.io/amazing-chalice-243510/metamover@sha256:dc868ce5d6aa0f0fb194af84951f3e22922aa523f17ca1d7174441d72022cb77",
          "name": "metamover"
        },
        {
          "digest": "sha256:222b9317935dd19e9a333520bdf0b1f68d9768880bce6f482cb1b2250806da76",
          "image": "eu.gcr.io/amazing-chalice-243510/datamover@sha256:222b9317935dd19e9a333520bdf0b1f68d9768880bce6f482cb1b2250806da76",
          "name": "datamover"
        },
        {
          "digest": "sha256:806090cc5ac8a65fcc5e90d82143dc7df230f742c29ff1c21e685bb49879aaa7",
          "image": "eu.gcr.io/amazing-chalice-243510/datastore-attacher@sha256:806090cc5ac8a65fcc5e90d82143dc7df230f742c29ff1c21e685bb49879aaa7",
          "name": "datastore_attacher"
        },
        {
          "digest": "sha256:8b3f03459aedfb7829dad4c2e9f731d2f11abf9ba38319c3d2f0d8303a642c5e",
          "image": "eu.gcr.io/amazing-chalice-243510/backup-scheduler@sha256:8b3f03459aedfb7829dad4c2e9f731d2f11abf9ba38319c3d2f0d8303a642c5e",
          "name": "backup_scheduler"
        },
        {
          "digest": "sha256:e687443babeb3b9850aa3050b6c6935976358bcdea66666fb79b487ee35c5c25",
          "image": "eu.gcr.io/amazing-chalice-243510/backup-cleaner@sha256:e687443babeb3b9850aa3050b6c6935976358bcdea66666fb79b487ee35c5c25",
          "name": "backup_cleaner"
        },
        {
          "digest": "sha256:3eb71f17b6b04a7207f3cc921f29cd070993402d951aa940a6c0be61733fe958",
          "image": "eu.gcr.io/amazing-chalice-243510/backup-retention@sha256:3eb71f17b6b04a7207f3cc921f29cd070993402d951aa940a6c0be61733fe958",
          "name": "backup_retention"
        },
        {
          "digest": "sha256:6729338fadd130c21e830fc9c5dacb4efae3ffb37427c415d377ee7c8f152872",
          "image": "eu.gcr.io/amazing-chalice-243510/target-browser@sha256:6729338fadd130c21e830fc9c5dacb4efae3ffb37427c415d377ee7c8f152872",
          "name": "target_browser"
        },
        {
          "digest": "sha256:7a76cad51eab8ceb492426507cf6c92ed90047184ae2a8d0ce6c2e1a57762078",
          "image": "eu.gcr.io/amazing-chalice-243510/hook-executor@sha256:7a76cad51eab8ceb492426507cf6c92ed90047184ae2a8d0ce6c2e1a57762078",
          "name": "hook"
        },
        {
          "digest": "sha256:08b4bb891506388fe6bc96490c3ee8117a2c4b7f99919e2e8a5333d2bc12ee5d",
          "image": "eu.gcr.io/amazing-chalice-243510/resource-cleaner@sha256:08b4bb891506388fe6bc96490c3ee8117a2c4b7f99919e2e8a5333d2bc12ee5d",
          "name": "resource_cleaner"
        },
        {
          "digest": "sha256:6015efd6fe0f935ee77588573d1f1e8c4a4d453d27e6925ef1c89fbab0aa1068",
          "image": "eu.gcr.io/amazing-chalice-243510/minio@sha256:6015efd6fe0f935ee77588573d1f1e8c4a4d453d27e6925ef1c89fbab0aa1068",
          "name": "minio"
        },
        {
          "digest": "sha256:040caf348ac11511b63271dd473bf31bf1d96d3e0fcbfc40e6d1bf4df2bb0f76",
          "image": "eu.gcr.io/amazing-chalice-243510/dex@sha256:040caf348ac11511b63271dd473bf31bf1d96d3e0fcbfc40e6d1bf4df2bb0f76",
          "name": "dex"
        },
        {
          "digest": "sha256:73dd29b19b61a8fea3c4b94c7e479a5bc4546abf00deb35d47341b83246abf62",
          "image": "eu.gcr.io/amazing-chalice-243510/trilio-init@sha256:73dd29b19b61a8fea3c4b94c7e479a5bc4546abf00deb35d47341b83246abf62",
          "name": "tvk_init"
        }
      ],
      "replaces": null,
      "skip_range": "<2.7.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "2.7.0",
      "version_original": "2.7.0"
    },
    {
      "_id": "632842f9d1a8ccdba1fb07c3",
      "alm_examples": [
        {
          "api_version": "cache.omarg.net/v1alpha1",
          "kind": "Memcached",
          "metadata": {
            "name": "memcached-sample"
          },
          "spec": {
            "foo": "bar"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ogaye/ogaye@sha256:f35a21fb3936b259aabe27b453612616fca4e6327c9042361b4d00ef332905c0",
      "bundle_path_digest": "sha256:f35a21fb3936b259aabe27b453612616fca4e6327c9042361b4d00ef332905c0",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:22:49.744000+00:00",
      "csv_description": "Omar memcached operator",
      "csv_display_name": "memcached-operator-ogaye",
      "csv_metadata_description": "",
      "csv_name": "memcached-operator.v0.0.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:29:28.774000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "memcached-operator-ogaye",
      "provided_apis": [
        {
          "group": "cache.omarg.net",
          "kind": "Memcached",
          "version": "v1alpha1"
        }
      ],
      "provider": "Omar Gaye IBM",
      "related_images": [
        {
          "digest": "sha256:9211b70edbb93d718428e1c9a992e5fc74a20cb213f8a0592ffe340c362890fe",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:9211b70edbb93d718428e1c9a992e5fc74a20cb213f8a0592ffe340c362890fe",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:5340ac11ce676dd3204bf3807a4c2333a8dddcbcec918db0aeafbc977163c1c6",
          "image": "quay.io/ogaye/memcached-operator@sha256:5340ac11ce676dd3204bf3807a4c2333a8dddcbcec918db0aeafbc977163c1c6",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "0.0.1",
      "version_original": "0.0.1"
    },
    {
      "_id": "632842fba9c6e63893ae5351",
      "alm_examples": [
        {
          "api_version": "apm.neuvector.com/v1alpha1",
          "kind": "Neuvector",
          "metadata": {
            "name": "neuvector"
          },
          "spec": {
            "admissionwebhook": {
              "type": "ClusterIP"
            },
            "bottlerocket": {
              "enabled": false,
              "runtimePath": "/run/dockershim.sock"
            },
            "containerd": {
              "enabled": false,
              "path": "/var/run/containerd/containerd.sock"
            },
            "controller": {
              "apisvc": {
                "annotations": {},
                "route": {
                  "enabled": false,
                  "host": "",
                  "termination": "passthrough"
                },
                "type": ""
              },
              "azureFileShare": {
                "enabled": false,
                "secretName": "",
                "shareName": ""
              },
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "configmap": {
                "data": "",
                "enabled": false
              },
              "disruptionbudget": 0,
              "enabled": true,
              "federation": {
                "managedsvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                },
                "mastersvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                }
              },
              "image": "registry.connect.redhat.com/neuvector/controller",
              "ingress": {
                "annotations": {
                  "ingress.kubernetes.io/protocol": "https"
                },
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "priorityClassName": "",
              "pvc": {
                "accessModes": [
                  "ReadWriteMany"
                ],
                "capacity": "",
                "enabled": false,
                "storageClass": ""
              },
              "replicas": 3,
              "resources": {},
              "schedulerName": "",
              "strategy": {
                "rollingUpdate": {
                  "maxSurge": 1,
                  "maxUnavailable": 0
                },
                "type": "RollingUpdate"
              }
            },
            "crdwebhook": {
              "enabled": true,
              "type": "ClusterIP"
            },
            "crio": {
              "enabled": true,
              "path": "/var/run/crio/crio.sock"
            },
            "cve": {
              "scanner": {
                "dockerPath": "",
                "enabled": true,
                "image": "registry.connect.redhat.com/neuvector/scanner@sha256:5f2d23d20f9ea5d1d3bc56b758ddc3f3b4f57a9db47c7cc95e74f6d7a4072e00",
                "priorityClassName": "",
                "replicas": 3,
                "resources": {},
                "strategy": {
                  "rollingUpdate": {
                    "maxSurge": 1,
                    "maxUnavailable": 0
                  },
                  "type": "RollingUpdate"
                }
              },
              "updater": {
                "enabled": true,
                "image": "registry.access.redhat.com/ubi8@sha256:910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7",
                "priorityClassName": "",
                "schedule": "0 0 * * *",
                "secure": false
              }
            },
            "docker": {
              "enabled": false,
              "path": "/var/run/docker.sock"
            },
            "enforcer": {
              "enabled": true,
              "image": "registry.connect.redhat.com/neuvector/enforcer",
              "priorityClassName": "",
              "resources": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                }
              ]
            },
            "k3s": {
              "enabled": false,
              "runtimePath": "/run/k3s/containerd/containerd.sock"
            },
            "manager": {
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "enabled": true,
              "env": {
                "ssl": true
              },
              "image": "registry.connect.redhat.com/neuvector/manager",
              "ingress": {
                "annotations": {},
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "priorityClassName": "",
              "resources": {},
              "route": {
                "enabled": true,
                "host": "",
                "termination": "passthrough"
              },
              "svc": {
                "annotations": {},
                "loadBalancerIP": "",
                "type": "NodePort"
              }
            },
            "openshift": true,
            "psp": false,
            "resources": {},
            "serviceAccount": "default"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/neuvector/neuvector-operator-bundle@sha256:38e93c5f551f7ebfc1736a58cf2f07a793974fdd04f59af1c15df20e38e195da",
      "bundle_path_digest": "sha256:38e93c5f551f7ebfc1736a58cf2f07a793974fdd04f59af1c15df20e38e195da",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-09-19T10:22:51.572000+00:00",
      "csv_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.\n\nThe NeuVector Operator runs  in the openshift container platform to deploy and manage the NeuVector Security cluster components. The NeuVector operator contains all necessary information to deploy NeuVector using helm charts. You simply need to install the NeuVector operator from the OpenShift embeded operator hub and create NeuVector instance. You can modify the NeuVector installation configuration by modifying yaml while creating the NeuVector instance such as imagePullSecrets, tag version, etc. Please refer to [github link](https://github.com/neuvector/neuvector-helm/tree/master/charts/core) for the values that can be modifed during installation. To upgrade to a newer version of NeuVector, just reapply the NeuVector instance with desired tag , which in turn pulls the specified NeuVector image tags and upgrades as per upgrade plan configured on the helm chart.  NeuVector Operator versions are tied to NeuVector product versions. Version 1.3.0 of the NeuVector Certified Operator deploys version 4.3.2 of NeuVector.\n\n**Complete below steps to Grant Service Account Access to the Privileged SCC before installation.**\n\nCreate the NeuVector namespace\n\n         oc new-project  neuvector\nLogin as system:admin account\n\n         oc login -u system:admin\n\nGrant Service Account Access to the Privileged SCC\n\n         oc -n neuvector adm policy add-scc-to-user privileged -z default\n\nThe following info will be added in the Privileged SCC users:\n\n         - system:serviceaccount:neuvector:default\n\nIn OpenShift 4.6+ use the following to check:\n\n         oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide\n         system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/default\n\n\n**Add NeuVector license from NeuVector WebUI->setting**\n\n\n#Deploying the NeuVector Operator#\n\n\nPlease refer to the instructions [here](https://github.com/neuvector/neuvector-operator/blob/master/README.md)\n\n\n",
      "csv_display_name": "NeuVector Operator",
      "csv_metadata_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.",
      "csv_name": "neuvector-operator.v1.3.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:35:21.858000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "neuvector-certified-operator",
      "provided_apis": [
        {
          "group": "apm.neuvector.com",
          "kind": "Neuvector",
          "version": "v1alpha1"
        }
      ],
      "provider": "NeuVector",
      "related_images": [
        {
          "digest": "sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "name": "neuvector-operator-487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1-annotation"
        },
        {
          "digest": "sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "name": "neuvector-operator"
        },
        {
          "digest": "sha256:a748a22eff64576a89b15a0f70b0d50d781bc0bff809029e78cdcd19c105e6ff",
          "image": "registry.connect.redhat.com/neuvector/controller@sha256:a748a22eff64576a89b15a0f70b0d50d781bc0bff809029e78cdcd19c105e6ff",
          "name": "controller"
        },
        {
          "digest": "sha256:45c5e78ed5a72944dfdd3123623d71376fea8ef329e2980e162c633c58c049f2",
          "image": "registry.connect.redhat.com/neuvector/enforcer@sha256:45c5e78ed5a72944dfdd3123623d71376fea8ef329e2980e162c633c58c049f2",
          "name": "enforcer"
        },
        {
          "digest": "sha256:a7139cddaf9f7e53494cd9ad553331473466973f151489cb92bd6ffee864a56a",
          "image": "registry.connect.redhat.com/neuvector/manager@sha256:a7139cddaf9f7e53494cd9ad553331473466973f151489cb92bd6ffee864a56a",
          "name": "manager"
        },
        {
          "digest": "sha256:5f2d23d20f9ea5d1d3bc56b758ddc3f3b4f57a9db47c7cc95e74f6d7a4072e00",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:5f2d23d20f9ea5d1d3bc56b758ddc3f3b4f57a9db47c7cc95e74f6d7a4072e00",
          "name": "scanner"
        },
        {
          "digest": "sha256:910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7",
          "image": "registry.access.redhat.com/ubi8@sha256:910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7",
          "name": "updater"
        },
        {
          "digest": "sha256:5f2d23d20f9ea5d1d3bc56b758ddc3f3b4f57a9db47c7cc95e74f6d7a4072e00",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:5f2d23d20f9ea5d1d3bc56b758ddc3f3b4f57a9db47c7cc95e74f6d7a4072e00",
          "name": "scanner-5f2d23d20f9ea5d1d3bc56b758ddc3f3b4f57a9db47c7cc95e74f6d7a4072e00-annotation"
        },
        {
          "digest": "sha256:910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7",
          "image": "registry.access.redhat.com/ubi8@sha256:910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7",
          "name": "ubi8-910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.3.0",
      "version_original": "1.3.0"
    },
    {
      "_id": "632842fd316b8eb377f07746",
      "alm_examples": [
        {
          "api_version": "apm.neuvector.com/v1alpha1",
          "kind": "Neuvector",
          "metadata": {
            "name": "neuvector"
          },
          "spec": {
            "admissionwebhook": {
              "type": "ClusterIP"
            },
            "bottlerocket": {
              "enabled": false,
              "runtimePath": "/run/dockershim.sock"
            },
            "containerd": {
              "enabled": false,
              "path": "/var/run/containerd/containerd.sock"
            },
            "controller": {
              "apisvc": {
                "annotations": {},
                "route": {
                  "enabled": false,
                  "host": "",
                  "termination": "passthrough"
                },
                "type": ""
              },
              "azureFileShare": {
                "enabled": false,
                "secretName": "",
                "shareName": ""
              },
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "configmap": {
                "data": "",
                "enabled": false
              },
              "disruptionbudget": 0,
              "enabled": true,
              "federation": {
                "managedsvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                },
                "mastersvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                }
              },
              "image": "registry.connect.redhat.com/neuvector/controller",
              "ingress": {
                "annotations": {
                  "ingress.kubernetes.io/protocol": "https"
                },
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "priorityClassName": "",
              "pvc": {
                "accessModes": [
                  "ReadWriteMany"
                ],
                "capacity": "",
                "enabled": false,
                "storageClass": ""
              },
              "replicas": 3,
              "resources": {},
              "schedulerName": "",
              "strategy": {
                "rollingUpdate": {
                  "maxSurge": 1,
                  "maxUnavailable": 0
                },
                "type": "RollingUpdate"
              }
            },
            "crdwebhook": {
              "enabled": true,
              "type": "ClusterIP"
            },
            "crio": {
              "enabled": true,
              "path": "/var/run/crio/crio.sock"
            },
            "cve": {
              "scanner": {
                "dockerPath": "",
                "enabled": true,
                "image": "registry.connect.redhat.com/neuvector/scanner@sha256:c0c7095bcb36e93a4c074e5c97d652db5f0133022fd2ab6838a092e8959f2041",
                "priorityClassName": "",
                "replicas": 3,
                "resources": {},
                "strategy": {
                  "rollingUpdate": {
                    "maxSurge": 1,
                    "maxUnavailable": 0
                  },
                  "type": "RollingUpdate"
                }
              },
              "updater": {
                "enabled": true,
                "image": "registry.access.redhat.com/ubi8@sha256:060d7d6827b34949cc0fc58a50f72a5dccf00a4cc594406bdf5982f41dfe6118",
                "priorityClassName": "",
                "schedule": "0 0 * * *",
                "secure": false
              }
            },
            "docker": {
              "enabled": false,
              "path": "/var/run/docker.sock"
            },
            "enforcer": {
              "enabled": true,
              "image": "registry.connect.redhat.com/neuvector/enforcer",
              "priorityClassName": "",
              "resources": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                }
              ]
            },
            "k3s": {
              "enabled": false,
              "runtimePath": "/run/k3s/containerd/containerd.sock"
            },
            "manager": {
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "enabled": true,
              "env": {
                "ssl": true
              },
              "image": "registry.connect.redhat.com/neuvector/manager",
              "ingress": {
                "annotations": {},
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "priorityClassName": "",
              "resources": {},
              "route": {
                "enabled": true,
                "host": "",
                "termination": "passthrough"
              },
              "svc": {
                "annotations": {},
                "loadBalancerIP": "",
                "type": "NodePort"
              }
            },
            "openshift": true,
            "psp": false,
            "resources": {},
            "serviceAccount": "default"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/neuvector/neuvector-operator-bundle@sha256:bd5db9f3403eee933627d3a1ef0c534cac8c7b53eda247589d546c1f6cfed71b",
      "bundle_path_digest": "sha256:bd5db9f3403eee933627d3a1ef0c534cac8c7b53eda247589d546c1f6cfed71b",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-09-19T10:22:53.662000+00:00",
      "csv_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.\n\nThe NeuVector Operator runs  in the openshift container platform to deploy and manage the NeuVector Security cluster components. The NeuVector operator contains all necessary information to deploy NeuVector using helm charts. You simply need to install the NeuVector operator from the OpenShift embeded operator hub and create NeuVector instance. You can modify the NeuVector installation configuration by modifying yaml while creating the NeuVector instance such as imagePullSecrets, tag version, etc. Please refer to [github link](https://github.com/neuvector/neuvector-helm/tree/master/charts/core) for the values that can be modifed during installation. To upgrade to a newer version of NeuVector, just reapply the NeuVector instance with desired tag , which in turn pulls the specified NeuVector image tags and upgrades as per upgrade plan configured on the helm chart.  NeuVector Operator versions are tied to NeuVector product versions. Version 1.3.1 of the NeuVector Certified Operator deploys version 4.3.2-s1 of NeuVector.\n\n**Complete below steps to Grant Service Account Access to the Privileged SCC before installation.**\n\nCreate the NeuVector namespace\n\n         oc new-project  neuvector\nLogin as system:admin account\n\n         oc login -u system:admin\n\nGrant Service Account Access to the Privileged SCC\n\n         oc -n neuvector adm policy add-scc-to-user privileged -z default\n\nThe following info will be added in the Privileged SCC users:\n\n         - system:serviceaccount:neuvector:default\n\nIn OpenShift 4.6+ use the following to check:\n\n         oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide\n         system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/default\n\n\n**Add NeuVector license from NeuVector WebUI->setting**\n\n\n#Deploying the NeuVector Operator#\n\n\nPlease refer to the instructions [here](https://github.com/neuvector/neuvector-operator/blob/master/README.md)\n\n\n",
      "csv_display_name": "NeuVector Operator",
      "csv_metadata_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.",
      "csv_name": "neuvector-operator.v1.3.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:35:04.386000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "neuvector-certified-operator",
      "provided_apis": [
        {
          "group": "apm.neuvector.com",
          "kind": "Neuvector",
          "version": "v1alpha1"
        }
      ],
      "provider": "NeuVector",
      "related_images": [
        {
          "digest": "sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "name": "neuvector-operator-487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1-annotation"
        },
        {
          "digest": "sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "name": "neuvector-operator"
        },
        {
          "digest": "sha256:afa454d7a22de6161e6ff6b6f859ce15fa0bfc4e9d4e5e191b61125dfc5cad6b",
          "image": "registry.connect.redhat.com/neuvector/controller@sha256:afa454d7a22de6161e6ff6b6f859ce15fa0bfc4e9d4e5e191b61125dfc5cad6b",
          "name": "controller"
        },
        {
          "digest": "sha256:f9543cdf9bb338161a3f84a81381f26cbf724a23f6363583417c9da682e91cf8",
          "image": "registry.connect.redhat.com/neuvector/enforcer@sha256:f9543cdf9bb338161a3f84a81381f26cbf724a23f6363583417c9da682e91cf8",
          "name": "enforcer"
        },
        {
          "digest": "sha256:085bd24dadcd9d023c6600227ca088ed8d03ab83a70b62401477d10272450952",
          "image": "registry.connect.redhat.com/neuvector/manager@sha256:085bd24dadcd9d023c6600227ca088ed8d03ab83a70b62401477d10272450952",
          "name": "manager"
        },
        {
          "digest": "sha256:c0c7095bcb36e93a4c074e5c97d652db5f0133022fd2ab6838a092e8959f2041",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:c0c7095bcb36e93a4c074e5c97d652db5f0133022fd2ab6838a092e8959f2041",
          "name": "scanner"
        },
        {
          "digest": "sha256:060d7d6827b34949cc0fc58a50f72a5dccf00a4cc594406bdf5982f41dfe6118",
          "image": "registry.access.redhat.com/ubi8@sha256:060d7d6827b34949cc0fc58a50f72a5dccf00a4cc594406bdf5982f41dfe6118",
          "name": "updater"
        },
        {
          "digest": "sha256:c0c7095bcb36e93a4c074e5c97d652db5f0133022fd2ab6838a092e8959f2041",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:c0c7095bcb36e93a4c074e5c97d652db5f0133022fd2ab6838a092e8959f2041",
          "name": "scanner-c0c7095bcb36e93a4c074e5c97d652db5f0133022fd2ab6838a092e8959f2041-annotation"
        },
        {
          "digest": "sha256:060d7d6827b34949cc0fc58a50f72a5dccf00a4cc594406bdf5982f41dfe6118",
          "image": "registry.access.redhat.com/ubi8@sha256:060d7d6827b34949cc0fc58a50f72a5dccf00a4cc594406bdf5982f41dfe6118",
          "name": "ubi8-060d7d6827b34949cc0fc58a50f72a5dccf00a4cc594406bdf5982f41dfe6118-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.3.1",
      "version_original": "1.3.1"
    },
    {
      "_id": "632842ff8454bee1cb723ae3",
      "alm_examples": [
        {
          "api_version": "apm.neuvector.com/v1alpha1",
          "kind": "Neuvector",
          "metadata": {
            "name": "neuvector"
          },
          "spec": {
            "admissionwebhook": {
              "type": "ClusterIP"
            },
            "bottlerocket": {
              "enabled": false,
              "runtimePath": "/run/dockershim.sock"
            },
            "containerd": {
              "enabled": false,
              "path": "/var/run/containerd/containerd.sock"
            },
            "controller": {
              "affinity": {
                "podAntiAffinity": {
                  "preferredDuringSchedulingIgnoredDuringExecution": [
                    {
                      "podAffinityTerm": {
                        "labelSelector": {
                          "matchExpressions": [
                            {
                              "key": "app",
                              "operator": "In",
                              "values": [
                                "neuvector-controller-pod"
                              ]
                            }
                          ]
                        },
                        "topologyKey": "kubernetes.io/hostname"
                      },
                      "weight": 100
                    }
                  ]
                }
              },
              "apisvc": {
                "annotations": {},
                "route": {
                  "enabled": false,
                  "host": "",
                  "termination": "passthrough"
                },
                "type": ""
              },
              "azureFileShare": {
                "enabled": false,
                "secretName": "",
                "shareName": ""
              },
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "configmap": {
                "data": "",
                "enabled": false
              },
              "disruptionbudget": 0,
              "enabled": true,
              "env": [],
              "federation": {
                "managedsvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                },
                "mastersvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                }
              },
              "image": "registry.connect.redhat.com/neuvector/controller",
              "ingress": {
                "annotations": {
                  "ingress.kubernetes.io/protocol": "https"
                },
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "pvc": {
                "accessModes": [
                  "ReadWriteMany"
                ],
                "capacity": "",
                "enabled": false,
                "storageClass": ""
              },
              "replicas": 3,
              "resources": {},
              "schedulerName": "",
              "secret": {
                "data": {},
                "enabled": false
              },
              "strategy": {
                "rollingUpdate": {
                  "maxSurge": 1,
                  "maxUnavailable": 0
                },
                "type": "RollingUpdate"
              },
              "tolerations": []
            },
            "crdwebhook": {
              "enabled": true,
              "type": "ClusterIP"
            },
            "crio": {
              "enabled": true,
              "path": "/var/run/crio/crio.sock"
            },
            "cve": {
              "scanner": {
                "affinity": {},
                "dockerPath": "",
                "enabled": true,
                "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
                "nodeSelector": {},
                "priorityClassName": "",
                "replicas": 3,
                "resources": {},
                "strategy": {
                  "rollingUpdate": {
                    "maxSurge": 1,
                    "maxUnavailable": 0
                  },
                  "type": "RollingUpdate"
                },
                "tolerations": []
              },
              "updater": {
                "enabled": true,
                "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
                "priorityClassName": "",
                "schedule": "0 0 * * *",
                "secure": false
              }
            },
            "docker": {
              "enabled": false,
              "path": "/var/run/docker.sock"
            },
            "enforcer": {
              "enabled": true,
              "image": "registry.connect.redhat.com/neuvector/enforcer",
              "priorityClassName": "",
              "resources": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                }
              ]
            },
            "k3s": {
              "enabled": false,
              "runtimePath": "/run/k3s/containerd/containerd.sock"
            },
            "manager": {
              "affinity": {},
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "enabled": true,
              "env": {
                "ssl": true
              },
              "image": "registry.connect.redhat.com/neuvector/manager",
              "ingress": {
                "annotations": {},
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "resources": {},
              "route": {
                "enabled": true,
                "host": "",
                "termination": "passthrough"
              },
              "svc": {
                "annotations": {},
                "loadBalancerIP": "",
                "type": "NodePort"
              },
              "tolerations": []
            },
            "openshift": true,
            "psp": false,
            "resources": {},
            "serviceAccount": "default"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/neuvector/neuvector-operator-bundle@sha256:bb9a141e7420196baf0bfc456ae28d7d150f6b40de987b214d0833207fcc1a3e",
      "bundle_path_digest": "sha256:bb9a141e7420196baf0bfc456ae28d7d150f6b40de987b214d0833207fcc1a3e",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-09-19T10:22:55.985000+00:00",
      "csv_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.\n\nThe NeuVector Operator runs  in the openshift container platform to deploy and manage the NeuVector Security cluster components. The NeuVector operator contains all necessary information to deploy NeuVector using helm charts. You simply need to install the NeuVector operator from the OpenShift embeded operator hub and create NeuVector instance. You can modify the NeuVector installation configuration by modifying yaml while creating the NeuVector instance such as imagePullSecrets, tag version, etc. Please refer to [github link](https://github.com/neuvector/neuvector-helm/tree/master/charts/core) for the values that can be modifed during installation. To upgrade to a newer version of NeuVector, just reapply the NeuVector instance with desired tag , which in turn pulls the specified NeuVector image tags and upgrades as per upgrade plan configured on the helm chart.  NeuVector Operator versions are tied to NeuVector product versions. Version 1.3.2 of the NeuVector Certified Operator deploys version 4.4.2 of NeuVector.\n\n**Complete below steps to Grant Service Account Access to the Privileged SCC before installation.**\n\nCreate the NeuVector namespace\n\n         oc new-project  neuvector\nLogin as system:admin account\n\n         oc login -u system:admin\n\nGrant Service Account Access to the Privileged SCC\n\n         oc -n neuvector adm policy add-scc-to-user privileged -z default\n\nThe following info will be added in the Privileged SCC users:\n\n         - system:serviceaccount:neuvector:default\n\nIn OpenShift 4.6+ use the following to check:\n\n         oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide\n         system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/default\n\n\n**Add NeuVector license from NeuVector WebUI->setting**\n\n\n#Deploying the NeuVector Operator#\n\n\nPlease refer to the instructions [here](https://github.com/neuvector/neuvector-operator/blob/master/README.md)\n\n\n",
      "csv_display_name": "NeuVector Operator",
      "csv_metadata_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.",
      "csv_name": "neuvector-operator.v1.3.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:35:07.430000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "neuvector-certified-operator",
      "provided_apis": [
        {
          "group": "apm.neuvector.com",
          "kind": "Neuvector",
          "version": "v1alpha1"
        }
      ],
      "provider": "NeuVector",
      "related_images": [
        {
          "digest": "sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "name": "neuvector-operator-a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0-annotation"
        },
        {
          "digest": "sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:a9f3e9bb91fa89aeff8133349673c0900258586f955251dd30fbd5fecabdf4d0",
          "name": "neuvector-operator"
        },
        {
          "digest": "sha256:ecc4814bf9e38d41898ae2354bbafd2f1ed7c6e5602bb30cb40486e67725395c",
          "image": "registry.connect.redhat.com/neuvector/controller@sha256:ecc4814bf9e38d41898ae2354bbafd2f1ed7c6e5602bb30cb40486e67725395c",
          "name": "controller"
        },
        {
          "digest": "sha256:4621d69ca47929eedcab2c9163fc9d73ede09e0cd14f2a14db495e610590f5c2",
          "image": "registry.connect.redhat.com/neuvector/enforcer@sha256:4621d69ca47929eedcab2c9163fc9d73ede09e0cd14f2a14db495e610590f5c2",
          "name": "enforcer"
        },
        {
          "digest": "sha256:b49ba8bba9aaf292603896d5d3b9e5328b23260dfd977c70e7f3e39460564679",
          "image": "registry.connect.redhat.com/neuvector/manager@sha256:b49ba8bba9aaf292603896d5d3b9e5328b23260dfd977c70e7f3e39460564679",
          "name": "manager"
        },
        {
          "digest": "sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "name": "scanner"
        },
        {
          "digest": "sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "name": "updater"
        },
        {
          "digest": "sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "name": "scanner-d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038-annotation"
        },
        {
          "digest": "sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "name": "ubi8-228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.3.2",
      "version_original": "1.3.2"
    },
    {
      "_id": "63284302eb69678e80bd1efa",
      "alm_examples": [
        {
          "api_version": "apm.neuvector.com/v1alpha1",
          "kind": "Neuvector",
          "metadata": {
            "name": "neuvector"
          },
          "spec": {
            "admissionwebhook": {
              "type": "ClusterIP"
            },
            "bottlerocket": {
              "enabled": false,
              "runtimePath": "/run/dockershim.sock"
            },
            "containerd": {
              "enabled": false,
              "path": "/var/run/containerd/containerd.sock"
            },
            "controller": {
              "affinity": {
                "podAntiAffinity": {
                  "preferredDuringSchedulingIgnoredDuringExecution": [
                    {
                      "podAffinityTerm": {
                        "labelSelector": {
                          "matchExpressions": [
                            {
                              "key": "app",
                              "operator": "In",
                              "values": [
                                "neuvector-controller-pod"
                              ]
                            }
                          ]
                        },
                        "topologyKey": "kubernetes.io/hostname"
                      },
                      "weight": 100
                    }
                  ]
                }
              },
              "apisvc": {
                "annotations": {},
                "route": {
                  "enabled": false,
                  "host": "",
                  "termination": "passthrough"
                },
                "type": ""
              },
              "azureFileShare": {
                "enabled": false,
                "secretName": "",
                "shareName": ""
              },
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "configmap": {
                "data": "",
                "enabled": false
              },
              "disruptionbudget": 0,
              "enabled": true,
              "env": [],
              "federation": {
                "managedsvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                },
                "mastersvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                }
              },
              "image": "registry.connect.redhat.com/neuvector/controller",
              "ingress": {
                "annotations": {
                  "ingress.kubernetes.io/protocol": "https"
                },
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "pvc": {
                "accessModes": [
                  "ReadWriteMany"
                ],
                "capacity": "",
                "enabled": false,
                "storageClass": ""
              },
              "replicas": 3,
              "resources": {},
              "schedulerName": "",
              "secret": {
                "data": {},
                "enabled": false
              },
              "strategy": {
                "rollingUpdate": {
                  "maxSurge": 1,
                  "maxUnavailable": 0
                },
                "type": "RollingUpdate"
              },
              "tolerations": []
            },
            "crdwebhook": {
              "enabled": true,
              "type": "ClusterIP"
            },
            "crio": {
              "enabled": true,
              "path": "/var/run/crio/crio.sock"
            },
            "cve": {
              "scanner": {
                "affinity": {},
                "dockerPath": "",
                "enabled": true,
                "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
                "nodeSelector": {},
                "priorityClassName": "",
                "replicas": 3,
                "resources": {},
                "strategy": {
                  "rollingUpdate": {
                    "maxSurge": 1,
                    "maxUnavailable": 0
                  },
                  "type": "RollingUpdate"
                },
                "tolerations": []
              },
              "updater": {
                "enabled": true,
                "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
                "priorityClassName": "",
                "schedule": "0 0 * * *",
                "secure": false
              }
            },
            "docker": {
              "enabled": false,
              "path": "/var/run/docker.sock"
            },
            "enforcer": {
              "enabled": true,
              "image": "registry.connect.redhat.com/neuvector/enforcer",
              "priorityClassName": "",
              "resources": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                }
              ]
            },
            "k3s": {
              "enabled": false,
              "runtimePath": "/run/k3s/containerd/containerd.sock"
            },
            "manager": {
              "affinity": {},
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "enabled": true,
              "env": {
                "ssl": true
              },
              "image": "registry.connect.redhat.com/neuvector/manager",
              "ingress": {
                "annotations": {},
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "resources": {},
              "route": {
                "enabled": true,
                "host": "",
                "termination": "passthrough"
              },
              "svc": {
                "annotations": {},
                "loadBalancerIP": "",
                "type": "NodePort"
              },
              "tolerations": []
            },
            "openshift": true,
            "psp": false,
            "resources": {},
            "serviceAccount": "default"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/neuvector/neuvector-operator-bundle@sha256:ceb11d8e4544f3bb43fa3b217ccf2e2bb7f1e1887340fb7bf8cdafab7a25a25d",
      "bundle_path_digest": "sha256:ceb11d8e4544f3bb43fa3b217ccf2e2bb7f1e1887340fb7bf8cdafab7a25a25d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-09-19T10:22:58.316000+00:00",
      "csv_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.\n\nThe NeuVector Operator runs  in the openshift container platform to deploy and manage the NeuVector Security cluster components. The NeuVector operator contains all necessary information to deploy NeuVector using helm charts. You simply need to install the NeuVector operator from the OpenShift embeded operator hub and create NeuVector instance. You can modify the NeuVector installation configuration by modifying yaml while creating the NeuVector instance such as imagePullSecrets, tag version, etc. Please refer to [github link](https://github.com/neuvector/neuvector-helm/tree/master/charts/core) for the values that can be modifed during installation. To upgrade to a newer version of NeuVector, just reapply the NeuVector instance with desired tag , which in turn pulls the specified NeuVector image tags and upgrades as per upgrade plan configured on the helm chart.  NeuVector Operator versions are tied to NeuVector product versions. Version 1.3.3 of the NeuVector Certified Operator deploys version 4.4.3 of NeuVector.\n\n**Complete below steps to Grant Service Account Access to the Privileged SCC before installation.**\n\nCreate the NeuVector namespace\n\n         oc new-project  neuvector\nLogin as system:admin account\n\n         oc login -u system:admin\n\nGrant Service Account Access to the Privileged SCC\n\n         oc -n neuvector adm policy add-scc-to-user privileged -z default\n\nThe following info will be added in the Privileged SCC users:\n\n         - system:serviceaccount:neuvector:default\n\nIn OpenShift 4.6+ use the following to check:\n\n         oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide\n         system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/default\n\n\n**Add NeuVector license from NeuVector WebUI->setting**\n\n\n#Deploying the NeuVector Operator#\n\n\nPlease refer to the instructions [here](https://github.com/neuvector/neuvector-operator/blob/master/README.md)\n\n\n",
      "csv_display_name": "NeuVector Operator",
      "csv_metadata_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.",
      "csv_name": "neuvector-operator.v1.3.3",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:35:12.205000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "neuvector-certified-operator",
      "provided_apis": [
        {
          "group": "apm.neuvector.com",
          "kind": "Neuvector",
          "version": "v1alpha1"
        }
      ],
      "provider": "NeuVector",
      "related_images": [
        {
          "digest": "sha256:6155ac3c95aa6471c9857e0a6f5e5d19e6fc1d8cc7d014108d7d4a10d14f96bb",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:6155ac3c95aa6471c9857e0a6f5e5d19e6fc1d8cc7d014108d7d4a10d14f96bb",
          "name": "neuvector-operator-6155ac3c95aa6471c9857e0a6f5e5d19e6fc1d8cc7d014108d7d4a10d14f96bb-annotation"
        },
        {
          "digest": "sha256:6155ac3c95aa6471c9857e0a6f5e5d19e6fc1d8cc7d014108d7d4a10d14f96bb",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:6155ac3c95aa6471c9857e0a6f5e5d19e6fc1d8cc7d014108d7d4a10d14f96bb",
          "name": "neuvector-operator"
        },
        {
          "digest": "sha256:ecc4814bf9e38d41898ae2354bbafd2f1ed7c6e5602bb30cb40486e67725395c",
          "image": "registry.connect.redhat.com/neuvector/controller@sha256:ecc4814bf9e38d41898ae2354bbafd2f1ed7c6e5602bb30cb40486e67725395c",
          "name": "controller"
        },
        {
          "digest": "sha256:4621d69ca47929eedcab2c9163fc9d73ede09e0cd14f2a14db495e610590f5c2",
          "image": "registry.connect.redhat.com/neuvector/enforcer@sha256:4621d69ca47929eedcab2c9163fc9d73ede09e0cd14f2a14db495e610590f5c2",
          "name": "enforcer"
        },
        {
          "digest": "sha256:b49ba8bba9aaf292603896d5d3b9e5328b23260dfd977c70e7f3e39460564679",
          "image": "registry.connect.redhat.com/neuvector/manager@sha256:b49ba8bba9aaf292603896d5d3b9e5328b23260dfd977c70e7f3e39460564679",
          "name": "manager"
        },
        {
          "digest": "sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "name": "scanner"
        },
        {
          "digest": "sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "name": "updater"
        },
        {
          "digest": "sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038",
          "name": "scanner-d79fd60afb6c93359314f01433fc5a4e23604b7035822809b4817d4e7d1b1038-annotation"
        },
        {
          "digest": "sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "name": "ubi8-228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.3.3",
      "version_original": "1.3.3"
    },
    {
      "_id": "632843032dd1cd9660afbac6",
      "alm_examples": [
        {
          "api_version": "apm.neuvector.com/v1alpha1",
          "kind": "Neuvector",
          "metadata": {
            "name": "neuvector"
          },
          "spec": {
            "admissionwebhook": {
              "type": "ClusterIP"
            },
            "bottlerocket": {
              "enabled": false,
              "runtimePath": "/run/dockershim.sock"
            },
            "containerd": {
              "enabled": false,
              "path": "/var/run/containerd/containerd.sock"
            },
            "controller": {
              "affinity": {
                "podAntiAffinity": {
                  "preferredDuringSchedulingIgnoredDuringExecution": [
                    {
                      "podAffinityTerm": {
                        "labelSelector": {
                          "matchExpressions": [
                            {
                              "key": "app",
                              "operator": "In",
                              "values": [
                                "neuvector-controller-pod"
                              ]
                            }
                          ]
                        },
                        "topologyKey": "kubernetes.io/hostname"
                      },
                      "weight": 100
                    }
                  ]
                }
              },
              "apisvc": {
                "annotations": {},
                "route": {
                  "enabled": false,
                  "host": "",
                  "termination": "passthrough"
                },
                "type": ""
              },
              "azureFileShare": {
                "enabled": false,
                "secretName": "",
                "shareName": ""
              },
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "configmap": {
                "data": "",
                "enabled": false
              },
              "disruptionbudget": 0,
              "enabled": true,
              "env": [],
              "federation": {
                "managedsvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                },
                "mastersvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                }
              },
              "image": "registry.connect.redhat.com/neuvector/controller",
              "ingress": {
                "annotations": {
                  "ingress.kubernetes.io/protocol": "https"
                },
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "pvc": {
                "accessModes": [
                  "ReadWriteMany"
                ],
                "capacity": "",
                "enabled": false,
                "storageClass": ""
              },
              "replicas": 3,
              "resources": {},
              "schedulerName": "",
              "secret": {
                "data": {},
                "enabled": false
              },
              "strategy": {
                "rollingUpdate": {
                  "maxSurge": 1,
                  "maxUnavailable": 0
                },
                "type": "RollingUpdate"
              },
              "tolerations": []
            },
            "crdwebhook": {
              "enabled": true,
              "type": "ClusterIP"
            },
            "crio": {
              "enabled": true,
              "path": "/var/run/crio/crio.sock"
            },
            "cve": {
              "scanner": {
                "affinity": {},
                "dockerPath": "",
                "enabled": true,
                "image": "registry.connect.redhat.com/neuvector/scanner@sha256:42004e13b348bb43b58ae8538c983a70b237e3aca870758ac629fb4fc43e8130",
                "nodeSelector": {},
                "priorityClassName": "",
                "replicas": 3,
                "resources": {},
                "strategy": {
                  "rollingUpdate": {
                    "maxSurge": 1,
                    "maxUnavailable": 0
                  },
                  "type": "RollingUpdate"
                },
                "tolerations": []
              },
              "updater": {
                "enabled": true,
                "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
                "priorityClassName": "",
                "schedule": "0 0 * * *",
                "secure": false
              }
            },
            "docker": {
              "enabled": false,
              "path": "/var/run/docker.sock"
            },
            "enforcer": {
              "enabled": true,
              "image": "registry.connect.redhat.com/neuvector/enforcer",
              "priorityClassName": "",
              "resources": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                }
              ]
            },
            "k3s": {
              "enabled": false,
              "runtimePath": "/run/k3s/containerd/containerd.sock"
            },
            "manager": {
              "affinity": {},
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "enabled": true,
              "env": {
                "ssl": true
              },
              "image": "registry.connect.redhat.com/neuvector/manager",
              "ingress": {
                "annotations": {},
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "resources": {},
              "route": {
                "enabled": true,
                "host": "",
                "termination": "passthrough"
              },
              "svc": {
                "annotations": {},
                "loadBalancerIP": "",
                "type": "NodePort"
              },
              "tolerations": []
            },
            "openshift": true,
            "psp": false,
            "resources": {},
            "serviceAccount": "default"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/neuvector/neuvector-operator-bundle@sha256:7060f7f130f0de1b20e377a846cfea20353202ea6dddce915b2b7918a3ef8efa",
      "bundle_path_digest": "sha256:7060f7f130f0de1b20e377a846cfea20353202ea6dddce915b2b7918a3ef8efa",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-09-19T10:22:59.844000+00:00",
      "csv_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.\n\nThe NeuVector Operator runs  in the openshift container platform to deploy and manage the NeuVector Security cluster components. The NeuVector operator contains all necessary information to deploy NeuVector using helm charts. You simply need to install the NeuVector operator from the OpenShift embeded operator hub and create NeuVector instance. You can modify the NeuVector installation configuration by modifying yaml while creating the NeuVector instance such as imagePullSecrets, tag version, etc. Please refer to [github link](https://github.com/neuvector/neuvector-helm/tree/master/charts/core) for the values that can be modifed during installation. To upgrade to a newer version of NeuVector, just reapply the NeuVector instance with desired tag , which in turn pulls the specified NeuVector image tags and upgrades as per upgrade plan configured on the helm chart.  NeuVector Operator versions are tied to NeuVector product versions. Version 1.3.4 of the NeuVector Certified Operator deploys version 4.4.3 of NeuVector.\n\n**Complete below steps to Grant Service Account Access to the Privileged SCC before installation.**\n\nCreate the NeuVector namespace\n\n         oc new-project  neuvector\nLogin as system:admin account\n\n         oc login -u system:admin\n\nGrant Service Account Access to the Privileged SCC\n\n         oc -n neuvector adm policy add-scc-to-user privileged -z default\n\nThe following info will be added in the Privileged SCC users:\n\n         - system:serviceaccount:neuvector:default\n\nIn OpenShift 4.6+ use the following to check:\n\n         oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide\n         system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/default\n\n\n**Add NeuVector license from NeuVector WebUI->setting**\n\n\n#Deploying the NeuVector Operator#\n\n\nPlease refer to the instructions [here](https://github.com/neuvector/neuvector-operator/blob/master/README.md)\n\n\n",
      "csv_display_name": "NeuVector Operator",
      "csv_metadata_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.",
      "csv_name": "neuvector-operator.v1.3.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:35:13.853000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "neuvector-certified-operator",
      "provided_apis": [
        {
          "group": "apm.neuvector.com",
          "kind": "Neuvector",
          "version": "v1alpha1"
        }
      ],
      "provider": "NeuVector",
      "related_images": [
        {
          "digest": "sha256:6155ac3c95aa6471c9857e0a6f5e5d19e6fc1d8cc7d014108d7d4a10d14f96bb",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:6155ac3c95aa6471c9857e0a6f5e5d19e6fc1d8cc7d014108d7d4a10d14f96bb",
          "name": "neuvector-operator-6155ac3c95aa6471c9857e0a6f5e5d19e6fc1d8cc7d014108d7d4a10d14f96bb-annotation"
        },
        {
          "digest": "sha256:6155ac3c95aa6471c9857e0a6f5e5d19e6fc1d8cc7d014108d7d4a10d14f96bb",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:6155ac3c95aa6471c9857e0a6f5e5d19e6fc1d8cc7d014108d7d4a10d14f96bb",
          "name": "neuvector-operator"
        },
        {
          "digest": "sha256:acc943568520282061547b310c50080dc32924a531bbb543d959b281eb6664f4",
          "image": "registry.connect.redhat.com/neuvector/controller@sha256:acc943568520282061547b310c50080dc32924a531bbb543d959b281eb6664f4",
          "name": "controller"
        },
        {
          "digest": "sha256:be1d299ec3532d55444681a882e9fd1238949da6598987308e2800ed26291b7a",
          "image": "registry.connect.redhat.com/neuvector/enforcer@sha256:be1d299ec3532d55444681a882e9fd1238949da6598987308e2800ed26291b7a",
          "name": "enforcer"
        },
        {
          "digest": "sha256:8245cd179d11fff279690c5a422f46b4ff252ed72b9b998f0c9b5453bc7d8fc0",
          "image": "registry.connect.redhat.com/neuvector/manager@sha256:8245cd179d11fff279690c5a422f46b4ff252ed72b9b998f0c9b5453bc7d8fc0",
          "name": "manager"
        },
        {
          "digest": "sha256:42004e13b348bb43b58ae8538c983a70b237e3aca870758ac629fb4fc43e8130",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:42004e13b348bb43b58ae8538c983a70b237e3aca870758ac629fb4fc43e8130",
          "name": "scanner"
        },
        {
          "digest": "sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "name": "updater"
        },
        {
          "digest": "sha256:42004e13b348bb43b58ae8538c983a70b237e3aca870758ac629fb4fc43e8130",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:42004e13b348bb43b58ae8538c983a70b237e3aca870758ac629fb4fc43e8130",
          "name": "scanner-42004e13b348bb43b58ae8538c983a70b237e3aca870758ac629fb4fc43e8130-annotation"
        },
        {
          "digest": "sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "image": "registry.access.redhat.com/ubi8@sha256:228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2",
          "name": "ubi8-228824aa581f3b31bf79411f8448b798291c667a37155bdea61cfa128b2833f2-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.3.4",
      "version_original": "1.3.4"
    },
    {
      "_id": "63284305a9c6e63893ae5364",
      "alm_examples": [
        {
          "api_version": "apm.neuvector.com/v1alpha1",
          "kind": "Neuvector",
          "metadata": {
            "name": "neuvector"
          },
          "spec": {
            "admissionwebhook": {
              "type": "ClusterIP"
            },
            "bottlerocket": {
              "enabled": false,
              "runtimePath": "/run/dockershim.sock"
            },
            "containerd": {
              "enabled": false,
              "path": "/var/run/containerd/containerd.sock"
            },
            "controller": {
              "affinity": {
                "podAntiAffinity": {
                  "preferredDuringSchedulingIgnoredDuringExecution": [
                    {
                      "podAffinityTerm": {
                        "labelSelector": {
                          "matchExpressions": [
                            {
                              "key": "app",
                              "operator": "In",
                              "values": [
                                "neuvector-controller-pod"
                              ]
                            }
                          ]
                        },
                        "topologyKey": "kubernetes.io/hostname"
                      },
                      "weight": 100
                    }
                  ]
                }
              },
              "apisvc": {
                "annotations": {},
                "route": {
                  "enabled": false,
                  "host": "",
                  "termination": "passthrough"
                },
                "type": ""
              },
              "azureFileShare": {
                "enabled": false,
                "secretName": "",
                "shareName": ""
              },
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "configmap": {
                "data": "",
                "enabled": false
              },
              "disruptionbudget": 0,
              "enabled": true,
              "env": [],
              "federation": {
                "managedsvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                },
                "mastersvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                }
              },
              "image": "registry.connect.redhat.com/neuvector/controller",
              "ingress": {
                "annotations": {
                  "ingress.kubernetes.io/protocol": "https"
                },
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "pvc": {
                "accessModes": [
                  "ReadWriteMany"
                ],
                "capacity": "",
                "enabled": false,
                "storageClass": ""
              },
              "replicas": 3,
              "resources": {},
              "schedulerName": "",
              "secret": {
                "data": {},
                "enabled": false
              },
              "strategy": {
                "rollingUpdate": {
                  "maxSurge": 1,
                  "maxUnavailable": 0
                },
                "type": "RollingUpdate"
              },
              "tolerations": []
            },
            "crdwebhook": {
              "enabled": true,
              "type": "ClusterIP"
            },
            "crio": {
              "enabled": true,
              "path": "/var/run/crio/crio.sock"
            },
            "cve": {
              "scanner": {
                "affinity": {},
                "dockerPath": "",
                "enabled": true,
                "image": "registry.connect.redhat.com/neuvector/scanner@sha256:30b8c4ad5ab2a616bd07c7bd2e24dd58e19bf743a56788fd53808b2c54503515",
                "nodeSelector": {},
                "priorityClassName": "",
                "replicas": 3,
                "resources": {},
                "strategy": {
                  "rollingUpdate": {
                    "maxSurge": 1,
                    "maxUnavailable": 0
                  },
                  "type": "RollingUpdate"
                },
                "tolerations": []
              },
              "updater": {
                "enabled": true,
                "image": "registry.access.redhat.com/ubi8@sha256:f3e11575aee05d474cb994c0ece89d992ece85be0596480582251fdec7a68f0b",
                "priorityClassName": "",
                "schedule": "0 0 * * *",
                "secure": false
              }
            },
            "docker": {
              "enabled": false,
              "path": "/var/run/docker.sock"
            },
            "enforcer": {
              "enabled": true,
              "image": "registry.connect.redhat.com/neuvector/enforcer",
              "priorityClassName": "",
              "resources": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                }
              ]
            },
            "k3s": {
              "enabled": false,
              "runtimePath": "/run/k3s/containerd/containerd.sock"
            },
            "manager": {
              "affinity": {},
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "enabled": true,
              "env": {
                "ssl": true
              },
              "image": "registry.connect.redhat.com/neuvector/manager",
              "ingress": {
                "annotations": {},
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "nodeSelector": {},
              "priorityClassName": "",
              "resources": {},
              "route": {
                "enabled": true,
                "host": "",
                "termination": "passthrough"
              },
              "svc": {
                "annotations": {},
                "loadBalancerIP": "",
                "type": "NodePort"
              },
              "tolerations": []
            },
            "openshift": true,
            "psp": false,
            "resources": {},
            "serviceAccount": "default"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/neuvector/neuvector-operator-bundle@sha256:aa613d5a3f9f2f111cbdc8bbb0d8e66a785a80983b26f591fe065b1a6ad3b714",
      "bundle_path_digest": "sha256:aa613d5a3f9f2f111cbdc8bbb0d8e66a785a80983b26f591fe065b1a6ad3b714",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-09-19T10:23:01.958000+00:00",
      "csv_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.\n\nThe NeuVector Operator runs  in the openshift container platform to deploy and manage the NeuVector Security cluster components. The NeuVector operator contains all necessary information to deploy NeuVector using helm charts. You simply need to install the NeuVector operator from the OpenShift embeded operator hub and create NeuVector instance. You can modify the NeuVector installation configuration by modifying yaml while creating the NeuVector instance such as imagePullSecrets, tag version, etc. Please refer to [github link](https://github.com/neuvector/neuvector-helm/tree/master/charts/core) for the values that can be modifed during installation. To upgrade to a newer version of NeuVector, just reapply the NeuVector instance with desired tag , which in turn pulls the specified NeuVector image tags and upgrades as per upgrade plan configured on the helm chart.  NeuVector Operator versions are tied to NeuVector product versions. Version 1.3.5 of the NeuVector Certified Operator deploys version 4.4.4 of NeuVector.\n\n**Complete below steps to Grant Service Account Access to the Privileged SCC before installation.**\n\nCreate the NeuVector namespace\n\n         oc new-project  neuvector\nLogin as system:admin account\n\n         oc login -u system:admin\n\nGrant Service Account Access to the Privileged SCC\n\n         oc -n neuvector adm policy add-scc-to-user privileged -z default\n\nThe following info will be added in the Privileged SCC users:\n\n         - system:serviceaccount:neuvector:default\n\nIn OpenShift 4.6+ use the following to check:\n\n         oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide\n         system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/default\n\n\n**Add NeuVector license from NeuVector WebUI->setting**\n\n\n#Deploying the NeuVector Operator#\n\n\nPlease refer to the instructions [here](https://github.com/neuvector/neuvector-operator/blob/master/README.md)\n\n\n",
      "csv_display_name": "NeuVector Operator",
      "csv_metadata_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.",
      "csv_name": "neuvector-operator.v1.3.5",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:35:15.838000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "neuvector-certified-operator",
      "provided_apis": [
        {
          "group": "apm.neuvector.com",
          "kind": "Neuvector",
          "version": "v1alpha1"
        }
      ],
      "provider": "NeuVector",
      "related_images": [
        {
          "digest": "sha256:725bace9f5d0302b4c6681cfd8b1523aa70f7951f1d03677b388341d91043e4c",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:725bace9f5d0302b4c6681cfd8b1523aa70f7951f1d03677b388341d91043e4c",
          "name": "neuvector-operator-725bace9f5d0302b4c6681cfd8b1523aa70f7951f1d03677b388341d91043e4c-annotation"
        },
        {
          "digest": "sha256:725bace9f5d0302b4c6681cfd8b1523aa70f7951f1d03677b388341d91043e4c",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:725bace9f5d0302b4c6681cfd8b1523aa70f7951f1d03677b388341d91043e4c",
          "name": "neuvector-operator"
        },
        {
          "digest": "sha256:cfbc29a7179c0a9dad1b4952317eed1573d340cd36dc50b25b06a345ae2cbaad",
          "image": "registry.connect.redhat.com/neuvector/controller@sha256:cfbc29a7179c0a9dad1b4952317eed1573d340cd36dc50b25b06a345ae2cbaad",
          "name": "controller"
        },
        {
          "digest": "sha256:f38526a125ff0f884ec834db6779875228879927a810b47e7955dc5ed9585f44",
          "image": "registry.connect.redhat.com/neuvector/enforcer@sha256:f38526a125ff0f884ec834db6779875228879927a810b47e7955dc5ed9585f44",
          "name": "enforcer"
        },
        {
          "digest": "sha256:48839dec3d696b2540646c2e92f54df7fd32699b871f4243d485fc5a4a23da70",
          "image": "registry.connect.redhat.com/neuvector/manager@sha256:48839dec3d696b2540646c2e92f54df7fd32699b871f4243d485fc5a4a23da70",
          "name": "manager"
        },
        {
          "digest": "sha256:30b8c4ad5ab2a616bd07c7bd2e24dd58e19bf743a56788fd53808b2c54503515",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:30b8c4ad5ab2a616bd07c7bd2e24dd58e19bf743a56788fd53808b2c54503515",
          "name": "scanner"
        },
        {
          "digest": "sha256:f3e11575aee05d474cb994c0ece89d992ece85be0596480582251fdec7a68f0b",
          "image": "registry.access.redhat.com/ubi8@sha256:f3e11575aee05d474cb994c0ece89d992ece85be0596480582251fdec7a68f0b",
          "name": "updater"
        },
        {
          "digest": "sha256:30b8c4ad5ab2a616bd07c7bd2e24dd58e19bf743a56788fd53808b2c54503515",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:30b8c4ad5ab2a616bd07c7bd2e24dd58e19bf743a56788fd53808b2c54503515",
          "name": "scanner-30b8c4ad5ab2a616bd07c7bd2e24dd58e19bf743a56788fd53808b2c54503515-annotation"
        },
        {
          "digest": "sha256:f3e11575aee05d474cb994c0ece89d992ece85be0596480582251fdec7a68f0b",
          "image": "registry.access.redhat.com/ubi8@sha256:f3e11575aee05d474cb994c0ece89d992ece85be0596480582251fdec7a68f0b",
          "name": "ubi8-f3e11575aee05d474cb994c0ece89d992ece85be0596480582251fdec7a68f0b-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.3.5",
      "version_original": "1.3.5"
    },
    {
      "_id": "63284308eb69678e80bd1f08",
      "alm_examples": [
        {
          "api_version": "apm.neuvector.com/v1alpha1",
          "kind": "Neuvector",
          "metadata": {
            "name": "neuvector"
          },
          "spec": {
            "admissionwebhook": {
              "type": "ClusterIP"
            },
            "bottlerocket": {
              "enabled": false,
              "runtimePath": "/run/dockershim.sock"
            },
            "containerd": {
              "enabled": false,
              "path": "/var/run/containerd/containerd.sock"
            },
            "controller": {
              "apisvc": {
                "annotations": {},
                "route": {
                  "enabled": false,
                  "host": "",
                  "termination": "passthrough"
                },
                "type": ""
              },
              "azureFileShare": {
                "enabled": false,
                "secretName": "",
                "shareName": ""
              },
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "configmap": {
                "data": "",
                "enabled": false
              },
              "disruptionbudget": 0,
              "enabled": true,
              "federation": {
                "managedsvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                },
                "mastersvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                }
              },
              "image": "registry.connect.redhat.com/neuvector/controller",
              "ingress": {
                "annotations": {
                  "ingress.kubernetes.io/protocol": "https"
                },
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "priorityClassName": "",
              "pvc": {
                "accessModes": [
                  "ReadWriteMany"
                ],
                "capacity": "",
                "enabled": false,
                "storageClass": ""
              },
              "replicas": 3,
              "resources": {},
              "strategy": {
                "rollingUpdate": {
                  "maxSurge": 1,
                  "maxUnavailable": 0
                },
                "type": "RollingUpdate"
              }
            },
            "crdwebhook": {
              "enabled": true,
              "type": "ClusterIP"
            },
            "crio": {
              "enabled": true,
              "path": "/var/run/crio/crio.sock"
            },
            "cve": {
              "scanner": {
                "dockerPath": "",
                "enabled": true,
                "image": "registry.connect.redhat.com/neuvector/scanner@sha256:a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06",
                "priorityClassName": "",
                "replicas": 3,
                "resources": {},
                "strategy": {
                  "rollingUpdate": {
                    "maxSurge": 1,
                    "maxUnavailable": 0
                  },
                  "type": "RollingUpdate"
                }
              },
              "updater": {
                "enabled": true,
                "image": "registry.access.redhat.com/ubi8@sha256:091ad37a5a638af2c21d01c2d3f4d489c2368070a6c43371e897013fb0987e49",
                "priorityClassName": "",
                "schedule": "0 0 * * *"
              }
            },
            "docker": {
              "enabled": false,
              "path": "/var/run/docker.sock"
            },
            "enforcer": {
              "enabled": true,
              "image": "registry.connect.redhat.com/neuvector/enforcer",
              "priorityClassName": "",
              "resources": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                }
              ]
            },
            "k3s": {
              "enabled": false,
              "runtimePath": "/run/k3s/containerd/containerd.sock"
            },
            "manager": {
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "enabled": true,
              "env": {
                "ssl": true
              },
              "image": "registry.connect.redhat.com/neuvector/manager",
              "ingress": {
                "annotations": {},
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "priorityClassName": "",
              "resources": {},
              "route": {
                "enabled": true,
                "host": "",
                "termination": "passthrough"
              },
              "svc": {
                "annotations": {},
                "loadBalancerIP": "",
                "type": "NodePort"
              }
            },
            "openshift": true,
            "psp": false,
            "resources": {},
            "serviceAccount": "default"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/neuvector/neuvector-operator-bundle@sha256:6f4ff463c67af42c1c3603e36e512a60dedb95775380a1a6b26c4cded86de5e1",
      "bundle_path_digest": "sha256:6f4ff463c67af42c1c3603e36e512a60dedb95775380a1a6b26c4cded86de5e1",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-09-19T10:23:04.247000+00:00",
      "csv_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.\n\nThe NeuVector Operator runs  in the openshift container platform to deploy and manage the NeuVector Security cluster components. The NeuVector operator contains all necessary information to deploy NeuVector using helm charts. You simply need to install the NeuVector operator from the OpenShift embeded operator hub and create NeuVector instance. You can modify the NeuVector installation configuration by modifying yaml while creating the NeuVector instance such as imagePullSecrets, tag version, etc. Please refer to [github link](https://github.com/neuvector/neuvector-helm/tree/master/charts/core) for the values that can be modifed during installation. To upgrade to a newer version of NeuVector, just reapply the NeuVector instance with desired tag , which in turn pulls the specified NeuVector image tags and upgrades as per upgrade plan configured on the helm chart.  NeuVector Operator versions are tied to NeuVector product versions. Version 1.2.8 of the NeuVector Certified Operator deploys version 4.3.1 of NeuVector.\n\n**Complete below steps to Grant Service Account Access to the Privileged SCC before installation.**\n\nCreate the NeuVector namespace\n\n         oc new-project  neuvector\nLogin as system:admin account\n\n         oc login -u system:admin\n\nGrant Service Account Access to the Privileged SCC\n\n         oc -n neuvector adm policy add-scc-to-user privileged -z default\n\nThe following info will be added in the Privileged SCC users:\n\n         - system:serviceaccount:neuvector:default\n\nIn OpenShift 4.6+ use the following to check:\n\n         oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide\n         NAME                              ROLE                                          AGE     USERS   GROUPS   SERVICEACCOUNTS\n         system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/default\n\n\n**Add NeuVector license from NeuVector WebUI->setting**\n\n\n#Deploying the NeuVector Operator#\n\n\nPlease refer to the instructions [here](https://github.com/neuvector/neuvector-operator/blob/master/README.md)\n\n\n",
      "csv_display_name": "NeuVector Operator",
      "csv_metadata_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.",
      "csv_name": "neuvector-operator.v1.2.8",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:35:18.132000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "neuvector-certified-operator",
      "provided_apis": [
        {
          "group": "apm.neuvector.com",
          "kind": "Neuvector",
          "version": "v1alpha1"
        }
      ],
      "provider": "NeuVector",
      "related_images": [
        {
          "digest": "sha256:9d8ab5fc5e3122fe1332ccf624e6897277e2e935690f4b07ca1c491599daec72",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:9d8ab5fc5e3122fe1332ccf624e6897277e2e935690f4b07ca1c491599daec72",
          "name": "neuvector-operator-9d8ab5fc5e3122fe1332ccf624e6897277e2e935690f4b07ca1c491599daec72-annotation"
        },
        {
          "digest": "sha256:9d8ab5fc5e3122fe1332ccf624e6897277e2e935690f4b07ca1c491599daec72",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:9d8ab5fc5e3122fe1332ccf624e6897277e2e935690f4b07ca1c491599daec72",
          "name": "neuvector-operator"
        },
        {
          "digest": "sha256:55b3d9873846d0a8670b58e8a8a76c426d3aba74d4e5c4fca43d05c1dd296f10",
          "image": "registry.connect.redhat.com/neuvector/controller@sha256:55b3d9873846d0a8670b58e8a8a76c426d3aba74d4e5c4fca43d05c1dd296f10",
          "name": "controller"
        },
        {
          "digest": "sha256:fdd66288454dd01f4f618c8cf04c7da501d4362773266ec6f448d63e26e3a35c",
          "image": "registry.connect.redhat.com/neuvector/enforcer@sha256:fdd66288454dd01f4f618c8cf04c7da501d4362773266ec6f448d63e26e3a35c",
          "name": "enforcer"
        },
        {
          "digest": "sha256:73445c18ea18f131b6fa630a97623a3043d05758205ef93fc02fa920abbedaa6",
          "image": "registry.connect.redhat.com/neuvector/manager@sha256:73445c18ea18f131b6fa630a97623a3043d05758205ef93fc02fa920abbedaa6",
          "name": "manager"
        },
        {
          "digest": "sha256:a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06",
          "name": "scanner"
        },
        {
          "digest": "sha256:091ad37a5a638af2c21d01c2d3f4d489c2368070a6c43371e897013fb0987e49",
          "image": "registry.access.redhat.com/ubi8@sha256:091ad37a5a638af2c21d01c2d3f4d489c2368070a6c43371e897013fb0987e49",
          "name": "updater"
        },
        {
          "digest": "sha256:a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06",
          "name": "scanner-a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06-annotation"
        },
        {
          "digest": "sha256:091ad37a5a638af2c21d01c2d3f4d489c2368070a6c43371e897013fb0987e49",
          "image": "registry.access.redhat.com/ubi8@sha256:091ad37a5a638af2c21d01c2d3f4d489c2368070a6c43371e897013fb0987e49",
          "name": "ubi8-091ad37a5a638af2c21d01c2d3f4d489c2368070a6c43371e897013fb0987e49-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.2.8",
      "version_original": "1.2.8"
    },
    {
      "_id": "63284309eb69678e80bd1f0d",
      "alm_examples": [
        {
          "api_version": "apm.neuvector.com/v1alpha1",
          "kind": "Neuvector",
          "metadata": {
            "name": "neuvector"
          },
          "spec": {
            "admissionwebhook": {
              "type": "ClusterIP"
            },
            "bottlerocket": {
              "enabled": false,
              "runtimePath": "/run/dockershim.sock"
            },
            "containerd": {
              "enabled": false,
              "path": "/var/run/containerd/containerd.sock"
            },
            "controller": {
              "apisvc": {
                "annotations": {},
                "route": {
                  "enabled": false,
                  "host": "",
                  "termination": "passthrough"
                },
                "type": ""
              },
              "azureFileShare": {
                "enabled": false,
                "secretName": "",
                "shareName": ""
              },
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "configmap": {
                "data": "",
                "enabled": false
              },
              "disruptionbudget": 0,
              "enabled": true,
              "federation": {
                "managedsvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                },
                "mastersvc": {
                  "ingress": {
                    "annotations": {
                      "ingress.kubernetes.io/protocol": "https"
                    },
                    "enabled": false,
                    "host": "",
                    "path": "/",
                    "secretName": "",
                    "tls": false
                  },
                  "route": {
                    "enabled": false,
                    "host": "",
                    "termination": "passthrough"
                  },
                  "type": ""
                }
              },
              "image": "registry.connect.redhat.com/neuvector/controller",
              "ingress": {
                "annotations": {
                  "ingress.kubernetes.io/protocol": "https"
                },
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "priorityClassName": "",
              "pvc": {
                "accessModes": [
                  "ReadWriteMany"
                ],
                "capacity": "",
                "enabled": false,
                "storageClass": ""
              },
              "replicas": 3,
              "resources": {},
              "schedulerName": "",
              "strategy": {
                "rollingUpdate": {
                  "maxSurge": 1,
                  "maxUnavailable": 0
                },
                "type": "RollingUpdate"
              }
            },
            "crdwebhook": {
              "enabled": true,
              "type": "ClusterIP"
            },
            "crio": {
              "enabled": true,
              "path": "/var/run/crio/crio.sock"
            },
            "cve": {
              "scanner": {
                "dockerPath": "",
                "enabled": true,
                "image": "registry.connect.redhat.com/neuvector/scanner@sha256:a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06",
                "priorityClassName": "",
                "replicas": 3,
                "resources": {},
                "strategy": {
                  "rollingUpdate": {
                    "maxSurge": 1,
                    "maxUnavailable": 0
                  },
                  "type": "RollingUpdate"
                }
              },
              "updater": {
                "enabled": true,
                "image": "registry.access.redhat.com/ubi8@sha256:910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7",
                "priorityClassName": "",
                "schedule": "0 0 * * *",
                "secure": false
              }
            },
            "docker": {
              "enabled": false,
              "path": "/var/run/docker.sock"
            },
            "enforcer": {
              "enabled": true,
              "image": "registry.connect.redhat.com/neuvector/enforcer",
              "priorityClassName": "",
              "resources": {},
              "tolerations": [
                {
                  "effect": "NoSchedule",
                  "key": "node-role.kubernetes.io/master"
                }
              ]
            },
            "k3s": {
              "enabled": false,
              "runtimePath": "/run/k3s/containerd/containerd.sock"
            },
            "manager": {
              "certificate": {
                "keyFile": "tls.key",
                "pemFile": "tls.pem",
                "secret": ""
              },
              "enabled": true,
              "env": {
                "ssl": true
              },
              "image": "registry.connect.redhat.com/neuvector/manager",
              "ingress": {
                "annotations": {},
                "enabled": false,
                "host": "",
                "path": "/",
                "secretName": "",
                "tls": false
              },
              "priorityClassName": "",
              "resources": {},
              "route": {
                "enabled": true,
                "host": "",
                "termination": "passthrough"
              },
              "svc": {
                "annotations": {},
                "loadBalancerIP": "",
                "type": "NodePort"
              }
            },
            "openshift": true,
            "psp": false,
            "resources": {},
            "serviceAccount": "default"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/neuvector/neuvector-operator-bundle@sha256:29996196f2eba8f7662bdf1efeaac3a0ccf56bdfb2e522b340d9a239f7ca51e4",
      "bundle_path_digest": "sha256:29996196f2eba8f7662bdf1efeaac3a0ccf56bdfb2e522b340d9a239f7ca51e4",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-09-19T10:23:05.731000+00:00",
      "csv_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.\n\nThe NeuVector Operator runs  in the openshift container platform to deploy and manage the NeuVector Security cluster components. The NeuVector operator contains all necessary information to deploy NeuVector using helm charts. You simply need to install the NeuVector operator from the OpenShift embeded operator hub and create NeuVector instance. You can modify the NeuVector installation configuration by modifying yaml while creating the NeuVector instance such as imagePullSecrets, tag version, etc. Please refer to [github link](https://github.com/neuvector/neuvector-helm/tree/master/charts/core) for the values that can be modifed during installation. To upgrade to a newer version of NeuVector, just reapply the NeuVector instance with desired tag , which in turn pulls the specified NeuVector image tags and upgrades as per upgrade plan configured on the helm chart.  NeuVector Operator versions are tied to NeuVector product versions. Version 1.2.9 of the NeuVector Certified Operator deploys version 4.3.1 of NeuVector.\n\n**Complete below steps to Grant Service Account Access to the Privileged SCC before installation.**\n\nCreate the NeuVector namespace\n\n         oc new-project  neuvector\nLogin as system:admin account\n\n         oc login -u system:admin\n\nGrant Service Account Access to the Privileged SCC\n\n         oc -n neuvector adm policy add-scc-to-user privileged -z default\n\nThe following info will be added in the Privileged SCC users:\n\n         - system:serviceaccount:neuvector:default\n\nIn OpenShift 4.6+ use the following to check:\n\n         oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide\n         NAME                              ROLE                                          AGE     USERS   GROUPS   SERVICEACCOUNTS\n         system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/default\n\n\n**Add NeuVector license from NeuVector WebUI->setting**\n\n\n#Deploying the NeuVector Operator#\n\n\nPlease refer to the instructions [here](https://github.com/neuvector/neuvector-operator/blob/master/README.md)\n\n\n",
      "csv_display_name": "NeuVector Operator",
      "csv_metadata_description": "NeuVector delivers the only cloud-native Kubernetes security platform with uncompromising end-to-end protection from DevOps vulnerability protection to automated run-time security, and featuring a true Layer 7 container firewall.",
      "csv_name": "neuvector-operator.v1.2.9",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:35:20.040000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "neuvector-certified-operator",
      "provided_apis": [
        {
          "group": "apm.neuvector.com",
          "kind": "Neuvector",
          "version": "v1alpha1"
        }
      ],
      "provider": "NeuVector",
      "related_images": [
        {
          "digest": "sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "name": "neuvector-operator-487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1-annotation"
        },
        {
          "digest": "sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "image": "registry.connect.redhat.com/neuvector/neuvector-operator@sha256:487e2d6e817b7e006fb90cf1d5da2964de665424acada7bc63b4fa7b642b64f1",
          "name": "neuvector-operator"
        },
        {
          "digest": "sha256:55b3d9873846d0a8670b58e8a8a76c426d3aba74d4e5c4fca43d05c1dd296f10",
          "image": "registry.connect.redhat.com/neuvector/controller@sha256:55b3d9873846d0a8670b58e8a8a76c426d3aba74d4e5c4fca43d05c1dd296f10",
          "name": "controller"
        },
        {
          "digest": "sha256:fdd66288454dd01f4f618c8cf04c7da501d4362773266ec6f448d63e26e3a35c",
          "image": "registry.connect.redhat.com/neuvector/enforcer@sha256:fdd66288454dd01f4f618c8cf04c7da501d4362773266ec6f448d63e26e3a35c",
          "name": "enforcer"
        },
        {
          "digest": "sha256:73445c18ea18f131b6fa630a97623a3043d05758205ef93fc02fa920abbedaa6",
          "image": "registry.connect.redhat.com/neuvector/manager@sha256:73445c18ea18f131b6fa630a97623a3043d05758205ef93fc02fa920abbedaa6",
          "name": "manager"
        },
        {
          "digest": "sha256:a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06",
          "name": "scanner"
        },
        {
          "digest": "sha256:910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7",
          "image": "registry.access.redhat.com/ubi8@sha256:910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7",
          "name": "updater"
        },
        {
          "digest": "sha256:a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06",
          "image": "registry.connect.redhat.com/neuvector/scanner@sha256:a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06",
          "name": "scanner-a802c012eee80444d9deea8c4402a1d977cf57d7b2b2044f90c9acc0e7ca3e06-annotation"
        },
        {
          "digest": "sha256:910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7",
          "image": "registry.access.redhat.com/ubi8@sha256:910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7",
          "name": "ubi8-910f6bc0b5ae9b555eb91b88d28d568099b060088616eba2867b07ab6ea457c7-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.2.9",
      "version_original": "1.2.9"
    },
    {
      "_id": "6328430ba1826a2016e6ff0e",
      "alm_examples": [
        {
          "api_version": "citrix.citrix.com/v1alpha1",
          "kind": "Citrix-adc-istio-ingress-gateway",
          "metadata": {
            "name": "cxa-ingress-gateway-sample"
          },
          "spec": {
            "ADMSettings": {
              "ADMIP": "",
              "bandWidth": "",
              "bandWidthLicense": false,
              "cpxCores": "",
              "licenseServerIP": "",
              "licenseServerPort": 27000,
              "vCPULicense": false
            },
            "certProvider": {
              "caAddr": "istiod.istio-system.svc",
              "caPort": 15012,
              "certTTLinHours": 720,
              "clusterId": "Kubernetes",
              "jwtPolicy": "",
              "trustDomain": "cluster.local"
            },
            "citrixCPX": false,
            "coe": {
              "coeTracing": false,
              "coeURL": ""
            },
            "ingressGateway": {
              "EULA": false,
              "adcServerName": "",
              "httpNodePort": 30180,
              "httpsNodePort": 31443,
              "image": "quay.io/citrix/citrix-k8s-cpx-ingress@sha256:8f28c8af17909f0c0ced2109701755be1edea22b2a80f00aa37da70168abe1dc",
              "imagePullPolicy": "IfNotPresent",
              "label": "citrix-ingressgateway",
              "lightWeightCPX": 1,
              "mgmtHttpPort": 10080,
              "mgmtHttpsPort": 10443,
              "multiClusterIngress": false,
              "multiClusterListenerNodePort": 32443,
              "multiClusterListenerPort": 15443,
              "multiClusterSvcDomain": "global",
              "netProfile": "",
              "netscalerUrl": "",
              "nodePortRequired": false,
              "secretVolumes": [],
              "tcpPort": [],
              "vserverIP": "nsip"
            },
            "istioPilot": {
              "insecureGrpcPort": 15010,
              "name": "istiod",
              "namespace": "istio-system",
              "secureGrpcPort": 15012
            },
            "metricExporter": {
              "image": "quay.io/citrix/citrix-adc-metrics-exporter@sha256:edc7f42fed88a1652904abb3a9cca09cd555374320a55693087eea2da629e536",
              "imagePullPolicy": "IfNotPresent",
              "logLevel": "ERROR",
              "port": 8888,
              "required": true,
              "secure": "YES"
            },
            "secretName": "nslogin",
            "xDSAdaptor": {
              "image": "quay.io/citrix/citrix-xds-adaptor@sha256:b5b5ab8435d65dcbe4348c0f1b4b69fef8fcc8a27e67927821ff4b4f0b8594f6",
              "imagePullPolicy": "IfNotPresent",
              "jsonLog": false,
              "logLevel": "DEBUG",
              "proxyType": "router",
              "secureConnect": true
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/citrix/istioingressgateway-bundle@sha256:5af6bafd200b94629bf0c5371a779ec19a726225821daa796d494fa99ef2c6e8",
      "bundle_path_digest": "sha256:5af6bafd200b94629bf0c5371a779ec19a726225821daa796d494fa99ef2c6e8",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:23:07.842000+00:00",
      "csv_description": "An Istio ingress gateway acts as an entry point for the incoming traffic and secures and controls access to the service mesh from outside. It also performs routing and load balancing. Citrix ADC CPX, MPX, or VPX can be deployed as an ingress gateway to the Istio service mesh",
      "csv_display_name": "Citrix ADC Istio Ingress Gateway Operator",
      "csv_metadata_description": "An Istio ingress gateway acts as an entry point for the incoming traffic. Citrix ADC CPX, MPX, or VPX can be deployed as an ingress gateway to the Istio service jeee An Istio ingress gateway acts as an entry point for the incoming traffic and secures and controls access to the service mesh from outside. It also perform routing and load balancing. Citrix ADC CPX, MPX, or VPX can be deployed as an ingress gateway to the Istio service mesh.",
      "csv_name": "citrix-adc-istio-ingress-gateway-operator.v0.9.9",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:30:47.437000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "citrix-adc-istio-ingress-gateway-operator",
      "provided_apis": [
        {
          "group": "citrix.citrix.com",
          "kind": "Citrix-adc-istio-ingress-gateway",
          "version": "v1alpha1"
        }
      ],
      "provider": "citrix",
      "related_images": [
        {
          "digest": "sha256:8333b7fb73ad7479be45cb6a71d391554480ee0a623744e0a2e185cd1f45c226",
          "image": "registry.connect.redhat.com/citrix/citrix-adc-istio-ingress-gateway@sha256:8333b7fb73ad7479be45cb6a71d391554480ee0a623744e0a2e185cd1f45c226",
          "name": "citrix-adc-istio-ingress-gateway-8333b7fb73ad7479be45cb6a71d391554480ee0a623744e0a2e185cd1f45c226-annotation"
        },
        {
          "digest": "sha256:a5c16c64229aac3564c66816c123e81a849ff93b8a443cd6ff14bd8d63c06644",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:a5c16c64229aac3564c66816c123e81a849ff93b8a443cd6ff14bd8d63c06644",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:8333b7fb73ad7479be45cb6a71d391554480ee0a623744e0a2e185cd1f45c226",
          "image": "registry.connect.redhat.com/citrix/citrix-adc-istio-ingress-gateway@sha256:8333b7fb73ad7479be45cb6a71d391554480ee0a623744e0a2e185cd1f45c226",
          "name": "manager"
        },
        {
          "digest": "sha256:b5b5ab8435d65dcbe4348c0f1b4b69fef8fcc8a27e67927821ff4b4f0b8594f6",
          "image": "quay.io/citrix/citrix-xds-adaptor@sha256:b5b5ab8435d65dcbe4348c0f1b4b69fef8fcc8a27e67927821ff4b4f0b8594f6",
          "name": "citrix-xds-adaptor-b5b5ab8435d65dcbe4348c0f1b4b69fef8fcc8a27e67927821ff4b4f0b8594f6-annotation"
        },
        {
          "digest": "sha256:edc7f42fed88a1652904abb3a9cca09cd555374320a55693087eea2da629e536",
          "image": "quay.io/citrix/citrix-adc-metrics-exporter@sha256:edc7f42fed88a1652904abb3a9cca09cd555374320a55693087eea2da629e536",
          "name": "citrix-adc-metrics-exporter-edc7f42fed88a1652904abb3a9cca09cd555374320a55693087eea2da629e536-annotation"
        },
        {
          "digest": "sha256:8f28c8af17909f0c0ced2109701755be1edea22b2a80f00aa37da70168abe1dc",
          "image": "quay.io/citrix/citrix-k8s-cpx-ingress@sha256:8f28c8af17909f0c0ced2109701755be1edea22b2a80f00aa37da70168abe1dc",
          "name": "citrix-k8s-cpx-ingress-8f28c8af17909f0c0ced2109701755be1edea22b2a80f00aa37da70168abe1dc-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "0.9.9",
      "version_original": "0.9.9"
    },
    {
      "_id": "6328430da1826a2016e6ff16",
      "alm_examples": [
        {
          "api_version": "apps.gitlab.com/v1beta2",
          "kind": "Runner",
          "metadata": {
            "name": "example"
          },
          "spec": {
            "gitlabUrl": "https://gitlab.com",
            "imagePullPolicy": "Always",
            "tags": "openshift, test",
            "token": "gitlab-dev-runner-secret"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/gitlab/gitlab-runner-operator-bundle@sha256:a983d27fdb8e3c63bdbf40efe22a2ab62016c3ca75040c2f1a4b429278d72731",
      "bundle_path_digest": "sha256:a983d27fdb8e3c63bdbf40efe22a2ab62016c3ca75040c2f1a4b429278d72731",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T10:23:09.941000+00:00",
      "csv_description": "GitLab Runner is the lightweight, highly-scalable agent that runs your build jobs and sends the results back to a GitLab instance. GitLab Runner works in conjunction with GitLab CI/CD, the open-source continuous integration service included with GitLab.\n\nThe GitLab Runner operator manages the lifecycle of GitLab Runner in Kubernetes or Openshift clusters. The operator aims to automate the tasks needed to run your CI/CD jobs in your container orchestration platform.\n\n## Usage\n\n To link a GitLab Runner instance to a self-hosted GitLab instance or the hosted [GitLab](https://gitlab.com), you first need to:\n\n 1. create a secret containing the `runner-registration-token` from your GitLab project.\n\n   ```\n  cat > gitlab-runner-secret.yml << EOF\n  apiVersion: v1\n  kind: Secret\n  metadata:\n    name: gitlab-runner-secret\n  type: Opaque\n  stringData:\n    runner-registration-token: REPLACE_ME # your project runner secret\n  EOF\n  ```\n\n  ```\n  oc apply -f gitlab-runner-secret.yml\n  ```\n\n 2. Create the Custom Resource Definition (CRD) file and include the following information. The tags value must be openshift for the job to run.\n\n   ```\n   cat > gitlab-runner.yml << EOF\n   apiVersion: apps.gitlab.com/v1beta2\n   kind: Runner\n   metadata:\n     name: gitlab-runner\n   spec:\n     gitlabUrl: https://gitlab.example.com\n     buildImage: alpine\n     token: gitlab-runner-secret\n     tags: openshift\n   EOF\n   ```\n\n  ```\n  oc apply -f gitlab-runner.yml\n  ```\n\n## Full documentation\n\nVisit [Install GitLab Runner on Red Hat OpenShift](https://docs.gitlab.com/runner/install/openshift.html)\n",
      "csv_display_name": "GitLab Runner",
      "csv_metadata_description": "GitLab Runner operator manages lifecycle of GitLab Runner instances",
      "csv_name": "gitlab-runner-operator.v1.4.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:31:29.305000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "gitlab-runner-operator",
      "provided_apis": [
        {
          "group": "apps.gitlab.com",
          "kind": "Runner",
          "version": "v1beta2"
        }
      ],
      "provider": "GitLab, Inc.",
      "related_images": [
        {
          "digest": "sha256:4cd860f02a5c22208cebfdae751fdc27069a4c14442a9020024c576c700f0634",
          "image": "registry.connect.redhat.com/gitlab/gitlab-runner@sha256:4cd860f02a5c22208cebfdae751fdc27069a4c14442a9020024c576c700f0634",
          "name": "gitlab-runner"
        },
        {
          "digest": "sha256:272c50ca9ef77c92deac0ca302df9e0127d5c54609c35230f96cf1d91de5fe97",
          "image": "registry.connect.redhat.com/gitlab/gitlab-runner-helper@sha256:272c50ca9ef77c92deac0ca302df9e0127d5c54609c35230f96cf1d91de5fe97",
          "name": "gitlab-runner-helper"
        },
        {
          "digest": "sha256:c6572cb1c20713f2f582f8b436307e80c23dcac08c1d7bde37833fd266ef9618",
          "image": "registry.connect.redhat.com/gitlab/gitlab-runner-operator@sha256:c6572cb1c20713f2f582f8b436307e80c23dcac08c1d7bde37833fd266ef9618",
          "name": "gitlab-runner-operator"
        },
        {
          "digest": "sha256:dc0f91e256c86c3f7cb930d0e4d48eb68576425bc4bd288fb76decb0577c7e9e",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:dc0f91e256c86c3f7cb930d0e4d48eb68576425bc4bd288fb76decb0577c7e9e",
          "name": "kube-rbac-proxy"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.4.0",
      "version_original": "1.4.0"
    },
    {
      "_id": "6328430f2dd1cd9660afbade",
      "alm_examples": [
        {
          "api_version": "apps.gitlab.com/v1beta2",
          "kind": "Runner",
          "metadata": {
            "name": "example"
          },
          "spec": {
            "gitlabUrl": "https://gitlab.com",
            "imagePullPolicy": "Always",
            "tags": "openshift, test",
            "token": "gitlab-dev-runner-secret"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/gitlab/gitlab-runner-operator-bundle@sha256:abe1504fedbf38bc1cb45e5393216bae9cca95066ca84fa730c7e8b129930074",
      "bundle_path_digest": "sha256:abe1504fedbf38bc1cb45e5393216bae9cca95066ca84fa730c7e8b129930074",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T10:23:11.660000+00:00",
      "csv_description": "GitLab Runner is the lightweight, highly-scalable agent that runs your build jobs and sends the results back to a GitLab instance. GitLab Runner works in conjunction with GitLab CI/CD, the open-source continuous integration service included with GitLab.\n\nThe GitLab Runner operator manages the lifecycle of GitLab Runner in Kubernetes or Openshift clusters. The operator aims to automate the tasks needed to run your CI/CD jobs in your container orchestration platform.\n\n## Usage\n\n To link a GitLab Runner instance to a self-hosted GitLab instance or the hosted [GitLab](https://gitlab.com), you first need to:\n\n 1. create a secret containing the `runner-registration-token` from your GitLab project.\n\n   ```\n  cat > gitlab-runner-secret.yml << EOF\n  apiVersion: v1\n  kind: Secret\n  metadata:\n    name: gitlab-runner-secret\n  type: Opaque\n  stringData:\n    runner-registration-token: REPLACE_ME # your project runner secret\n  EOF\n  ```\n\n  ```\n  oc apply -f gitlab-runner-secret.yml\n  ```\n\n 2. Create the Custom Resource Definition (CRD) file and include the following information. The tags value must be openshift for the job to run.\n\n   ```\n   cat > gitlab-runner.yml << EOF\n   apiVersion: apps.gitlab.com/v1beta2\n   kind: Runner\n   metadata:\n     name: gitlab-runner\n   spec:\n     gitlabUrl: https://gitlab.example.com\n     buildImage: alpine\n     token: gitlab-runner-secret\n     tags: openshift\n   EOF\n   ```\n\n  ```\n  oc apply -f gitlab-runner.yml\n  ```\n\n## Full documentation\n\nVisit [Install GitLab Runner on Red Hat OpenShift](https://docs.gitlab.com/runner/install/openshift.html)\n",
      "csv_display_name": "GitLab Runner",
      "csv_metadata_description": "GitLab Runner operator manages lifecycle of GitLab Runner instances",
      "csv_name": "gitlab-runner-operator.v1.2.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:31:26.842000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "gitlab-runner-operator",
      "provided_apis": [
        {
          "group": "apps.gitlab.com",
          "kind": "Runner",
          "version": "v1beta2"
        }
      ],
      "provider": "GitLab, Inc.",
      "related_images": [
        {
          "digest": "sha256:f48d93d89905284a35a72ec312ad4313bb1a42deaaab662eb181a65d34a89cd9",
          "image": "registry.connect.redhat.com/gitlab/gitlab-runner@sha256:f48d93d89905284a35a72ec312ad4313bb1a42deaaab662eb181a65d34a89cd9",
          "name": "gitlab-runner"
        },
        {
          "digest": "sha256:9148c4c10685871e3bbed037d9c36e85f0603da38e721c5db2a85b9c6defeac9",
          "image": "registry.connect.redhat.com/gitlab/gitlab-runner-helper@sha256:9148c4c10685871e3bbed037d9c36e85f0603da38e721c5db2a85b9c6defeac9",
          "name": "gitlab-runner-helper"
        },
        {
          "digest": "sha256:6ac79da50858f82949e1dae4a016cbe86b75de977fe747a958d28dcd5c8e4080",
          "image": "registry.connect.redhat.com/gitlab/gitlab-runner-operator@sha256:6ac79da50858f82949e1dae4a016cbe86b75de977fe747a958d28dcd5c8e4080",
          "name": "gitlab-runner-operator"
        },
        {
          "digest": "sha256:dc0f91e256c86c3f7cb930d0e4d48eb68576425bc4bd288fb76decb0577c7e9e",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:dc0f91e256c86c3f7cb930d0e4d48eb68576425bc4bd288fb76decb0577c7e9e",
          "name": "kube-rbac-proxy"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.2.0",
      "version_original": "1.2.0"
    },
    {
      "_id": "63284311316b8eb377f0775e",
      "alm_examples": [
        {
          "api_version": "deviceplugin.intel.com/v1",
          "kind": "SgxDevicePlugin",
          "metadata": {
            "name": "sgxdeviceplugin-sample"
          },
          "spec": {
            "enclaveLimit": 110,
            "image": "registry.connect.redhat.com/intel/intel-sgx-plugin@sha256:c0423b149b909472460f84a299b087a5104ed40a3572687d6b450609e3bb3076",
            "initImage": "registry.connect.redhat.com/intel/intel-sgx-initcontainer@sha256:236cc06aea0b957eb0a67aa2c8b2778a485b34f8d4aeec691f0de4a6baccf364",
            "logLevel": 4,
            "nodeSelector": {
              "intel.feature.node.kubernetes.io/sgx": "true"
            },
            "provisionLimit": 110
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/intel/intel-device-plugins-operator-bundle@sha256:47efe9eb7a9d540931ceacf85abfaef8ef4208703174b17ee9ce908d62cca9ed",
      "bundle_path_digest": "sha256:47efe9eb7a9d540931ceacf85abfaef8ef4208703174b17ee9ce908d62cca9ed",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:23:13.265000+00:00",
      "csv_description": "[Intel Device Plugins for Kubernetes](https://github.com/intel/intel-device-plugins-for-kubernetes) is a collection of\n[device plugins](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/) advertising Intel specific hardware resources\nto the kubelet. Currently the operator only supports the Intel SGX device plugin. Other device plugins like Intel GPU, Intel QAT, Intel DSA, Intel IAA will be supported in future releases.\n",
      "csv_display_name": "Intel Device Plugins Operator",
      "csv_metadata_description": "This operator is a Kubernetes custom controller whose goal is to serve the installation and lifecycle management of Intel device plugins for Kubernetes.",
      "csv_name": "intel-device-plugins-operator.v0.24.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:26:44.943000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "intel-device-plugins-operator",
      "provided_apis": [
        {
          "group": "deviceplugin.intel.com",
          "kind": "SgxDevicePlugin",
          "version": "v1"
        }
      ],
      "provider": "Intel\u00ae Corporation",
      "related_images": [
        {
          "digest": "sha256:c92c19d283f5292916258b393e765d0d00f81e9150be75d4d8ec68796d408ecd",
          "image": "registry.connect.redhat.com/intel/intel-deviceplugin-operator@sha256:c92c19d283f5292916258b393e765d0d00f81e9150be75d4d8ec68796d408ecd",
          "name": "intel-deviceplugin-operator-c92c19d283f5292916258b393e765d0d00f81e9150be75d4d8ec68796d408ecd-annotation"
        },
        {
          "digest": "sha256:c92c19d283f5292916258b393e765d0d00f81e9150be75d4d8ec68796d408ecd",
          "image": "registry.connect.redhat.com/intel/intel-deviceplugin-operator@sha256:c92c19d283f5292916258b393e765d0d00f81e9150be75d4d8ec68796d408ecd",
          "name": "manager"
        },
        {
          "digest": "sha256:e10d1d982dd653db74ca87a1d1ad017bc5ef1aeb651bdea089debf16485b080b",
          "image": "gcr.io/kubebuilder/kube-rbac-proxy@sha256:e10d1d982dd653db74ca87a1d1ad017bc5ef1aeb651bdea089debf16485b080b",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:236cc06aea0b957eb0a67aa2c8b2778a485b34f8d4aeec691f0de4a6baccf364",
          "image": "registry.connect.redhat.com/intel/intel-sgx-initcontainer@sha256:236cc06aea0b957eb0a67aa2c8b2778a485b34f8d4aeec691f0de4a6baccf364",
          "name": "intel-sgx-initcontainer-236cc06aea0b957eb0a67aa2c8b2778a485b34f8d4aeec691f0de4a6baccf364-annotation"
        },
        {
          "digest": "sha256:c0423b149b909472460f84a299b087a5104ed40a3572687d6b450609e3bb3076",
          "image": "registry.connect.redhat.com/intel/intel-sgx-plugin@sha256:c0423b149b909472460f84a299b087a5104ed40a3572687d6b450609e3bb3076",
          "name": "intel-sgx-plugin-c0423b149b909472460f84a299b087a5104ed40a3572687d6b450609e3bb3076-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "0.24.0",
      "version_original": "0.24.0"
    },
    {
      "_id": "632843128454bee1cb723b01",
      "alm_examples": [
        {
          "api_version": "pcc.paloaltonetworks.com/v1alpha1",
          "kind": "Console",
          "metadata": {
            "name": "pcc-console",
            "namespace": "twistlock"
          },
          "spec": {
            "consoleConfig": {
              "serviceType": "ClusterIP"
            },
            "namespace": "twistlock",
            "version": "21_08_520"
          }
        },
        {
          "api_version": "pcc.paloaltonetworks.com/v1alpha1",
          "kind": "ConsoleDefender",
          "metadata": {
            "name": "pcc-consoledefender",
            "namespace": "twistlock"
          },
          "spec": {
            "consoleConfig": {
              "serviceType": "ClusterIP"
            },
            "defenderConfig": {
              "docker": false
            },
            "namespace": "twistlock",
            "version": "21_08_520"
          }
        },
        {
          "api_version": "pcc.paloaltonetworks.com/v1alpha1",
          "kind": "Defender",
          "metadata": {
            "name": "pcc-defender",
            "namespace": "twistlock"
          },
          "spec": {
            "defenderConfig": {
              "clusterAddress": "twistlock-console.example.com",
              "consoleAddress": "https://twistlock-console.example.com:8083",
              "docker": false
            },
            "namespace": "twistlock",
            "version": "21_08_520"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [
          "Disconnected"
        ],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/paloalto/pcc-operator@sha256:cd2291126f3c56ed2001e6ca9157ac4c752ff0a1f6de2c0e920e06f83c84d17b",
      "bundle_path_digest": "sha256:cd2291126f3c56ed2001e6ca9157ac4c752ff0a1f6de2c0e920e06f83c84d17b",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T10:23:14.303000+00:00",
      "csv_description": "## Features\n- Deploy Console\n    - Create initial local administrator user\n    - Add license\n- Deploy Defenders\n- Support for offline deployments\n- Upgrade Console\n- Upgrade Defenders\n\n## Installation\nSee the [Prisma Cloud Compute Operator documentation](https://github.com/PaloAltoNetworks/prisma-cloud-compute-operator) for installation guides.\n\n## Support\nThis operator is available \"as is,\" and should be seen as community-supported; however, Palo Alto Networks will continue contributing whenever possible.\nPalo Alto Networks does not provide technical support or help with using or troubleshooting the operator through normal support channels.\nWe encourage you to open GitHub [issues](https://github.com/PaloAltoNetworks/prisma-cloud-compute-operator/issues) and [pull requests](https://github.com/PaloAltoNetworks/prisma-cloud-compute-operator/pulls) to track bugs and feature requests.\n\n## Other links\n[Prisma Cloud Compute product documentation](https://docs.paloaltonetworks.com/prisma/prisma-cloud/prisma-cloud-admin-compute.html)\n\n[Prisma Cloud Compute API documentation](https://prisma.pan.dev/api/cloud/cwpp)\n",
      "csv_display_name": "Prisma Cloud Compute Operator",
      "csv_metadata_description": "Deploy Prisma Cloud Compute for cloud-native security in your clusters",
      "csv_name": "pcc-operator.v0.2.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:29:25.143000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "pcc-operator",
      "provided_apis": [
        {
          "group": "pcc.paloaltonetworks.com",
          "kind": "Console",
          "version": "v1alpha1"
        },
        {
          "group": "pcc.paloaltonetworks.com",
          "kind": "ConsoleDefender",
          "version": "v1alpha1"
        },
        {
          "group": "pcc.paloaltonetworks.com",
          "kind": "Defender",
          "version": "v1alpha1"
        }
      ],
      "provider": "Palo Alto Networks",
      "related_images": [
        {
          "digest": "sha256:91469e90fb442d747a5dd462a3b8e80cea2c590881a685bc58c562f1382e2fec",
          "image": "quay.io/prismacloud/pcc-operator@sha256:91469e90fb442d747a5dd462a3b8e80cea2c590881a685bc58c562f1382e2fec",
          "name": "pcc-operator-91469e90fb442d747a5dd462a3b8e80cea2c590881a685bc58c562f1382e2fec-annotation"
        },
        {
          "digest": "sha256:91469e90fb442d747a5dd462a3b8e80cea2c590881a685bc58c562f1382e2fec",
          "image": "quay.io/prismacloud/pcc-operator@sha256:91469e90fb442d747a5dd462a3b8e80cea2c590881a685bc58c562f1382e2fec",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "0.2.2",
      "version_original": "0.2.2"
    },
    {
      "_id": "63284314a9c6e63893ae5383",
      "alm_examples": [
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyApplication",
          "metadata": {
            "name": "openliberty-app-sample"
          },
          "spec": {
            "applicationImage": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
            "expose": true,
            "replicas": 1
          }
        },
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyDump",
          "metadata": {
            "name": "openliberty-dump-sample"
          },
          "spec": {
            "include": [
              "thread",
              "heap"
            ],
            "podName": "Specify_Pod_Name_Here"
          }
        },
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyTrace",
          "metadata": {
            "name": "openliberty-trace-sample"
          },
          "spec": {
            "maxFileSize": 20,
            "maxFiles": 5,
            "podName": "Specify_Pod_Name_Here",
            "traceSpecification": "*=info:com.ibm.ws.webcontainer*=all"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/open-liberty-operator-bundle@sha256:88ff3cd847c4b606466b1e782cec0dfbdb62fb3dd0e4e1bc8b9c2d1016c74132",
      "bundle_path_digest": "sha256:88ff3cd847c4b606466b1e782cec0dfbdb62fb3dd0e4e1bc8b9c2d1016c74132",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "beta2",
      "creation_date": "2022-09-19T10:23:16.509000+00:00",
      "csv_description": "This advanced Operator can be used to deploy and manage Open Liberty applications with consistent, production-grade QoS. This operator is based on the [Runtime Component Operator](https://github.com/application-stacks/runtime-component-operator) and provides all of its capabilities in addition to Open Liberty specific features such as gathering traces and dumps (Day-2 operations) and easily configuring and managing the single sign-on information for your Open Liberty applications.\n\nOpen Liberty Operator enables enterprise architects to govern the way their applications get deployed & managed in the cluster, while dramatically reducing the learning curve for developers to deploy into Kubernetes - allowing them to focus on writing the code! Here are some key features:\n\n#### Application Lifecyle\nYou can deploy your Open Liberty application container by either pointing to a container image, or an OpenShift ImageStream. When using an ImageStream the Operator will watch for any updates and will re-deploy the modified image.\n\n#### Custom RBAC\nThis Operator is capable of using a custom ServiceAccount from the caller, allowing it to follow RBAC restrictions. By default it creates a ServiceAccount if one is not specified, which can also be bound with specific roles.\n\n#### Environment Configuration\nYou can configure a variety of artifacts with your deployment, such as: labels, annotations, and environment variables from a ConfigMap, a Secret or a value.\n\n#### Routing\nExpose your application to external users via a single toggle to create a Route on OpenShift or an Ingress on other Kubernetes environments. Advanced configuration, such as TLS settings, are also easily enabled. Expiring Route certificates are re-issued.\n\n#### High Availability via Horizontal Pod Autoscaling\nRun multiple instances of your application for high availability. Either specify a static number of replicas or easily configure horizontal auto scaling to create (and delete) instances based on resource consumption.\n\n#### Persistence and advanced storage\nEnable persistence for your application by specifying simple requirements: just tell us the size of the storage and where you would like it to be mounted and We will create and manage that storage for you.\nThis toggles a StatefulSet resource instead of a Deployment resource, so your container can recover transactions and state upon a pod restart.\nWe offer an advanced mode where the user specifies a built-in PersistentVolumeClaim, allowing them to configure many details of the persistent volume, such as its storage class and access mode.\nYou can also easily configure and use a single storage for serviceability related Day-2 operations, such as gatherig server traces and dumps.\n\n#### Service Binding\nYour runtime components can expose services by a simple toggle. We take care of the heavy lifting such as creating kubernetes Secrets with information other services can use to bind. We also keep the bindable information synchronized, so your applications can dynamically reconnect to its required services without any intervention or interruption.\n\n#### Single Sign-On (SSO)\nOpen Liberty provides capabilities to delegate authentication to external providers. Your application users can log in using their existing social media credentials from providers such as Google, Facebook, LinkedIn, Twitter, GitHub, and any OpenID Connect (OIDC) or OAuth 2.0 clients. Open Liberty Operator allows to easily configure and manage the single sign-on information for your applications.\n\n#### Exposing metrics to Prometheus\nThe Open Liberty Operator exposes the runtime container's metrics via the [Prometheus Operator](https://operatorhub.io/operator/prometheus).\nUsers can pick between a basic mode, where they simply specify the label that Prometheus is watching to scrape the metrics from the container, or they can specify the full `ServiceMonitor` spec embedded into the OpenLibertyApplication's `spec.monitoring` key controlling things like the poll internal and security credentials.\n\n#### Easily mount logs and transaction directories\nIf you need to mount the logs and transaction data from your application to an external volume such as NFS (or any storage supported in your cluster), simply add the following (customizing the folder location and size) to your OpenLibertyApplication CR:\n``` storage: size: 2Gi mountPath: \"/logs\" ```\n\n#### Integration with OpenShift Serverless\nDeploy your serverless runtime component using a single toggle.  The Operator will convert all of its generated resources into [Knative](https://knative.dev) resources, allowing your pod to automatically scale to 0 when it is idle.\n\n#### Integration with OpenShift's Topology UI\nWe set the corresponding labels to support OpenShift's Developer Topology UI, which allows you to visualize your entire set of deployments and how they are connected.\n\nSee our [**documentation**](https://github.com/OpenLiberty/open-liberty-operator/tree/main/doc/) for more information.\n",
      "csv_display_name": "Open Liberty",
      "csv_metadata_description": "Deploy and manage applications running on Liberty",
      "csv_name": "open-liberty-operator.v0.8.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:34:06.397000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "open-liberty-certified",
      "provided_apis": [
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyApplication",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyDump",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyTrace",
          "version": "v1beta2"
        }
      ],
      "provider": "IBM",
      "related_images": [
        {
          "digest": "sha256:43b3f004a19c91c80ba815aedc1b361b87cd12daa28bb215e6775e64ef890af1",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:43b3f004a19c91c80ba815aedc1b361b87cd12daa28bb215e6775e64ef890af1",
          "name": "open-liberty-operator-controller-43b3f004a19c91c80ba815aedc1b361b87cd12daa28bb215e6775e64ef890af1-annotation"
        },
        {
          "digest": "sha256:43b3f004a19c91c80ba815aedc1b361b87cd12daa28bb215e6775e64ef890af1",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:43b3f004a19c91c80ba815aedc1b361b87cd12daa28bb215e6775e64ef890af1",
          "name": "manager"
        },
        {
          "digest": "sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "image": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "name": "open-liberty-samples-8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4-annotation"
        }
      ],
      "replaces": null,
      "skip_range": "<0.8.0",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "0.8.0",
      "version_original": "0.8.0"
    },
    {
      "_id": "632843152dd1cd9660afbae5",
      "alm_examples": [
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyApplication",
          "metadata": {
            "name": "openliberty-app-sample"
          },
          "spec": {
            "applicationImage": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
            "expose": true,
            "replicas": 1
          }
        },
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyDump",
          "metadata": {
            "name": "openliberty-dump-sample"
          },
          "spec": {
            "include": [
              "thread",
              "heap"
            ],
            "podName": "Specify_Pod_Name_Here"
          }
        },
        {
          "api_version": "apps.openliberty.io/v1beta2",
          "kind": "OpenLibertyTrace",
          "metadata": {
            "name": "openliberty-trace-sample"
          },
          "spec": {
            "maxFileSize": 20,
            "maxFiles": 5,
            "podName": "Specify_Pod_Name_Here",
            "traceSpecification": "*=info:com.ibm.ws.webcontainer*=all"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/open-liberty-operator-bundle@sha256:591fc4b5867dff26df1952653423b33889c0f56ba3f756057694d4c0e396eeb0",
      "bundle_path_digest": "sha256:591fc4b5867dff26df1952653423b33889c0f56ba3f756057694d4c0e396eeb0",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "beta2",
      "creation_date": "2022-09-19T10:23:17.961000+00:00",
      "csv_description": "This advanced Operator can be used to deploy and manage Open Liberty applications with consistent, production-grade QoS. This operator is based on the [Runtime Component Operator](https://github.com/application-stacks/runtime-component-operator) and provides all of its capabilities in addition to Open Liberty specific features such as gathering traces and dumps (Day-2 operations) and easily configuring and managing the single sign-on information for your Open Liberty applications.\n\nOpen Liberty Operator enables enterprise architects to govern the way their applications get deployed & managed in the cluster, while dramatically reducing the learning curve for developers to deploy into Kubernetes - allowing them to focus on writing the code!\n\nHere are some key features:\n\n#### Application Lifecyle\nYou can deploy your Open Liberty application container by either pointing to a container image, or an OpenShift ImageStream. When using an ImageStream the Operator will watch for any updates and will re-deploy the modified image.\n\n#### Custom RBAC\nThis Operator is capable of using a custom ServiceAccount from the caller, allowing it to follow RBAC restrictions. By default it creates a ServiceAccount if one is not specified, which can also be bound with specific roles.\n\n#### Environment Configuration\nYou can configure a variety of artifacts with your deployment, such as: labels, annotations, and environment variables from a ConfigMap, a Secret or a value.\n\n#### Routing\nExpose your application to external users via a single toggle to create a Route on OpenShift or an Ingress on other Kubernetes environments. Advanced configuration, such as TLS settings, are also easily enabled.\n\n#### High Availability via Horizontal Pod Autoscaling\nRun multiple instances of your application for high availability. Either specify a static number of replicas or easily configure horizontal auto scaling to create (and delete) instances based on resource consumption.\n\n#### Persistence and advanced storage\nEnable persistence for your application by specifying simple requirements: just tell us the size of the storage and where you would like it to be mounted and we will create and manage that storage for you.\nThis toggles a StatefulSet resource instead of a Deployment resource, so your container can recover transactions and state upon a pod restart.\nWe offer an advanced mode where you can specify a built-in PersistentVolumeClaim, allowing you to configure many details of the persistent volume, such as its storage class and access mode.\nYou can also easily configure and use a single storage for serviceability related Day-2 operations, such as gatherig server traces and dumps.\n\n#### Service Binding\nYour runtime components can expose services by a simple toggle. We take care of the heavy lifting such as creating kubernetes Secrets with information other services can use to bind. We also keep the bindable information synchronized, so your applications can dynamically reconnect to its required services without any intervention or interruption.\n\n#### Single Sign-On (SSO)\nOpen Liberty provides capabilities to delegate authentication to external providers. Your application users can log in using their existing social media credentials from providers such as Google, Facebook, LinkedIn, Twitter, GitHub, and any OpenID Connect (OIDC) or OAuth 2.0 clients. Open Liberty Operator allows to easily configure and manage the single sign-on information for your applications.\n\n#### Exposing metrics to Prometheus\nExpose the Open Liberty application's metrics via the Prometheus Operator.\nYou can pick between a basic mode, where you simply specify the label that Prometheus is watching to scrape the metrics from the container, or you can specify the full `ServiceMonitor` spec embedded into the OpenLibertyApplication's `spec.monitoring` field to control configurations such as poll interval and security credentials.\n\n#### Easily mount logs and transaction directories\nDo you need to mount the logs and transaction data from your application to an external volume such as NFS (or any storage supported in your cluster)? Simply add the following configuration (to specify the volume size and the location to persist) to your OpenLibertyApplication CR:\n``` storage: size: 2Gi mountPath: \"/logs\" ```\n\n#### Integration with OpenShift Serverless\nDeploy your serverless runtime component using a single toggle.  The Operator will convert all of its generated resources into [Knative](https://knative.dev) resources, allowing your pod to automatically scale to 0 when it is idle.\n\n#### Integration with OpenShift's Topology UI\nWe set the corresponding labels to support OpenShift's Developer Topology UI, which allows you to visualize your entire set of deployments and how they are connected.\n\nSee our [**documentation**](https://github.com/OpenLiberty/open-liberty-operator/tree/main/doc/) for more information.\n",
      "csv_display_name": "Open Liberty",
      "csv_metadata_description": "Deploy and manage applications running on Liberty",
      "csv_name": "open-liberty-operator.v0.8.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:34:08.900000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "open-liberty-certified",
      "provided_apis": [
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyApplication",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyDump",
          "version": "v1beta2"
        },
        {
          "group": "apps.openliberty.io",
          "kind": "OpenLibertyTrace",
          "version": "v1beta2"
        }
      ],
      "provider": "IBM",
      "related_images": [
        {
          "digest": "sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "name": "open-liberty-operator-controller-18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db-annotation"
        },
        {
          "digest": "sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "image": "registry.connect.redhat.com/ibm/open-liberty-operator-controller@sha256:18f188e48725c785557c8edea46f69c464d6f81ab47860a3bb0ec978c20a26db",
          "name": "manager"
        },
        {
          "digest": "sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "image": "registry.connect.redhat.com/ibm/open-liberty-samples@sha256:8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4",
          "name": "open-liberty-samples-8ea2d3405ff2829d93c5dda4dab5d695ea8ead34e804aaf6e39ea84f53a15ee4-annotation"
        }
      ],
      "replaces": null,
      "skip_range": "<0.8.1",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "0.8.1",
      "version_original": "0.8.1"
    },
    {
      "_id": "63284317316b8eb377f07768",
      "alm_examples": [
        {
          "api_version": "aikit.intel/v1alpha1",
          "kind": "AIKitContainer",
          "metadata": {
            "name": "intel-aikit-container",
            "namespace": "redhat-ods-applications"
          },
          "spec": {
            "fullnameOverride": "",
            "imagestream": {
              "name": "oneapi-aikit",
              "namespace": "redhat-ods-applications",
              "registry": {
                "name": "oneapi-aikit",
                "repo": "intel",
                "root": "registry.connect.redhat.com",
                "version": "latest"
              }
            },
            "nameOverride": ""
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/intel/aikit-operator-bundle@sha256:2861cb69274ed1313bc97d870f9a52f361d5fc003b2d66752d38c9577bf1cf7c",
      "bundle_path_digest": "sha256:2861cb69274ed1313bc97d870f9a52f361d5fc003b2d66752d38c9577bf1cf7c",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:23:19.508000+00:00",
      "csv_description": "The Intel\u00ae oneAPI AI Analytics Toolkit gives data scientists, AI developers, and researchers familiar Python* tools and frameworks to accelerate end-to-end data science and machine learning pipelines on Intel\u00ae architectures. The components are built using oneAPI libraries for low-level compute optimizations. This toolkit maximizes performance from preprocessing through machine and deep learning phases and provides interoperability for efficient model development and deployment across single and multinodes.\n",
      "csv_display_name": "Intel\u00ae oneAPI AI Analytics Toolkit Operator",
      "csv_metadata_description": "",
      "csv_name": "aikit-operator.v2021.2.100410",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:31:50.279000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "aikit-operator",
      "provided_apis": [
        {
          "group": "aikit.intel",
          "kind": "AIKitContainer",
          "version": "v1alpha1"
        }
      ],
      "provider": "Intel",
      "related_images": [
        {
          "digest": "sha256:1f232b2c9ecc3219835cd98b1e0ea96485d5630856fe611c5fb9f2a5219160e8",
          "image": "registry.connect.redhat.com/intel/aikit-operator@sha256:1f232b2c9ecc3219835cd98b1e0ea96485d5630856fe611c5fb9f2a5219160e8",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "2021.2.100410",
      "version_original": "2021.2.100410"
    },
    {
      "_id": "63284319eb69678e80bd1f1d",
      "alm_examples": [
        {
          "api_version": "aikit.intel/v1alpha1",
          "kind": "AIKitContainer",
          "metadata": {
            "name": "intel-aikit-container",
            "namespace": "redhat-ods-applications"
          },
          "spec": {
            "fullnameOverride": "",
            "imagestream": {
              "name": "oneapi-aikit",
              "namespace": "redhat-ods-applications",
              "registry": {
                "name": "oneapi-aikit",
                "repo": "intel",
                "root": "registry.connect.redhat.com",
                "version": "latest"
              }
            },
            "nameOverride": ""
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/intel/aikit-operator-bundle@sha256:504672b2db7fd25d1c85c9614f8242f98b4d2d04184a947dbaaada41ec205b45",
      "bundle_path_digest": "sha256:504672b2db7fd25d1c85c9614f8242f98b4d2d04184a947dbaaada41ec205b45",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:23:21.292000+00:00",
      "csv_description": "The Intel\u00ae oneAPI AI Analytics Toolkit gives data scientists, AI developers, and researchers familiar Python* tools and frameworks to accelerate end-to-end data science and machine learning pipelines on Intel\u00ae architectures. The components are built using oneAPI libraries for low-level compute optimizations. This toolkit maximizes performance from preprocessing through machine and deep learning phases and provides interoperability for efficient model development and deployment across single and multinodes.\n",
      "csv_display_name": "Intel\u00ae oneAPI AI Analytics Toolkit Operator",
      "csv_metadata_description": "",
      "csv_name": "aikit-operator.v2021.2.102120",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:31:39.524000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "aikit-operator",
      "provided_apis": [
        {
          "group": "aikit.intel",
          "kind": "AIKitContainer",
          "version": "v1alpha1"
        }
      ],
      "provider": "Intel",
      "related_images": [
        {
          "digest": "sha256:7abb5e6164ffb3e4b87c39061f45d09848218fcfb74b48bf5e1035d56b41ee0c",
          "image": "registry.connect.redhat.com/intel/aikit-operator@sha256:7abb5e6164ffb3e4b87c39061f45d09848218fcfb74b48bf5e1035d56b41ee0c",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "2021.2.102120",
      "version_original": "2021.2.102120"
    },
    {
      "_id": "6328431a1fe6c3c921e6b33f",
      "alm_examples": [
        {
          "api_version": "aikit.intel/v1alpha1",
          "kind": "AIKitContainer",
          "metadata": {
            "name": "intel-aikit-container",
            "namespace": "redhat-ods-applications"
          },
          "spec": {
            "fullnameOverride": "",
            "imagestream": {
              "name": "oneapi-aikit",
              "namespace": "redhat-ods-applications",
              "registry": {
                "name": "oneapi-aikit",
                "repo": "intel",
                "root": "registry.connect.redhat.com",
                "version": "latest"
              }
            },
            "nameOverride": ""
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/intel/aikit-operator-bundle@sha256:044fe556abd0194f7e44a9b20875caa3ded4b2e479b45d9cf5acfa097ef6c6c1",
      "bundle_path_digest": "sha256:044fe556abd0194f7e44a9b20875caa3ded4b2e479b45d9cf5acfa097ef6c6c1",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:23:22.422000+00:00",
      "csv_description": "The Intel\u00ae oneAPI AI Analytics Toolkit gives data scientists, AI developers, and researchers familiar Python* tools and frameworks to accelerate end-to-end data science and machine learning pipelines on Intel\u00ae architectures. The components are built using oneAPI libraries for low-level compute optimizations. This toolkit maximizes performance from preprocessing through machine and deep learning phases and provides interoperability for efficient model development and deployment across single and multinodes.\n",
      "csv_display_name": "Intel\u00ae oneAPI AI Analytics Toolkit Operator",
      "csv_metadata_description": "",
      "csv_name": "aikit-operator.v2021.2.92808-dev-a60e5ba",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:31:42.654000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "aikit-operator",
      "provided_apis": [
        {
          "group": "aikit.intel",
          "kind": "AIKitContainer",
          "version": "v1alpha1"
        }
      ],
      "provider": "Intel",
      "related_images": [
        {
          "digest": "sha256:34516d6df20aa91b4fcd691aafed3260c8a43aaaded64fdbe8078fc45c1357f0",
          "image": "registry.connect.redhat.com/intel/aikit-operator@sha256:34516d6df20aa91b4fcd691aafed3260c8a43aaaded64fdbe8078fc45c1357f0",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "2021.2.92808-dev-a60e5ba",
      "version_original": "2021.2.92808-dev-a60e5ba"
    },
    {
      "_id": "6328431ba9c6e63893ae538e",
      "alm_examples": [
        {
          "api_version": "aikit.intel/v1alpha1",
          "kind": "AIKitContainer",
          "metadata": {
            "name": "intel-aikit-container",
            "namespace": "redhat-ods-applications"
          },
          "spec": {
            "fullnameOverride": "",
            "imagestream": {
              "name": "oneapi-aikit",
              "namespace": "redhat-ods-applications",
              "registry": {
                "name": "oneapi-aikit",
                "repo": "intel",
                "root": "registry.connect.redhat.com",
                "version": "latest"
              }
            },
            "nameOverride": ""
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/intel/aikit-operator-bundle@sha256:951e1dc1384a046270a6d5f540b1883aa47fa0c04895b5845635327c80281976",
      "bundle_path_digest": "sha256:951e1dc1384a046270a6d5f540b1883aa47fa0c04895b5845635327c80281976",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:23:23.470000+00:00",
      "csv_description": "The Intel\u00ae oneAPI AI Analytics Toolkit gives data scientists, AI developers, and researchers familiar Python* tools and frameworks to accelerate end-to-end data science and machine learning pipelines on Intel\u00ae architectures. The components are built using oneAPI libraries for low-level compute optimizations. This toolkit maximizes performance from preprocessing through machine and deep learning phases and provides interoperability for efficient model development and deployment across single and multinodes.\n",
      "csv_display_name": "Intel\u00ae oneAPI AI Analytics Toolkit Operator",
      "csv_metadata_description": "",
      "csv_name": "aikit-operator.v2021.2.92814",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:31:45.119000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "aikit-operator",
      "provided_apis": [
        {
          "group": "aikit.intel",
          "kind": "AIKitContainer",
          "version": "v1alpha1"
        }
      ],
      "provider": "Intel",
      "related_images": [
        {
          "digest": "sha256:5448635df26ff738f5dd39256c961ad2a5756ca8ee0cb66370b261a242ef6f7b",
          "image": "registry.connect.redhat.com/intel/aikit-operator@sha256:5448635df26ff738f5dd39256c961ad2a5756ca8ee0cb66370b261a242ef6f7b",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "2021.2.92814",
      "version_original": "2021.2.92814"
    },
    {
      "_id": "6328431c2dd1cd9660afbaed",
      "alm_examples": [
        {
          "api_version": "aikit.intel/v1alpha1",
          "kind": "AIKitContainer",
          "metadata": {
            "name": "intel-aikit-container",
            "namespace": "redhat-ods-applications"
          },
          "spec": {
            "fullnameOverride": "",
            "imagestream": {
              "name": "oneapi-aikit",
              "namespace": "redhat-ods-applications",
              "registry": {
                "name": "oneapi-aikit",
                "repo": "intel",
                "root": "registry.connect.redhat.com",
                "version": "latest"
              }
            },
            "nameOverride": ""
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/intel/aikit-operator-bundle@sha256:db2074b8ef12a3037a7aaa515c9055f080e546706f769404d6f9005a28f57e61",
      "bundle_path_digest": "sha256:db2074b8ef12a3037a7aaa515c9055f080e546706f769404d6f9005a28f57e61",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:23:24.580000+00:00",
      "csv_description": "The Intel\u00ae oneAPI AI Analytics Toolkit gives data scientists, AI developers, and researchers familiar Python* tools and frameworks to accelerate end-to-end data science and machine learning pipelines on Intel\u00ae architectures. The components are built using oneAPI libraries for low-level compute optimizations. This toolkit maximizes performance from preprocessing through machine and deep learning phases and provides interoperability for efficient model development and deployment across single and multinodes.\n",
      "csv_display_name": "Intel\u00ae oneAPI AI Analytics Toolkit Operator",
      "csv_metadata_description": "",
      "csv_name": "aikit-operator.v2021.2.92911",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:31:47.667000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "aikit-operator",
      "provided_apis": [
        {
          "group": "aikit.intel",
          "kind": "AIKitContainer",
          "version": "v1alpha1"
        }
      ],
      "provider": "Intel",
      "related_images": [
        {
          "digest": "sha256:6c55351004f5b04f901a2a3ad3ffab01c7b7d237dde9943dda3116e354d3cfe7",
          "image": "registry.connect.redhat.com/intel/aikit-operator@sha256:6c55351004f5b04f901a2a3ad3ffab01c7b7d237dde9943dda3116e354d3cfe7",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "2021.2.92911",
      "version_original": "2021.2.92911"
    },
    {
      "_id": "6328431e5ec32701224aa6cd",
      "alm_examples": [
        {
          "api_version": "hazelcast.com/v1alpha1",
          "kind": "HazelcastEnterprise",
          "metadata": {
            "name": "hz"
          },
          "spec": {
            "hazelcast": {
              "licenseKeySecretName": "hz-license-key-secret"
            },
            "securityContext": {
              "fsGroup": "",
              "runAsGroup": "",
              "runAsUser": ""
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/hazelcast/hazelcast-enterprise-operator-bundle@sha256:4090c5206fa7c0602ff0ce4cca18c632b97d294a70ad8b0d2b68ef1081927ea6",
      "bundle_path_digest": "sha256:4090c5206fa7c0602ff0ce4cca18c632b97d294a70ad8b0d2b68ef1081927ea6",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:23:26.055000+00:00",
      "csv_description": "Hazelcast IMDG Enterprise is the most widely used in-memory data grid with hundreds of thousands of installed clusters around the world. It offers caching solutions ensuring that data is in the right place when it\u2019s needed for optimal performance.\n\n   ### Before Your Start\n\nYou need Hazelcast Enterprise License Key. If you don't have one, get a trial key from this [link](https://hazelcast.com/hazelcast-enterprise-download/trial/).\n\n### Installation Guide & Configuration\n\nFor the complete installation guide and all configuration options please refer to [Hazelcast RHM Deployment Instructions](https://github.com/hazelcast/hazelcast-operator/tree/master/hazelcast-enterprise-operator#step-4-hazelcast-enterprise-cluster-and-management-center-installation).\n",
      "csv_display_name": "Hazelcast Enterprise Operator",
      "csv_metadata_description": "Install Hazelcast Enterprise cluster.",
      "csv_name": "hazelcast-enterprise-operator.v0.3.7",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:31:33.406000+00:00",
      "latest_in_channel": false,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "hazelcast-enterprise-certified",
      "provided_apis": [
        {
          "group": "hazelcast.com",
          "kind": "HazelcastEnterprise",
          "version": "v1alpha1"
        }
      ],
      "provider": "Hazelcast, Inc",
      "related_images": [
        {
          "digest": "sha256:1283c27946205177c143edd2cbed9594de0f9ae8be4a0b4f7ebf5974efbc7caf",
          "image": "registry.connect.redhat.com/hazelcast/hazelcast-enterprise-operator@sha256:1283c27946205177c143edd2cbed9594de0f9ae8be4a0b4f7ebf5974efbc7caf",
          "name": "hazelcast-enterprise-operator-1283c27946205177c143edd2cbed9594de0f9ae8be4a0b4f7ebf5974efbc7caf-annotation"
        },
        {
          "digest": "sha256:1283c27946205177c143edd2cbed9594de0f9ae8be4a0b4f7ebf5974efbc7caf",
          "image": "registry.connect.redhat.com/hazelcast/hazelcast-enterprise-operator@sha256:1283c27946205177c143edd2cbed9594de0f9ae8be4a0b4f7ebf5974efbc7caf",
          "name": "hazelcast-enterprise-operator"
        },
        {
          "digest": "sha256:1773b71eccc4a45fcf8a8d62c55a377507581ac479f73aa3e2e2f62136da73fa",
          "image": "registry.connect.redhat.com/hazelcast/hazelcast-enterprise-4-rhel8@sha256:1773b71eccc4a45fcf8a8d62c55a377507581ac479f73aa3e2e2f62136da73fa",
          "name": "hazelcast"
        },
        {
          "digest": "sha256:b0c404e3309afc509942502fbf87664e5cdb349aefb587b3592d2dfc22d25f8e",
          "image": "registry.connect.redhat.com/hazelcast/management-center-4-rhel8@sha256:b0c404e3309afc509942502fbf87664e5cdb349aefb587b3592d2dfc22d25f8e",
          "name": "mancenter"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "0.3.7",
      "version_original": "0.3.7"
    },
    {
      "_id": "6328431f5ec32701224aa6cf",
      "alm_examples": [
        {
          "api_version": "hazelcast.com/v1alpha1",
          "kind": "HazelcastEnterprise",
          "metadata": {
            "name": "hz"
          },
          "spec": {
            "hazelcast": {
              "licenseKeySecretName": "hz-license-key-secret"
            },
            "securityContext": {
              "fsGroup": "",
              "runAsGroup": "",
              "runAsUser": ""
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/hazelcast/hazelcast-enterprise-operator-bundle@sha256:b1d7468e045f4c0964b4c4b7950a674ee96850c41a0f4014aa0e62273b69f4b4",
      "bundle_path_digest": "sha256:b1d7468e045f4c0964b4c4b7950a674ee96850c41a0f4014aa0e62273b69f4b4",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "alpha",
      "creation_date": "2022-09-19T10:23:27.543000+00:00",
      "csv_description": "Hazelcast IMDG Enterprise is the most widely used in-memory data grid with hundreds of thousands of installed clusters around the world. It offers caching solutions ensuring that data is in the right place when it\u2019s needed for optimal performance.\n\n   ### Before Your Start\n\nYou need Hazelcast Enterprise License Key. If you don't have one, get a trial key from this [link](https://hazelcast.com/hazelcast-enterprise-download/trial/).\n\n### Installation Guide & Configuration\n\nFor the complete installation guide and all configuration options please refer to [Hazelcast RHM Deployment Instructions](https://github.com/hazelcast/hazelcast-operator/tree/master/hazelcast-enterprise-operator#step-4-hazelcast-enterprise-cluster-and-management-center-installation).\n",
      "csv_display_name": "Hazelcast Enterprise Operator",
      "csv_metadata_description": "Install Hazelcast Enterprise cluster.",
      "csv_name": "hazelcast-enterprise-operator.v0.3.8",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:31:36.133000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "hazelcast-enterprise-certified",
      "provided_apis": [
        {
          "group": "hazelcast.com",
          "kind": "HazelcastEnterprise",
          "version": "v1alpha1"
        }
      ],
      "provider": "Hazelcast, Inc",
      "related_images": [
        {
          "digest": "sha256:ff2abf2506ede16ed998f36061b90746b239b694e950ca86a58f3d5df7f2bde6",
          "image": "registry.connect.redhat.com/hazelcast/hazelcast-enterprise-operator@sha256:ff2abf2506ede16ed998f36061b90746b239b694e950ca86a58f3d5df7f2bde6",
          "name": "hazelcast-enterprise-operator-ff2abf2506ede16ed998f36061b90746b239b694e950ca86a58f3d5df7f2bde6-annotation"
        },
        {
          "digest": "sha256:ff2abf2506ede16ed998f36061b90746b239b694e950ca86a58f3d5df7f2bde6",
          "image": "registry.connect.redhat.com/hazelcast/hazelcast-enterprise-operator@sha256:ff2abf2506ede16ed998f36061b90746b239b694e950ca86a58f3d5df7f2bde6",
          "name": "hazelcast-enterprise-operator"
        },
        {
          "digest": "sha256:c54fcdc49dd23bb3c1aa7e727b2d664f954bd0b614cb67577165391cfad0f832",
          "image": "registry.connect.redhat.com/hazelcast/hazelcast-enterprise-5-rhel8@sha256:c54fcdc49dd23bb3c1aa7e727b2d664f954bd0b614cb67577165391cfad0f832",
          "name": "hazelcast"
        },
        {
          "digest": "sha256:e9a11e785a7b3c6ec5292ceb25a54c78a8d9e536788b945f64fb746ee7a1f030",
          "image": "registry.connect.redhat.com/hazelcast/management-center-5-rhel8@sha256:e9a11e785a7b3c6ec5292ceb25a54c78a8d9e536788b945f64fb746ee7a1f030",
          "name": "mancenter"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "0.3.8",
      "version_original": "0.3.8"
    },
    {
      "_id": "632854395ec32701224abe56",
      "alm_examples": [
        {
          "api_version": "infrastructure.asset.orchestrator.com/v1",
          "kind": "Generatekey",
          "metadata": {
            "name": "modelbuilder-token"
          },
          "spec": {}
        },
        {
          "api_version": "infrastructure.asset.orchestrator.com/v1",
          "kind": "Mb-broker-service",
          "metadata": {
            "name": "mb-broker-service-sample"
          },
          "spec": {
            "env_type": "prod",
            "external_db": {
              "enabled": false
            },
            "postgres": {
              "enable_pg_tls": true,
              "storage#": "20G",
              "storage_class": "ibmc-block-bronze"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/ibm/iao-bundle@sha256:a05da58a27648ee35f38a912cffedfd8968146fbb3eeeb618fe35355c08a8d8a",
      "bundle_path_digest": "sha256:a05da58a27648ee35f38a912cffedfd8968146fbb3eeeb618fe35355c08a8d8a",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T11:36:25.955000+00:00",
      "csv_description": "Infrastructure Asset Orchestrator provides users access to cloud resources and services. Leverages the dynamic nature of the cloud platforms to provide significant cost savings and efficiencies. Using the Infrastructure Asset Orchestrator user can provision, configure, utilize and deprovision variety of services on the IBM Cloud Catalog.",
      "csv_display_name": "Infrastructure Asset Orchestrator",
      "csv_metadata_description": "",
      "csv_name": "infrastructure-asset-orchestrator.v1.0.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T11:36:25.955000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.5",
      "organization": "certified-operators",
      "package": "infrastructure-asset-orchestrator-certified",
      "provided_apis": [
        {
          "group": "infrastructure.asset.orchestrator.com",
          "kind": "Generatekey",
          "plural": "generatekeys",
          "version": "v1"
        },
        {
          "group": "infrastructure.asset.orchestrator.com",
          "kind": "Mb-broker-service",
          "plural": "mb-broker-services",
          "version": "v1"
        }
      ],
      "provider": "IBM Edge",
      "related_images": [
        {
          "digest": "sha256:7cc06c2be3eb4db457a79efd6bca85e7b2abde3b59df509e3ce69a81d9e1df26",
          "image": "registry.connect.redhat.com/ibm/iao-operator@sha256:7cc06c2be3eb4db457a79efd6bca85e7b2abde3b59df509e3ce69a81d9e1df26",
          "name": "iao-operator-7cc06c2be3eb4db457a79efd6bca85e7b2abde3b59df509e3ce69a81d9e1df26-annotation"
        },
        {
          "digest": "sha256:7cc06c2be3eb4db457a79efd6bca85e7b2abde3b59df509e3ce69a81d9e1df26",
          "image": "registry.connect.redhat.com/ibm/iao-operator@sha256:7cc06c2be3eb4db457a79efd6bca85e7b2abde3b59df509e3ce69a81d9e1df26",
          "name": "infrastructure-asset-orchestrator"
        },
        {
          "digest": "sha256:8ce51f160748de50a023e6fe8c2a50f3f0088988e1244e25de9d27594f4c0b2e",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:8ce51f160748de50a023e6fe8c2a50f3f0088988e1244e25de9d27594f4c0b2e",
          "name": "kube-rbac-proxy"
        },
        {
          "digest": "sha256:918f9be30fe11bc97652dfaf90a9277d9ab79e8c258b790fa94125386994261d",
          "image": "registry.connect.redhat.com/ibm/iao-orchestrator-service@sha256:918f9be30fe11bc97652dfaf90a9277d9ab79e8c258b790fa94125386994261d",
          "name": "orchestrator"
        },
        {
          "digest": "sha256:6781457b1471b03e8878fbf2fa52c00d4fd8d7307b233a71ddfcdfa3dae40611",
          "image": "registry.connect.redhat.com/ibm/iao-mb-broker-service@sha256:6781457b1471b03e8878fbf2fa52c00d4fd8d7307b233a71ddfcdfa3dae40611",
          "name": "mb_broker"
        },
        {
          "digest": "sha256:336ee99fb072c2c7281de94c83b506fa7e3fe91d1015f10d5db275da81c568ae",
          "image": "registry.connect.redhat.com/ibm/iao-util@sha256:336ee99fb072c2c7281de94c83b506fa7e3fe91d1015f10d5db275da81c568ae",
          "name": "mb_util"
        },
        {
          "digest": "sha256:dfef558bda03a13bdc3802220a31e89994b2c16db6588c374421df57bd539e9e",
          "image": "registry.connect.redhat.com/ibm/iao-pgo-util@sha256:dfef558bda03a13bdc3802220a31e89994b2c16db6588c374421df57bd539e9e",
          "name": "pgo_client"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.5",
      "version": "1.0.0",
      "version_original": "1.0.0"
    },
    {
      "_id": "632855c1787bb4d00dc940d7",
      "alm_examples": [
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Backup",
          "metadata": {
            "name": "backup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Cluster",
          "metadata": {
            "name": "cluster-sample"
          },
          "spec": {
            "instances": 3,
            "logLevel": "info",
            "primaryUpdateStrategy": "unsupervised",
            "storage": {
              "size": "1Gi"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Pooler",
          "metadata": {
            "name": "pooler-sample-rw"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "instances": 1,
            "pgbouncer": {
              "poolMode": "session"
            },
            "type": "rw"
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "ScheduledBackup",
          "metadata": {
            "name": "scheduledbackup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "schedule": "0 0 0 * * *"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [
        "amd64",
        "ppc64le",
        "s390x"
      ],
      "bundle_path": "registry.connect.redhat.com/enterprisedb/cloud-native-postgresql@sha256:e0624abf48e3f643638e93a633a4017961b454f133830f6d369b238d58a6eb8b",
      "bundle_path_digest": "sha256:e0624abf48e3f643638e93a633a4017961b454f133830f6d369b238d58a6eb8b",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "null",
      "creation_date": "2022-09-19T11:42:57.468000+00:00",
      "csv_description": "EDB Postgres for Kubernetes is an operator designed, developed, and supported by EDB that covers the full \nlifecycle of a highly available Postgres database clusters with a primary/standby architecture, using native\nstreaming replication. It is based on the open source CloudNativePG operator, and provides additional value\nsuch as compatibility with Oracle using EDB Postgres Advanced Server and additional supported platforms such\nas IBM Power and OpenShift.\n\nKey features available include:\n\n* Kubernetes API integration for high availability\n* Self-healing through failover and automated recreation of replicas\n* Capacity management with scale up/down capabilities\n* Planned switchovers for scheduled maintenance\n* Read-only and read-write Kubernetes services definitions\n* Rolling updates for Postgres minor versions and operator upgrades\n* Continuous backup and point-in-time recovery\n* Connection Pooling with PgBouncer\n* Integrated metrics exporter out of the box\n* PostgreSQL replication across multiple Kubernetes clusters\n* Red Hat certified operator for OpenShift\n\nThe operator has been renamed from Cloud Native PostgreSQL. Existing users of Cloud Native PostgreSQL will not\nexperience any change, as the underlying components and resources have not changed.\n",
      "csv_display_name": "EDB Postgres for Kubernetes",
      "csv_metadata_description": "Operator to manage Postgres high availability clusters with a primary/standby architecture.",
      "csv_name": "cloud-native-postgresql.v1.15.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-09-19T11:42:57.468000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "cloud-native-postgresql",
      "provided_apis": [
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "ScheduledBackup",
          "plural": "scheduledbackups",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Backup",
          "plural": "backups",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Cluster",
          "plural": "clusters",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Pooler",
          "plural": "poolers",
          "version": "v1"
        }
      ],
      "provider": "EnterpriseDB Corporation",
      "related_images": [
        {
          "digest": "sha256:af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc",
          "name": "cloud-native-postgresql-af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc-annotation"
        },
        {
          "digest": "sha256:af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": ">=0.6.0 < 1.15.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.15.2",
      "version_original": "1.15.2"
    },
    {
      "_id": "63285679eb69678e80bd3875",
      "alm_examples": [
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Backup",
          "metadata": {
            "name": "backup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Cluster",
          "metadata": {
            "name": "cluster-sample"
          },
          "spec": {
            "instances": 3,
            "logLevel": "info",
            "primaryUpdateStrategy": "unsupervised",
            "storage": {
              "size": "1Gi"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Pooler",
          "metadata": {
            "name": "pooler-sample-rw"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "instances": 1,
            "pgbouncer": {
              "poolMode": "session"
            },
            "type": "rw"
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "ScheduledBackup",
          "metadata": {
            "name": "scheduledbackup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "schedule": "0 0 0 * * *"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [
        "amd64",
        "ppc64le",
        "s390x"
      ],
      "bundle_path": "registry.connect.redhat.com/enterprisedb/cloud-native-postgresql@sha256:e0624abf48e3f643638e93a633a4017961b454f133830f6d369b238d58a6eb8b",
      "bundle_path_digest": "sha256:e0624abf48e3f643638e93a633a4017961b454f133830f6d369b238d58a6eb8b",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "null",
      "creation_date": "2022-09-19T11:46:01.552000+00:00",
      "csv_description": "EDB Postgres for Kubernetes is an operator designed, developed, and supported by EDB that covers the full \nlifecycle of a highly available Postgres database clusters with a primary/standby architecture, using native\nstreaming replication. It is based on the open source CloudNativePG operator, and provides additional value\nsuch as compatibility with Oracle using EDB Postgres Advanced Server and additional supported platforms such\nas IBM Power and OpenShift.\n\nKey features available include:\n\n* Kubernetes API integration for high availability\n* Self-healing through failover and automated recreation of replicas\n* Capacity management with scale up/down capabilities\n* Planned switchovers for scheduled maintenance\n* Read-only and read-write Kubernetes services definitions\n* Rolling updates for Postgres minor versions and operator upgrades\n* Continuous backup and point-in-time recovery\n* Connection Pooling with PgBouncer\n* Integrated metrics exporter out of the box\n* PostgreSQL replication across multiple Kubernetes clusters\n* Red Hat certified operator for OpenShift\n\nThe operator has been renamed from Cloud Native PostgreSQL. Existing users of Cloud Native PostgreSQL will not\nexperience any change, as the underlying components and resources have not changed.\n",
      "csv_display_name": "EDB Postgres for Kubernetes",
      "csv_metadata_description": "Operator to manage Postgres high availability clusters with a primary/standby architecture.",
      "csv_name": "cloud-native-postgresql.v1.15.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-09-19T11:46:01.552000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "cloud-native-postgresql",
      "provided_apis": [
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Backup",
          "plural": "backups",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Cluster",
          "plural": "clusters",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Pooler",
          "plural": "poolers",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "ScheduledBackup",
          "plural": "scheduledbackups",
          "version": "v1"
        }
      ],
      "provider": "EnterpriseDB Corporation",
      "related_images": [
        {
          "digest": "sha256:af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc",
          "name": "cloud-native-postgresql-af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc-annotation"
        },
        {
          "digest": "sha256:af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": ">=0.6.0 < 1.15.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.15.2",
      "version_original": "1.15.2"
    },
    {
      "_id": "63285937a9c6e63893ae6e43",
      "alm_examples": [
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Backup",
          "metadata": {
            "name": "backup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Cluster",
          "metadata": {
            "name": "cluster-sample"
          },
          "spec": {
            "instances": 3,
            "logLevel": "info",
            "primaryUpdateStrategy": "unsupervised",
            "storage": {
              "size": "1Gi"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Pooler",
          "metadata": {
            "name": "pooler-sample-rw"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "instances": 1,
            "pgbouncer": {
              "poolMode": "session"
            },
            "type": "rw"
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "ScheduledBackup",
          "metadata": {
            "name": "scheduledbackup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "schedule": "0 0 0 * * *"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [
        "amd64",
        "ppc64le",
        "s390x"
      ],
      "bundle_path": "registry.connect.redhat.com/enterprisedb/cloud-native-postgresql@sha256:e0624abf48e3f643638e93a633a4017961b454f133830f6d369b238d58a6eb8b",
      "bundle_path_digest": "sha256:e0624abf48e3f643638e93a633a4017961b454f133830f6d369b238d58a6eb8b",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "null",
      "creation_date": "2022-09-19T11:57:43.771000+00:00",
      "csv_description": "EDB Postgres for Kubernetes is an operator designed, developed, and supported by EDB that covers the full \nlifecycle of a highly available Postgres database clusters with a primary/standby architecture, using native\nstreaming replication. It is based on the open source CloudNativePG operator, and provides additional value\nsuch as compatibility with Oracle using EDB Postgres Advanced Server and additional supported platforms such\nas IBM Power and OpenShift.\n\nKey features available include:\n\n* Kubernetes API integration for high availability\n* Self-healing through failover and automated recreation of replicas\n* Capacity management with scale up/down capabilities\n* Planned switchovers for scheduled maintenance\n* Read-only and read-write Kubernetes services definitions\n* Rolling updates for Postgres minor versions and operator upgrades\n* Continuous backup and point-in-time recovery\n* Connection Pooling with PgBouncer\n* Integrated metrics exporter out of the box\n* PostgreSQL replication across multiple Kubernetes clusters\n* Red Hat certified operator for OpenShift\n\nThe operator has been renamed from Cloud Native PostgreSQL. Existing users of Cloud Native PostgreSQL will not\nexperience any change, as the underlying components and resources have not changed.\n",
      "csv_display_name": "EDB Postgres for Kubernetes",
      "csv_metadata_description": "Operator to manage Postgres high availability clusters with a primary/standby architecture.",
      "csv_name": "cloud-native-postgresql.v1.15.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-09-19T11:57:43.771000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "cloud-native-postgresql",
      "provided_apis": [
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Cluster",
          "plural": "clusters",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Pooler",
          "plural": "poolers",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "ScheduledBackup",
          "plural": "scheduledbackups",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Backup",
          "plural": "backups",
          "version": "v1"
        }
      ],
      "provider": "EnterpriseDB Corporation",
      "related_images": [
        {
          "digest": "sha256:af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc",
          "name": "cloud-native-postgresql-af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc-annotation"
        },
        {
          "digest": "sha256:af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": ">=0.6.0 < 1.15.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "1.15.2",
      "version_original": "1.15.2"
    },
    {
      "_id": "63285d78d1a8ccdba1fb2405",
      "alm_examples": [
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Backup",
          "metadata": {
            "name": "backup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Cluster",
          "metadata": {
            "name": "cluster-sample"
          },
          "spec": {
            "instances": 3,
            "logLevel": "info",
            "primaryUpdateStrategy": "unsupervised",
            "storage": {
              "size": "1Gi"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Pooler",
          "metadata": {
            "name": "pooler-sample-rw"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "instances": 1,
            "pgbouncer": {
              "poolMode": "session"
            },
            "type": "rw"
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "ScheduledBackup",
          "metadata": {
            "name": "scheduledbackup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "schedule": "0 0 0 * * *"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [
        "amd64",
        "ppc64le",
        "s390x"
      ],
      "bundle_path": "registry.connect.redhat.com/enterprisedb/cloud-native-postgresql@sha256:e0624abf48e3f643638e93a633a4017961b454f133830f6d369b238d58a6eb8b",
      "bundle_path_digest": "sha256:e0624abf48e3f643638e93a633a4017961b454f133830f6d369b238d58a6eb8b",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "null",
      "creation_date": "2022-09-19T12:15:52.261000+00:00",
      "csv_description": "EDB Postgres for Kubernetes is an operator designed, developed, and supported by EDB that covers the full \nlifecycle of a highly available Postgres database clusters with a primary/standby architecture, using native\nstreaming replication. It is based on the open source CloudNativePG operator, and provides additional value\nsuch as compatibility with Oracle using EDB Postgres Advanced Server and additional supported platforms such\nas IBM Power and OpenShift.\n\nKey features available include:\n\n* Kubernetes API integration for high availability\n* Self-healing through failover and automated recreation of replicas\n* Capacity management with scale up/down capabilities\n* Planned switchovers for scheduled maintenance\n* Read-only and read-write Kubernetes services definitions\n* Rolling updates for Postgres minor versions and operator upgrades\n* Continuous backup and point-in-time recovery\n* Connection Pooling with PgBouncer\n* Integrated metrics exporter out of the box\n* PostgreSQL replication across multiple Kubernetes clusters\n* Red Hat certified operator for OpenShift\n\nThe operator has been renamed from Cloud Native PostgreSQL. Existing users of Cloud Native PostgreSQL will not\nexperience any change, as the underlying components and resources have not changed.\n",
      "csv_display_name": "EDB Postgres for Kubernetes",
      "csv_metadata_description": "Operator to manage Postgres high availability clusters with a primary/standby architecture.",
      "csv_name": "cloud-native-postgresql.v1.15.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-09-19T12:15:52.261000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "cloud-native-postgresql",
      "provided_apis": [
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Cluster",
          "plural": "clusters",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Pooler",
          "plural": "poolers",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "ScheduledBackup",
          "plural": "scheduledbackups",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Backup",
          "plural": "backups",
          "version": "v1"
        }
      ],
      "provider": "EnterpriseDB Corporation",
      "related_images": [
        {
          "digest": "sha256:af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc",
          "name": "cloud-native-postgresql-af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc-annotation"
        },
        {
          "digest": "sha256:af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": ">=0.6.0 < 1.15.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.15.2",
      "version_original": "1.15.2"
    },
    {
      "_id": "63285f515d877a39af333be2",
      "alm_examples": [
        {
          "api_version": "pg.percona.com/v1",
          "kind": "PerconaPGCluster",
          "metadata": {
            "annotations": {
              "current-primary": "cluster1"
            },
            "labels": {
              "crunchy-pgha-scope": "cluster1",
              "deployment-name": "cluster1",
              "name": "cluster1",
              "pg-cluster": "cluster1",
              "pgo-version": "1.0.0",
              "pgouser": "admin"
            },
            "name": "cluster1"
          },
          "spec": {
            "backup": {
              "backrestRepoImage": "percona/percona-postgresql-operator:1.0.0-ppg13-pgbackrest-repo",
              "image": "percona/percona-postgresql-operator:1.0.0-ppg13-pgbackrest",
              "resources": {
                "requests": {
                  "memory": "48Mi"
                }
              },
              "schedule": [
                {
                  "keep": 3,
                  "name": "sat-night-backup",
                  "schedule": "0 0 * * 6",
                  "storage": "local",
                  "type": "full"
                }
              ],
              "volumeSpec": {
                "accessmode": "ReadWriteOnce",
                "size": "1G",
                "storageclass": "",
                "storagetype": "dynamic"
              }
            },
            "database": "pgdb",
            "disableAutofail": false,
            "pause": false,
            "pgBadger": {
              "enabled": false,
              "image": "percona/percona-postgresql-operator:1.0.0-ppg13-pgbadger",
              "port": 10000
            },
            "pgBouncer": {
              "expose": {
                "serviceType": "ClusterIP"
              },
              "image": "percona/percona-postgresql-operator:1.0.0-ppg13-pgbouncer",
              "resources": {
                "limits": {
                  "cpu": "2",
                  "memory": "512Mi"
                },
                "requests": {
                  "cpu": "1",
                  "memory": "128Mi"
                }
              },
              "size": 1
            },
            "pgPrimary": {
              "expose": {
                "serviceType": "ClusterIP"
              },
              "image": "percona/percona-postgresql-operator:1.0.0-ppg13-postgres-ha",
              "resources": {
                "requests": {
                  "memory": "128Mi"
                }
              },
              "tolerations": [],
              "volumeSpec": {
                "accessmode": "ReadWriteOnce",
                "size": "1G",
                "storageclass": "",
                "storagetype": "dynamic"
              }
            },
            "pgReplicas": {
              "hotStandby": {
                "enableSyncStandby": false,
                "expose": {
                  "serviceType": "ClusterIP"
                },
                "resources": {
                  "requests": {
                    "memory": "128Mi"
                  }
                },
                "size": 2,
                "volumeSpec": {
                  "accessmode": "ReadWriteOnce",
                  "size": "1G",
                  "storageclass": "",
                  "storagetype": "dynamic"
                }
              }
            },
            "pmm": {
              "enabled": false,
              "image": "percona/pmm-client:2.21.0",
              "pmmSecret": "cluster1-pmm-secret",
              "resources": {
                "requests": {
                  "cpu": "500m",
                  "memory": "200M"
                }
              },
              "serverHost": "monitoring-service",
              "serverUser": "admin"
            },
            "port": "5432",
            "standby": false,
            "tlsOnly": false,
            "user": "pguser",
            "userLabels": {
              "pgo-version": "1.0.0"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/percona/percona-postgresql-operator-bundle@sha256:1d2bba0a6ef29287e1908f4cc7a5f2ceea301a0d7a63d23c2966dc914a38a03f",
      "bundle_path_digest": "sha256:1d2bba0a6ef29287e1908f4cc7a5f2ceea301a0d7a63d23c2966dc914a38a03f",
      "capabilities": [
        "Deep Insights"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T12:23:45.690000+00:00",
      "csv_description": "",
      "csv_display_name": "Percona Distribution for PostgreSQL Operator",
      "csv_metadata_description": "Percona Distribution for PostgreSQL Operator manages the lifecycle of Percona PostgreSQL cluster instances.",
      "csv_name": "percona-postgresql-operator.v1.0.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T12:23:45.690000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "percona-postgresql-operator-certified",
      "provided_apis": [
        {
          "group": "pg.percona.com",
          "kind": "Pgpolicy",
          "plural": "pgpolicies",
          "version": "v1"
        },
        {
          "group": "pg.percona.com",
          "kind": "Pgreplica",
          "plural": "pgreplicas",
          "version": "v1"
        },
        {
          "group": "pg.percona.com",
          "kind": "Pgtask",
          "plural": "pgtasks",
          "version": "v1"
        },
        {
          "group": "pg.percona.com",
          "kind": "PerconaPGCluster",
          "plural": "perconapgclusters",
          "version": "v1"
        },
        {
          "group": "pg.percona.com",
          "kind": "Pgcluster",
          "plural": "pgclusters",
          "version": "v1"
        }
      ],
      "provider": "Percona",
      "related_images": [
        {
          "digest": "sha256:cbeb03fd1ca5c57124272993c591bef8970a71a5ad128ce3f1d3af556382ca7e",
          "image": "registry.connect.redhat.com/percona/percona-postgresql-operator@sha256:cbeb03fd1ca5c57124272993c591bef8970a71a5ad128ce3f1d3af556382ca7e",
          "name": "percona-postgresql-operator-cbeb03fd1ca5c57124272993c591bef8970a71a5ad128ce3f1d3af556382ca7e-annotation"
        },
        {
          "digest": "sha256:3ef498def581f5944e09c6e964001f260e6acdb8b2ae52945e3929b7d5d07891",
          "image": "registry.connect.redhat.com/percona/percona-postgresql-operator@sha256:3ef498def581f5944e09c6e964001f260e6acdb8b2ae52945e3929b7d5d07891",
          "name": "apiserver"
        },
        {
          "digest": "sha256:cbeb03fd1ca5c57124272993c591bef8970a71a5ad128ce3f1d3af556382ca7e",
          "image": "registry.connect.redhat.com/percona/percona-postgresql-operator@sha256:cbeb03fd1ca5c57124272993c591bef8970a71a5ad128ce3f1d3af556382ca7e",
          "name": "operator"
        },
        {
          "digest": "sha256:460508bcfde49b1c80b776b84269c7185d9929ee39164218591849c454bda3d2",
          "image": "registry.connect.redhat.com/percona/percona-postgresql-operator@sha256:460508bcfde49b1c80b776b84269c7185d9929ee39164218591849c454bda3d2",
          "name": "scheduler"
        },
        {
          "digest": "sha256:c4f9a3aa8039c69099fe0f65b4504e2edeb4eb8530df8e7491d91f663e0a1a1f",
          "image": "registry.connect.redhat.com/percona/percona-postgresql-operator@sha256:c4f9a3aa8039c69099fe0f65b4504e2edeb4eb8530df8e7491d91f663e0a1a1f",
          "name": "event"
        },
        {
          "digest": "sha256:d0c362c7dabfcce021a3cf4bb3a60439e991e8bc18f00c101aac6eab8e9b6743",
          "image": "registry.connect.redhat.com/percona/percona-postgresql-operator-containers@sha256:d0c362c7dabfcce021a3cf4bb3a60439e991e8bc18f00c101aac6eab8e9b6743",
          "name": "pgo_backrest"
        },
        {
          "digest": "sha256:5fd84c6fd7831284b5a48d698e57d2ce6cc2257a00cc6757408cf0321ee1df71",
          "image": "registry.connect.redhat.com/percona/percona-postgresql-operator-containers@sha256:5fd84c6fd7831284b5a48d698e57d2ce6cc2257a00cc6757408cf0321ee1df71",
          "name": "pgo_backrest_repo"
        },
        {
          "digest": "sha256:3b370aa297742a0c13650457b32ab9e698c24409d287887afdec6a6ccdeb1628",
          "image": "registry.connect.redhat.com/percona/percona-postgresql-operator@sha256:3b370aa297742a0c13650457b32ab9e698c24409d287887afdec6a6ccdeb1628",
          "name": "pgo_rmdata"
        },
        {
          "digest": "sha256:fe125347e73542a96aeddaba20de13d30933cc3a7835d29484491d2f86c157a4",
          "image": "registry.connect.redhat.com/percona/percona-postgresql-operator-containers@sha256:fe125347e73542a96aeddaba20de13d30933cc3a7835d29484491d2f86c157a4",
          "name": "crunchy_pgbadger"
        },
        {
          "digest": "sha256:53d0036c9377a6af0a4e6f9271b0dd4f687b7d8968e2885c76d4add76ab01808",
          "image": "registry.connect.redhat.com/percona/percona-postgresql-operator-containers@sha256:53d0036c9377a6af0a4e6f9271b0dd4f687b7d8968e2885c76d4add76ab01808",
          "name": "crunchy_pgbouncer"
        },
        {
          "digest": "sha256:61ee6450cf35ff6267ba766ec3ffe4b67cff483b449be9d5571fe5b66a4a739c",
          "image": "registry.connect.redhat.com/percona/percona-postgresql-operator-containers@sha256:61ee6450cf35ff6267ba766ec3ffe4b67cff483b449be9d5571fe5b66a4a739c",
          "name": "crunchy_postgres_ha"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "1.0.0",
      "version_original": "1.0.0"
    },
    {
      "_id": "63285f678454bee1cb7258a1",
      "alm_examples": [
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Backup",
          "metadata": {
            "name": "backup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Cluster",
          "metadata": {
            "name": "cluster-sample"
          },
          "spec": {
            "instances": 3,
            "logLevel": "info",
            "primaryUpdateStrategy": "unsupervised",
            "storage": {
              "size": "1Gi"
            }
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "Pooler",
          "metadata": {
            "name": "pooler-sample-rw"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "instances": 1,
            "pgbouncer": {
              "poolMode": "session"
            },
            "type": "rw"
          }
        },
        {
          "api_version": "postgresql.k8s.enterprisedb.io/v1",
          "kind": "ScheduledBackup",
          "metadata": {
            "name": "scheduledbackup-sample"
          },
          "spec": {
            "cluster": {
              "name": "cluster-sample"
            },
            "schedule": "0 0 0 * * *"
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [
        "amd64",
        "ppc64le",
        "s390x"
      ],
      "bundle_path": "registry.connect.redhat.com/enterprisedb/cloud-native-postgresql@sha256:e0624abf48e3f643638e93a633a4017961b454f133830f6d369b238d58a6eb8b",
      "bundle_path_digest": "sha256:e0624abf48e3f643638e93a633a4017961b454f133830f6d369b238d58a6eb8b",
      "capabilities": [
        "Auto Pilot"
      ],
      "channel_name": "null",
      "creation_date": "2022-09-19T12:24:07.441000+00:00",
      "csv_description": "EDB Postgres for Kubernetes is an operator designed, developed, and supported by EDB that covers the full \nlifecycle of a highly available Postgres database clusters with a primary/standby architecture, using native\nstreaming replication. It is based on the open source CloudNativePG operator, and provides additional value\nsuch as compatibility with Oracle using EDB Postgres Advanced Server and additional supported platforms such\nas IBM Power and OpenShift.\n\nKey features available include:\n\n* Kubernetes API integration for high availability\n* Self-healing through failover and automated recreation of replicas\n* Capacity management with scale up/down capabilities\n* Planned switchovers for scheduled maintenance\n* Read-only and read-write Kubernetes services definitions\n* Rolling updates for Postgres minor versions and operator upgrades\n* Continuous backup and point-in-time recovery\n* Connection Pooling with PgBouncer\n* Integrated metrics exporter out of the box\n* PostgreSQL replication across multiple Kubernetes clusters\n* Red Hat certified operator for OpenShift\n\nThe operator has been renamed from Cloud Native PostgreSQL. Existing users of Cloud Native PostgreSQL will not\nexperience any change, as the underlying components and resources have not changed.\n",
      "csv_display_name": "EDB Postgres for Kubernetes",
      "csv_metadata_description": "Operator to manage Postgres high availability clusters with a primary/standby architecture.",
      "csv_name": "cloud-native-postgresql.v1.15.2",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": true,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-09-19T12:24:07.441000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "cloud-native-postgresql",
      "provided_apis": [
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "ScheduledBackup",
          "plural": "scheduledbackups",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Backup",
          "plural": "backups",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Cluster",
          "plural": "clusters",
          "version": "v1"
        },
        {
          "group": "postgresql.k8s.enterprisedb.io",
          "kind": "Pooler",
          "plural": "poolers",
          "version": "v1"
        }
      ],
      "provider": "EnterpriseDB Corporation",
      "related_images": [
        {
          "digest": "sha256:af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc",
          "name": "cloud-native-postgresql-af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc-annotation"
        },
        {
          "digest": "sha256:af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc",
          "image": "quay.io/enterprisedb/cloud-native-postgresql@sha256:af4718fd40222fb3fc68fa1952baa69e61a35085429f10e6fcd5db46d60f0bfc",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": ">=0.6.0 < 1.15.2",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "1.15.2",
      "version_original": "1.15.2"
    },
    {
      "_id": "63287e135ec32701224adb4e",
      "alm_examples": [
        {
          "api_version": "mlops.cnvrg.io/v1",
          "kind": "CnvrgApp",
          "metadata": {
            "name": "cnvrg-app"
          },
          "spec": {
            "clusterDomain": "",
            "controlPlane": {
              "baseConfig": {
                "agentCustomTag": "agnostic-logs",
                "cnvrgJobRbacStrict": true,
                "cnvrgJobUid": "0",
                "cnvrgPrivilegedJob": false,
                "featureFlags": {
                  "CNVRG_ENABLE_MOUNT_FOLDERS": "false",
                  "CNVRG_MOUNT_HOST_FOLDERS": "false",
                  "OCP_ENABLED": "true"
                },
                "metagpuEnabled": false
              },
              "cnvrgScheduler": {
                "enabled": false
              },
              "hyper": {
                "enabled": true
              },
              "image": "docker.io/cnvrg/core@sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
              "nomex": {
                "enabled": true
              },
              "searchkiq": {
                "enabled": true
              },
              "sidekiq": {
                "enabled": true,
                "replicas": 1,
                "split": true
              },
              "systemkiq": {
                "enabled": true
              },
              "webapp": {
                "enabled": true
              }
            },
            "dbs": {
              "es": {
                "elastalert": {
                  "enabled": true
                },
                "enabled": true,
                "kibana": {
                  "enabled": true
                }
              },
              "minio": {
                "enabled": true
              },
              "pg": {
                "enabled": true
              },
              "prom": {
                "enabled": true,
                "extraScrapeConfigs": [
                  {
                    "labelSelector": "app=nvidia-dcgm-exporter",
                    "namespace": "nvidia-gpu-operator",
                    "role": "endpoints"
                  },
                  {
                    "labelSelector": "app=metagpu-exporter",
                    "namespace": "cnvrg",
                    "role": "endpoints"
                  }
                ]
              },
              "redis": {
                "enabled": true
              }
            },
            "imageHub": "docker.io/cnvrg",
            "networking": {
              "ingress": {
                "type": "openshift"
              }
            },
            "registry": {
              "name": "cnvrg-app-registry",
              "password": "",
              "url": "docker.io",
              "user": ""
            }
          }
        },
        {
          "api_version": "mlops.cnvrg.io/v1",
          "kind": "CnvrgThirdParty",
          "metadata": {
            "name": "cnvrg-thirdparty"
          },
          "spec": {
            "imageHub": "docker.io/cnvrg",
            "metagpu": {
              "enabled": true,
              "nodeSelector": {
                "nvidia.com/gpu.deploy.device-plugin": "true"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cnvrg-core/cnvrg@sha256:3d83b07215e5564fc1e7641fb4242e11e57969513189643c49cb09fd3b23fb6d",
      "bundle_path_digest": "sha256:3d83b07215e5564fc1e7641fb4242e11e57969513189643c49cb09fd3b23fb6d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T14:34:59.873000+00:00",
      "csv_description": "## Cnvrg is a Cloud Native AI:OS, transforming the way enterprises manage, scale and accelerate AI.\n#### Installation\nFor quick start, deploy the default CnvrgApp spec.  For advanced deployment scenarios, make required changes\non the CnvrgApp spec through the OpenShift console and deploy the spec.\nHave additional questions? Email us at support@cnvrg.io or read the [docs](https://app.cnvrg.io/docs/).\n#### MetaGpu (Fractional GPU) support\nFor deploying the MetaGPU device plugin, install the default CnvrgThirdParty spec on your OpenShift cluster.\n**Note**: make sure all the low level GPU components (mainly the GPU drivers & GPU container runtimes)\nhas been installed on the OpenShift GPU nodes.",
      "csv_display_name": "Cnvrg Operator",
      "csv_metadata_description": "cnvrg.io is an AI OS, transforming the way enterprises manage, scale and accelerate AI.",
      "csv_name": "cnvrg.v4.3.36",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T14:34:59.873000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "cnvrg",
      "provided_apis": [
        {
          "group": "mlops.cnvrg.io",
          "kind": "CnvrgApp",
          "plural": "cnvrgapps",
          "version": "v1"
        },
        {
          "group": "mlops.cnvrg.io",
          "kind": "CnvrgThirdParty",
          "plural": "cnvrgthirdparties",
          "version": "v1"
        }
      ],
      "provider": "cnvrg.io",
      "related_images": [
        {
          "digest": "sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "image": "docker.io/cnvrg/cnvrg-operator@sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "name": "cnvrg-operator"
        },
        {
          "digest": "sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "image": "docker.io/cnvrg/core@sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "name": "core"
        },
        {
          "digest": "sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "image": "docker.io/cnvrg/cnvrg-operator@sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "name": "cnvrg-operator-18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510-annotation"
        },
        {
          "digest": "sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "image": "docker.io/cnvrg/core@sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "name": "core-a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "4.3.36",
      "version_original": "4.3.36"
    },
    {
      "_id": "63287e4cfc81574279e6c769",
      "alm_examples": [
        {
          "api_version": "mlops.cnvrg.io/v1",
          "kind": "CnvrgApp",
          "metadata": {
            "name": "cnvrg-app"
          },
          "spec": {
            "clusterDomain": "",
            "controlPlane": {
              "baseConfig": {
                "agentCustomTag": "agnostic-logs",
                "cnvrgJobRbacStrict": true,
                "cnvrgJobUid": "0",
                "cnvrgPrivilegedJob": false,
                "featureFlags": {
                  "CNVRG_ENABLE_MOUNT_FOLDERS": "false",
                  "CNVRG_MOUNT_HOST_FOLDERS": "false",
                  "OCP_ENABLED": "true"
                },
                "metagpuEnabled": false
              },
              "cnvrgScheduler": {
                "enabled": false
              },
              "hyper": {
                "enabled": true
              },
              "image": "docker.io/cnvrg/core@sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
              "nomex": {
                "enabled": true
              },
              "searchkiq": {
                "enabled": true
              },
              "sidekiq": {
                "enabled": true,
                "replicas": 1,
                "split": true
              },
              "systemkiq": {
                "enabled": true
              },
              "webapp": {
                "enabled": true
              }
            },
            "dbs": {
              "es": {
                "elastalert": {
                  "enabled": true
                },
                "enabled": true,
                "kibana": {
                  "enabled": true
                }
              },
              "minio": {
                "enabled": true
              },
              "pg": {
                "enabled": true
              },
              "prom": {
                "enabled": true,
                "extraScrapeConfigs": [
                  {
                    "labelSelector": "app=nvidia-dcgm-exporter",
                    "namespace": "nvidia-gpu-operator",
                    "role": "endpoints"
                  },
                  {
                    "labelSelector": "app=metagpu-exporter",
                    "namespace": "cnvrg",
                    "role": "endpoints"
                  }
                ]
              },
              "redis": {
                "enabled": true
              }
            },
            "imageHub": "docker.io/cnvrg",
            "networking": {
              "ingress": {
                "type": "openshift"
              }
            },
            "registry": {
              "name": "cnvrg-app-registry",
              "password": "",
              "url": "docker.io",
              "user": ""
            }
          }
        },
        {
          "api_version": "mlops.cnvrg.io/v1",
          "kind": "CnvrgThirdParty",
          "metadata": {
            "name": "cnvrg-thirdparty"
          },
          "spec": {
            "imageHub": "docker.io/cnvrg",
            "metagpu": {
              "enabled": true,
              "nodeSelector": {
                "nvidia.com/gpu.deploy.device-plugin": "true"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cnvrg-core/cnvrg@sha256:3d83b07215e5564fc1e7641fb4242e11e57969513189643c49cb09fd3b23fb6d",
      "bundle_path_digest": "sha256:3d83b07215e5564fc1e7641fb4242e11e57969513189643c49cb09fd3b23fb6d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T14:35:56.594000+00:00",
      "csv_description": "## Cnvrg is a Cloud Native AI:OS, transforming the way enterprises manage, scale and accelerate AI.\n#### Installation\nFor quick start, deploy the default CnvrgApp spec.  For advanced deployment scenarios, make required changes\non the CnvrgApp spec through the OpenShift console and deploy the spec.\nHave additional questions? Email us at support@cnvrg.io or read the [docs](https://app.cnvrg.io/docs/).\n#### MetaGpu (Fractional GPU) support\nFor deploying the MetaGPU device plugin, install the default CnvrgThirdParty spec on your OpenShift cluster.\n**Note**: make sure all the low level GPU components (mainly the GPU drivers & GPU container runtimes)\nhas been installed on the OpenShift GPU nodes.",
      "csv_display_name": "Cnvrg Operator",
      "csv_metadata_description": "cnvrg.io is an AI OS, transforming the way enterprises manage, scale and accelerate AI.",
      "csv_name": "cnvrg.v4.3.36",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T14:35:56.594000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "cnvrg",
      "provided_apis": [
        {
          "group": "mlops.cnvrg.io",
          "kind": "CnvrgApp",
          "version": "v1"
        },
        {
          "group": "mlops.cnvrg.io",
          "kind": "CnvrgThirdParty",
          "version": "v1"
        }
      ],
      "provider": "cnvrg.io",
      "related_images": [
        {
          "digest": "sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "image": "docker.io/cnvrg/cnvrg-operator@sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "name": "cnvrg-operator"
        },
        {
          "digest": "sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "image": "docker.io/cnvrg/core@sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "name": "core"
        },
        {
          "digest": "sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "image": "docker.io/cnvrg/cnvrg-operator@sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "name": "cnvrg-operator-18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510-annotation"
        },
        {
          "digest": "sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "image": "docker.io/cnvrg/core@sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "name": "core-a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "4.3.36",
      "version_original": "4.3.36"
    },
    {
      "_id": "632881b9787bb4d00dc95d27",
      "alm_examples": [
        {
          "api_version": "mlops.cnvrg.io/v1",
          "kind": "CnvrgApp",
          "metadata": {
            "name": "cnvrg-app"
          },
          "spec": {
            "clusterDomain": "",
            "controlPlane": {
              "baseConfig": {
                "agentCustomTag": "agnostic-logs",
                "cnvrgJobRbacStrict": true,
                "cnvrgJobUid": "0",
                "cnvrgPrivilegedJob": false,
                "featureFlags": {
                  "CNVRG_ENABLE_MOUNT_FOLDERS": "false",
                  "CNVRG_MOUNT_HOST_FOLDERS": "false",
                  "OCP_ENABLED": "true"
                },
                "metagpuEnabled": false
              },
              "cnvrgScheduler": {
                "enabled": false
              },
              "hyper": {
                "enabled": true
              },
              "image": "docker.io/cnvrg/core@sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
              "nomex": {
                "enabled": true
              },
              "searchkiq": {
                "enabled": true
              },
              "sidekiq": {
                "enabled": true,
                "replicas": 1,
                "split": true
              },
              "systemkiq": {
                "enabled": true
              },
              "webapp": {
                "enabled": true
              }
            },
            "dbs": {
              "es": {
                "elastalert": {
                  "enabled": true
                },
                "enabled": true,
                "kibana": {
                  "enabled": true
                }
              },
              "minio": {
                "enabled": true
              },
              "pg": {
                "enabled": true
              },
              "prom": {
                "enabled": true,
                "extraScrapeConfigs": [
                  {
                    "labelSelector": "app=nvidia-dcgm-exporter",
                    "namespace": "nvidia-gpu-operator",
                    "role": "endpoints"
                  },
                  {
                    "labelSelector": "app=metagpu-exporter",
                    "namespace": "cnvrg",
                    "role": "endpoints"
                  }
                ]
              },
              "redis": {
                "enabled": true
              }
            },
            "imageHub": "docker.io/cnvrg",
            "networking": {
              "ingress": {
                "type": "openshift"
              }
            },
            "registry": {
              "name": "cnvrg-app-registry",
              "password": "",
              "url": "docker.io",
              "user": ""
            }
          }
        },
        {
          "api_version": "mlops.cnvrg.io/v1",
          "kind": "CnvrgThirdParty",
          "metadata": {
            "name": "cnvrg-thirdparty"
          },
          "spec": {
            "imageHub": "docker.io/cnvrg",
            "metagpu": {
              "enabled": true,
              "nodeSelector": {
                "nvidia.com/gpu.deploy.device-plugin": "true"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cnvrg-core/cnvrg@sha256:3d83b07215e5564fc1e7641fb4242e11e57969513189643c49cb09fd3b23fb6d",
      "bundle_path_digest": "sha256:3d83b07215e5564fc1e7641fb4242e11e57969513189643c49cb09fd3b23fb6d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T14:50:33.843000+00:00",
      "csv_description": "## Cnvrg is a Cloud Native AI:OS, transforming the way enterprises manage, scale and accelerate AI.\n#### Installation\nFor quick start, deploy the default CnvrgApp spec.  For advanced deployment scenarios, make required changes\non the CnvrgApp spec through the OpenShift console and deploy the spec.\nHave additional questions? Email us at support@cnvrg.io or read the [docs](https://app.cnvrg.io/docs/).\n#### MetaGpu (Fractional GPU) support\nFor deploying the MetaGPU device plugin, install the default CnvrgThirdParty spec on your OpenShift cluster.\n**Note**: make sure all the low level GPU components (mainly the GPU drivers & GPU container runtimes)\nhas been installed on the OpenShift GPU nodes.",
      "csv_display_name": "Cnvrg Operator",
      "csv_metadata_description": "cnvrg.io is an AI OS, transforming the way enterprises manage, scale and accelerate AI.",
      "csv_name": "cnvrg.v4.3.36",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T14:50:33.843000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "cnvrg",
      "provided_apis": [
        {
          "group": "mlops.cnvrg.io",
          "kind": "CnvrgApp",
          "plural": "cnvrgapps",
          "version": "v1"
        },
        {
          "group": "mlops.cnvrg.io",
          "kind": "CnvrgThirdParty",
          "plural": "cnvrgthirdparties",
          "version": "v1"
        }
      ],
      "provider": "cnvrg.io",
      "related_images": [
        {
          "digest": "sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "image": "docker.io/cnvrg/cnvrg-operator@sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "name": "cnvrg-operator"
        },
        {
          "digest": "sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "image": "docker.io/cnvrg/core@sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "name": "core"
        },
        {
          "digest": "sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "image": "docker.io/cnvrg/cnvrg-operator@sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "name": "cnvrg-operator-18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510-annotation"
        },
        {
          "digest": "sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "image": "docker.io/cnvrg/core@sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "name": "core-a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "4.3.36",
      "version_original": "4.3.36"
    },
    {
      "_id": "63288228c9abe8b4a6e93817",
      "alm_examples": [
        {
          "api_version": "mlops.cnvrg.io/v1",
          "kind": "CnvrgApp",
          "metadata": {
            "name": "cnvrg-app"
          },
          "spec": {
            "clusterDomain": "",
            "controlPlane": {
              "baseConfig": {
                "agentCustomTag": "agnostic-logs",
                "cnvrgJobRbacStrict": true,
                "cnvrgJobUid": "0",
                "cnvrgPrivilegedJob": false,
                "featureFlags": {
                  "CNVRG_ENABLE_MOUNT_FOLDERS": "false",
                  "CNVRG_MOUNT_HOST_FOLDERS": "false",
                  "OCP_ENABLED": "true"
                },
                "metagpuEnabled": false
              },
              "cnvrgScheduler": {
                "enabled": false
              },
              "hyper": {
                "enabled": true
              },
              "image": "docker.io/cnvrg/core@sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
              "nomex": {
                "enabled": true
              },
              "searchkiq": {
                "enabled": true
              },
              "sidekiq": {
                "enabled": true,
                "replicas": 1,
                "split": true
              },
              "systemkiq": {
                "enabled": true
              },
              "webapp": {
                "enabled": true
              }
            },
            "dbs": {
              "es": {
                "elastalert": {
                  "enabled": true
                },
                "enabled": true,
                "kibana": {
                  "enabled": true
                }
              },
              "minio": {
                "enabled": true
              },
              "pg": {
                "enabled": true
              },
              "prom": {
                "enabled": true,
                "extraScrapeConfigs": [
                  {
                    "labelSelector": "app=nvidia-dcgm-exporter",
                    "namespace": "nvidia-gpu-operator",
                    "role": "endpoints"
                  },
                  {
                    "labelSelector": "app=metagpu-exporter",
                    "namespace": "cnvrg",
                    "role": "endpoints"
                  }
                ]
              },
              "redis": {
                "enabled": true
              }
            },
            "imageHub": "docker.io/cnvrg",
            "networking": {
              "ingress": {
                "type": "openshift"
              }
            },
            "registry": {
              "name": "cnvrg-app-registry",
              "password": "",
              "url": "docker.io",
              "user": ""
            }
          }
        },
        {
          "api_version": "mlops.cnvrg.io/v1",
          "kind": "CnvrgThirdParty",
          "metadata": {
            "name": "cnvrg-thirdparty"
          },
          "spec": {
            "imageHub": "docker.io/cnvrg",
            "metagpu": {
              "enabled": true,
              "nodeSelector": {
                "nvidia.com/gpu.deploy.device-plugin": "true"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cnvrg-core/cnvrg@sha256:3d83b07215e5564fc1e7641fb4242e11e57969513189643c49cb09fd3b23fb6d",
      "bundle_path_digest": "sha256:3d83b07215e5564fc1e7641fb4242e11e57969513189643c49cb09fd3b23fb6d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T14:52:24.701000+00:00",
      "csv_description": "## Cnvrg is a Cloud Native AI:OS, transforming the way enterprises manage, scale and accelerate AI.\n#### Installation\nFor quick start, deploy the default CnvrgApp spec.  For advanced deployment scenarios, make required changes\non the CnvrgApp spec through the OpenShift console and deploy the spec.\nHave additional questions? Email us at support@cnvrg.io or read the [docs](https://app.cnvrg.io/docs/).\n#### MetaGpu (Fractional GPU) support\nFor deploying the MetaGPU device plugin, install the default CnvrgThirdParty spec on your OpenShift cluster.\n**Note**: make sure all the low level GPU components (mainly the GPU drivers & GPU container runtimes)\nhas been installed on the OpenShift GPU nodes.",
      "csv_display_name": "Cnvrg Operator",
      "csv_metadata_description": "cnvrg.io is an AI OS, transforming the way enterprises manage, scale and accelerate AI.",
      "csv_name": "cnvrg.v4.3.36",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T14:52:24.701000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "cnvrg",
      "provided_apis": [
        {
          "group": "mlops.cnvrg.io",
          "kind": "CnvrgApp",
          "plural": "cnvrgapps",
          "version": "v1"
        },
        {
          "group": "mlops.cnvrg.io",
          "kind": "CnvrgThirdParty",
          "plural": "cnvrgthirdparties",
          "version": "v1"
        }
      ],
      "provider": "cnvrg.io",
      "related_images": [
        {
          "digest": "sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "image": "docker.io/cnvrg/cnvrg-operator@sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "name": "cnvrg-operator"
        },
        {
          "digest": "sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "image": "docker.io/cnvrg/core@sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "name": "core"
        },
        {
          "digest": "sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "image": "docker.io/cnvrg/cnvrg-operator@sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "name": "cnvrg-operator-18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510-annotation"
        },
        {
          "digest": "sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "image": "docker.io/cnvrg/core@sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "name": "core-a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "4.3.36",
      "version_original": "4.3.36"
    },
    {
      "_id": "6328823bc9abe8b4a6e9381c",
      "alm_examples": [
        {
          "api_version": "mlops.cnvrg.io/v1",
          "kind": "CnvrgApp",
          "metadata": {
            "name": "cnvrg-app"
          },
          "spec": {
            "clusterDomain": "",
            "controlPlane": {
              "baseConfig": {
                "agentCustomTag": "agnostic-logs",
                "cnvrgJobRbacStrict": true,
                "cnvrgJobUid": "0",
                "cnvrgPrivilegedJob": false,
                "featureFlags": {
                  "CNVRG_ENABLE_MOUNT_FOLDERS": "false",
                  "CNVRG_MOUNT_HOST_FOLDERS": "false",
                  "OCP_ENABLED": "true"
                },
                "metagpuEnabled": false
              },
              "cnvrgScheduler": {
                "enabled": false
              },
              "hyper": {
                "enabled": true
              },
              "image": "docker.io/cnvrg/core@sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
              "nomex": {
                "enabled": true
              },
              "searchkiq": {
                "enabled": true
              },
              "sidekiq": {
                "enabled": true,
                "replicas": 1,
                "split": true
              },
              "systemkiq": {
                "enabled": true
              },
              "webapp": {
                "enabled": true
              }
            },
            "dbs": {
              "es": {
                "elastalert": {
                  "enabled": true
                },
                "enabled": true,
                "kibana": {
                  "enabled": true
                }
              },
              "minio": {
                "enabled": true
              },
              "pg": {
                "enabled": true
              },
              "prom": {
                "enabled": true,
                "extraScrapeConfigs": [
                  {
                    "labelSelector": "app=nvidia-dcgm-exporter",
                    "namespace": "nvidia-gpu-operator",
                    "role": "endpoints"
                  },
                  {
                    "labelSelector": "app=metagpu-exporter",
                    "namespace": "cnvrg",
                    "role": "endpoints"
                  }
                ]
              },
              "redis": {
                "enabled": true
              }
            },
            "imageHub": "docker.io/cnvrg",
            "networking": {
              "ingress": {
                "type": "openshift"
              }
            },
            "registry": {
              "name": "cnvrg-app-registry",
              "password": "",
              "url": "docker.io",
              "user": ""
            }
          }
        },
        {
          "api_version": "mlops.cnvrg.io/v1",
          "kind": "CnvrgThirdParty",
          "metadata": {
            "name": "cnvrg-thirdparty"
          },
          "spec": {
            "imageHub": "docker.io/cnvrg",
            "metagpu": {
              "enabled": true,
              "nodeSelector": {
                "nvidia.com/gpu.deploy.device-plugin": "true"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cnvrg-core/cnvrg@sha256:3d83b07215e5564fc1e7641fb4242e11e57969513189643c49cb09fd3b23fb6d",
      "bundle_path_digest": "sha256:3d83b07215e5564fc1e7641fb4242e11e57969513189643c49cb09fd3b23fb6d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T14:52:43.586000+00:00",
      "csv_description": "## Cnvrg is a Cloud Native AI:OS, transforming the way enterprises manage, scale and accelerate AI.\n#### Installation\nFor quick start, deploy the default CnvrgApp spec.  For advanced deployment scenarios, make required changes\non the CnvrgApp spec through the OpenShift console and deploy the spec.\nHave additional questions? Email us at support@cnvrg.io or read the [docs](https://app.cnvrg.io/docs/).\n#### MetaGpu (Fractional GPU) support\nFor deploying the MetaGPU device plugin, install the default CnvrgThirdParty spec on your OpenShift cluster.\n**Note**: make sure all the low level GPU components (mainly the GPU drivers & GPU container runtimes)\nhas been installed on the OpenShift GPU nodes.",
      "csv_display_name": "Cnvrg Operator",
      "csv_metadata_description": "cnvrg.io is an AI OS, transforming the way enterprises manage, scale and accelerate AI.",
      "csv_name": "cnvrg.v4.3.36",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T14:52:43.586000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "cnvrg",
      "provided_apis": [
        {
          "group": "mlops.cnvrg.io",
          "kind": "CnvrgApp",
          "plural": "cnvrgapps",
          "version": "v1"
        },
        {
          "group": "mlops.cnvrg.io",
          "kind": "CnvrgThirdParty",
          "plural": "cnvrgthirdparties",
          "version": "v1"
        }
      ],
      "provider": "cnvrg.io",
      "related_images": [
        {
          "digest": "sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "image": "docker.io/cnvrg/cnvrg-operator@sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "name": "cnvrg-operator"
        },
        {
          "digest": "sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "image": "docker.io/cnvrg/core@sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "name": "core"
        },
        {
          "digest": "sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "image": "docker.io/cnvrg/cnvrg-operator@sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "name": "cnvrg-operator-18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510-annotation"
        },
        {
          "digest": "sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "image": "docker.io/cnvrg/core@sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "name": "core-a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "4.3.36",
      "version_original": "4.3.36"
    },
    {
      "_id": "632885effc81574279e6c86f",
      "alm_examples": [
        {
          "api_version": "mlops.cnvrg.io/v1",
          "kind": "CnvrgApp",
          "metadata": {
            "name": "cnvrg-app"
          },
          "spec": {
            "clusterDomain": "",
            "controlPlane": {
              "baseConfig": {
                "agentCustomTag": "agnostic-logs",
                "cnvrgJobRbacStrict": true,
                "cnvrgJobUid": "0",
                "cnvrgPrivilegedJob": false,
                "featureFlags": {
                  "CNVRG_ENABLE_MOUNT_FOLDERS": "false",
                  "CNVRG_MOUNT_HOST_FOLDERS": "false",
                  "OCP_ENABLED": "true"
                },
                "metagpuEnabled": false
              },
              "cnvrgScheduler": {
                "enabled": false
              },
              "hyper": {
                "enabled": true
              },
              "image": "docker.io/cnvrg/core@sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
              "nomex": {
                "enabled": true
              },
              "searchkiq": {
                "enabled": true
              },
              "sidekiq": {
                "enabled": true,
                "replicas": 1,
                "split": true
              },
              "systemkiq": {
                "enabled": true
              },
              "webapp": {
                "enabled": true
              }
            },
            "dbs": {
              "es": {
                "elastalert": {
                  "enabled": true
                },
                "enabled": true,
                "kibana": {
                  "enabled": true
                }
              },
              "minio": {
                "enabled": true
              },
              "pg": {
                "enabled": true
              },
              "prom": {
                "enabled": true,
                "extraScrapeConfigs": [
                  {
                    "labelSelector": "app=nvidia-dcgm-exporter",
                    "namespace": "nvidia-gpu-operator",
                    "role": "endpoints"
                  },
                  {
                    "labelSelector": "app=metagpu-exporter",
                    "namespace": "cnvrg",
                    "role": "endpoints"
                  }
                ]
              },
              "redis": {
                "enabled": true
              }
            },
            "imageHub": "docker.io/cnvrg",
            "networking": {
              "ingress": {
                "type": "openshift"
              }
            },
            "registry": {
              "name": "cnvrg-app-registry",
              "password": "",
              "url": "docker.io",
              "user": ""
            }
          }
        },
        {
          "api_version": "mlops.cnvrg.io/v1",
          "kind": "CnvrgThirdParty",
          "metadata": {
            "name": "cnvrg-thirdparty"
          },
          "spec": {
            "imageHub": "docker.io/cnvrg",
            "metagpu": {
              "enabled": true,
              "nodeSelector": {
                "nvidia.com/gpu.deploy.device-plugin": "true"
              }
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/cnvrg-core/cnvrg@sha256:3d83b07215e5564fc1e7641fb4242e11e57969513189643c49cb09fd3b23fb6d",
      "bundle_path_digest": "sha256:3d83b07215e5564fc1e7641fb4242e11e57969513189643c49cb09fd3b23fb6d",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T15:08:31.054000+00:00",
      "csv_description": "## Cnvrg is a Cloud Native AI:OS, transforming the way enterprises manage, scale and accelerate AI.\n#### Installation\nFor quick start, deploy the default CnvrgApp spec.  For advanced deployment scenarios, make required changes\non the CnvrgApp spec through the OpenShift console and deploy the spec.\nHave additional questions? Email us at support@cnvrg.io or read the [docs](https://app.cnvrg.io/docs/).\n#### MetaGpu (Fractional GPU) support\nFor deploying the MetaGPU device plugin, install the default CnvrgThirdParty spec on your OpenShift cluster.\n**Note**: make sure all the low level GPU components (mainly the GPU drivers & GPU container runtimes)\nhas been installed on the OpenShift GPU nodes.",
      "csv_display_name": "Cnvrg Operator",
      "csv_metadata_description": "cnvrg.io is an AI OS, transforming the way enterprises manage, scale and accelerate AI.",
      "csv_name": "cnvrg.v4.3.36",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": false,
          "type": "OwnNamespace"
        },
        {
          "supported": false,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T15:08:31.054000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "cnvrg",
      "provided_apis": [
        {
          "group": "mlops.cnvrg.io",
          "kind": "CnvrgApp",
          "plural": "cnvrgapps",
          "version": "v1"
        },
        {
          "group": "mlops.cnvrg.io",
          "kind": "CnvrgThirdParty",
          "plural": "cnvrgthirdparties",
          "version": "v1"
        }
      ],
      "provider": "cnvrg.io",
      "related_images": [
        {
          "digest": "sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "image": "docker.io/cnvrg/cnvrg-operator@sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "name": "cnvrg-operator"
        },
        {
          "digest": "sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "image": "docker.io/cnvrg/core@sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "name": "core"
        },
        {
          "digest": "sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "image": "docker.io/cnvrg/cnvrg-operator@sha256:18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510",
          "name": "cnvrg-operator-18c1b1007181bcc1a727fe3039341fff02aaf19a048ce37f6cffabc3e5f84510-annotation"
        },
        {
          "digest": "sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "image": "docker.io/cnvrg/core@sha256:a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e",
          "name": "core-a5091a76ac60e9726dc88f1b6bf5f25a89f51920da8893f6cafb9d1445c4b59e-annotation"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "4.3.36",
      "version_original": "4.3.36"
    },
    {
      "_id": "6328b82b787bb4d00dc965b5",
      "alm_examples": [
        {
          "api_version": "sysdig.com/v1",
          "kind": "SysdigAgent",
          "metadata": {
            "name": "sysdigagent-sample"
          },
          "spec": {
            "sysdig": {
              "accessKey": "REPLACE ME",
              "disableCaptures": false,
              "existingAccessKeySecret": "",
              "settings": {}
            },
            "tolerations": [
              {
                "effect": "NoSchedule",
                "key": "node-role.kubernetes.io/master"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/sysdig/sysdig-operator-bundle@sha256:69dbc1df3b4702d50fc04c0dbf74dd96d0d4fadac86d452d08a2c2d5880c1a99",
      "bundle_path_digest": "sha256:69dbc1df3b4702d50fc04c0dbf74dd96d0d4fadac86d452d08a2c2d5880c1a99",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T18:42:51.836000+00:00",
      "csv_description": "[Sysdig](https://www.sysdig.com/) is a unified platform for container and\nmicroservices monitoring, troubleshooting, security and forensics. Sysdig\nplatform has been built on top of\n[Sysdig tool](https://sysdig.com/opensource/sysdig/) and\n[Sysdig Inspect](https://sysdig.com/blog/sysdig-inspect/) open-source\ntechnologies.\nThis operator installs the Sysdig Agent for\n[Sysdig Monitor](https://sysdig.com/product/monitor/) and\n[Sysdig Secure](https://sysdig.com/product/secure/) to all nodes in your\ncluster via a DaemonSet.\n## Settings\nThis operator, uses the same options than the\n[Helm Chart](https://hub.helm.sh/charts/stable/sysdig), please take a look\nto all the options in the following table:\n| Parameter                         | Description                                                            | Default                                     |\n| ---                               | ---                                                                    | ---                                         |\n| `image.registry`                  | Sysdig agent image registry                                            | `docker.io`                                 |\n| `image.repository`                | The image repository to pull from                                      | `sysdig/agent`                              |\n| `image.tag`                       | The image tag to pull                                                  | `REPLACE_AGENT_VERSION`                                     |\n| `image.pullPolicy`                | The Image pull policy                                                  | `IfNotPresent`                              |\n| `image.pullSecrets`               | Image pull secrets                                                     | `nil`                                       |\n| `resources.requests.cpu`          | CPU requested for being run in a node                                  | `600m`                                      |\n| `resources.requests.memory`       | Memory requested for being run in a node                               | `512Mi`                                     |\n| `resources.limits.cpu`            | CPU limit                                                              | `2000m`                                     |\n| `resources.limits.memory`         | Memory limit                                                           | `1536Mi`                                    |\n| `rbac.create`                     | If true, create & use RBAC resources                                   | `true`                                      |\n| `serviceAccount.create`           | Create serviceAccount                                                  | `true`                                      |\n| `serviceAccount.name`             | Use this value as serviceAccountName                                   | ` `                                         |\n| `daemonset.updateStrategy.type`   | The updateStrategy for updating the daemonset                          | `RollingUpdate`                             |\n| `daemonset.affinity`              | Node affinities                                                        | `nil`                                       |\n| `daemonset.annotations`           | Custom annotations for daemonset                                       | `{}`                                        |\n| `slim.enabled`                    | Use the slim based Sysdig Agent image                                  | `false`                                     |\n| `slim.kmoduleImage.repository`    | The kernel module image builder repository to pull from                | `sysdig/agent-kmodule`                      |\n| `slim.resources.requests.cpu`     | CPU requested for building the kernel module                           | `1000m`                                     |\n| `slim.resources.requests.memory`  | Memory requested for building the kernel module                        | `348Mi`                                     |\n| `slim.resources.limits.memory`    | Memory limit for building the kernel module                            | `512Mi`                                     |\n| `ebpf.enabled`                    | Enable eBPF support for Sysdig instead of `sysdig-probe` kernel module | `false`                                     |\n| `ebpf.settings.mountEtcVolume`    | Needed to detect which kernel version are running in Google COS        | `true`                                      |\n| `sysdig.accessKey`                | Your Sysdig Monitor Access Key                                         | `Nil` You must provide your own key         |\n| `sysdig.settings`                 | Settings for agent's configuration file                                | ` `                                         |\n| `secure.enabled`                  | Enable Sysdig Secure                                                   | `true`                                      |\n| `auditLog.enabled`                | Enable K8s audit log support for Sysdig Secure                         | `false`                                     |\n| `auditLog.auditServerUrl`         | The URL where Sysdig Agent listens for K8s audit log events            | `0.0.0.0`                                   |\n| `auditLog.auditServerPort`        | Port where Sysdig Agent listens for K8s audit log events               | `7765`                                      |\n| `auditLog.dynamicBackend.enabled` | Deploy the Audit Sink where Sysdig listens for K8s audit log events    | `false`                                     |\n| `customAppChecks`                 | The custom app checks deployed with your agent                         | `{}`                                        |\n| `tolerations`                     | The tolerations for scheduling                                         | `node-role.kubernetes.io/master:NoSchedule` |\n| `scc.create`                      | Create OpenShift's Security Context Constraint                         | `false`                                     |\nFor example, if you want to deploy a DaemonSet with eBPF and with Sysdig Secure\nenabled:\n```yaml\napiVersion: sysdig.com/v1\nkind: SysdigAgent\nmetadata:\n  name: agent-with-ebpf-and-secure\nspec:\n  ebpf:\n    enabled: true\n  daemonset:\n    annotations:\n      productID: SysdigSecureDevopsPlatform\n      productName: Sysdig Secure DevOps Platform\n      productVersion: REPLACE_VERSION\n  scc:\n    create: true\n  sysdig:\n    accessKey: XXX\n```\nPlease, notice that `sysdig.accessKey` is **mandatory**. Once you have provided\nthe accessKey, you can apply this file with `kubectl apply -f`\n## Getting your Access Key\nTo retrieve the key and use it in the agent:\n1. Log in to Sysdig Monitor or Sysdig Secure (maybe as administrator) and\n   select **Settings**.\n2. Choose Agent Installation.\n3. Use the Copy button to copy the access key at the top of the page.\nIf you need more help, you can read more about this process in the [Agent Installation: Overview and Key](\nhttps://sysdigdocs.atlassian.net/wiki/spaces/Platform/pages/213352719/Agent+Installation+Overview+and+Key)\ndocumentation page.\n## Verify Metrics in Sysdig Monitor UI\nOnce you have deployed the Sysdig Agent, it's time to verify that everything is\nworking as expected. So, we are going to log in Sysdig Monitor to do the check.\n1. Access Sysdig Monitor:\n   **SaaS**: https://app.sysdigcloud.com\n   Log in with your Sysdig user name and password.\n2. Select the **Explore** tab to see if metrics are displayed.\n3. To verify that kube state metrics and cluster name are working correctly:\n   Select the **Explore tab** and create a grouping by `kubernetes.cluster.name` and `kubernetes.pod.name`.\n4. Select an individual container or pod to see details.\nDon't rush about getting Kubernetes metadata. Pods, deployments ... appear a\nminute or two later than the nodes/containers themselves; if pod names do not\nappear immediately, wait and retry the Explore view.\nYou can read more about verification in the [Verify Metrics in Sysdig Monitor UI section](https://sysdigdocs.atlassian.net/wiki/spaces/Platform/pages/256475257/GKE+Installation+Steps#GKEInstallationSteps-VerifyMetricsinSysdigMonitorUI)\nin the documentation pages.",
      "csv_display_name": "Sysdig Agent Operator",
      "csv_metadata_description": "Sysdig is a unified platform for container and microservices monitoring, troubleshooting, security and forensics. Sysdig platform has been built on top of Sysdig tool and Sysdig Inspect open-source technologies.\n",
      "csv_name": "sysdig-certified.v1.15.37",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T18:42:51.836000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "sysdig-certified",
      "provided_apis": [
        {
          "group": "sysdig.com",
          "kind": "SysdigAgent",
          "version": "v1"
        }
      ],
      "provider": "Sysdig",
      "related_images": [
        {
          "digest": "sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "image": "registry.connect.redhat.com/sysdig/sysdig-operator@sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "name": "sysdig-operator-23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88-annotation"
        },
        {
          "digest": "sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "image": "registry.connect.redhat.com/sysdig/sysdig-operator@sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "name": "manager"
        },
        {
          "digest": "sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "name": "kube-rbac-proxy"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.15.37",
      "version_original": "1.15.37"
    },
    {
      "_id": "6328ba1d8a97b22f4fc1451a",
      "alm_examples": [
        {
          "api_version": "sysdig.com/v1",
          "kind": "SysdigAgent",
          "metadata": {
            "name": "sysdigagent-sample"
          },
          "spec": {
            "sysdig": {
              "accessKey": "REPLACE ME",
              "disableCaptures": false,
              "existingAccessKeySecret": "",
              "settings": {}
            },
            "tolerations": [
              {
                "effect": "NoSchedule",
                "key": "node-role.kubernetes.io/master"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/sysdig/sysdig-operator-bundle@sha256:69dbc1df3b4702d50fc04c0dbf74dd96d0d4fadac86d452d08a2c2d5880c1a99",
      "bundle_path_digest": "sha256:69dbc1df3b4702d50fc04c0dbf74dd96d0d4fadac86d452d08a2c2d5880c1a99",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T18:51:09.246000+00:00",
      "csv_description": "[Sysdig](https://www.sysdig.com/) is a unified platform for container and\nmicroservices monitoring, troubleshooting, security and forensics. Sysdig\nplatform has been built on top of\n[Sysdig tool](https://sysdig.com/opensource/sysdig/) and\n[Sysdig Inspect](https://sysdig.com/blog/sysdig-inspect/) open-source\ntechnologies.\nThis operator installs the Sysdig Agent for\n[Sysdig Monitor](https://sysdig.com/product/monitor/) and\n[Sysdig Secure](https://sysdig.com/product/secure/) to all nodes in your\ncluster via a DaemonSet.\n## Settings\nThis operator, uses the same options than the\n[Helm Chart](https://hub.helm.sh/charts/stable/sysdig), please take a look\nto all the options in the following table:\n| Parameter                         | Description                                                            | Default                                     |\n| ---                               | ---                                                                    | ---                                         |\n| `image.registry`                  | Sysdig agent image registry                                            | `docker.io`                                 |\n| `image.repository`                | The image repository to pull from                                      | `sysdig/agent`                              |\n| `image.tag`                       | The image tag to pull                                                  | `REPLACE_AGENT_VERSION`                                     |\n| `image.pullPolicy`                | The Image pull policy                                                  | `IfNotPresent`                              |\n| `image.pullSecrets`               | Image pull secrets                                                     | `nil`                                       |\n| `resources.requests.cpu`          | CPU requested for being run in a node                                  | `600m`                                      |\n| `resources.requests.memory`       | Memory requested for being run in a node                               | `512Mi`                                     |\n| `resources.limits.cpu`            | CPU limit                                                              | `2000m`                                     |\n| `resources.limits.memory`         | Memory limit                                                           | `1536Mi`                                    |\n| `rbac.create`                     | If true, create & use RBAC resources                                   | `true`                                      |\n| `serviceAccount.create`           | Create serviceAccount                                                  | `true`                                      |\n| `serviceAccount.name`             | Use this value as serviceAccountName                                   | ` `                                         |\n| `daemonset.updateStrategy.type`   | The updateStrategy for updating the daemonset                          | `RollingUpdate`                             |\n| `daemonset.affinity`              | Node affinities                                                        | `nil`                                       |\n| `daemonset.annotations`           | Custom annotations for daemonset                                       | `{}`                                        |\n| `slim.enabled`                    | Use the slim based Sysdig Agent image                                  | `false`                                     |\n| `slim.kmoduleImage.repository`    | The kernel module image builder repository to pull from                | `sysdig/agent-kmodule`                      |\n| `slim.resources.requests.cpu`     | CPU requested for building the kernel module                           | `1000m`                                     |\n| `slim.resources.requests.memory`  | Memory requested for building the kernel module                        | `348Mi`                                     |\n| `slim.resources.limits.memory`    | Memory limit for building the kernel module                            | `512Mi`                                     |\n| `ebpf.enabled`                    | Enable eBPF support for Sysdig instead of `sysdig-probe` kernel module | `false`                                     |\n| `ebpf.settings.mountEtcVolume`    | Needed to detect which kernel version are running in Google COS        | `true`                                      |\n| `sysdig.accessKey`                | Your Sysdig Monitor Access Key                                         | `Nil` You must provide your own key         |\n| `sysdig.settings`                 | Settings for agent's configuration file                                | ` `                                         |\n| `secure.enabled`                  | Enable Sysdig Secure                                                   | `true`                                      |\n| `auditLog.enabled`                | Enable K8s audit log support for Sysdig Secure                         | `false`                                     |\n| `auditLog.auditServerUrl`         | The URL where Sysdig Agent listens for K8s audit log events            | `0.0.0.0`                                   |\n| `auditLog.auditServerPort`        | Port where Sysdig Agent listens for K8s audit log events               | `7765`                                      |\n| `auditLog.dynamicBackend.enabled` | Deploy the Audit Sink where Sysdig listens for K8s audit log events    | `false`                                     |\n| `customAppChecks`                 | The custom app checks deployed with your agent                         | `{}`                                        |\n| `tolerations`                     | The tolerations for scheduling                                         | `node-role.kubernetes.io/master:NoSchedule` |\n| `scc.create`                      | Create OpenShift's Security Context Constraint                         | `false`                                     |\nFor example, if you want to deploy a DaemonSet with eBPF and with Sysdig Secure\nenabled:\n```yaml\napiVersion: sysdig.com/v1\nkind: SysdigAgent\nmetadata:\n  name: agent-with-ebpf-and-secure\nspec:\n  ebpf:\n    enabled: true\n  daemonset:\n    annotations:\n      productID: SysdigSecureDevopsPlatform\n      productName: Sysdig Secure DevOps Platform\n      productVersion: REPLACE_VERSION\n  scc:\n    create: true\n  sysdig:\n    accessKey: XXX\n```\nPlease, notice that `sysdig.accessKey` is **mandatory**. Once you have provided\nthe accessKey, you can apply this file with `kubectl apply -f`\n## Getting your Access Key\nTo retrieve the key and use it in the agent:\n1. Log in to Sysdig Monitor or Sysdig Secure (maybe as administrator) and\n   select **Settings**.\n2. Choose Agent Installation.\n3. Use the Copy button to copy the access key at the top of the page.\nIf you need more help, you can read more about this process in the [Agent Installation: Overview and Key](\nhttps://sysdigdocs.atlassian.net/wiki/spaces/Platform/pages/213352719/Agent+Installation+Overview+and+Key)\ndocumentation page.\n## Verify Metrics in Sysdig Monitor UI\nOnce you have deployed the Sysdig Agent, it's time to verify that everything is\nworking as expected. So, we are going to log in Sysdig Monitor to do the check.\n1. Access Sysdig Monitor:\n   **SaaS**: https://app.sysdigcloud.com\n   Log in with your Sysdig user name and password.\n2. Select the **Explore** tab to see if metrics are displayed.\n3. To verify that kube state metrics and cluster name are working correctly:\n   Select the **Explore tab** and create a grouping by `kubernetes.cluster.name` and `kubernetes.pod.name`.\n4. Select an individual container or pod to see details.\nDon't rush about getting Kubernetes metadata. Pods, deployments ... appear a\nminute or two later than the nodes/containers themselves; if pod names do not\nappear immediately, wait and retry the Explore view.\nYou can read more about verification in the [Verify Metrics in Sysdig Monitor UI section](https://sysdigdocs.atlassian.net/wiki/spaces/Platform/pages/256475257/GKE+Installation+Steps#GKEInstallationSteps-VerifyMetricsinSysdigMonitorUI)\nin the documentation pages.",
      "csv_display_name": "Sysdig Agent Operator",
      "csv_metadata_description": "Sysdig is a unified platform for container and microservices monitoring, troubleshooting, security and forensics. Sysdig platform has been built on top of Sysdig tool and Sysdig Inspect open-source technologies.\n",
      "csv_name": "sysdig-certified.v1.15.37",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T18:51:09.246000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "sysdig-certified",
      "provided_apis": [
        {
          "group": "sysdig.com",
          "kind": "SysdigAgent",
          "version": "v1"
        }
      ],
      "provider": "Sysdig",
      "related_images": [
        {
          "digest": "sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "image": "registry.connect.redhat.com/sysdig/sysdig-operator@sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "name": "sysdig-operator-23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88-annotation"
        },
        {
          "digest": "sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "image": "registry.connect.redhat.com/sysdig/sysdig-operator@sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "name": "manager"
        },
        {
          "digest": "sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "name": "kube-rbac-proxy"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.15.37",
      "version_original": "1.15.37"
    },
    {
      "_id": "6328ba5dfc81574279e6d0d6",
      "alm_examples": [
        {
          "api_version": "sysdig.com/v1",
          "kind": "SysdigAgent",
          "metadata": {
            "name": "sysdigagent-sample"
          },
          "spec": {
            "sysdig": {
              "accessKey": "REPLACE ME",
              "disableCaptures": false,
              "existingAccessKeySecret": "",
              "settings": {}
            },
            "tolerations": [
              {
                "effect": "NoSchedule",
                "key": "node-role.kubernetes.io/master"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/sysdig/sysdig-operator-bundle@sha256:69dbc1df3b4702d50fc04c0dbf74dd96d0d4fadac86d452d08a2c2d5880c1a99",
      "bundle_path_digest": "sha256:69dbc1df3b4702d50fc04c0dbf74dd96d0d4fadac86d452d08a2c2d5880c1a99",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T18:52:13.665000+00:00",
      "csv_description": "[Sysdig](https://www.sysdig.com/) is a unified platform for container and\nmicroservices monitoring, troubleshooting, security and forensics. Sysdig\nplatform has been built on top of\n[Sysdig tool](https://sysdig.com/opensource/sysdig/) and\n[Sysdig Inspect](https://sysdig.com/blog/sysdig-inspect/) open-source\ntechnologies.\nThis operator installs the Sysdig Agent for\n[Sysdig Monitor](https://sysdig.com/product/monitor/) and\n[Sysdig Secure](https://sysdig.com/product/secure/) to all nodes in your\ncluster via a DaemonSet.\n## Settings\nThis operator, uses the same options than the\n[Helm Chart](https://hub.helm.sh/charts/stable/sysdig), please take a look\nto all the options in the following table:\n| Parameter                         | Description                                                            | Default                                     |\n| ---                               | ---                                                                    | ---                                         |\n| `image.registry`                  | Sysdig agent image registry                                            | `docker.io`                                 |\n| `image.repository`                | The image repository to pull from                                      | `sysdig/agent`                              |\n| `image.tag`                       | The image tag to pull                                                  | `REPLACE_AGENT_VERSION`                                     |\n| `image.pullPolicy`                | The Image pull policy                                                  | `IfNotPresent`                              |\n| `image.pullSecrets`               | Image pull secrets                                                     | `nil`                                       |\n| `resources.requests.cpu`          | CPU requested for being run in a node                                  | `600m`                                      |\n| `resources.requests.memory`       | Memory requested for being run in a node                               | `512Mi`                                     |\n| `resources.limits.cpu`            | CPU limit                                                              | `2000m`                                     |\n| `resources.limits.memory`         | Memory limit                                                           | `1536Mi`                                    |\n| `rbac.create`                     | If true, create & use RBAC resources                                   | `true`                                      |\n| `serviceAccount.create`           | Create serviceAccount                                                  | `true`                                      |\n| `serviceAccount.name`             | Use this value as serviceAccountName                                   | ` `                                         |\n| `daemonset.updateStrategy.type`   | The updateStrategy for updating the daemonset                          | `RollingUpdate`                             |\n| `daemonset.affinity`              | Node affinities                                                        | `nil`                                       |\n| `daemonset.annotations`           | Custom annotations for daemonset                                       | `{}`                                        |\n| `slim.enabled`                    | Use the slim based Sysdig Agent image                                  | `false`                                     |\n| `slim.kmoduleImage.repository`    | The kernel module image builder repository to pull from                | `sysdig/agent-kmodule`                      |\n| `slim.resources.requests.cpu`     | CPU requested for building the kernel module                           | `1000m`                                     |\n| `slim.resources.requests.memory`  | Memory requested for building the kernel module                        | `348Mi`                                     |\n| `slim.resources.limits.memory`    | Memory limit for building the kernel module                            | `512Mi`                                     |\n| `ebpf.enabled`                    | Enable eBPF support for Sysdig instead of `sysdig-probe` kernel module | `false`                                     |\n| `ebpf.settings.mountEtcVolume`    | Needed to detect which kernel version are running in Google COS        | `true`                                      |\n| `sysdig.accessKey`                | Your Sysdig Monitor Access Key                                         | `Nil` You must provide your own key         |\n| `sysdig.settings`                 | Settings for agent's configuration file                                | ` `                                         |\n| `secure.enabled`                  | Enable Sysdig Secure                                                   | `true`                                      |\n| `auditLog.enabled`                | Enable K8s audit log support for Sysdig Secure                         | `false`                                     |\n| `auditLog.auditServerUrl`         | The URL where Sysdig Agent listens for K8s audit log events            | `0.0.0.0`                                   |\n| `auditLog.auditServerPort`        | Port where Sysdig Agent listens for K8s audit log events               | `7765`                                      |\n| `auditLog.dynamicBackend.enabled` | Deploy the Audit Sink where Sysdig listens for K8s audit log events    | `false`                                     |\n| `customAppChecks`                 | The custom app checks deployed with your agent                         | `{}`                                        |\n| `tolerations`                     | The tolerations for scheduling                                         | `node-role.kubernetes.io/master:NoSchedule` |\n| `scc.create`                      | Create OpenShift's Security Context Constraint                         | `false`                                     |\nFor example, if you want to deploy a DaemonSet with eBPF and with Sysdig Secure\nenabled:\n```yaml\napiVersion: sysdig.com/v1\nkind: SysdigAgent\nmetadata:\n  name: agent-with-ebpf-and-secure\nspec:\n  ebpf:\n    enabled: true\n  daemonset:\n    annotations:\n      productID: SysdigSecureDevopsPlatform\n      productName: Sysdig Secure DevOps Platform\n      productVersion: REPLACE_VERSION\n  scc:\n    create: true\n  sysdig:\n    accessKey: XXX\n```\nPlease, notice that `sysdig.accessKey` is **mandatory**. Once you have provided\nthe accessKey, you can apply this file with `kubectl apply -f`\n## Getting your Access Key\nTo retrieve the key and use it in the agent:\n1. Log in to Sysdig Monitor or Sysdig Secure (maybe as administrator) and\n   select **Settings**.\n2. Choose Agent Installation.\n3. Use the Copy button to copy the access key at the top of the page.\nIf you need more help, you can read more about this process in the [Agent Installation: Overview and Key](\nhttps://sysdigdocs.atlassian.net/wiki/spaces/Platform/pages/213352719/Agent+Installation+Overview+and+Key)\ndocumentation page.\n## Verify Metrics in Sysdig Monitor UI\nOnce you have deployed the Sysdig Agent, it's time to verify that everything is\nworking as expected. So, we are going to log in Sysdig Monitor to do the check.\n1. Access Sysdig Monitor:\n   **SaaS**: https://app.sysdigcloud.com\n   Log in with your Sysdig user name and password.\n2. Select the **Explore** tab to see if metrics are displayed.\n3. To verify that kube state metrics and cluster name are working correctly:\n   Select the **Explore tab** and create a grouping by `kubernetes.cluster.name` and `kubernetes.pod.name`.\n4. Select an individual container or pod to see details.\nDon't rush about getting Kubernetes metadata. Pods, deployments ... appear a\nminute or two later than the nodes/containers themselves; if pod names do not\nappear immediately, wait and retry the Explore view.\nYou can read more about verification in the [Verify Metrics in Sysdig Monitor UI section](https://sysdigdocs.atlassian.net/wiki/spaces/Platform/pages/256475257/GKE+Installation+Steps#GKEInstallationSteps-VerifyMetricsinSysdigMonitorUI)\nin the documentation pages.",
      "csv_display_name": "Sysdig Agent Operator",
      "csv_metadata_description": "Sysdig is a unified platform for container and microservices monitoring, troubleshooting, security and forensics. Sysdig platform has been built on top of Sysdig tool and Sysdig Inspect open-source technologies.\n",
      "csv_name": "sysdig-certified.v1.15.37",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T18:52:13.665000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "sysdig-certified",
      "provided_apis": [
        {
          "group": "sysdig.com",
          "kind": "SysdigAgent",
          "plural": "sysdigagents",
          "version": "v1"
        }
      ],
      "provider": "Sysdig",
      "related_images": [
        {
          "digest": "sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "image": "registry.connect.redhat.com/sysdig/sysdig-operator@sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "name": "sysdig-operator-23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88-annotation"
        },
        {
          "digest": "sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "image": "registry.connect.redhat.com/sysdig/sysdig-operator@sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "name": "manager"
        },
        {
          "digest": "sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "name": "kube-rbac-proxy"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.15.37",
      "version_original": "1.15.37"
    },
    {
      "_id": "6328bc38eb69678e80bd5cf7",
      "alm_examples": [
        {
          "api_version": "sysdig.com/v1",
          "kind": "SysdigAgent",
          "metadata": {
            "name": "sysdigagent-sample"
          },
          "spec": {
            "sysdig": {
              "accessKey": "REPLACE ME",
              "disableCaptures": false,
              "existingAccessKeySecret": "",
              "settings": {}
            },
            "tolerations": [
              {
                "effect": "NoSchedule",
                "key": "node-role.kubernetes.io/master"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/sysdig/sysdig-operator-bundle@sha256:69dbc1df3b4702d50fc04c0dbf74dd96d0d4fadac86d452d08a2c2d5880c1a99",
      "bundle_path_digest": "sha256:69dbc1df3b4702d50fc04c0dbf74dd96d0d4fadac86d452d08a2c2d5880c1a99",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T19:00:08.067000+00:00",
      "csv_description": "[Sysdig](https://www.sysdig.com/) is a unified platform for container and\nmicroservices monitoring, troubleshooting, security and forensics. Sysdig\nplatform has been built on top of\n[Sysdig tool](https://sysdig.com/opensource/sysdig/) and\n[Sysdig Inspect](https://sysdig.com/blog/sysdig-inspect/) open-source\ntechnologies.\nThis operator installs the Sysdig Agent for\n[Sysdig Monitor](https://sysdig.com/product/monitor/) and\n[Sysdig Secure](https://sysdig.com/product/secure/) to all nodes in your\ncluster via a DaemonSet.\n## Settings\nThis operator, uses the same options than the\n[Helm Chart](https://hub.helm.sh/charts/stable/sysdig), please take a look\nto all the options in the following table:\n| Parameter                         | Description                                                            | Default                                     |\n| ---                               | ---                                                                    | ---                                         |\n| `image.registry`                  | Sysdig agent image registry                                            | `docker.io`                                 |\n| `image.repository`                | The image repository to pull from                                      | `sysdig/agent`                              |\n| `image.tag`                       | The image tag to pull                                                  | `REPLACE_AGENT_VERSION`                                     |\n| `image.pullPolicy`                | The Image pull policy                                                  | `IfNotPresent`                              |\n| `image.pullSecrets`               | Image pull secrets                                                     | `nil`                                       |\n| `resources.requests.cpu`          | CPU requested for being run in a node                                  | `600m`                                      |\n| `resources.requests.memory`       | Memory requested for being run in a node                               | `512Mi`                                     |\n| `resources.limits.cpu`            | CPU limit                                                              | `2000m`                                     |\n| `resources.limits.memory`         | Memory limit                                                           | `1536Mi`                                    |\n| `rbac.create`                     | If true, create & use RBAC resources                                   | `true`                                      |\n| `serviceAccount.create`           | Create serviceAccount                                                  | `true`                                      |\n| `serviceAccount.name`             | Use this value as serviceAccountName                                   | ` `                                         |\n| `daemonset.updateStrategy.type`   | The updateStrategy for updating the daemonset                          | `RollingUpdate`                             |\n| `daemonset.affinity`              | Node affinities                                                        | `nil`                                       |\n| `daemonset.annotations`           | Custom annotations for daemonset                                       | `{}`                                        |\n| `slim.enabled`                    | Use the slim based Sysdig Agent image                                  | `false`                                     |\n| `slim.kmoduleImage.repository`    | The kernel module image builder repository to pull from                | `sysdig/agent-kmodule`                      |\n| `slim.resources.requests.cpu`     | CPU requested for building the kernel module                           | `1000m`                                     |\n| `slim.resources.requests.memory`  | Memory requested for building the kernel module                        | `348Mi`                                     |\n| `slim.resources.limits.memory`    | Memory limit for building the kernel module                            | `512Mi`                                     |\n| `ebpf.enabled`                    | Enable eBPF support for Sysdig instead of `sysdig-probe` kernel module | `false`                                     |\n| `ebpf.settings.mountEtcVolume`    | Needed to detect which kernel version are running in Google COS        | `true`                                      |\n| `sysdig.accessKey`                | Your Sysdig Monitor Access Key                                         | `Nil` You must provide your own key         |\n| `sysdig.settings`                 | Settings for agent's configuration file                                | ` `                                         |\n| `secure.enabled`                  | Enable Sysdig Secure                                                   | `true`                                      |\n| `auditLog.enabled`                | Enable K8s audit log support for Sysdig Secure                         | `false`                                     |\n| `auditLog.auditServerUrl`         | The URL where Sysdig Agent listens for K8s audit log events            | `0.0.0.0`                                   |\n| `auditLog.auditServerPort`        | Port where Sysdig Agent listens for K8s audit log events               | `7765`                                      |\n| `auditLog.dynamicBackend.enabled` | Deploy the Audit Sink where Sysdig listens for K8s audit log events    | `false`                                     |\n| `customAppChecks`                 | The custom app checks deployed with your agent                         | `{}`                                        |\n| `tolerations`                     | The tolerations for scheduling                                         | `node-role.kubernetes.io/master:NoSchedule` |\n| `scc.create`                      | Create OpenShift's Security Context Constraint                         | `false`                                     |\nFor example, if you want to deploy a DaemonSet with eBPF and with Sysdig Secure\nenabled:\n```yaml\napiVersion: sysdig.com/v1\nkind: SysdigAgent\nmetadata:\n  name: agent-with-ebpf-and-secure\nspec:\n  ebpf:\n    enabled: true\n  daemonset:\n    annotations:\n      productID: SysdigSecureDevopsPlatform\n      productName: Sysdig Secure DevOps Platform\n      productVersion: REPLACE_VERSION\n  scc:\n    create: true\n  sysdig:\n    accessKey: XXX\n```\nPlease, notice that `sysdig.accessKey` is **mandatory**. Once you have provided\nthe accessKey, you can apply this file with `kubectl apply -f`\n## Getting your Access Key\nTo retrieve the key and use it in the agent:\n1. Log in to Sysdig Monitor or Sysdig Secure (maybe as administrator) and\n   select **Settings**.\n2. Choose Agent Installation.\n3. Use the Copy button to copy the access key at the top of the page.\nIf you need more help, you can read more about this process in the [Agent Installation: Overview and Key](\nhttps://sysdigdocs.atlassian.net/wiki/spaces/Platform/pages/213352719/Agent+Installation+Overview+and+Key)\ndocumentation page.\n## Verify Metrics in Sysdig Monitor UI\nOnce you have deployed the Sysdig Agent, it's time to verify that everything is\nworking as expected. So, we are going to log in Sysdig Monitor to do the check.\n1. Access Sysdig Monitor:\n   **SaaS**: https://app.sysdigcloud.com\n   Log in with your Sysdig user name and password.\n2. Select the **Explore** tab to see if metrics are displayed.\n3. To verify that kube state metrics and cluster name are working correctly:\n   Select the **Explore tab** and create a grouping by `kubernetes.cluster.name` and `kubernetes.pod.name`.\n4. Select an individual container or pod to see details.\nDon't rush about getting Kubernetes metadata. Pods, deployments ... appear a\nminute or two later than the nodes/containers themselves; if pod names do not\nappear immediately, wait and retry the Explore view.\nYou can read more about verification in the [Verify Metrics in Sysdig Monitor UI section](https://sysdigdocs.atlassian.net/wiki/spaces/Platform/pages/256475257/GKE+Installation+Steps#GKEInstallationSteps-VerifyMetricsinSysdigMonitorUI)\nin the documentation pages.",
      "csv_display_name": "Sysdig Agent Operator",
      "csv_metadata_description": "Sysdig is a unified platform for container and microservices monitoring, troubleshooting, security and forensics. Sysdig platform has been built on top of Sysdig tool and Sysdig Inspect open-source technologies.\n",
      "csv_name": "sysdig-certified.v1.15.37",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T19:00:08.067000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "sysdig-certified",
      "provided_apis": [
        {
          "group": "sysdig.com",
          "kind": "SysdigAgent",
          "plural": "sysdigagents",
          "version": "v1"
        }
      ],
      "provider": "Sysdig",
      "related_images": [
        {
          "digest": "sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "image": "registry.connect.redhat.com/sysdig/sysdig-operator@sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "name": "sysdig-operator-23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88-annotation"
        },
        {
          "digest": "sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "image": "registry.connect.redhat.com/sysdig/sysdig-operator@sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "name": "manager"
        },
        {
          "digest": "sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "name": "kube-rbac-proxy"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.15.37",
      "version_original": "1.15.37"
    },
    {
      "_id": "6328bf87c9abe8b4a6e9430a",
      "alm_examples": [
        {
          "api_version": "sysdig.com/v1",
          "kind": "SysdigAgent",
          "metadata": {
            "name": "sysdigagent-sample"
          },
          "spec": {
            "sysdig": {
              "accessKey": "REPLACE ME",
              "disableCaptures": false,
              "existingAccessKeySecret": "",
              "settings": {}
            },
            "tolerations": [
              {
                "effect": "NoSchedule",
                "key": "node-role.kubernetes.io/master"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/sysdig/sysdig-operator-bundle@sha256:69dbc1df3b4702d50fc04c0dbf74dd96d0d4fadac86d452d08a2c2d5880c1a99",
      "bundle_path_digest": "sha256:69dbc1df3b4702d50fc04c0dbf74dd96d0d4fadac86d452d08a2c2d5880c1a99",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T19:14:15.801000+00:00",
      "csv_description": "[Sysdig](https://www.sysdig.com/) is a unified platform for container and\nmicroservices monitoring, troubleshooting, security and forensics. Sysdig\nplatform has been built on top of\n[Sysdig tool](https://sysdig.com/opensource/sysdig/) and\n[Sysdig Inspect](https://sysdig.com/blog/sysdig-inspect/) open-source\ntechnologies.\nThis operator installs the Sysdig Agent for\n[Sysdig Monitor](https://sysdig.com/product/monitor/) and\n[Sysdig Secure](https://sysdig.com/product/secure/) to all nodes in your\ncluster via a DaemonSet.\n## Settings\nThis operator, uses the same options than the\n[Helm Chart](https://hub.helm.sh/charts/stable/sysdig), please take a look\nto all the options in the following table:\n| Parameter                         | Description                                                            | Default                                     |\n| ---                               | ---                                                                    | ---                                         |\n| `image.registry`                  | Sysdig agent image registry                                            | `docker.io`                                 |\n| `image.repository`                | The image repository to pull from                                      | `sysdig/agent`                              |\n| `image.tag`                       | The image tag to pull                                                  | `REPLACE_AGENT_VERSION`                                     |\n| `image.pullPolicy`                | The Image pull policy                                                  | `IfNotPresent`                              |\n| `image.pullSecrets`               | Image pull secrets                                                     | `nil`                                       |\n| `resources.requests.cpu`          | CPU requested for being run in a node                                  | `600m`                                      |\n| `resources.requests.memory`       | Memory requested for being run in a node                               | `512Mi`                                     |\n| `resources.limits.cpu`            | CPU limit                                                              | `2000m`                                     |\n| `resources.limits.memory`         | Memory limit                                                           | `1536Mi`                                    |\n| `rbac.create`                     | If true, create & use RBAC resources                                   | `true`                                      |\n| `serviceAccount.create`           | Create serviceAccount                                                  | `true`                                      |\n| `serviceAccount.name`             | Use this value as serviceAccountName                                   | ` `                                         |\n| `daemonset.updateStrategy.type`   | The updateStrategy for updating the daemonset                          | `RollingUpdate`                             |\n| `daemonset.affinity`              | Node affinities                                                        | `nil`                                       |\n| `daemonset.annotations`           | Custom annotations for daemonset                                       | `{}`                                        |\n| `slim.enabled`                    | Use the slim based Sysdig Agent image                                  | `false`                                     |\n| `slim.kmoduleImage.repository`    | The kernel module image builder repository to pull from                | `sysdig/agent-kmodule`                      |\n| `slim.resources.requests.cpu`     | CPU requested for building the kernel module                           | `1000m`                                     |\n| `slim.resources.requests.memory`  | Memory requested for building the kernel module                        | `348Mi`                                     |\n| `slim.resources.limits.memory`    | Memory limit for building the kernel module                            | `512Mi`                                     |\n| `ebpf.enabled`                    | Enable eBPF support for Sysdig instead of `sysdig-probe` kernel module | `false`                                     |\n| `ebpf.settings.mountEtcVolume`    | Needed to detect which kernel version are running in Google COS        | `true`                                      |\n| `sysdig.accessKey`                | Your Sysdig Monitor Access Key                                         | `Nil` You must provide your own key         |\n| `sysdig.settings`                 | Settings for agent's configuration file                                | ` `                                         |\n| `secure.enabled`                  | Enable Sysdig Secure                                                   | `true`                                      |\n| `auditLog.enabled`                | Enable K8s audit log support for Sysdig Secure                         | `false`                                     |\n| `auditLog.auditServerUrl`         | The URL where Sysdig Agent listens for K8s audit log events            | `0.0.0.0`                                   |\n| `auditLog.auditServerPort`        | Port where Sysdig Agent listens for K8s audit log events               | `7765`                                      |\n| `auditLog.dynamicBackend.enabled` | Deploy the Audit Sink where Sysdig listens for K8s audit log events    | `false`                                     |\n| `customAppChecks`                 | The custom app checks deployed with your agent                         | `{}`                                        |\n| `tolerations`                     | The tolerations for scheduling                                         | `node-role.kubernetes.io/master:NoSchedule` |\n| `scc.create`                      | Create OpenShift's Security Context Constraint                         | `false`                                     |\nFor example, if you want to deploy a DaemonSet with eBPF and with Sysdig Secure\nenabled:\n```yaml\napiVersion: sysdig.com/v1\nkind: SysdigAgent\nmetadata:\n  name: agent-with-ebpf-and-secure\nspec:\n  ebpf:\n    enabled: true\n  daemonset:\n    annotations:\n      productID: SysdigSecureDevopsPlatform\n      productName: Sysdig Secure DevOps Platform\n      productVersion: REPLACE_VERSION\n  scc:\n    create: true\n  sysdig:\n    accessKey: XXX\n```\nPlease, notice that `sysdig.accessKey` is **mandatory**. Once you have provided\nthe accessKey, you can apply this file with `kubectl apply -f`\n## Getting your Access Key\nTo retrieve the key and use it in the agent:\n1. Log in to Sysdig Monitor or Sysdig Secure (maybe as administrator) and\n   select **Settings**.\n2. Choose Agent Installation.\n3. Use the Copy button to copy the access key at the top of the page.\nIf you need more help, you can read more about this process in the [Agent Installation: Overview and Key](\nhttps://sysdigdocs.atlassian.net/wiki/spaces/Platform/pages/213352719/Agent+Installation+Overview+and+Key)\ndocumentation page.\n## Verify Metrics in Sysdig Monitor UI\nOnce you have deployed the Sysdig Agent, it's time to verify that everything is\nworking as expected. So, we are going to log in Sysdig Monitor to do the check.\n1. Access Sysdig Monitor:\n   **SaaS**: https://app.sysdigcloud.com\n   Log in with your Sysdig user name and password.\n2. Select the **Explore** tab to see if metrics are displayed.\n3. To verify that kube state metrics and cluster name are working correctly:\n   Select the **Explore tab** and create a grouping by `kubernetes.cluster.name` and `kubernetes.pod.name`.\n4. Select an individual container or pod to see details.\nDon't rush about getting Kubernetes metadata. Pods, deployments ... appear a\nminute or two later than the nodes/containers themselves; if pod names do not\nappear immediately, wait and retry the Explore view.\nYou can read more about verification in the [Verify Metrics in Sysdig Monitor UI section](https://sysdigdocs.atlassian.net/wiki/spaces/Platform/pages/256475257/GKE+Installation+Steps#GKEInstallationSteps-VerifyMetricsinSysdigMonitorUI)\nin the documentation pages.",
      "csv_display_name": "Sysdig Agent Operator",
      "csv_metadata_description": "Sysdig is a unified platform for container and microservices monitoring, troubleshooting, security and forensics. Sysdig platform has been built on top of Sysdig tool and Sysdig Inspect open-source technologies.\n",
      "csv_name": "sysdig-certified.v1.15.37",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T19:14:15.801000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "sysdig-certified",
      "provided_apis": [
        {
          "group": "sysdig.com",
          "kind": "SysdigAgent",
          "plural": "sysdigagents",
          "version": "v1"
        }
      ],
      "provider": "Sysdig",
      "related_images": [
        {
          "digest": "sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "image": "registry.connect.redhat.com/sysdig/sysdig-operator@sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "name": "sysdig-operator-23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88-annotation"
        },
        {
          "digest": "sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "image": "registry.connect.redhat.com/sysdig/sysdig-operator@sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "name": "manager"
        },
        {
          "digest": "sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "name": "kube-rbac-proxy"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "1.15.37",
      "version_original": "1.15.37"
    },
    {
      "_id": "6328bfab9bb8b51dd3561239",
      "alm_examples": [
        {
          "api_version": "sysdig.com/v1",
          "kind": "SysdigAgent",
          "metadata": {
            "name": "sysdigagent-sample"
          },
          "spec": {
            "sysdig": {
              "accessKey": "REPLACE ME",
              "disableCaptures": false,
              "existingAccessKeySecret": "",
              "settings": {}
            },
            "tolerations": [
              {
                "effect": "NoSchedule",
                "key": "node-role.kubernetes.io/master"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/sysdig/sysdig-operator-bundle@sha256:69dbc1df3b4702d50fc04c0dbf74dd96d0d4fadac86d452d08a2c2d5880c1a99",
      "bundle_path_digest": "sha256:69dbc1df3b4702d50fc04c0dbf74dd96d0d4fadac86d452d08a2c2d5880c1a99",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T19:14:51.086000+00:00",
      "csv_description": "[Sysdig](https://www.sysdig.com/) is a unified platform for container and\nmicroservices monitoring, troubleshooting, security and forensics. Sysdig\nplatform has been built on top of\n[Sysdig tool](https://sysdig.com/opensource/sysdig/) and\n[Sysdig Inspect](https://sysdig.com/blog/sysdig-inspect/) open-source\ntechnologies.\nThis operator installs the Sysdig Agent for\n[Sysdig Monitor](https://sysdig.com/product/monitor/) and\n[Sysdig Secure](https://sysdig.com/product/secure/) to all nodes in your\ncluster via a DaemonSet.\n## Settings\nThis operator, uses the same options than the\n[Helm Chart](https://hub.helm.sh/charts/stable/sysdig), please take a look\nto all the options in the following table:\n| Parameter                         | Description                                                            | Default                                     |\n| ---                               | ---                                                                    | ---                                         |\n| `image.registry`                  | Sysdig agent image registry                                            | `docker.io`                                 |\n| `image.repository`                | The image repository to pull from                                      | `sysdig/agent`                              |\n| `image.tag`                       | The image tag to pull                                                  | `REPLACE_AGENT_VERSION`                                     |\n| `image.pullPolicy`                | The Image pull policy                                                  | `IfNotPresent`                              |\n| `image.pullSecrets`               | Image pull secrets                                                     | `nil`                                       |\n| `resources.requests.cpu`          | CPU requested for being run in a node                                  | `600m`                                      |\n| `resources.requests.memory`       | Memory requested for being run in a node                               | `512Mi`                                     |\n| `resources.limits.cpu`            | CPU limit                                                              | `2000m`                                     |\n| `resources.limits.memory`         | Memory limit                                                           | `1536Mi`                                    |\n| `rbac.create`                     | If true, create & use RBAC resources                                   | `true`                                      |\n| `serviceAccount.create`           | Create serviceAccount                                                  | `true`                                      |\n| `serviceAccount.name`             | Use this value as serviceAccountName                                   | ` `                                         |\n| `daemonset.updateStrategy.type`   | The updateStrategy for updating the daemonset                          | `RollingUpdate`                             |\n| `daemonset.affinity`              | Node affinities                                                        | `nil`                                       |\n| `daemonset.annotations`           | Custom annotations for daemonset                                       | `{}`                                        |\n| `slim.enabled`                    | Use the slim based Sysdig Agent image                                  | `false`                                     |\n| `slim.kmoduleImage.repository`    | The kernel module image builder repository to pull from                | `sysdig/agent-kmodule`                      |\n| `slim.resources.requests.cpu`     | CPU requested for building the kernel module                           | `1000m`                                     |\n| `slim.resources.requests.memory`  | Memory requested for building the kernel module                        | `348Mi`                                     |\n| `slim.resources.limits.memory`    | Memory limit for building the kernel module                            | `512Mi`                                     |\n| `ebpf.enabled`                    | Enable eBPF support for Sysdig instead of `sysdig-probe` kernel module | `false`                                     |\n| `ebpf.settings.mountEtcVolume`    | Needed to detect which kernel version are running in Google COS        | `true`                                      |\n| `sysdig.accessKey`                | Your Sysdig Monitor Access Key                                         | `Nil` You must provide your own key         |\n| `sysdig.settings`                 | Settings for agent's configuration file                                | ` `                                         |\n| `secure.enabled`                  | Enable Sysdig Secure                                                   | `true`                                      |\n| `auditLog.enabled`                | Enable K8s audit log support for Sysdig Secure                         | `false`                                     |\n| `auditLog.auditServerUrl`         | The URL where Sysdig Agent listens for K8s audit log events            | `0.0.0.0`                                   |\n| `auditLog.auditServerPort`        | Port where Sysdig Agent listens for K8s audit log events               | `7765`                                      |\n| `auditLog.dynamicBackend.enabled` | Deploy the Audit Sink where Sysdig listens for K8s audit log events    | `false`                                     |\n| `customAppChecks`                 | The custom app checks deployed with your agent                         | `{}`                                        |\n| `tolerations`                     | The tolerations for scheduling                                         | `node-role.kubernetes.io/master:NoSchedule` |\n| `scc.create`                      | Create OpenShift's Security Context Constraint                         | `false`                                     |\nFor example, if you want to deploy a DaemonSet with eBPF and with Sysdig Secure\nenabled:\n```yaml\napiVersion: sysdig.com/v1\nkind: SysdigAgent\nmetadata:\n  name: agent-with-ebpf-and-secure\nspec:\n  ebpf:\n    enabled: true\n  daemonset:\n    annotations:\n      productID: SysdigSecureDevopsPlatform\n      productName: Sysdig Secure DevOps Platform\n      productVersion: REPLACE_VERSION\n  scc:\n    create: true\n  sysdig:\n    accessKey: XXX\n```\nPlease, notice that `sysdig.accessKey` is **mandatory**. Once you have provided\nthe accessKey, you can apply this file with `kubectl apply -f`\n## Getting your Access Key\nTo retrieve the key and use it in the agent:\n1. Log in to Sysdig Monitor or Sysdig Secure (maybe as administrator) and\n   select **Settings**.\n2. Choose Agent Installation.\n3. Use the Copy button to copy the access key at the top of the page.\nIf you need more help, you can read more about this process in the [Agent Installation: Overview and Key](\nhttps://sysdigdocs.atlassian.net/wiki/spaces/Platform/pages/213352719/Agent+Installation+Overview+and+Key)\ndocumentation page.\n## Verify Metrics in Sysdig Monitor UI\nOnce you have deployed the Sysdig Agent, it's time to verify that everything is\nworking as expected. So, we are going to log in Sysdig Monitor to do the check.\n1. Access Sysdig Monitor:\n   **SaaS**: https://app.sysdigcloud.com\n   Log in with your Sysdig user name and password.\n2. Select the **Explore** tab to see if metrics are displayed.\n3. To verify that kube state metrics and cluster name are working correctly:\n   Select the **Explore tab** and create a grouping by `kubernetes.cluster.name` and `kubernetes.pod.name`.\n4. Select an individual container or pod to see details.\nDon't rush about getting Kubernetes metadata. Pods, deployments ... appear a\nminute or two later than the nodes/containers themselves; if pod names do not\nappear immediately, wait and retry the Explore view.\nYou can read more about verification in the [Verify Metrics in Sysdig Monitor UI section](https://sysdigdocs.atlassian.net/wiki/spaces/Platform/pages/256475257/GKE+Installation+Steps#GKEInstallationSteps-VerifyMetricsinSysdigMonitorUI)\nin the documentation pages.",
      "csv_display_name": "Sysdig Agent Operator",
      "csv_metadata_description": "Sysdig is a unified platform for container and microservices monitoring, troubleshooting, security and forensics. Sysdig platform has been built on top of Sysdig tool and Sysdig Inspect open-source technologies.\n",
      "csv_name": "sysdig-certified.v1.15.37",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T19:14:51.086000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "sysdig-certified",
      "provided_apis": [
        {
          "group": "sysdig.com",
          "kind": "SysdigAgent",
          "plural": "sysdigagents",
          "version": "v1"
        }
      ],
      "provider": "Sysdig",
      "related_images": [
        {
          "digest": "sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "image": "registry.connect.redhat.com/sysdig/sysdig-operator@sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "name": "sysdig-operator-23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88-annotation"
        },
        {
          "digest": "sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "image": "registry.connect.redhat.com/sysdig/sysdig-operator@sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "name": "manager"
        },
        {
          "digest": "sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "name": "kube-rbac-proxy"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "1.15.37",
      "version_original": "1.15.37"
    },
    {
      "_id": "6328bfb35ec32701224ae695",
      "alm_examples": [
        {
          "api_version": "sysdig.com/v1",
          "kind": "SysdigAgent",
          "metadata": {
            "name": "sysdigagent-sample"
          },
          "spec": {
            "sysdig": {
              "accessKey": "REPLACE ME",
              "disableCaptures": false,
              "existingAccessKeySecret": "",
              "settings": {}
            },
            "tolerations": [
              {
                "effect": "NoSchedule",
                "key": "node-role.kubernetes.io/master"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/sysdig/sysdig-operator-bundle@sha256:69dbc1df3b4702d50fc04c0dbf74dd96d0d4fadac86d452d08a2c2d5880c1a99",
      "bundle_path_digest": "sha256:69dbc1df3b4702d50fc04c0dbf74dd96d0d4fadac86d452d08a2c2d5880c1a99",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-19T19:14:59.947000+00:00",
      "csv_description": "[Sysdig](https://www.sysdig.com/) is a unified platform for container and\nmicroservices monitoring, troubleshooting, security and forensics. Sysdig\nplatform has been built on top of\n[Sysdig tool](https://sysdig.com/opensource/sysdig/) and\n[Sysdig Inspect](https://sysdig.com/blog/sysdig-inspect/) open-source\ntechnologies.\nThis operator installs the Sysdig Agent for\n[Sysdig Monitor](https://sysdig.com/product/monitor/) and\n[Sysdig Secure](https://sysdig.com/product/secure/) to all nodes in your\ncluster via a DaemonSet.\n## Settings\nThis operator, uses the same options than the\n[Helm Chart](https://hub.helm.sh/charts/stable/sysdig), please take a look\nto all the options in the following table:\n| Parameter                         | Description                                                            | Default                                     |\n| ---                               | ---                                                                    | ---                                         |\n| `image.registry`                  | Sysdig agent image registry                                            | `docker.io`                                 |\n| `image.repository`                | The image repository to pull from                                      | `sysdig/agent`                              |\n| `image.tag`                       | The image tag to pull                                                  | `REPLACE_AGENT_VERSION`                                     |\n| `image.pullPolicy`                | The Image pull policy                                                  | `IfNotPresent`                              |\n| `image.pullSecrets`               | Image pull secrets                                                     | `nil`                                       |\n| `resources.requests.cpu`          | CPU requested for being run in a node                                  | `600m`                                      |\n| `resources.requests.memory`       | Memory requested for being run in a node                               | `512Mi`                                     |\n| `resources.limits.cpu`            | CPU limit                                                              | `2000m`                                     |\n| `resources.limits.memory`         | Memory limit                                                           | `1536Mi`                                    |\n| `rbac.create`                     | If true, create & use RBAC resources                                   | `true`                                      |\n| `serviceAccount.create`           | Create serviceAccount                                                  | `true`                                      |\n| `serviceAccount.name`             | Use this value as serviceAccountName                                   | ` `                                         |\n| `daemonset.updateStrategy.type`   | The updateStrategy for updating the daemonset                          | `RollingUpdate`                             |\n| `daemonset.affinity`              | Node affinities                                                        | `nil`                                       |\n| `daemonset.annotations`           | Custom annotations for daemonset                                       | `{}`                                        |\n| `slim.enabled`                    | Use the slim based Sysdig Agent image                                  | `false`                                     |\n| `slim.kmoduleImage.repository`    | The kernel module image builder repository to pull from                | `sysdig/agent-kmodule`                      |\n| `slim.resources.requests.cpu`     | CPU requested for building the kernel module                           | `1000m`                                     |\n| `slim.resources.requests.memory`  | Memory requested for building the kernel module                        | `348Mi`                                     |\n| `slim.resources.limits.memory`    | Memory limit for building the kernel module                            | `512Mi`                                     |\n| `ebpf.enabled`                    | Enable eBPF support for Sysdig instead of `sysdig-probe` kernel module | `false`                                     |\n| `ebpf.settings.mountEtcVolume`    | Needed to detect which kernel version are running in Google COS        | `true`                                      |\n| `sysdig.accessKey`                | Your Sysdig Monitor Access Key                                         | `Nil` You must provide your own key         |\n| `sysdig.settings`                 | Settings for agent's configuration file                                | ` `                                         |\n| `secure.enabled`                  | Enable Sysdig Secure                                                   | `true`                                      |\n| `auditLog.enabled`                | Enable K8s audit log support for Sysdig Secure                         | `false`                                     |\n| `auditLog.auditServerUrl`         | The URL where Sysdig Agent listens for K8s audit log events            | `0.0.0.0`                                   |\n| `auditLog.auditServerPort`        | Port where Sysdig Agent listens for K8s audit log events               | `7765`                                      |\n| `auditLog.dynamicBackend.enabled` | Deploy the Audit Sink where Sysdig listens for K8s audit log events    | `false`                                     |\n| `customAppChecks`                 | The custom app checks deployed with your agent                         | `{}`                                        |\n| `tolerations`                     | The tolerations for scheduling                                         | `node-role.kubernetes.io/master:NoSchedule` |\n| `scc.create`                      | Create OpenShift's Security Context Constraint                         | `false`                                     |\nFor example, if you want to deploy a DaemonSet with eBPF and with Sysdig Secure\nenabled:\n```yaml\napiVersion: sysdig.com/v1\nkind: SysdigAgent\nmetadata:\n  name: agent-with-ebpf-and-secure\nspec:\n  ebpf:\n    enabled: true\n  daemonset:\n    annotations:\n      productID: SysdigSecureDevopsPlatform\n      productName: Sysdig Secure DevOps Platform\n      productVersion: REPLACE_VERSION\n  scc:\n    create: true\n  sysdig:\n    accessKey: XXX\n```\nPlease, notice that `sysdig.accessKey` is **mandatory**. Once you have provided\nthe accessKey, you can apply this file with `kubectl apply -f`\n## Getting your Access Key\nTo retrieve the key and use it in the agent:\n1. Log in to Sysdig Monitor or Sysdig Secure (maybe as administrator) and\n   select **Settings**.\n2. Choose Agent Installation.\n3. Use the Copy button to copy the access key at the top of the page.\nIf you need more help, you can read more about this process in the [Agent Installation: Overview and Key](\nhttps://sysdigdocs.atlassian.net/wiki/spaces/Platform/pages/213352719/Agent+Installation+Overview+and+Key)\ndocumentation page.\n## Verify Metrics in Sysdig Monitor UI\nOnce you have deployed the Sysdig Agent, it's time to verify that everything is\nworking as expected. So, we are going to log in Sysdig Monitor to do the check.\n1. Access Sysdig Monitor:\n   **SaaS**: https://app.sysdigcloud.com\n   Log in with your Sysdig user name and password.\n2. Select the **Explore** tab to see if metrics are displayed.\n3. To verify that kube state metrics and cluster name are working correctly:\n   Select the **Explore tab** and create a grouping by `kubernetes.cluster.name` and `kubernetes.pod.name`.\n4. Select an individual container or pod to see details.\nDon't rush about getting Kubernetes metadata. Pods, deployments ... appear a\nminute or two later than the nodes/containers themselves; if pod names do not\nappear immediately, wait and retry the Explore view.\nYou can read more about verification in the [Verify Metrics in Sysdig Monitor UI section](https://sysdigdocs.atlassian.net/wiki/spaces/Platform/pages/256475257/GKE+Installation+Steps#GKEInstallationSteps-VerifyMetricsinSysdigMonitorUI)\nin the documentation pages.",
      "csv_display_name": "Sysdig Agent Operator",
      "csv_metadata_description": "Sysdig is a unified platform for container and microservices monitoring, troubleshooting, security and forensics. Sysdig platform has been built on top of Sysdig tool and Sysdig Inspect open-source technologies.\n",
      "csv_name": "sysdig-certified.v1.15.37",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-19T19:14:59.947000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "sysdig-certified",
      "provided_apis": [
        {
          "group": "sysdig.com",
          "kind": "SysdigAgent",
          "plural": "sysdigagents",
          "version": "v1"
        }
      ],
      "provider": "Sysdig",
      "related_images": [
        {
          "digest": "sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "image": "registry.connect.redhat.com/sysdig/sysdig-operator@sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "name": "sysdig-operator-23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88-annotation"
        },
        {
          "digest": "sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "image": "registry.connect.redhat.com/sysdig/sysdig-operator@sha256:23e1547c319dd83d6bcb1a1f5ff3152649aa33e9097a5a296c5abb97aae5df88",
          "name": "manager"
        },
        {
          "digest": "sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "image": "registry.redhat.io/openshift4/ose-kube-rbac-proxy@sha256:8b4f814c112d7b91dc5e7904d4f3c684f3d77227344d2b553a84d4a1bc2829d3",
          "name": "kube-rbac-proxy"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.15.37",
      "version_original": "1.15.37"
    },
    {
      "_id": "6329f14cc9abe8b4a6e97c20",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:4cf65addf36a34de4e74dd9ec7937ef77d5bf4a0276a44bfcba7bf232898353c",
      "bundle_path_digest": "sha256:4cf65addf36a34de4e74dd9ec7937ef77d5bf4a0276a44bfcba7bf232898353c",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-09-20T16:58:52.898000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.6.4-beta.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-09-20T16:58:52.898000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "name": "kubeturbo-operator-2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172-annotation"
        },
        {
          "digest": "sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:4accb71d2a86b9d292f62a50f70c022c358e5bf4fa851be5b931a29cc54ecd24",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:4accb71d2a86b9d292f62a50f70c022c358e5bf4fa851be5b931a29cc54ecd24",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "8.6.4-beta.1",
      "version_original": "8.6.4-beta.1"
    },
    {
      "_id": "6329f3c65ec32701224b20ac",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:4cf65addf36a34de4e74dd9ec7937ef77d5bf4a0276a44bfcba7bf232898353c",
      "bundle_path_digest": "sha256:4cf65addf36a34de4e74dd9ec7937ef77d5bf4a0276a44bfcba7bf232898353c",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-09-20T17:09:26.105000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.6.4-beta.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-09-20T17:09:26.105000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "name": "kubeturbo-operator-2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172-annotation"
        },
        {
          "digest": "sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:4accb71d2a86b9d292f62a50f70c022c358e5bf4fa851be5b931a29cc54ecd24",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:4accb71d2a86b9d292f62a50f70c022c358e5bf4fa851be5b931a29cc54ecd24",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "8.6.4-beta.1",
      "version_original": "8.6.4-beta.1"
    },
    {
      "_id": "6329f3de787bb4d00dc9a138",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:4cf65addf36a34de4e74dd9ec7937ef77d5bf4a0276a44bfcba7bf232898353c",
      "bundle_path_digest": "sha256:4cf65addf36a34de4e74dd9ec7937ef77d5bf4a0276a44bfcba7bf232898353c",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-09-20T17:09:50.009000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.6.4-beta.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-09-20T17:09:50.009000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "name": "kubeturbo-operator-2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172-annotation"
        },
        {
          "digest": "sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:4accb71d2a86b9d292f62a50f70c022c358e5bf4fa851be5b931a29cc54ecd24",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:4accb71d2a86b9d292f62a50f70c022c358e5bf4fa851be5b931a29cc54ecd24",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "8.6.4-beta.1",
      "version_original": "8.6.4-beta.1"
    },
    {
      "_id": "6329f4005569e1b12a93f6b0",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:4cf65addf36a34de4e74dd9ec7937ef77d5bf4a0276a44bfcba7bf232898353c",
      "bundle_path_digest": "sha256:4cf65addf36a34de4e74dd9ec7937ef77d5bf4a0276a44bfcba7bf232898353c",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-09-20T17:10:24.536000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.6.4-beta.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-09-20T17:10:24.536000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "name": "kubeturbo-operator-2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172-annotation"
        },
        {
          "digest": "sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:4accb71d2a86b9d292f62a50f70c022c358e5bf4fa851be5b931a29cc54ecd24",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:4accb71d2a86b9d292f62a50f70c022c358e5bf4fa851be5b931a29cc54ecd24",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "8.6.4-beta.1",
      "version_original": "8.6.4-beta.1"
    },
    {
      "_id": "6329f493787bb4d00dc9a176",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:4cf65addf36a34de4e74dd9ec7937ef77d5bf4a0276a44bfcba7bf232898353c",
      "bundle_path_digest": "sha256:4cf65addf36a34de4e74dd9ec7937ef77d5bf4a0276a44bfcba7bf232898353c",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-09-20T17:12:51.878000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.6.4-beta.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-09-20T17:12:51.878000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "name": "kubeturbo-operator-2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172-annotation"
        },
        {
          "digest": "sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:4accb71d2a86b9d292f62a50f70c022c358e5bf4fa851be5b931a29cc54ecd24",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:4accb71d2a86b9d292f62a50f70c022c358e5bf4fa851be5b931a29cc54ecd24",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "8.6.4-beta.1",
      "version_original": "8.6.4-beta.1"
    },
    {
      "_id": "6329f4bc8a97b22f4fc18043",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:4cf65addf36a34de4e74dd9ec7937ef77d5bf4a0276a44bfcba7bf232898353c",
      "bundle_path_digest": "sha256:4cf65addf36a34de4e74dd9ec7937ef77d5bf4a0276a44bfcba7bf232898353c",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-09-20T17:13:32.713000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.6.4-beta.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-09-20T17:13:32.713000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "name": "kubeturbo-operator-2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172-annotation"
        },
        {
          "digest": "sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:4accb71d2a86b9d292f62a50f70c022c358e5bf4fa851be5b931a29cc54ecd24",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:4accb71d2a86b9d292f62a50f70c022c358e5bf4fa851be5b931a29cc54ecd24",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "8.6.4-beta.1",
      "version_original": "8.6.4-beta.1"
    },
    {
      "_id": "6329f784787bb4d00dc9a27e",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:4cf65addf36a34de4e74dd9ec7937ef77d5bf4a0276a44bfcba7bf232898353c",
      "bundle_path_digest": "sha256:4cf65addf36a34de4e74dd9ec7937ef77d5bf4a0276a44bfcba7bf232898353c",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "beta",
      "creation_date": "2022-09-20T17:25:24.351000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.6.4-beta.1",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": false,
      "last_update_date": "2022-09-20T17:25:24.351000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1alpha1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "plural": "kubeturbos",
          "version": "v1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "name": "kubeturbo-operator-2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172-annotation"
        },
        {
          "digest": "sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:2365dee35d493041db2e00900bd8461433e6f598e1cb8c5cbaf9368543d78172",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:4accb71d2a86b9d292f62a50f70c022c358e5bf4fa851be5b931a29cc54ecd24",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:4accb71d2a86b9d292f62a50f70c022c358e5bf4fa851be5b931a29cc54ecd24",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "8.6.4-beta.1",
      "version_original": "8.6.4-beta.1"
    },
    {
      "_id": "632acf6a2bdd76944b8e5192",
      "alm_examples": [
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupPolicy",
          "metadata": {
            "name": "atlasbackuppolicy-sample"
          },
          "spec": {
            "id": "1",
            "items": [
              {
                "frequencyInterval": 6,
                "frequencyType": "WEEKLY",
                "id": "2",
                "retentionUnit": "DAYS",
                "retentionValue": 6
              }
            ]
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupSchedule",
          "metadata": {
            "name": "atlasbackupschedule-sample"
          },
          "spec": {
            "autoExportEnabled": true,
            "policies": [
              {
                "name": "atlas-default-backuppolicy",
                "namespace": "mongodb-atlas-system"
              },
              {
                "name": "atlas-default-backuppolicy2",
                "namespace": "mongodb-atlas-system"
              }
            ],
            "referenceHourOfDay": 10,
            "referenceMinuteOfHour": 10,
            "restoreWindowDays": 2
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDatabaseUser",
          "metadata": {
            "name": "my-database-user"
          },
          "spec": {
            "databaseName": "admin",
            "passwordSecretRef": {
              "name": "my-database-user-password"
            },
            "projectRef": {
              "name": "my-project"
            },
            "roles": [
              {
                "databaseName": "admin",
                "roleName": "readWriteAnyDatabase"
              }
            ],
            "username": "david"
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDeployment",
          "metadata": {
            "name": "my-atlas-deployment"
          },
          "spec": {
            "deploymentSpec": {
              "name": "test-deployment",
              "providerSettings": {
                "instanceSizeName": "M10",
                "providerName": "AWS",
                "regionName": "US_EAST_1"
              }
            },
            "projectRef": {
              "name": "my-project"
            }
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasProject",
          "metadata": {
            "name": "my-project"
          },
          "spec": {
            "name": "Test Atlas Operator Project",
            "projectIpAccessList": [
              {
                "comment": "IP address for Application Server A",
                "ipAddress": "192.0.2.15"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator-bundle@sha256:2549eb2faa7bca746da915f9a15a6febcdd8605a0b2c6ae59d4481edcd8f8906",
      "bundle_path_digest": "sha256:2549eb2faa7bca746da915f9a15a6febcdd8605a0b2c6ae59d4481edcd8f8906",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-21T08:46:34.797000+00:00",
      "csv_description": "The MongoDB Atlas Operator provides a native integration between the Kubernetes orchestration platform and MongoDB Atlas \u2014\nthe only multi-cloud document database service that gives you the versatility you need to build sophisticated and resilient applications that can adapt to changing customer demands and market trends.\n\n> Current Status: *Beta*. The Operator gives users the ability to provision\n> Atlas projects, clusters and database users using Kubernetes Specifications and bind connection information\n> into applications deployed to Kubernetes.\n\n## Quick Start guide\n### Step 1. Deploy Kubernetes operator by clicking Install button.\n\n### Step 2. Create Atlas Cluster\n\n**1.** Create an Atlas API Key Secret\nIn order to work with the Atlas Operator you need to provide [authentication information](https://docs.atlas.mongodb.com/configure-api-access)\n to allow the Atlas Operator to communicate with Atlas API. Once you have generated a Public and Private key in Atlas, you can create a Kuberentes Secret with:\n```\nkubectl create secret generic mongodb-atlas-operator-api-key \\\n         --from-literal=\"orgId=<the_atlas_organization_id>\" \\\n         --from-literal=\"publicApiKey=<the_atlas_api_public_key>\" \\\n         --from-literal=\"privateApiKey=<the_atlas_api_private_key>\" \\\n         -n openshift-operators\n```\n(Note, that you should use the namespace where the Operator was installed - it's `openshift-operators` by default)\n\n**2.** Create an `AtlasProject` Custom Resource\n\nThe `AtlasProject` CustomResource represents Atlas Projects in our Kubernetes cluster. You need to specify\n`projectIpAccessList` with the IP addresses or CIDR blocks of any hosts that will connect to the Atlas Cluster.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\nspec:\n  name: Test Atlas Operator Project\n  projectIpAccessList:\n    - ipAddress: \"192.0.2.15\"\n      comment: \"IP address for Application Server A\"\n    - ipAddress: \"203.0.113.0/24\"\n      comment: \"CIDR block for Application Server B - D\"\n```\n**3.** Create an `AtlasDeployment` Custom Resource.\nThe example below is a minimal configuration to create an M10 Atlas cluster in the AWS US East region. For a full list of properties, check\n`atlasclusters.atlas.mongodb.com` [CRD specification](config/crd/bases/atlas.mongodb.com_atlasclusters.yaml)):\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: my-atlas-cluster\nspec:\n  name: \"Test-cluster\"\n  projectRef:\n    name: my-project\n  providerSettings:\n    instanceSizeName: M10\n    providerName: AWS\n    regionName: US_EAST_1\n```\n\n**4.** Create a database user password Kubernetes Secret\nThe Secret must be created in the same namespace as the `AtlasDeployment` and `AtlasProject` were created.\n```\nkubectl create secret generic the-user-password --from-literal=\"password=P@@sword%\"\n```\n\n**5.** Create an `AtlasDatabaseUser` Custom Resource\n\nIn order to connect to an Atlas Cluster the database user needs to be created. `AtlasDatabaseUser` resource should reference\nthe password Kubernetes Secret created in the previous step.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDatabaseUser\nmetadata:\n  name: my-database-user\nspec:\n  roles:\n    - roleName: \"readWriteAnyDatabase\"\n      databaseName: \"admin\"\n  projectRef:\n    name: my-project\n  username: theuser\n  passwordSecretRef:\n    name: the-user-password\n```\n**6.** Wait for the `AtlasDatabaseUser` Custom Resource to be ready\n\nWait until the AtlasDatabaseUser resource gets to \"ready\" status (it will wait until the cluster is created that may take around 10 minutes):\n```\nkubectl get atlasdatabaseusers my-database-user -o=jsonpath='{.status.conditions[?(@.type==\"Ready\")].status}'\nTrue\n```\n### Step 3. Connect your application to the Atlas Cluster\n\nThe Atlas Operator will create a Kubernetes Secret with the information necessary to connect to the Atlas Cluster created\nin the previous step. An application in the same Kubernetes Cluster can mount and use the Secret:\n\n```\n...\ncontainers:\n      - name: test-app\n        env:\n         - name: \"CONNECTION_STRING\"\n           valueFrom:\n             secretKeyRef:\n               name: test-atlas-operator-project-test-cluster-theuser\n               key: connectionStringStandardSrv\n\n```\n",
      "csv_display_name": "MongoDB Atlas Operator",
      "csv_metadata_description": "The MongoDB Atlas Kubernetes Operator enables easy management of Clusters in MongoDB Atlas",
      "csv_name": "mongodb-atlas-kubernetes.v1.3.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-21T08:46:34.797000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "mongodb-atlas-kubernetes",
      "provided_apis": [
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupPolicy",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupSchedule",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDatabaseUser",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDeployment",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasProject",
          "version": "v1"
        }
      ],
      "provider": "MongoDB, Inc",
      "related_images": [
        {
          "digest": "sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "name": "mongodb-atlas-kubernetes-operator-e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02-annotation"
        },
        {
          "digest": "sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "1.3.0",
      "version_original": "1.3.0"
    },
    {
      "_id": "632acfae9bb8b51dd35677cd",
      "alm_examples": [
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupPolicy",
          "metadata": {
            "name": "atlasbackuppolicy-sample"
          },
          "spec": {
            "id": "1",
            "items": [
              {
                "frequencyInterval": 6,
                "frequencyType": "WEEKLY",
                "id": "2",
                "retentionUnit": "DAYS",
                "retentionValue": 6
              }
            ]
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupSchedule",
          "metadata": {
            "name": "atlasbackupschedule-sample"
          },
          "spec": {
            "autoExportEnabled": true,
            "policies": [
              {
                "name": "atlas-default-backuppolicy",
                "namespace": "mongodb-atlas-system"
              },
              {
                "name": "atlas-default-backuppolicy2",
                "namespace": "mongodb-atlas-system"
              }
            ],
            "referenceHourOfDay": 10,
            "referenceMinuteOfHour": 10,
            "restoreWindowDays": 2
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDatabaseUser",
          "metadata": {
            "name": "my-database-user"
          },
          "spec": {
            "databaseName": "admin",
            "passwordSecretRef": {
              "name": "my-database-user-password"
            },
            "projectRef": {
              "name": "my-project"
            },
            "roles": [
              {
                "databaseName": "admin",
                "roleName": "readWriteAnyDatabase"
              }
            ],
            "username": "david"
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDeployment",
          "metadata": {
            "name": "my-atlas-deployment"
          },
          "spec": {
            "deploymentSpec": {
              "name": "test-deployment",
              "providerSettings": {
                "instanceSizeName": "M10",
                "providerName": "AWS",
                "regionName": "US_EAST_1"
              }
            },
            "projectRef": {
              "name": "my-project"
            }
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasProject",
          "metadata": {
            "name": "my-project"
          },
          "spec": {
            "name": "Test Atlas Operator Project",
            "projectIpAccessList": [
              {
                "comment": "IP address for Application Server A",
                "ipAddress": "192.0.2.15"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator-bundle@sha256:2549eb2faa7bca746da915f9a15a6febcdd8605a0b2c6ae59d4481edcd8f8906",
      "bundle_path_digest": "sha256:2549eb2faa7bca746da915f9a15a6febcdd8605a0b2c6ae59d4481edcd8f8906",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-21T08:47:42.076000+00:00",
      "csv_description": "The MongoDB Atlas Operator provides a native integration between the Kubernetes orchestration platform and MongoDB Atlas \u2014\nthe only multi-cloud document database service that gives you the versatility you need to build sophisticated and resilient applications that can adapt to changing customer demands and market trends.\n\n> Current Status: *Beta*. The Operator gives users the ability to provision\n> Atlas projects, clusters and database users using Kubernetes Specifications and bind connection information\n> into applications deployed to Kubernetes.\n\n## Quick Start guide\n### Step 1. Deploy Kubernetes operator by clicking Install button.\n\n### Step 2. Create Atlas Cluster\n\n**1.** Create an Atlas API Key Secret\nIn order to work with the Atlas Operator you need to provide [authentication information](https://docs.atlas.mongodb.com/configure-api-access)\n to allow the Atlas Operator to communicate with Atlas API. Once you have generated a Public and Private key in Atlas, you can create a Kuberentes Secret with:\n```\nkubectl create secret generic mongodb-atlas-operator-api-key \\\n         --from-literal=\"orgId=<the_atlas_organization_id>\" \\\n         --from-literal=\"publicApiKey=<the_atlas_api_public_key>\" \\\n         --from-literal=\"privateApiKey=<the_atlas_api_private_key>\" \\\n         -n openshift-operators\n```\n(Note, that you should use the namespace where the Operator was installed - it's `openshift-operators` by default)\n\n**2.** Create an `AtlasProject` Custom Resource\n\nThe `AtlasProject` CustomResource represents Atlas Projects in our Kubernetes cluster. You need to specify\n`projectIpAccessList` with the IP addresses or CIDR blocks of any hosts that will connect to the Atlas Cluster.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\nspec:\n  name: Test Atlas Operator Project\n  projectIpAccessList:\n    - ipAddress: \"192.0.2.15\"\n      comment: \"IP address for Application Server A\"\n    - ipAddress: \"203.0.113.0/24\"\n      comment: \"CIDR block for Application Server B - D\"\n```\n**3.** Create an `AtlasDeployment` Custom Resource.\nThe example below is a minimal configuration to create an M10 Atlas cluster in the AWS US East region. For a full list of properties, check\n`atlasclusters.atlas.mongodb.com` [CRD specification](config/crd/bases/atlas.mongodb.com_atlasclusters.yaml)):\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: my-atlas-cluster\nspec:\n  name: \"Test-cluster\"\n  projectRef:\n    name: my-project\n  providerSettings:\n    instanceSizeName: M10\n    providerName: AWS\n    regionName: US_EAST_1\n```\n\n**4.** Create a database user password Kubernetes Secret\nThe Secret must be created in the same namespace as the `AtlasDeployment` and `AtlasProject` were created.\n```\nkubectl create secret generic the-user-password --from-literal=\"password=P@@sword%\"\n```\n\n**5.** Create an `AtlasDatabaseUser` Custom Resource\n\nIn order to connect to an Atlas Cluster the database user needs to be created. `AtlasDatabaseUser` resource should reference\nthe password Kubernetes Secret created in the previous step.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDatabaseUser\nmetadata:\n  name: my-database-user\nspec:\n  roles:\n    - roleName: \"readWriteAnyDatabase\"\n      databaseName: \"admin\"\n  projectRef:\n    name: my-project\n  username: theuser\n  passwordSecretRef:\n    name: the-user-password\n```\n**6.** Wait for the `AtlasDatabaseUser` Custom Resource to be ready\n\nWait until the AtlasDatabaseUser resource gets to \"ready\" status (it will wait until the cluster is created that may take around 10 minutes):\n```\nkubectl get atlasdatabaseusers my-database-user -o=jsonpath='{.status.conditions[?(@.type==\"Ready\")].status}'\nTrue\n```\n### Step 3. Connect your application to the Atlas Cluster\n\nThe Atlas Operator will create a Kubernetes Secret with the information necessary to connect to the Atlas Cluster created\nin the previous step. An application in the same Kubernetes Cluster can mount and use the Secret:\n\n```\n...\ncontainers:\n      - name: test-app\n        env:\n         - name: \"CONNECTION_STRING\"\n           valueFrom:\n             secretKeyRef:\n               name: test-atlas-operator-project-test-cluster-theuser\n               key: connectionStringStandardSrv\n\n```\n",
      "csv_display_name": "MongoDB Atlas Operator",
      "csv_metadata_description": "The MongoDB Atlas Kubernetes Operator enables easy management of Clusters in MongoDB Atlas",
      "csv_name": "mongodb-atlas-kubernetes.v1.3.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-21T08:47:42.076000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "mongodb-atlas-kubernetes",
      "provided_apis": [
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDeployment",
          "plural": "atlasdeployments",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasProject",
          "plural": "atlasprojects",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupPolicy",
          "plural": "atlasbackuppolicies",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupSchedule",
          "plural": "atlasbackupschedules",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDatabaseUser",
          "plural": "atlasdatabaseusers",
          "version": "v1"
        }
      ],
      "provider": "MongoDB, Inc",
      "related_images": [
        {
          "digest": "sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "name": "mongodb-atlas-kubernetes-operator-e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02-annotation"
        },
        {
          "digest": "sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "1.3.0",
      "version_original": "1.3.0"
    },
    {
      "_id": "632acfbd8a97b22f4fc1aad7",
      "alm_examples": [
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupPolicy",
          "metadata": {
            "name": "atlasbackuppolicy-sample"
          },
          "spec": {
            "id": "1",
            "items": [
              {
                "frequencyInterval": 6,
                "frequencyType": "WEEKLY",
                "id": "2",
                "retentionUnit": "DAYS",
                "retentionValue": 6
              }
            ]
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupSchedule",
          "metadata": {
            "name": "atlasbackupschedule-sample"
          },
          "spec": {
            "autoExportEnabled": true,
            "policies": [
              {
                "name": "atlas-default-backuppolicy",
                "namespace": "mongodb-atlas-system"
              },
              {
                "name": "atlas-default-backuppolicy2",
                "namespace": "mongodb-atlas-system"
              }
            ],
            "referenceHourOfDay": 10,
            "referenceMinuteOfHour": 10,
            "restoreWindowDays": 2
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDatabaseUser",
          "metadata": {
            "name": "my-database-user"
          },
          "spec": {
            "databaseName": "admin",
            "passwordSecretRef": {
              "name": "my-database-user-password"
            },
            "projectRef": {
              "name": "my-project"
            },
            "roles": [
              {
                "databaseName": "admin",
                "roleName": "readWriteAnyDatabase"
              }
            ],
            "username": "david"
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDeployment",
          "metadata": {
            "name": "my-atlas-deployment"
          },
          "spec": {
            "deploymentSpec": {
              "name": "test-deployment",
              "providerSettings": {
                "instanceSizeName": "M10",
                "providerName": "AWS",
                "regionName": "US_EAST_1"
              }
            },
            "projectRef": {
              "name": "my-project"
            }
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasProject",
          "metadata": {
            "name": "my-project"
          },
          "spec": {
            "name": "Test Atlas Operator Project",
            "projectIpAccessList": [
              {
                "comment": "IP address for Application Server A",
                "ipAddress": "192.0.2.15"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator-bundle@sha256:2549eb2faa7bca746da915f9a15a6febcdd8605a0b2c6ae59d4481edcd8f8906",
      "bundle_path_digest": "sha256:2549eb2faa7bca746da915f9a15a6febcdd8605a0b2c6ae59d4481edcd8f8906",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-21T08:47:57.667000+00:00",
      "csv_description": "The MongoDB Atlas Operator provides a native integration between the Kubernetes orchestration platform and MongoDB Atlas \u2014\nthe only multi-cloud document database service that gives you the versatility you need to build sophisticated and resilient applications that can adapt to changing customer demands and market trends.\n\n> Current Status: *Beta*. The Operator gives users the ability to provision\n> Atlas projects, clusters and database users using Kubernetes Specifications and bind connection information\n> into applications deployed to Kubernetes.\n\n## Quick Start guide\n### Step 1. Deploy Kubernetes operator by clicking Install button.\n\n### Step 2. Create Atlas Cluster\n\n**1.** Create an Atlas API Key Secret\nIn order to work with the Atlas Operator you need to provide [authentication information](https://docs.atlas.mongodb.com/configure-api-access)\n to allow the Atlas Operator to communicate with Atlas API. Once you have generated a Public and Private key in Atlas, you can create a Kuberentes Secret with:\n```\nkubectl create secret generic mongodb-atlas-operator-api-key \\\n         --from-literal=\"orgId=<the_atlas_organization_id>\" \\\n         --from-literal=\"publicApiKey=<the_atlas_api_public_key>\" \\\n         --from-literal=\"privateApiKey=<the_atlas_api_private_key>\" \\\n         -n openshift-operators\n```\n(Note, that you should use the namespace where the Operator was installed - it's `openshift-operators` by default)\n\n**2.** Create an `AtlasProject` Custom Resource\n\nThe `AtlasProject` CustomResource represents Atlas Projects in our Kubernetes cluster. You need to specify\n`projectIpAccessList` with the IP addresses or CIDR blocks of any hosts that will connect to the Atlas Cluster.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\nspec:\n  name: Test Atlas Operator Project\n  projectIpAccessList:\n    - ipAddress: \"192.0.2.15\"\n      comment: \"IP address for Application Server A\"\n    - ipAddress: \"203.0.113.0/24\"\n      comment: \"CIDR block for Application Server B - D\"\n```\n**3.** Create an `AtlasDeployment` Custom Resource.\nThe example below is a minimal configuration to create an M10 Atlas cluster in the AWS US East region. For a full list of properties, check\n`atlasclusters.atlas.mongodb.com` [CRD specification](config/crd/bases/atlas.mongodb.com_atlasclusters.yaml)):\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: my-atlas-cluster\nspec:\n  name: \"Test-cluster\"\n  projectRef:\n    name: my-project\n  providerSettings:\n    instanceSizeName: M10\n    providerName: AWS\n    regionName: US_EAST_1\n```\n\n**4.** Create a database user password Kubernetes Secret\nThe Secret must be created in the same namespace as the `AtlasDeployment` and `AtlasProject` were created.\n```\nkubectl create secret generic the-user-password --from-literal=\"password=P@@sword%\"\n```\n\n**5.** Create an `AtlasDatabaseUser` Custom Resource\n\nIn order to connect to an Atlas Cluster the database user needs to be created. `AtlasDatabaseUser` resource should reference\nthe password Kubernetes Secret created in the previous step.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDatabaseUser\nmetadata:\n  name: my-database-user\nspec:\n  roles:\n    - roleName: \"readWriteAnyDatabase\"\n      databaseName: \"admin\"\n  projectRef:\n    name: my-project\n  username: theuser\n  passwordSecretRef:\n    name: the-user-password\n```\n**6.** Wait for the `AtlasDatabaseUser` Custom Resource to be ready\n\nWait until the AtlasDatabaseUser resource gets to \"ready\" status (it will wait until the cluster is created that may take around 10 minutes):\n```\nkubectl get atlasdatabaseusers my-database-user -o=jsonpath='{.status.conditions[?(@.type==\"Ready\")].status}'\nTrue\n```\n### Step 3. Connect your application to the Atlas Cluster\n\nThe Atlas Operator will create a Kubernetes Secret with the information necessary to connect to the Atlas Cluster created\nin the previous step. An application in the same Kubernetes Cluster can mount and use the Secret:\n\n```\n...\ncontainers:\n      - name: test-app\n        env:\n         - name: \"CONNECTION_STRING\"\n           valueFrom:\n             secretKeyRef:\n               name: test-atlas-operator-project-test-cluster-theuser\n               key: connectionStringStandardSrv\n\n```\n",
      "csv_display_name": "MongoDB Atlas Operator",
      "csv_metadata_description": "The MongoDB Atlas Kubernetes Operator enables easy management of Clusters in MongoDB Atlas",
      "csv_name": "mongodb-atlas-kubernetes.v1.3.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-21T08:47:57.667000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "mongodb-atlas-kubernetes",
      "provided_apis": [
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupPolicy",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupSchedule",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDatabaseUser",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDeployment",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasProject",
          "version": "v1"
        }
      ],
      "provider": "MongoDB, Inc",
      "related_images": [
        {
          "digest": "sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "name": "mongodb-atlas-kubernetes-operator-e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02-annotation"
        },
        {
          "digest": "sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "1.3.0",
      "version_original": "1.3.0"
    },
    {
      "_id": "632acfc68a97b22f4fc1aad9",
      "alm_examples": [
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupPolicy",
          "metadata": {
            "name": "atlasbackuppolicy-sample"
          },
          "spec": {
            "id": "1",
            "items": [
              {
                "frequencyInterval": 6,
                "frequencyType": "WEEKLY",
                "id": "2",
                "retentionUnit": "DAYS",
                "retentionValue": 6
              }
            ]
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupSchedule",
          "metadata": {
            "name": "atlasbackupschedule-sample"
          },
          "spec": {
            "autoExportEnabled": true,
            "policies": [
              {
                "name": "atlas-default-backuppolicy",
                "namespace": "mongodb-atlas-system"
              },
              {
                "name": "atlas-default-backuppolicy2",
                "namespace": "mongodb-atlas-system"
              }
            ],
            "referenceHourOfDay": 10,
            "referenceMinuteOfHour": 10,
            "restoreWindowDays": 2
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDatabaseUser",
          "metadata": {
            "name": "my-database-user"
          },
          "spec": {
            "databaseName": "admin",
            "passwordSecretRef": {
              "name": "my-database-user-password"
            },
            "projectRef": {
              "name": "my-project"
            },
            "roles": [
              {
                "databaseName": "admin",
                "roleName": "readWriteAnyDatabase"
              }
            ],
            "username": "david"
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDeployment",
          "metadata": {
            "name": "my-atlas-deployment"
          },
          "spec": {
            "deploymentSpec": {
              "name": "test-deployment",
              "providerSettings": {
                "instanceSizeName": "M10",
                "providerName": "AWS",
                "regionName": "US_EAST_1"
              }
            },
            "projectRef": {
              "name": "my-project"
            }
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasProject",
          "metadata": {
            "name": "my-project"
          },
          "spec": {
            "name": "Test Atlas Operator Project",
            "projectIpAccessList": [
              {
                "comment": "IP address for Application Server A",
                "ipAddress": "192.0.2.15"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator-bundle@sha256:2549eb2faa7bca746da915f9a15a6febcdd8605a0b2c6ae59d4481edcd8f8906",
      "bundle_path_digest": "sha256:2549eb2faa7bca746da915f9a15a6febcdd8605a0b2c6ae59d4481edcd8f8906",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-21T08:48:06.042000+00:00",
      "csv_description": "The MongoDB Atlas Operator provides a native integration between the Kubernetes orchestration platform and MongoDB Atlas \u2014\nthe only multi-cloud document database service that gives you the versatility you need to build sophisticated and resilient applications that can adapt to changing customer demands and market trends.\n\n> Current Status: *Beta*. The Operator gives users the ability to provision\n> Atlas projects, clusters and database users using Kubernetes Specifications and bind connection information\n> into applications deployed to Kubernetes.\n\n## Quick Start guide\n### Step 1. Deploy Kubernetes operator by clicking Install button.\n\n### Step 2. Create Atlas Cluster\n\n**1.** Create an Atlas API Key Secret\nIn order to work with the Atlas Operator you need to provide [authentication information](https://docs.atlas.mongodb.com/configure-api-access)\n to allow the Atlas Operator to communicate with Atlas API. Once you have generated a Public and Private key in Atlas, you can create a Kuberentes Secret with:\n```\nkubectl create secret generic mongodb-atlas-operator-api-key \\\n         --from-literal=\"orgId=<the_atlas_organization_id>\" \\\n         --from-literal=\"publicApiKey=<the_atlas_api_public_key>\" \\\n         --from-literal=\"privateApiKey=<the_atlas_api_private_key>\" \\\n         -n openshift-operators\n```\n(Note, that you should use the namespace where the Operator was installed - it's `openshift-operators` by default)\n\n**2.** Create an `AtlasProject` Custom Resource\n\nThe `AtlasProject` CustomResource represents Atlas Projects in our Kubernetes cluster. You need to specify\n`projectIpAccessList` with the IP addresses or CIDR blocks of any hosts that will connect to the Atlas Cluster.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\nspec:\n  name: Test Atlas Operator Project\n  projectIpAccessList:\n    - ipAddress: \"192.0.2.15\"\n      comment: \"IP address for Application Server A\"\n    - ipAddress: \"203.0.113.0/24\"\n      comment: \"CIDR block for Application Server B - D\"\n```\n**3.** Create an `AtlasDeployment` Custom Resource.\nThe example below is a minimal configuration to create an M10 Atlas cluster in the AWS US East region. For a full list of properties, check\n`atlasclusters.atlas.mongodb.com` [CRD specification](config/crd/bases/atlas.mongodb.com_atlasclusters.yaml)):\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: my-atlas-cluster\nspec:\n  name: \"Test-cluster\"\n  projectRef:\n    name: my-project\n  providerSettings:\n    instanceSizeName: M10\n    providerName: AWS\n    regionName: US_EAST_1\n```\n\n**4.** Create a database user password Kubernetes Secret\nThe Secret must be created in the same namespace as the `AtlasDeployment` and `AtlasProject` were created.\n```\nkubectl create secret generic the-user-password --from-literal=\"password=P@@sword%\"\n```\n\n**5.** Create an `AtlasDatabaseUser` Custom Resource\n\nIn order to connect to an Atlas Cluster the database user needs to be created. `AtlasDatabaseUser` resource should reference\nthe password Kubernetes Secret created in the previous step.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDatabaseUser\nmetadata:\n  name: my-database-user\nspec:\n  roles:\n    - roleName: \"readWriteAnyDatabase\"\n      databaseName: \"admin\"\n  projectRef:\n    name: my-project\n  username: theuser\n  passwordSecretRef:\n    name: the-user-password\n```\n**6.** Wait for the `AtlasDatabaseUser` Custom Resource to be ready\n\nWait until the AtlasDatabaseUser resource gets to \"ready\" status (it will wait until the cluster is created that may take around 10 minutes):\n```\nkubectl get atlasdatabaseusers my-database-user -o=jsonpath='{.status.conditions[?(@.type==\"Ready\")].status}'\nTrue\n```\n### Step 3. Connect your application to the Atlas Cluster\n\nThe Atlas Operator will create a Kubernetes Secret with the information necessary to connect to the Atlas Cluster created\nin the previous step. An application in the same Kubernetes Cluster can mount and use the Secret:\n\n```\n...\ncontainers:\n      - name: test-app\n        env:\n         - name: \"CONNECTION_STRING\"\n           valueFrom:\n             secretKeyRef:\n               name: test-atlas-operator-project-test-cluster-theuser\n               key: connectionStringStandardSrv\n\n```\n",
      "csv_display_name": "MongoDB Atlas Operator",
      "csv_metadata_description": "The MongoDB Atlas Kubernetes Operator enables easy management of Clusters in MongoDB Atlas",
      "csv_name": "mongodb-atlas-kubernetes.v1.3.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-21T08:48:06.042000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "mongodb-atlas-kubernetes",
      "provided_apis": [
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupSchedule",
          "plural": "atlasbackupschedules",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDatabaseUser",
          "plural": "atlasdatabaseusers",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDeployment",
          "plural": "atlasdeployments",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasProject",
          "plural": "atlasprojects",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupPolicy",
          "plural": "atlasbackuppolicies",
          "version": "v1"
        }
      ],
      "provider": "MongoDB, Inc",
      "related_images": [
        {
          "digest": "sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "name": "mongodb-atlas-kubernetes-operator-e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02-annotation"
        },
        {
          "digest": "sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "1.3.0",
      "version_original": "1.3.0"
    },
    {
      "_id": "632ad0698454bee1cb72dfe9",
      "alm_examples": [
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupPolicy",
          "metadata": {
            "name": "atlasbackuppolicy-sample"
          },
          "spec": {
            "id": "1",
            "items": [
              {
                "frequencyInterval": 6,
                "frequencyType": "WEEKLY",
                "id": "2",
                "retentionUnit": "DAYS",
                "retentionValue": 6
              }
            ]
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupSchedule",
          "metadata": {
            "name": "atlasbackupschedule-sample"
          },
          "spec": {
            "autoExportEnabled": true,
            "policies": [
              {
                "name": "atlas-default-backuppolicy",
                "namespace": "mongodb-atlas-system"
              },
              {
                "name": "atlas-default-backuppolicy2",
                "namespace": "mongodb-atlas-system"
              }
            ],
            "referenceHourOfDay": 10,
            "referenceMinuteOfHour": 10,
            "restoreWindowDays": 2
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDatabaseUser",
          "metadata": {
            "name": "my-database-user"
          },
          "spec": {
            "databaseName": "admin",
            "passwordSecretRef": {
              "name": "my-database-user-password"
            },
            "projectRef": {
              "name": "my-project"
            },
            "roles": [
              {
                "databaseName": "admin",
                "roleName": "readWriteAnyDatabase"
              }
            ],
            "username": "david"
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDeployment",
          "metadata": {
            "name": "my-atlas-deployment"
          },
          "spec": {
            "deploymentSpec": {
              "name": "test-deployment",
              "providerSettings": {
                "instanceSizeName": "M10",
                "providerName": "AWS",
                "regionName": "US_EAST_1"
              }
            },
            "projectRef": {
              "name": "my-project"
            }
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasProject",
          "metadata": {
            "name": "my-project"
          },
          "spec": {
            "name": "Test Atlas Operator Project",
            "projectIpAccessList": [
              {
                "comment": "IP address for Application Server A",
                "ipAddress": "192.0.2.15"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator-bundle@sha256:2549eb2faa7bca746da915f9a15a6febcdd8605a0b2c6ae59d4481edcd8f8906",
      "bundle_path_digest": "sha256:2549eb2faa7bca746da915f9a15a6febcdd8605a0b2c6ae59d4481edcd8f8906",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-21T08:50:49.487000+00:00",
      "csv_description": "The MongoDB Atlas Operator provides a native integration between the Kubernetes orchestration platform and MongoDB Atlas \u2014\nthe only multi-cloud document database service that gives you the versatility you need to build sophisticated and resilient applications that can adapt to changing customer demands and market trends.\n\n> Current Status: *Beta*. The Operator gives users the ability to provision\n> Atlas projects, clusters and database users using Kubernetes Specifications and bind connection information\n> into applications deployed to Kubernetes.\n\n## Quick Start guide\n### Step 1. Deploy Kubernetes operator by clicking Install button.\n\n### Step 2. Create Atlas Cluster\n\n**1.** Create an Atlas API Key Secret\nIn order to work with the Atlas Operator you need to provide [authentication information](https://docs.atlas.mongodb.com/configure-api-access)\n to allow the Atlas Operator to communicate with Atlas API. Once you have generated a Public and Private key in Atlas, you can create a Kuberentes Secret with:\n```\nkubectl create secret generic mongodb-atlas-operator-api-key \\\n         --from-literal=\"orgId=<the_atlas_organization_id>\" \\\n         --from-literal=\"publicApiKey=<the_atlas_api_public_key>\" \\\n         --from-literal=\"privateApiKey=<the_atlas_api_private_key>\" \\\n         -n openshift-operators\n```\n(Note, that you should use the namespace where the Operator was installed - it's `openshift-operators` by default)\n\n**2.** Create an `AtlasProject` Custom Resource\n\nThe `AtlasProject` CustomResource represents Atlas Projects in our Kubernetes cluster. You need to specify\n`projectIpAccessList` with the IP addresses or CIDR blocks of any hosts that will connect to the Atlas Cluster.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\nspec:\n  name: Test Atlas Operator Project\n  projectIpAccessList:\n    - ipAddress: \"192.0.2.15\"\n      comment: \"IP address for Application Server A\"\n    - ipAddress: \"203.0.113.0/24\"\n      comment: \"CIDR block for Application Server B - D\"\n```\n**3.** Create an `AtlasDeployment` Custom Resource.\nThe example below is a minimal configuration to create an M10 Atlas cluster in the AWS US East region. For a full list of properties, check\n`atlasclusters.atlas.mongodb.com` [CRD specification](config/crd/bases/atlas.mongodb.com_atlasclusters.yaml)):\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: my-atlas-cluster\nspec:\n  name: \"Test-cluster\"\n  projectRef:\n    name: my-project\n  providerSettings:\n    instanceSizeName: M10\n    providerName: AWS\n    regionName: US_EAST_1\n```\n\n**4.** Create a database user password Kubernetes Secret\nThe Secret must be created in the same namespace as the `AtlasDeployment` and `AtlasProject` were created.\n```\nkubectl create secret generic the-user-password --from-literal=\"password=P@@sword%\"\n```\n\n**5.** Create an `AtlasDatabaseUser` Custom Resource\n\nIn order to connect to an Atlas Cluster the database user needs to be created. `AtlasDatabaseUser` resource should reference\nthe password Kubernetes Secret created in the previous step.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDatabaseUser\nmetadata:\n  name: my-database-user\nspec:\n  roles:\n    - roleName: \"readWriteAnyDatabase\"\n      databaseName: \"admin\"\n  projectRef:\n    name: my-project\n  username: theuser\n  passwordSecretRef:\n    name: the-user-password\n```\n**6.** Wait for the `AtlasDatabaseUser` Custom Resource to be ready\n\nWait until the AtlasDatabaseUser resource gets to \"ready\" status (it will wait until the cluster is created that may take around 10 minutes):\n```\nkubectl get atlasdatabaseusers my-database-user -o=jsonpath='{.status.conditions[?(@.type==\"Ready\")].status}'\nTrue\n```\n### Step 3. Connect your application to the Atlas Cluster\n\nThe Atlas Operator will create a Kubernetes Secret with the information necessary to connect to the Atlas Cluster created\nin the previous step. An application in the same Kubernetes Cluster can mount and use the Secret:\n\n```\n...\ncontainers:\n      - name: test-app\n        env:\n         - name: \"CONNECTION_STRING\"\n           valueFrom:\n             secretKeyRef:\n               name: test-atlas-operator-project-test-cluster-theuser\n               key: connectionStringStandardSrv\n\n```\n",
      "csv_display_name": "MongoDB Atlas Operator",
      "csv_metadata_description": "The MongoDB Atlas Kubernetes Operator enables easy management of Clusters in MongoDB Atlas",
      "csv_name": "mongodb-atlas-kubernetes.v1.3.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-21T08:50:49.487000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "mongodb-atlas-kubernetes",
      "provided_apis": [
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasProject",
          "plural": "atlasprojects",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupPolicy",
          "plural": "atlasbackuppolicies",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupSchedule",
          "plural": "atlasbackupschedules",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDatabaseUser",
          "plural": "atlasdatabaseusers",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDeployment",
          "plural": "atlasdeployments",
          "version": "v1"
        }
      ],
      "provider": "MongoDB, Inc",
      "related_images": [
        {
          "digest": "sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "name": "mongodb-atlas-kubernetes-operator-e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02-annotation"
        },
        {
          "digest": "sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "1.3.0",
      "version_original": "1.3.0"
    },
    {
      "_id": "632ad3af5569e1b12a9422f4",
      "alm_examples": [
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupPolicy",
          "metadata": {
            "name": "atlasbackuppolicy-sample"
          },
          "spec": {
            "id": "1",
            "items": [
              {
                "frequencyInterval": 6,
                "frequencyType": "WEEKLY",
                "id": "2",
                "retentionUnit": "DAYS",
                "retentionValue": 6
              }
            ]
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupSchedule",
          "metadata": {
            "name": "atlasbackupschedule-sample"
          },
          "spec": {
            "autoExportEnabled": true,
            "policies": [
              {
                "name": "atlas-default-backuppolicy",
                "namespace": "mongodb-atlas-system"
              },
              {
                "name": "atlas-default-backuppolicy2",
                "namespace": "mongodb-atlas-system"
              }
            ],
            "referenceHourOfDay": 10,
            "referenceMinuteOfHour": 10,
            "restoreWindowDays": 2
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDatabaseUser",
          "metadata": {
            "name": "my-database-user"
          },
          "spec": {
            "databaseName": "admin",
            "passwordSecretRef": {
              "name": "my-database-user-password"
            },
            "projectRef": {
              "name": "my-project"
            },
            "roles": [
              {
                "databaseName": "admin",
                "roleName": "readWriteAnyDatabase"
              }
            ],
            "username": "david"
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDeployment",
          "metadata": {
            "name": "my-atlas-deployment"
          },
          "spec": {
            "deploymentSpec": {
              "name": "test-deployment",
              "providerSettings": {
                "instanceSizeName": "M10",
                "providerName": "AWS",
                "regionName": "US_EAST_1"
              }
            },
            "projectRef": {
              "name": "my-project"
            }
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasProject",
          "metadata": {
            "name": "my-project"
          },
          "spec": {
            "name": "Test Atlas Operator Project",
            "projectIpAccessList": [
              {
                "comment": "IP address for Application Server A",
                "ipAddress": "192.0.2.15"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator-bundle@sha256:2549eb2faa7bca746da915f9a15a6febcdd8605a0b2c6ae59d4481edcd8f8906",
      "bundle_path_digest": "sha256:2549eb2faa7bca746da915f9a15a6febcdd8605a0b2c6ae59d4481edcd8f8906",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-21T09:04:47.780000+00:00",
      "csv_description": "The MongoDB Atlas Operator provides a native integration between the Kubernetes orchestration platform and MongoDB Atlas \u2014\nthe only multi-cloud document database service that gives you the versatility you need to build sophisticated and resilient applications that can adapt to changing customer demands and market trends.\n\n> Current Status: *Beta*. The Operator gives users the ability to provision\n> Atlas projects, clusters and database users using Kubernetes Specifications and bind connection information\n> into applications deployed to Kubernetes.\n\n## Quick Start guide\n### Step 1. Deploy Kubernetes operator by clicking Install button.\n\n### Step 2. Create Atlas Cluster\n\n**1.** Create an Atlas API Key Secret\nIn order to work with the Atlas Operator you need to provide [authentication information](https://docs.atlas.mongodb.com/configure-api-access)\n to allow the Atlas Operator to communicate with Atlas API. Once you have generated a Public and Private key in Atlas, you can create a Kuberentes Secret with:\n```\nkubectl create secret generic mongodb-atlas-operator-api-key \\\n         --from-literal=\"orgId=<the_atlas_organization_id>\" \\\n         --from-literal=\"publicApiKey=<the_atlas_api_public_key>\" \\\n         --from-literal=\"privateApiKey=<the_atlas_api_private_key>\" \\\n         -n openshift-operators\n```\n(Note, that you should use the namespace where the Operator was installed - it's `openshift-operators` by default)\n\n**2.** Create an `AtlasProject` Custom Resource\n\nThe `AtlasProject` CustomResource represents Atlas Projects in our Kubernetes cluster. You need to specify\n`projectIpAccessList` with the IP addresses or CIDR blocks of any hosts that will connect to the Atlas Cluster.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\nspec:\n  name: Test Atlas Operator Project\n  projectIpAccessList:\n    - ipAddress: \"192.0.2.15\"\n      comment: \"IP address for Application Server A\"\n    - ipAddress: \"203.0.113.0/24\"\n      comment: \"CIDR block for Application Server B - D\"\n```\n**3.** Create an `AtlasDeployment` Custom Resource.\nThe example below is a minimal configuration to create an M10 Atlas cluster in the AWS US East region. For a full list of properties, check\n`atlasclusters.atlas.mongodb.com` [CRD specification](config/crd/bases/atlas.mongodb.com_atlasclusters.yaml)):\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: my-atlas-cluster\nspec:\n  name: \"Test-cluster\"\n  projectRef:\n    name: my-project\n  providerSettings:\n    instanceSizeName: M10\n    providerName: AWS\n    regionName: US_EAST_1\n```\n\n**4.** Create a database user password Kubernetes Secret\nThe Secret must be created in the same namespace as the `AtlasDeployment` and `AtlasProject` were created.\n```\nkubectl create secret generic the-user-password --from-literal=\"password=P@@sword%\"\n```\n\n**5.** Create an `AtlasDatabaseUser` Custom Resource\n\nIn order to connect to an Atlas Cluster the database user needs to be created. `AtlasDatabaseUser` resource should reference\nthe password Kubernetes Secret created in the previous step.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDatabaseUser\nmetadata:\n  name: my-database-user\nspec:\n  roles:\n    - roleName: \"readWriteAnyDatabase\"\n      databaseName: \"admin\"\n  projectRef:\n    name: my-project\n  username: theuser\n  passwordSecretRef:\n    name: the-user-password\n```\n**6.** Wait for the `AtlasDatabaseUser` Custom Resource to be ready\n\nWait until the AtlasDatabaseUser resource gets to \"ready\" status (it will wait until the cluster is created that may take around 10 minutes):\n```\nkubectl get atlasdatabaseusers my-database-user -o=jsonpath='{.status.conditions[?(@.type==\"Ready\")].status}'\nTrue\n```\n### Step 3. Connect your application to the Atlas Cluster\n\nThe Atlas Operator will create a Kubernetes Secret with the information necessary to connect to the Atlas Cluster created\nin the previous step. An application in the same Kubernetes Cluster can mount and use the Secret:\n\n```\n...\ncontainers:\n      - name: test-app\n        env:\n         - name: \"CONNECTION_STRING\"\n           valueFrom:\n             secretKeyRef:\n               name: test-atlas-operator-project-test-cluster-theuser\n               key: connectionStringStandardSrv\n\n```\n",
      "csv_display_name": "MongoDB Atlas Operator",
      "csv_metadata_description": "The MongoDB Atlas Kubernetes Operator enables easy management of Clusters in MongoDB Atlas",
      "csv_name": "mongodb-atlas-kubernetes.v1.3.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-21T09:04:47.780000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "mongodb-atlas-kubernetes",
      "provided_apis": [
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupSchedule",
          "plural": "atlasbackupschedules",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDatabaseUser",
          "plural": "atlasdatabaseusers",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDeployment",
          "plural": "atlasdeployments",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasProject",
          "plural": "atlasprojects",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupPolicy",
          "plural": "atlasbackuppolicies",
          "version": "v1"
        }
      ],
      "provider": "MongoDB, Inc",
      "related_images": [
        {
          "digest": "sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "name": "mongodb-atlas-kubernetes-operator-e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02-annotation"
        },
        {
          "digest": "sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "1.3.0",
      "version_original": "1.3.0"
    },
    {
      "_id": "632ad3b85569e1b12a9422f6",
      "alm_examples": [
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupPolicy",
          "metadata": {
            "name": "atlasbackuppolicy-sample"
          },
          "spec": {
            "id": "1",
            "items": [
              {
                "frequencyInterval": 6,
                "frequencyType": "WEEKLY",
                "id": "2",
                "retentionUnit": "DAYS",
                "retentionValue": 6
              }
            ]
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasBackupSchedule",
          "metadata": {
            "name": "atlasbackupschedule-sample"
          },
          "spec": {
            "autoExportEnabled": true,
            "policies": [
              {
                "name": "atlas-default-backuppolicy",
                "namespace": "mongodb-atlas-system"
              },
              {
                "name": "atlas-default-backuppolicy2",
                "namespace": "mongodb-atlas-system"
              }
            ],
            "referenceHourOfDay": 10,
            "referenceMinuteOfHour": 10,
            "restoreWindowDays": 2
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDatabaseUser",
          "metadata": {
            "name": "my-database-user"
          },
          "spec": {
            "databaseName": "admin",
            "passwordSecretRef": {
              "name": "my-database-user-password"
            },
            "projectRef": {
              "name": "my-project"
            },
            "roles": [
              {
                "databaseName": "admin",
                "roleName": "readWriteAnyDatabase"
              }
            ],
            "username": "david"
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasDeployment",
          "metadata": {
            "name": "my-atlas-deployment"
          },
          "spec": {
            "deploymentSpec": {
              "name": "test-deployment",
              "providerSettings": {
                "instanceSizeName": "M10",
                "providerName": "AWS",
                "regionName": "US_EAST_1"
              }
            },
            "projectRef": {
              "name": "my-project"
            }
          }
        },
        {
          "api_version": "atlas.mongodb.com/v1",
          "kind": "AtlasProject",
          "metadata": {
            "name": "my-project"
          },
          "spec": {
            "name": "Test Atlas Operator Project",
            "projectIpAccessList": [
              {
                "comment": "IP address for Application Server A",
                "ipAddress": "192.0.2.15"
              }
            ]
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator-bundle@sha256:2549eb2faa7bca746da915f9a15a6febcdd8605a0b2c6ae59d4481edcd8f8906",
      "bundle_path_digest": "sha256:2549eb2faa7bca746da915f9a15a6febcdd8605a0b2c6ae59d4481edcd8f8906",
      "capabilities": [
        "Full Lifecycle"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-21T09:04:56.719000+00:00",
      "csv_description": "The MongoDB Atlas Operator provides a native integration between the Kubernetes orchestration platform and MongoDB Atlas \u2014\nthe only multi-cloud document database service that gives you the versatility you need to build sophisticated and resilient applications that can adapt to changing customer demands and market trends.\n\n> Current Status: *Beta*. The Operator gives users the ability to provision\n> Atlas projects, clusters and database users using Kubernetes Specifications and bind connection information\n> into applications deployed to Kubernetes.\n\n## Quick Start guide\n### Step 1. Deploy Kubernetes operator by clicking Install button.\n\n### Step 2. Create Atlas Cluster\n\n**1.** Create an Atlas API Key Secret\nIn order to work with the Atlas Operator you need to provide [authentication information](https://docs.atlas.mongodb.com/configure-api-access)\n to allow the Atlas Operator to communicate with Atlas API. Once you have generated a Public and Private key in Atlas, you can create a Kuberentes Secret with:\n```\nkubectl create secret generic mongodb-atlas-operator-api-key \\\n         --from-literal=\"orgId=<the_atlas_organization_id>\" \\\n         --from-literal=\"publicApiKey=<the_atlas_api_public_key>\" \\\n         --from-literal=\"privateApiKey=<the_atlas_api_private_key>\" \\\n         -n openshift-operators\n```\n(Note, that you should use the namespace where the Operator was installed - it's `openshift-operators` by default)\n\n**2.** Create an `AtlasProject` Custom Resource\n\nThe `AtlasProject` CustomResource represents Atlas Projects in our Kubernetes cluster. You need to specify\n`projectIpAccessList` with the IP addresses or CIDR blocks of any hosts that will connect to the Atlas Cluster.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\nspec:\n  name: Test Atlas Operator Project\n  projectIpAccessList:\n    - ipAddress: \"192.0.2.15\"\n      comment: \"IP address for Application Server A\"\n    - ipAddress: \"203.0.113.0/24\"\n      comment: \"CIDR block for Application Server B - D\"\n```\n**3.** Create an `AtlasDeployment` Custom Resource.\nThe example below is a minimal configuration to create an M10 Atlas cluster in the AWS US East region. For a full list of properties, check\n`atlasclusters.atlas.mongodb.com` [CRD specification](config/crd/bases/atlas.mongodb.com_atlasclusters.yaml)):\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: my-atlas-cluster\nspec:\n  name: \"Test-cluster\"\n  projectRef:\n    name: my-project\n  providerSettings:\n    instanceSizeName: M10\n    providerName: AWS\n    regionName: US_EAST_1\n```\n\n**4.** Create a database user password Kubernetes Secret\nThe Secret must be created in the same namespace as the `AtlasDeployment` and `AtlasProject` were created.\n```\nkubectl create secret generic the-user-password --from-literal=\"password=P@@sword%\"\n```\n\n**5.** Create an `AtlasDatabaseUser` Custom Resource\n\nIn order to connect to an Atlas Cluster the database user needs to be created. `AtlasDatabaseUser` resource should reference\nthe password Kubernetes Secret created in the previous step.\n```\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDatabaseUser\nmetadata:\n  name: my-database-user\nspec:\n  roles:\n    - roleName: \"readWriteAnyDatabase\"\n      databaseName: \"admin\"\n  projectRef:\n    name: my-project\n  username: theuser\n  passwordSecretRef:\n    name: the-user-password\n```\n**6.** Wait for the `AtlasDatabaseUser` Custom Resource to be ready\n\nWait until the AtlasDatabaseUser resource gets to \"ready\" status (it will wait until the cluster is created that may take around 10 minutes):\n```\nkubectl get atlasdatabaseusers my-database-user -o=jsonpath='{.status.conditions[?(@.type==\"Ready\")].status}'\nTrue\n```\n### Step 3. Connect your application to the Atlas Cluster\n\nThe Atlas Operator will create a Kubernetes Secret with the information necessary to connect to the Atlas Cluster created\nin the previous step. An application in the same Kubernetes Cluster can mount and use the Secret:\n\n```\n...\ncontainers:\n      - name: test-app\n        env:\n         - name: \"CONNECTION_STRING\"\n           valueFrom:\n             secretKeyRef:\n               name: test-atlas-operator-project-test-cluster-theuser\n               key: connectionStringStandardSrv\n\n```\n",
      "csv_display_name": "MongoDB Atlas Operator",
      "csv_metadata_description": "The MongoDB Atlas Kubernetes Operator enables easy management of Clusters in MongoDB Atlas",
      "csv_name": "mongodb-atlas-kubernetes.v1.3.0",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": true,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-21T09:04:56.719000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "mongodb-atlas-kubernetes",
      "provided_apis": [
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDeployment",
          "plural": "atlasdeployments",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasProject",
          "plural": "atlasprojects",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupPolicy",
          "plural": "atlasbackuppolicies",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasBackupSchedule",
          "plural": "atlasbackupschedules",
          "version": "v1"
        },
        {
          "group": "atlas.mongodb.com",
          "kind": "AtlasDatabaseUser",
          "plural": "atlasdatabaseusers",
          "version": "v1"
        }
      ],
      "provider": "MongoDB, Inc",
      "related_images": [
        {
          "digest": "sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "name": "mongodb-atlas-kubernetes-operator-e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02-annotation"
        },
        {
          "digest": "sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "image": "registry.connect.redhat.com/mongodb/mongodb-atlas-kubernetes-operator@sha256:e1dce0f67768880258f8cfa856988ede9431f1d733d971e30d4b21aa55c08b02",
          "name": "manager"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "1.3.0",
      "version_original": "1.3.0"
    },
    {
      "_id": "632b21478a97b22f4fc1b7a6",
      "alm_examples": [
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaCsp",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "common": {
              "databaseSecret": {
                "key": "db-password",
                "name": "aqua-database-password"
              },
              "dbDiskSize": 10
            },
            "database": {
              "replicas": 1,
              "service": "ClusterIP"
            },
            "gateway": {
              "replicas": 1,
              "service": "ClusterIP"
            },
            "infra": {
              "namespace": "aqua",
              "requirements": true,
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            },
            "route": true,
            "runAsNonRoot": false,
            "server": {
              "replicas": 1,
              "service": "LoadBalancer"
            }
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaDatabase",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "common": {
              "splitDB": false
            },
            "deploy": {
              "replicas": 1,
              "service": "ClusterIP"
            },
            "diskSize": 10,
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            },
            "runAsNonRoot": false
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaEnforcer",
          "metadata": {
            "name": "aqua"
          },
          "spec": {
            "gateway": {
              "host": "aqua-gateway",
              "port": 8443
            },
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            },
            "runAsNonRoot": false,
            "token": "<<your-token>>"
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaKubeEnforcer",
          "metadata": {
            "name": "aqua"
          },
          "spec": {
            "config": {
              "cluster_name": "aqua-secure",
              "gateway_address": "aqua-gateway:8443",
              "imagePullSecret": "aqua-registry"
            },
            "deploy": {
              "service": "ClusterIP"
            },
            "infra": {
              "serviceAccount": "aqua-kube-enforcer-sa",
              "version": "2022.4"
            },
            "token": "<<KUBE_ENFORCER_GROUP_TOKEN>>"
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaGateway",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "common": {
              "databaseSecret": {
                "key": "<<EXTERNAL DB PASSWORD SECRET KEY>>",
                "name": "<<EXTERNAL DB PASSWORD SECRET NAME>>"
              },
              "splitDB": false
            },
            "deploy": {
              "replicas": 1,
              "service": "ClusterIP"
            },
            "externalDb": {
              "host": "<<EXTERNAL DB IP OR DNS>>",
              "password": "<<EXTERNAL DB PASSWORD (if secret does not exist)>>",
              "port": "<<EXTERNAL DB PORT>>",
              "username": "<<EXTERNAL DB USERNAME>>"
            },
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            }
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaScanner",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "deploy": {
              "replicas": 1
            },
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            },
            "login": {
              "host": "http://aqua-server:8080",
              "password": "<<YOUR AQUA USER PASSWORD>>",
              "username": "<<YOUR AQUA USER NAME>>"
            },
            "runAsNonRoot": false
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaServer",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "common": {
              "databaseSecret": {
                "key": "<<EXTERNAL DB PASSWORD SECRET KEY>>",
                "name": "<<EXTERNAL DB PASSWORD SECRET NAME>>"
              },
              "splitDB": false
            },
            "deploy": {
              "replicas": 1,
              "service": "LoadBalancer"
            },
            "externalDb": {
              "host": "<<EXTERNAL DB IP OR DNS>>",
              "password": "<<EXTERNAL DB PASSWORD (if secret does not exist)>>",
              "port": "<<EXTERNAL DB PORT>>",
              "username": "<<EXTERNAL DB USERNAME>>"
            },
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/aquasec/aquasec-operator-bundle@sha256:fe86c0b5a3b6da6d631a870971c178d71809fdca3e9e580a439080e33ec718fc",
      "bundle_path_digest": "sha256:fe86c0b5a3b6da6d631a870971c178d71809fdca3e9e580a439080e33ec718fc",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "2022.4",
      "creation_date": "2022-09-21T14:35:51.121000+00:00",
      "csv_description": "The Aqua Security Operator runs within an OpenShift cluster and provides a means to deploy and manage the Aqua Security cluster and components :\n* Server (aka \u201cconsole\u201d)\n* Database (for production environments we recommend to use an external database and not the Aqua default database)\n* Gateway\n* Enforcer (aka \u201cagent\u201d)\n* KubeEnforcer\n* Scanner\n* CSP (package that contains the Server, Database, and Gateway)\n\nUse the Aqua-Operator to\n* Deploy Aqua Security components on OpenShift\n* Scale up Aqua Security components with extra replicas\n* Assign metadata tags to Aqua Security components\n\nThe Aqua Operator provides a few [Custom Resources](https://github.com/aquasecurity/aqua-operator/tree/master/deploy/crds) for managing the Aqua CSP platform.\n\n## Prerequisites\n\nThere are only 3 prerequisites:\n1. Make sure you have a license and to obtain one, please contact Aqua Security at [Contact Us](mailto:cloudsales@aquasec.com).\n2. Create a new project for aqua\n\n    ```oc new-project aqua```\n\n3. Create the secret for Aqua Database password. If you are using an External Database, make sure you use those credentials.\nNOTE: This step is optional and you can specify the Database password when creating the CRs.\n\n    ```oc create secret generic aqua-database-password --from-literal=db-password=<password> -n aqua```\n\nPlease note that for the certified operator, the Docker registry secret is NOT needed. For the Red Hat certified operator, the Aqua application images are stored in the Red Hat Connect registry and will be automatically pulled by the Aqua operator.\n\n## Choosing the right channel\n\nChannels are a flexible publishing mechanism that offers you three different Aqua versions to deploy, at any point. These channels map to their respective Aqua versions, describing the maturity based on where they are in their lifecycle:\n* 4.6: This maps to the older version of Aqua 4.6.0\n* 5.0: This maps to the Aqua version 5.0.0\n* 5.3: This maps to the Aqua version 5.3.0\n* 6.0: This maps to the Aqua version 6.0.0\n* 6.2: This maps to the Aqua version 6.2.0\n* 6.5: This maps to the Aqua version 6.5.0\n* 2022.4: This is the latest and greatest version of Aqua (default)\n\n## Deploying the Aqua Operator\n\nAqua Operator follows an easy push button deployment that installs the operator in its own aqua namespace.\nPlease refer to the instructions [here](https://github.com/aquasecurity/aqua-operator/blob/2022.4.0/docs/DeployOpenShiftOperator.md).\n\n## Configuring the Aqua Operator\n\nOperators leverage CRDs as a configuration mechanism for the application. Aqua offers a number of CRDs that can be tweaked and configured as per your needs. Please refer to this [link](https://github.com/aquasecurity/aqua-operator/blob/6.2.0/docs/DeployOpenShiftOperator.md#aquacsp-crds) for Custom Resource examples for popular scenarios.\n\n## Support\n\nFor support please contact support@aquasec.com.",
      "csv_display_name": "Aqua Security Operator",
      "csv_metadata_description": "The Aqua Security Operator runs within a Openshift cluster and provides a means to deploy and manage Aqua Security cluster and components.",
      "csv_name": "aqua-operator.v2022.4.130",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-21T14:35:51.121000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.9",
      "organization": "certified-operators",
      "package": "aqua-operator-certified",
      "provided_apis": [
        {
          "group": "operator.aquasec.com",
          "kind": "AquaServer",
          "plural": "aquaservers",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaKubeEnforcer",
          "plural": "aquakubeenforcers",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaDatabase",
          "plural": "aquadatabases",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaGateway",
          "plural": "aquagateways",
          "version": "v1alpha1"
        },
        {
          "group": "aquasecurity.github.io",
          "kind": "ConfigAuditReport",
          "plural": "configauditreports",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaEnforcer",
          "plural": "aquaenforcers",
          "version": "v1alpha1"
        },
        {
          "group": "aquasecurity.github.io",
          "kind": "ClusterConfigAuditReport",
          "plural": "clusterconfigauditreports",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaCsp",
          "plural": "aquacsps",
          "version": "v1alpha1"
        },
        {
          "group": "aquasecurity.github.io",
          "kind": "AquaStarboard",
          "plural": "aquastarboards",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaScanner",
          "plural": "aquascanners",
          "version": "v1alpha1"
        }
      ],
      "provider": "Aqua Security, Inc.",
      "related_images": [
        {
          "digest": "sha256:be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080",
          "image": "registry.connect.redhat.com/aquasec/aquasec@sha256:be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080",
          "name": "aquasec-be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080-annotation"
        },
        {
          "digest": "sha256:be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080",
          "image": "registry.connect.redhat.com/aquasec/aquasec@sha256:be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080",
          "name": "aqua-operator"
        },
        {
          "digest": "sha256:2cb83939d45d32560b3499299c46f98d542a1f67f5378774e60c95d255a03768",
          "image": "registry.connect.redhat.com/aquasec/database@sha256:2cb83939d45d32560b3499299c46f98d542a1f67f5378774e60c95d255a03768",
          "name": "database"
        },
        {
          "digest": "sha256:6c03a0cb281e2151e688bd2c5245f6114377a4619bc9a0415358ccbd07c2807d",
          "image": "registry.connect.redhat.com/aquasec/gateway@sha256:6c03a0cb281e2151e688bd2c5245f6114377a4619bc9a0415358ccbd07c2807d",
          "name": "gateway"
        },
        {
          "digest": "sha256:e4ae759bfc2c11e210a77305d1b6c99c2d9b08db01b172d295b9cc18b59f6c11",
          "image": "registry.connect.redhat.com/aquasec/console@sha256:e4ae759bfc2c11e210a77305d1b6c99c2d9b08db01b172d295b9cc18b59f6c11",
          "name": "server"
        },
        {
          "digest": "sha256:848d4398a21380947a76047fb74690b333bbad0bc2bf9a312cea6dad0a5580dd",
          "image": "registry.connect.redhat.com/aquasec/scanner@sha256:848d4398a21380947a76047fb74690b333bbad0bc2bf9a312cea6dad0a5580dd",
          "name": "scanner"
        },
        {
          "digest": "sha256:09d6b9413077196cbd649b6e669b47555936d8751aa88eb4d4790b09860cb3a5",
          "image": "registry.connect.redhat.com/aquasec/enforcer@sha256:09d6b9413077196cbd649b6e669b47555936d8751aa88eb4d4790b09860cb3a5",
          "name": "enforcer"
        },
        {
          "digest": "sha256:42ba6232cd7c2d5b75164e6f86671634bdd4ab451766dec2b4b3bbd6874671ab",
          "image": "registry.connect.redhat.com/aquasec/kube-enforcer@sha256:42ba6232cd7c2d5b75164e6f86671634bdd4ab451766dec2b4b3bbd6874671ab",
          "name": "kube_enforcer"
        }
      ],
      "replaces": null,
      "skip_range": ">=1.0.2 <2022.4.130",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.9",
      "version": "2022.4.130",
      "version_original": "2022.4.130"
    },
    {
      "_id": "632b21726c4612132187f431",
      "alm_examples": [
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaCsp",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "common": {
              "databaseSecret": {
                "key": "db-password",
                "name": "aqua-database-password"
              },
              "dbDiskSize": 10
            },
            "database": {
              "replicas": 1,
              "service": "ClusterIP"
            },
            "gateway": {
              "replicas": 1,
              "service": "ClusterIP"
            },
            "infra": {
              "namespace": "aqua",
              "requirements": true,
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            },
            "route": true,
            "runAsNonRoot": false,
            "server": {
              "replicas": 1,
              "service": "LoadBalancer"
            }
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaDatabase",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "common": {
              "splitDB": false
            },
            "deploy": {
              "replicas": 1,
              "service": "ClusterIP"
            },
            "diskSize": 10,
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            },
            "runAsNonRoot": false
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaEnforcer",
          "metadata": {
            "name": "aqua"
          },
          "spec": {
            "gateway": {
              "host": "aqua-gateway",
              "port": 8443
            },
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            },
            "runAsNonRoot": false,
            "token": "<<your-token>>"
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaKubeEnforcer",
          "metadata": {
            "name": "aqua"
          },
          "spec": {
            "config": {
              "cluster_name": "aqua-secure",
              "gateway_address": "aqua-gateway:8443",
              "imagePullSecret": "aqua-registry"
            },
            "deploy": {
              "service": "ClusterIP"
            },
            "infra": {
              "serviceAccount": "aqua-kube-enforcer-sa",
              "version": "2022.4"
            },
            "token": "<<KUBE_ENFORCER_GROUP_TOKEN>>"
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaGateway",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "common": {
              "databaseSecret": {
                "key": "<<EXTERNAL DB PASSWORD SECRET KEY>>",
                "name": "<<EXTERNAL DB PASSWORD SECRET NAME>>"
              },
              "splitDB": false
            },
            "deploy": {
              "replicas": 1,
              "service": "ClusterIP"
            },
            "externalDb": {
              "host": "<<EXTERNAL DB IP OR DNS>>",
              "password": "<<EXTERNAL DB PASSWORD (if secret does not exist)>>",
              "port": "<<EXTERNAL DB PORT>>",
              "username": "<<EXTERNAL DB USERNAME>>"
            },
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            }
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaScanner",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "deploy": {
              "replicas": 1
            },
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            },
            "login": {
              "host": "http://aqua-server:8080",
              "password": "<<YOUR AQUA USER PASSWORD>>",
              "username": "<<YOUR AQUA USER NAME>>"
            },
            "runAsNonRoot": false
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaServer",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "common": {
              "databaseSecret": {
                "key": "<<EXTERNAL DB PASSWORD SECRET KEY>>",
                "name": "<<EXTERNAL DB PASSWORD SECRET NAME>>"
              },
              "splitDB": false
            },
            "deploy": {
              "replicas": 1,
              "service": "LoadBalancer"
            },
            "externalDb": {
              "host": "<<EXTERNAL DB IP OR DNS>>",
              "password": "<<EXTERNAL DB PASSWORD (if secret does not exist)>>",
              "port": "<<EXTERNAL DB PORT>>",
              "username": "<<EXTERNAL DB USERNAME>>"
            },
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/aquasec/aquasec-operator-bundle@sha256:fe86c0b5a3b6da6d631a870971c178d71809fdca3e9e580a439080e33ec718fc",
      "bundle_path_digest": "sha256:fe86c0b5a3b6da6d631a870971c178d71809fdca3e9e580a439080e33ec718fc",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "2022.4",
      "creation_date": "2022-09-21T14:36:34.410000+00:00",
      "csv_description": "The Aqua Security Operator runs within an OpenShift cluster and provides a means to deploy and manage the Aqua Security cluster and components :\n* Server (aka \u201cconsole\u201d)\n* Database (for production environments we recommend to use an external database and not the Aqua default database)\n* Gateway\n* Enforcer (aka \u201cagent\u201d)\n* KubeEnforcer\n* Scanner\n* CSP (package that contains the Server, Database, and Gateway)\n\nUse the Aqua-Operator to\n* Deploy Aqua Security components on OpenShift\n* Scale up Aqua Security components with extra replicas\n* Assign metadata tags to Aqua Security components\n\nThe Aqua Operator provides a few [Custom Resources](https://github.com/aquasecurity/aqua-operator/tree/master/deploy/crds) for managing the Aqua CSP platform.\n\n## Prerequisites\n\nThere are only 3 prerequisites:\n1. Make sure you have a license and to obtain one, please contact Aqua Security at [Contact Us](mailto:cloudsales@aquasec.com).\n2. Create a new project for aqua\n\n    ```oc new-project aqua```\n\n3. Create the secret for Aqua Database password. If you are using an External Database, make sure you use those credentials.\nNOTE: This step is optional and you can specify the Database password when creating the CRs.\n\n    ```oc create secret generic aqua-database-password --from-literal=db-password=<password> -n aqua```\n\nPlease note that for the certified operator, the Docker registry secret is NOT needed. For the Red Hat certified operator, the Aqua application images are stored in the Red Hat Connect registry and will be automatically pulled by the Aqua operator.\n\n## Choosing the right channel\n\nChannels are a flexible publishing mechanism that offers you three different Aqua versions to deploy, at any point. These channels map to their respective Aqua versions, describing the maturity based on where they are in their lifecycle:\n* 4.6: This maps to the older version of Aqua 4.6.0\n* 5.0: This maps to the Aqua version 5.0.0\n* 5.3: This maps to the Aqua version 5.3.0\n* 6.0: This maps to the Aqua version 6.0.0\n* 6.2: This maps to the Aqua version 6.2.0\n* 6.5: This maps to the Aqua version 6.5.0\n* 2022.4: This is the latest and greatest version of Aqua (default)\n\n## Deploying the Aqua Operator\n\nAqua Operator follows an easy push button deployment that installs the operator in its own aqua namespace.\nPlease refer to the instructions [here](https://github.com/aquasecurity/aqua-operator/blob/2022.4.0/docs/DeployOpenShiftOperator.md).\n\n## Configuring the Aqua Operator\n\nOperators leverage CRDs as a configuration mechanism for the application. Aqua offers a number of CRDs that can be tweaked and configured as per your needs. Please refer to this [link](https://github.com/aquasecurity/aqua-operator/blob/6.2.0/docs/DeployOpenShiftOperator.md#aquacsp-crds) for Custom Resource examples for popular scenarios.\n\n## Support\n\nFor support please contact support@aquasec.com.",
      "csv_display_name": "Aqua Security Operator",
      "csv_metadata_description": "The Aqua Security Operator runs within a Openshift cluster and provides a means to deploy and manage Aqua Security cluster and components.",
      "csv_name": "aqua-operator.v2022.4.130",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-21T14:36:34.410000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.10",
      "organization": "certified-operators",
      "package": "aqua-operator-certified",
      "provided_apis": [
        {
          "group": "operator.aquasec.com",
          "kind": "AquaGateway",
          "plural": "aquagateways",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaScanner",
          "plural": "aquascanners",
          "version": "v1alpha1"
        },
        {
          "group": "aquasecurity.github.io",
          "kind": "AquaStarboard",
          "plural": "aquastarboards",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaCsp",
          "plural": "aquacsps",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaDatabase",
          "plural": "aquadatabases",
          "version": "v1alpha1"
        },
        {
          "group": "aquasecurity.github.io",
          "kind": "ClusterConfigAuditReport",
          "plural": "clusterconfigauditreports",
          "version": "v1alpha1"
        },
        {
          "group": "aquasecurity.github.io",
          "kind": "ConfigAuditReport",
          "plural": "configauditreports",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaEnforcer",
          "plural": "aquaenforcers",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaKubeEnforcer",
          "plural": "aquakubeenforcers",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaServer",
          "plural": "aquaservers",
          "version": "v1alpha1"
        }
      ],
      "provider": "Aqua Security, Inc.",
      "related_images": [
        {
          "digest": "sha256:be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080",
          "image": "registry.connect.redhat.com/aquasec/aquasec@sha256:be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080",
          "name": "aquasec-be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080-annotation"
        },
        {
          "digest": "sha256:be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080",
          "image": "registry.connect.redhat.com/aquasec/aquasec@sha256:be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080",
          "name": "aqua-operator"
        },
        {
          "digest": "sha256:2cb83939d45d32560b3499299c46f98d542a1f67f5378774e60c95d255a03768",
          "image": "registry.connect.redhat.com/aquasec/database@sha256:2cb83939d45d32560b3499299c46f98d542a1f67f5378774e60c95d255a03768",
          "name": "database"
        },
        {
          "digest": "sha256:6c03a0cb281e2151e688bd2c5245f6114377a4619bc9a0415358ccbd07c2807d",
          "image": "registry.connect.redhat.com/aquasec/gateway@sha256:6c03a0cb281e2151e688bd2c5245f6114377a4619bc9a0415358ccbd07c2807d",
          "name": "gateway"
        },
        {
          "digest": "sha256:e4ae759bfc2c11e210a77305d1b6c99c2d9b08db01b172d295b9cc18b59f6c11",
          "image": "registry.connect.redhat.com/aquasec/console@sha256:e4ae759bfc2c11e210a77305d1b6c99c2d9b08db01b172d295b9cc18b59f6c11",
          "name": "server"
        },
        {
          "digest": "sha256:848d4398a21380947a76047fb74690b333bbad0bc2bf9a312cea6dad0a5580dd",
          "image": "registry.connect.redhat.com/aquasec/scanner@sha256:848d4398a21380947a76047fb74690b333bbad0bc2bf9a312cea6dad0a5580dd",
          "name": "scanner"
        },
        {
          "digest": "sha256:09d6b9413077196cbd649b6e669b47555936d8751aa88eb4d4790b09860cb3a5",
          "image": "registry.connect.redhat.com/aquasec/enforcer@sha256:09d6b9413077196cbd649b6e669b47555936d8751aa88eb4d4790b09860cb3a5",
          "name": "enforcer"
        },
        {
          "digest": "sha256:42ba6232cd7c2d5b75164e6f86671634bdd4ab451766dec2b4b3bbd6874671ab",
          "image": "registry.connect.redhat.com/aquasec/kube-enforcer@sha256:42ba6232cd7c2d5b75164e6f86671634bdd4ab451766dec2b4b3bbd6874671ab",
          "name": "kube_enforcer"
        }
      ],
      "replaces": null,
      "skip_range": ">=1.0.2 <2022.4.130",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.10",
      "version": "2022.4.130",
      "version_original": "2022.4.130"
    },
    {
      "_id": "632b26181b05b6df63f2cc7c",
      "alm_examples": [
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaCsp",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "common": {
              "databaseSecret": {
                "key": "db-password",
                "name": "aqua-database-password"
              },
              "dbDiskSize": 10
            },
            "database": {
              "replicas": 1,
              "service": "ClusterIP"
            },
            "gateway": {
              "replicas": 1,
              "service": "ClusterIP"
            },
            "infra": {
              "namespace": "aqua",
              "requirements": true,
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            },
            "route": true,
            "runAsNonRoot": false,
            "server": {
              "replicas": 1,
              "service": "LoadBalancer"
            }
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaDatabase",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "common": {
              "splitDB": false
            },
            "deploy": {
              "replicas": 1,
              "service": "ClusterIP"
            },
            "diskSize": 10,
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            },
            "runAsNonRoot": false
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaEnforcer",
          "metadata": {
            "name": "aqua"
          },
          "spec": {
            "gateway": {
              "host": "aqua-gateway",
              "port": 8443
            },
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            },
            "runAsNonRoot": false,
            "token": "<<your-token>>"
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaKubeEnforcer",
          "metadata": {
            "name": "aqua"
          },
          "spec": {
            "config": {
              "cluster_name": "aqua-secure",
              "gateway_address": "aqua-gateway:8443",
              "imagePullSecret": "aqua-registry"
            },
            "deploy": {
              "service": "ClusterIP"
            },
            "infra": {
              "serviceAccount": "aqua-kube-enforcer-sa",
              "version": "2022.4"
            },
            "token": "<<KUBE_ENFORCER_GROUP_TOKEN>>"
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaGateway",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "common": {
              "databaseSecret": {
                "key": "<<EXTERNAL DB PASSWORD SECRET KEY>>",
                "name": "<<EXTERNAL DB PASSWORD SECRET NAME>>"
              },
              "splitDB": false
            },
            "deploy": {
              "replicas": 1,
              "service": "ClusterIP"
            },
            "externalDb": {
              "host": "<<EXTERNAL DB IP OR DNS>>",
              "password": "<<EXTERNAL DB PASSWORD (if secret does not exist)>>",
              "port": "<<EXTERNAL DB PORT>>",
              "username": "<<EXTERNAL DB USERNAME>>"
            },
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            }
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaScanner",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "deploy": {
              "replicas": 1
            },
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            },
            "login": {
              "host": "http://aqua-server:8080",
              "password": "<<YOUR AQUA USER PASSWORD>>",
              "username": "<<YOUR AQUA USER NAME>>"
            },
            "runAsNonRoot": false
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaServer",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "common": {
              "databaseSecret": {
                "key": "<<EXTERNAL DB PASSWORD SECRET KEY>>",
                "name": "<<EXTERNAL DB PASSWORD SECRET NAME>>"
              },
              "splitDB": false
            },
            "deploy": {
              "replicas": 1,
              "service": "LoadBalancer"
            },
            "externalDb": {
              "host": "<<EXTERNAL DB IP OR DNS>>",
              "password": "<<EXTERNAL DB PASSWORD (if secret does not exist)>>",
              "port": "<<EXTERNAL DB PORT>>",
              "username": "<<EXTERNAL DB USERNAME>>"
            },
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/aquasec/aquasec-operator-bundle@sha256:fe86c0b5a3b6da6d631a870971c178d71809fdca3e9e580a439080e33ec718fc",
      "bundle_path_digest": "sha256:fe86c0b5a3b6da6d631a870971c178d71809fdca3e9e580a439080e33ec718fc",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "2022.4",
      "creation_date": "2022-09-21T14:56:24.104000+00:00",
      "csv_description": "The Aqua Security Operator runs within an OpenShift cluster and provides a means to deploy and manage the Aqua Security cluster and components :\n* Server (aka \u201cconsole\u201d)\n* Database (for production environments we recommend to use an external database and not the Aqua default database)\n* Gateway\n* Enforcer (aka \u201cagent\u201d)\n* KubeEnforcer\n* Scanner\n* CSP (package that contains the Server, Database, and Gateway)\n\nUse the Aqua-Operator to\n* Deploy Aqua Security components on OpenShift\n* Scale up Aqua Security components with extra replicas\n* Assign metadata tags to Aqua Security components\n\nThe Aqua Operator provides a few [Custom Resources](https://github.com/aquasecurity/aqua-operator/tree/master/deploy/crds) for managing the Aqua CSP platform.\n\n## Prerequisites\n\nThere are only 3 prerequisites:\n1. Make sure you have a license and to obtain one, please contact Aqua Security at [Contact Us](mailto:cloudsales@aquasec.com).\n2. Create a new project for aqua\n\n    ```oc new-project aqua```\n\n3. Create the secret for Aqua Database password. If you are using an External Database, make sure you use those credentials.\nNOTE: This step is optional and you can specify the Database password when creating the CRs.\n\n    ```oc create secret generic aqua-database-password --from-literal=db-password=<password> -n aqua```\n\nPlease note that for the certified operator, the Docker registry secret is NOT needed. For the Red Hat certified operator, the Aqua application images are stored in the Red Hat Connect registry and will be automatically pulled by the Aqua operator.\n\n## Choosing the right channel\n\nChannels are a flexible publishing mechanism that offers you three different Aqua versions to deploy, at any point. These channels map to their respective Aqua versions, describing the maturity based on where they are in their lifecycle:\n* 4.6: This maps to the older version of Aqua 4.6.0\n* 5.0: This maps to the Aqua version 5.0.0\n* 5.3: This maps to the Aqua version 5.3.0\n* 6.0: This maps to the Aqua version 6.0.0\n* 6.2: This maps to the Aqua version 6.2.0\n* 6.5: This maps to the Aqua version 6.5.0\n* 2022.4: This is the latest and greatest version of Aqua (default)\n\n## Deploying the Aqua Operator\n\nAqua Operator follows an easy push button deployment that installs the operator in its own aqua namespace.\nPlease refer to the instructions [here](https://github.com/aquasecurity/aqua-operator/blob/2022.4.0/docs/DeployOpenShiftOperator.md).\n\n## Configuring the Aqua Operator\n\nOperators leverage CRDs as a configuration mechanism for the application. Aqua offers a number of CRDs that can be tweaked and configured as per your needs. Please refer to this [link](https://github.com/aquasecurity/aqua-operator/blob/6.2.0/docs/DeployOpenShiftOperator.md#aquacsp-crds) for Custom Resource examples for popular scenarios.\n\n## Support\n\nFor support please contact support@aquasec.com.",
      "csv_display_name": "Aqua Security Operator",
      "csv_metadata_description": "The Aqua Security Operator runs within a Openshift cluster and provides a means to deploy and manage Aqua Security cluster and components.",
      "csv_name": "aqua-operator.v2022.4.130",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-21T14:56:24.104000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.8",
      "organization": "certified-operators",
      "package": "aqua-operator-certified",
      "provided_apis": [
        {
          "group": "operator.aquasec.com",
          "kind": "AquaCsp",
          "plural": "aquacsps",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaEnforcer",
          "plural": "aquaenforcers",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaScanner",
          "plural": "aquascanners",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaServer",
          "plural": "aquaservers",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaGateway",
          "plural": "aquagateways",
          "version": "v1alpha1"
        },
        {
          "group": "aquasecurity.github.io",
          "kind": "AquaStarboard",
          "plural": "aquastarboards",
          "version": "v1alpha1"
        },
        {
          "group": "aquasecurity.github.io",
          "kind": "ClusterConfigAuditReport",
          "plural": "clusterconfigauditreports",
          "version": "v1alpha1"
        },
        {
          "group": "aquasecurity.github.io",
          "kind": "ConfigAuditReport",
          "plural": "configauditreports",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaDatabase",
          "plural": "aquadatabases",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaKubeEnforcer",
          "plural": "aquakubeenforcers",
          "version": "v1alpha1"
        }
      ],
      "provider": "Aqua Security, Inc.",
      "related_images": [
        {
          "digest": "sha256:be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080",
          "image": "registry.connect.redhat.com/aquasec/aquasec@sha256:be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080",
          "name": "aquasec-be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080-annotation"
        },
        {
          "digest": "sha256:be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080",
          "image": "registry.connect.redhat.com/aquasec/aquasec@sha256:be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080",
          "name": "aqua-operator"
        },
        {
          "digest": "sha256:2cb83939d45d32560b3499299c46f98d542a1f67f5378774e60c95d255a03768",
          "image": "registry.connect.redhat.com/aquasec/database@sha256:2cb83939d45d32560b3499299c46f98d542a1f67f5378774e60c95d255a03768",
          "name": "database"
        },
        {
          "digest": "sha256:6c03a0cb281e2151e688bd2c5245f6114377a4619bc9a0415358ccbd07c2807d",
          "image": "registry.connect.redhat.com/aquasec/gateway@sha256:6c03a0cb281e2151e688bd2c5245f6114377a4619bc9a0415358ccbd07c2807d",
          "name": "gateway"
        },
        {
          "digest": "sha256:e4ae759bfc2c11e210a77305d1b6c99c2d9b08db01b172d295b9cc18b59f6c11",
          "image": "registry.connect.redhat.com/aquasec/console@sha256:e4ae759bfc2c11e210a77305d1b6c99c2d9b08db01b172d295b9cc18b59f6c11",
          "name": "server"
        },
        {
          "digest": "sha256:848d4398a21380947a76047fb74690b333bbad0bc2bf9a312cea6dad0a5580dd",
          "image": "registry.connect.redhat.com/aquasec/scanner@sha256:848d4398a21380947a76047fb74690b333bbad0bc2bf9a312cea6dad0a5580dd",
          "name": "scanner"
        },
        {
          "digest": "sha256:09d6b9413077196cbd649b6e669b47555936d8751aa88eb4d4790b09860cb3a5",
          "image": "registry.connect.redhat.com/aquasec/enforcer@sha256:09d6b9413077196cbd649b6e669b47555936d8751aa88eb4d4790b09860cb3a5",
          "name": "enforcer"
        },
        {
          "digest": "sha256:42ba6232cd7c2d5b75164e6f86671634bdd4ab451766dec2b4b3bbd6874671ab",
          "image": "registry.connect.redhat.com/aquasec/kube-enforcer@sha256:42ba6232cd7c2d5b75164e6f86671634bdd4ab451766dec2b4b3bbd6874671ab",
          "name": "kube_enforcer"
        }
      ],
      "replaces": null,
      "skip_range": ">=1.0.2 <2022.4.130",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.8",
      "version": "2022.4.130",
      "version_original": "2022.4.130"
    },
    {
      "_id": "632b2703407cfb8fa77c006c",
      "alm_examples": [
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaCsp",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "common": {
              "databaseSecret": {
                "key": "db-password",
                "name": "aqua-database-password"
              },
              "dbDiskSize": 10
            },
            "database": {
              "replicas": 1,
              "service": "ClusterIP"
            },
            "gateway": {
              "replicas": 1,
              "service": "ClusterIP"
            },
            "infra": {
              "namespace": "aqua",
              "requirements": true,
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            },
            "route": true,
            "runAsNonRoot": false,
            "server": {
              "replicas": 1,
              "service": "LoadBalancer"
            }
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaDatabase",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "common": {
              "splitDB": false
            },
            "deploy": {
              "replicas": 1,
              "service": "ClusterIP"
            },
            "diskSize": 10,
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            },
            "runAsNonRoot": false
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaEnforcer",
          "metadata": {
            "name": "aqua"
          },
          "spec": {
            "gateway": {
              "host": "aqua-gateway",
              "port": 8443
            },
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            },
            "runAsNonRoot": false,
            "token": "<<your-token>>"
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaKubeEnforcer",
          "metadata": {
            "name": "aqua"
          },
          "spec": {
            "config": {
              "cluster_name": "aqua-secure",
              "gateway_address": "aqua-gateway:8443",
              "imagePullSecret": "aqua-registry"
            },
            "deploy": {
              "service": "ClusterIP"
            },
            "infra": {
              "serviceAccount": "aqua-kube-enforcer-sa",
              "version": "2022.4"
            },
            "token": "<<KUBE_ENFORCER_GROUP_TOKEN>>"
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaGateway",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "common": {
              "databaseSecret": {
                "key": "<<EXTERNAL DB PASSWORD SECRET KEY>>",
                "name": "<<EXTERNAL DB PASSWORD SECRET NAME>>"
              },
              "splitDB": false
            },
            "deploy": {
              "replicas": 1,
              "service": "ClusterIP"
            },
            "externalDb": {
              "host": "<<EXTERNAL DB IP OR DNS>>",
              "password": "<<EXTERNAL DB PASSWORD (if secret does not exist)>>",
              "port": "<<EXTERNAL DB PORT>>",
              "username": "<<EXTERNAL DB USERNAME>>"
            },
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            }
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaScanner",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "deploy": {
              "replicas": 1
            },
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            },
            "login": {
              "host": "http://aqua-server:8080",
              "password": "<<YOUR AQUA USER PASSWORD>>",
              "username": "<<YOUR AQUA USER NAME>>"
            },
            "runAsNonRoot": false
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaServer",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "common": {
              "databaseSecret": {
                "key": "<<EXTERNAL DB PASSWORD SECRET KEY>>",
                "name": "<<EXTERNAL DB PASSWORD SECRET NAME>>"
              },
              "splitDB": false
            },
            "deploy": {
              "replicas": 1,
              "service": "LoadBalancer"
            },
            "externalDb": {
              "host": "<<EXTERNAL DB IP OR DNS>>",
              "password": "<<EXTERNAL DB PASSWORD (if secret does not exist)>>",
              "port": "<<EXTERNAL DB PORT>>",
              "username": "<<EXTERNAL DB USERNAME>>"
            },
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/aquasec/aquasec-operator-bundle@sha256:fe86c0b5a3b6da6d631a870971c178d71809fdca3e9e580a439080e33ec718fc",
      "bundle_path_digest": "sha256:fe86c0b5a3b6da6d631a870971c178d71809fdca3e9e580a439080e33ec718fc",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "2022.4",
      "creation_date": "2022-09-21T15:00:19.712000+00:00",
      "csv_description": "The Aqua Security Operator runs within an OpenShift cluster and provides a means to deploy and manage the Aqua Security cluster and components :\n* Server (aka \u201cconsole\u201d)\n* Database (for production environments we recommend to use an external database and not the Aqua default database)\n* Gateway\n* Enforcer (aka \u201cagent\u201d)\n* KubeEnforcer\n* Scanner\n* CSP (package that contains the Server, Database, and Gateway)\n\nUse the Aqua-Operator to\n* Deploy Aqua Security components on OpenShift\n* Scale up Aqua Security components with extra replicas\n* Assign metadata tags to Aqua Security components\n\nThe Aqua Operator provides a few [Custom Resources](https://github.com/aquasecurity/aqua-operator/tree/master/deploy/crds) for managing the Aqua CSP platform.\n\n## Prerequisites\n\nThere are only 3 prerequisites:\n1. Make sure you have a license and to obtain one, please contact Aqua Security at [Contact Us](mailto:cloudsales@aquasec.com).\n2. Create a new project for aqua\n\n    ```oc new-project aqua```\n\n3. Create the secret for Aqua Database password. If you are using an External Database, make sure you use those credentials.\nNOTE: This step is optional and you can specify the Database password when creating the CRs.\n\n    ```oc create secret generic aqua-database-password --from-literal=db-password=<password> -n aqua```\n\nPlease note that for the certified operator, the Docker registry secret is NOT needed. For the Red Hat certified operator, the Aqua application images are stored in the Red Hat Connect registry and will be automatically pulled by the Aqua operator.\n\n## Choosing the right channel\n\nChannels are a flexible publishing mechanism that offers you three different Aqua versions to deploy, at any point. These channels map to their respective Aqua versions, describing the maturity based on where they are in their lifecycle:\n* 4.6: This maps to the older version of Aqua 4.6.0\n* 5.0: This maps to the Aqua version 5.0.0\n* 5.3: This maps to the Aqua version 5.3.0\n* 6.0: This maps to the Aqua version 6.0.0\n* 6.2: This maps to the Aqua version 6.2.0\n* 6.5: This maps to the Aqua version 6.5.0\n* 2022.4: This is the latest and greatest version of Aqua (default)\n\n## Deploying the Aqua Operator\n\nAqua Operator follows an easy push button deployment that installs the operator in its own aqua namespace.\nPlease refer to the instructions [here](https://github.com/aquasecurity/aqua-operator/blob/2022.4.0/docs/DeployOpenShiftOperator.md).\n\n## Configuring the Aqua Operator\n\nOperators leverage CRDs as a configuration mechanism for the application. Aqua offers a number of CRDs that can be tweaked and configured as per your needs. Please refer to this [link](https://github.com/aquasecurity/aqua-operator/blob/6.2.0/docs/DeployOpenShiftOperator.md#aquacsp-crds) for Custom Resource examples for popular scenarios.\n\n## Support\n\nFor support please contact support@aquasec.com.",
      "csv_display_name": "Aqua Security Operator",
      "csv_metadata_description": "The Aqua Security Operator runs within a Openshift cluster and provides a means to deploy and manage Aqua Security cluster and components.",
      "csv_name": "aqua-operator.v2022.4.130",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-21T15:00:19.712000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.6",
      "organization": "certified-operators",
      "package": "aqua-operator-certified",
      "provided_apis": [
        {
          "group": "operator.aquasec.com",
          "kind": "AquaServer",
          "plural": "aquaservers",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaEnforcer",
          "plural": "aquaenforcers",
          "version": "v1alpha1"
        },
        {
          "group": "aquasecurity.github.io",
          "kind": "AquaStarboard",
          "plural": "aquastarboards",
          "version": "v1alpha1"
        },
        {
          "group": "aquasecurity.github.io",
          "kind": "ClusterConfigAuditReport",
          "plural": "clusterconfigauditreports",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaGateway",
          "plural": "aquagateways",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaKubeEnforcer",
          "plural": "aquakubeenforcers",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaCsp",
          "plural": "aquacsps",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaScanner",
          "plural": "aquascanners",
          "version": "v1alpha1"
        },
        {
          "group": "aquasecurity.github.io",
          "kind": "ConfigAuditReport",
          "plural": "configauditreports",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaDatabase",
          "plural": "aquadatabases",
          "version": "v1alpha1"
        }
      ],
      "provider": "Aqua Security, Inc.",
      "related_images": [
        {
          "digest": "sha256:be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080",
          "image": "registry.connect.redhat.com/aquasec/aquasec@sha256:be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080",
          "name": "aquasec-be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080-annotation"
        },
        {
          "digest": "sha256:be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080",
          "image": "registry.connect.redhat.com/aquasec/aquasec@sha256:be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080",
          "name": "aqua-operator"
        },
        {
          "digest": "sha256:2cb83939d45d32560b3499299c46f98d542a1f67f5378774e60c95d255a03768",
          "image": "registry.connect.redhat.com/aquasec/database@sha256:2cb83939d45d32560b3499299c46f98d542a1f67f5378774e60c95d255a03768",
          "name": "database"
        },
        {
          "digest": "sha256:6c03a0cb281e2151e688bd2c5245f6114377a4619bc9a0415358ccbd07c2807d",
          "image": "registry.connect.redhat.com/aquasec/gateway@sha256:6c03a0cb281e2151e688bd2c5245f6114377a4619bc9a0415358ccbd07c2807d",
          "name": "gateway"
        },
        {
          "digest": "sha256:e4ae759bfc2c11e210a77305d1b6c99c2d9b08db01b172d295b9cc18b59f6c11",
          "image": "registry.connect.redhat.com/aquasec/console@sha256:e4ae759bfc2c11e210a77305d1b6c99c2d9b08db01b172d295b9cc18b59f6c11",
          "name": "server"
        },
        {
          "digest": "sha256:848d4398a21380947a76047fb74690b333bbad0bc2bf9a312cea6dad0a5580dd",
          "image": "registry.connect.redhat.com/aquasec/scanner@sha256:848d4398a21380947a76047fb74690b333bbad0bc2bf9a312cea6dad0a5580dd",
          "name": "scanner"
        },
        {
          "digest": "sha256:09d6b9413077196cbd649b6e669b47555936d8751aa88eb4d4790b09860cb3a5",
          "image": "registry.connect.redhat.com/aquasec/enforcer@sha256:09d6b9413077196cbd649b6e669b47555936d8751aa88eb4d4790b09860cb3a5",
          "name": "enforcer"
        },
        {
          "digest": "sha256:42ba6232cd7c2d5b75164e6f86671634bdd4ab451766dec2b4b3bbd6874671ab",
          "image": "registry.connect.redhat.com/aquasec/kube-enforcer@sha256:42ba6232cd7c2d5b75164e6f86671634bdd4ab451766dec2b4b3bbd6874671ab",
          "name": "kube_enforcer"
        }
      ],
      "replaces": null,
      "skip_range": ">=1.0.2 <2022.4.130",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.6",
      "version": "2022.4.130",
      "version_original": "2022.4.130"
    },
    {
      "_id": "632b27642bdd76944b8e5fe9",
      "alm_examples": [
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaCsp",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "common": {
              "databaseSecret": {
                "key": "db-password",
                "name": "aqua-database-password"
              },
              "dbDiskSize": 10
            },
            "database": {
              "replicas": 1,
              "service": "ClusterIP"
            },
            "gateway": {
              "replicas": 1,
              "service": "ClusterIP"
            },
            "infra": {
              "namespace": "aqua",
              "requirements": true,
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            },
            "route": true,
            "runAsNonRoot": false,
            "server": {
              "replicas": 1,
              "service": "LoadBalancer"
            }
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaDatabase",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "common": {
              "splitDB": false
            },
            "deploy": {
              "replicas": 1,
              "service": "ClusterIP"
            },
            "diskSize": 10,
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            },
            "runAsNonRoot": false
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaEnforcer",
          "metadata": {
            "name": "aqua"
          },
          "spec": {
            "gateway": {
              "host": "aqua-gateway",
              "port": 8443
            },
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            },
            "runAsNonRoot": false,
            "token": "<<your-token>>"
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaKubeEnforcer",
          "metadata": {
            "name": "aqua"
          },
          "spec": {
            "config": {
              "cluster_name": "aqua-secure",
              "gateway_address": "aqua-gateway:8443",
              "imagePullSecret": "aqua-registry"
            },
            "deploy": {
              "service": "ClusterIP"
            },
            "infra": {
              "serviceAccount": "aqua-kube-enforcer-sa",
              "version": "2022.4"
            },
            "token": "<<KUBE_ENFORCER_GROUP_TOKEN>>"
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaGateway",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "common": {
              "databaseSecret": {
                "key": "<<EXTERNAL DB PASSWORD SECRET KEY>>",
                "name": "<<EXTERNAL DB PASSWORD SECRET NAME>>"
              },
              "splitDB": false
            },
            "deploy": {
              "replicas": 1,
              "service": "ClusterIP"
            },
            "externalDb": {
              "host": "<<EXTERNAL DB IP OR DNS>>",
              "password": "<<EXTERNAL DB PASSWORD (if secret does not exist)>>",
              "port": "<<EXTERNAL DB PORT>>",
              "username": "<<EXTERNAL DB USERNAME>>"
            },
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            }
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaScanner",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "deploy": {
              "replicas": 1
            },
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            },
            "login": {
              "host": "http://aqua-server:8080",
              "password": "<<YOUR AQUA USER PASSWORD>>",
              "username": "<<YOUR AQUA USER NAME>>"
            },
            "runAsNonRoot": false
          }
        },
        {
          "api_version": "operator.aquasec.com/v1alpha1",
          "kind": "AquaServer",
          "metadata": {
            "name": "aqua",
            "namespace": "aqua"
          },
          "spec": {
            "common": {
              "databaseSecret": {
                "key": "<<EXTERNAL DB PASSWORD SECRET KEY>>",
                "name": "<<EXTERNAL DB PASSWORD SECRET NAME>>"
              },
              "splitDB": false
            },
            "deploy": {
              "replicas": 1,
              "service": "LoadBalancer"
            },
            "externalDb": {
              "host": "<<EXTERNAL DB IP OR DNS>>",
              "password": "<<EXTERNAL DB PASSWORD (if secret does not exist)>>",
              "port": "<<EXTERNAL DB PORT>>",
              "username": "<<EXTERNAL DB USERNAME>>"
            },
            "infra": {
              "serviceAccount": "aqua-sa",
              "version": "2022.4"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/aquasec/aquasec-operator-bundle@sha256:fe86c0b5a3b6da6d631a870971c178d71809fdca3e9e580a439080e33ec718fc",
      "bundle_path_digest": "sha256:fe86c0b5a3b6da6d631a870971c178d71809fdca3e9e580a439080e33ec718fc",
      "capabilities": [
        "Seamless Upgrades"
      ],
      "channel_name": "2022.4",
      "creation_date": "2022-09-21T15:01:56.047000+00:00",
      "csv_description": "The Aqua Security Operator runs within an OpenShift cluster and provides a means to deploy and manage the Aqua Security cluster and components :\n* Server (aka \u201cconsole\u201d)\n* Database (for production environments we recommend to use an external database and not the Aqua default database)\n* Gateway\n* Enforcer (aka \u201cagent\u201d)\n* KubeEnforcer\n* Scanner\n* CSP (package that contains the Server, Database, and Gateway)\n\nUse the Aqua-Operator to\n* Deploy Aqua Security components on OpenShift\n* Scale up Aqua Security components with extra replicas\n* Assign metadata tags to Aqua Security components\n\nThe Aqua Operator provides a few [Custom Resources](https://github.com/aquasecurity/aqua-operator/tree/master/deploy/crds) for managing the Aqua CSP platform.\n\n## Prerequisites\n\nThere are only 3 prerequisites:\n1. Make sure you have a license and to obtain one, please contact Aqua Security at [Contact Us](mailto:cloudsales@aquasec.com).\n2. Create a new project for aqua\n\n    ```oc new-project aqua```\n\n3. Create the secret for Aqua Database password. If you are using an External Database, make sure you use those credentials.\nNOTE: This step is optional and you can specify the Database password when creating the CRs.\n\n    ```oc create secret generic aqua-database-password --from-literal=db-password=<password> -n aqua```\n\nPlease note that for the certified operator, the Docker registry secret is NOT needed. For the Red Hat certified operator, the Aqua application images are stored in the Red Hat Connect registry and will be automatically pulled by the Aqua operator.\n\n## Choosing the right channel\n\nChannels are a flexible publishing mechanism that offers you three different Aqua versions to deploy, at any point. These channels map to their respective Aqua versions, describing the maturity based on where they are in their lifecycle:\n* 4.6: This maps to the older version of Aqua 4.6.0\n* 5.0: This maps to the Aqua version 5.0.0\n* 5.3: This maps to the Aqua version 5.3.0\n* 6.0: This maps to the Aqua version 6.0.0\n* 6.2: This maps to the Aqua version 6.2.0\n* 6.5: This maps to the Aqua version 6.5.0\n* 2022.4: This is the latest and greatest version of Aqua (default)\n\n## Deploying the Aqua Operator\n\nAqua Operator follows an easy push button deployment that installs the operator in its own aqua namespace.\nPlease refer to the instructions [here](https://github.com/aquasecurity/aqua-operator/blob/2022.4.0/docs/DeployOpenShiftOperator.md).\n\n## Configuring the Aqua Operator\n\nOperators leverage CRDs as a configuration mechanism for the application. Aqua offers a number of CRDs that can be tweaked and configured as per your needs. Please refer to this [link](https://github.com/aquasecurity/aqua-operator/blob/6.2.0/docs/DeployOpenShiftOperator.md#aquacsp-crds) for Custom Resource examples for popular scenarios.\n\n## Support\n\nFor support please contact support@aquasec.com.",
      "csv_display_name": "Aqua Security Operator",
      "csv_metadata_description": "The Aqua Security Operator runs within a Openshift cluster and provides a means to deploy and manage Aqua Security cluster and components.",
      "csv_name": "aqua-operator.v2022.4.130",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-21T15:01:56.047000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.7",
      "organization": "certified-operators",
      "package": "aqua-operator-certified",
      "provided_apis": [
        {
          "group": "aquasecurity.github.io",
          "kind": "ConfigAuditReport",
          "plural": "configauditreports",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaDatabase",
          "plural": "aquadatabases",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaEnforcer",
          "plural": "aquaenforcers",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaGateway",
          "plural": "aquagateways",
          "version": "v1alpha1"
        },
        {
          "group": "aquasecurity.github.io",
          "kind": "AquaStarboard",
          "plural": "aquastarboards",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaCsp",
          "plural": "aquacsps",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaKubeEnforcer",
          "plural": "aquakubeenforcers",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaServer",
          "plural": "aquaservers",
          "version": "v1alpha1"
        },
        {
          "group": "operator.aquasec.com",
          "kind": "AquaScanner",
          "plural": "aquascanners",
          "version": "v1alpha1"
        },
        {
          "group": "aquasecurity.github.io",
          "kind": "ClusterConfigAuditReport",
          "plural": "clusterconfigauditreports",
          "version": "v1alpha1"
        }
      ],
      "provider": "Aqua Security, Inc.",
      "related_images": [
        {
          "digest": "sha256:be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080",
          "image": "registry.connect.redhat.com/aquasec/aquasec@sha256:be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080",
          "name": "aquasec-be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080-annotation"
        },
        {
          "digest": "sha256:be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080",
          "image": "registry.connect.redhat.com/aquasec/aquasec@sha256:be6844c048d1c1695d513894fe465d1f3286c5d085c14e6fdb55c7e14c0c8080",
          "name": "aqua-operator"
        },
        {
          "digest": "sha256:2cb83939d45d32560b3499299c46f98d542a1f67f5378774e60c95d255a03768",
          "image": "registry.connect.redhat.com/aquasec/database@sha256:2cb83939d45d32560b3499299c46f98d542a1f67f5378774e60c95d255a03768",
          "name": "database"
        },
        {
          "digest": "sha256:6c03a0cb281e2151e688bd2c5245f6114377a4619bc9a0415358ccbd07c2807d",
          "image": "registry.connect.redhat.com/aquasec/gateway@sha256:6c03a0cb281e2151e688bd2c5245f6114377a4619bc9a0415358ccbd07c2807d",
          "name": "gateway"
        },
        {
          "digest": "sha256:e4ae759bfc2c11e210a77305d1b6c99c2d9b08db01b172d295b9cc18b59f6c11",
          "image": "registry.connect.redhat.com/aquasec/console@sha256:e4ae759bfc2c11e210a77305d1b6c99c2d9b08db01b172d295b9cc18b59f6c11",
          "name": "server"
        },
        {
          "digest": "sha256:848d4398a21380947a76047fb74690b333bbad0bc2bf9a312cea6dad0a5580dd",
          "image": "registry.connect.redhat.com/aquasec/scanner@sha256:848d4398a21380947a76047fb74690b333bbad0bc2bf9a312cea6dad0a5580dd",
          "name": "scanner"
        },
        {
          "digest": "sha256:09d6b9413077196cbd649b6e669b47555936d8751aa88eb4d4790b09860cb3a5",
          "image": "registry.connect.redhat.com/aquasec/enforcer@sha256:09d6b9413077196cbd649b6e669b47555936d8751aa88eb4d4790b09860cb3a5",
          "name": "enforcer"
        },
        {
          "digest": "sha256:42ba6232cd7c2d5b75164e6f86671634bdd4ab451766dec2b4b3bbd6874671ab",
          "image": "registry.connect.redhat.com/aquasec/kube-enforcer@sha256:42ba6232cd7c2d5b75164e6f86671634bdd4ab451766dec2b4b3bbd6874671ab",
          "name": "kube_enforcer"
        }
      ],
      "replaces": null,
      "skip_range": ">=1.0.2 <2022.4.130",
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.7",
      "version": "2022.4.130",
      "version_original": "2022.4.130"
    },
    {
      "_id": "632b70ac6c4612132187ff13",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:3d318b2c367c9bbd417824ea425154cbfd92ba65baf55d094813e0b339873f39",
      "bundle_path_digest": "sha256:3d318b2c367c9bbd417824ea425154cbfd92ba65baf55d094813e0b339873f39",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-21T20:14:36.892000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.6.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-21T20:14:36.892000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.11",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:2fa2fd1bf32b6514e53f5bfdda1f401bd9a42aeb8af8237710f9434685e34893",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:2fa2fd1bf32b6514e53f5bfdda1f401bd9a42aeb8af8237710f9434685e34893",
          "name": "kubeturbo-operator-2fa2fd1bf32b6514e53f5bfdda1f401bd9a42aeb8af8237710f9434685e34893-annotation"
        },
        {
          "digest": "sha256:2fa2fd1bf32b6514e53f5bfdda1f401bd9a42aeb8af8237710f9434685e34893",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:2fa2fd1bf32b6514e53f5bfdda1f401bd9a42aeb8af8237710f9434685e34893",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:dcdc45a23a5f4a6b8272513f57b7165f84a4ad817eb89a20fe2e6d0a0fe8f7b8",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:dcdc45a23a5f4a6b8272513f57b7165f84a4ad817eb89a20fe2e6d0a0fe8f7b8",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.11",
      "version": "8.6.4",
      "version_original": "8.6.4"
    },
    {
      "_id": "632b71736c4612132187ff30",
      "alm_examples": [
        {
          "api_version": "charts.helm.k8s.io/v1",
          "kind": "Kubeturbo",
          "metadata": {
            "name": "kubeturbo-release"
          },
          "spec": {
            "serverMeta": {
              "turboServer": "https://Turbo_server_URL"
            },
            "targetConfig": {
              "targetName": "Cluster_Name"
            }
          }
        }
      ],
      "annotations": {
        "infrastructure_features": [],
        "valid_subscription": []
      },
      "architectures": [],
      "bundle_path": "registry.connect.redhat.com/turbonomic/kubeturbo-operator-bundle@sha256:3d318b2c367c9bbd417824ea425154cbfd92ba65baf55d094813e0b339873f39",
      "bundle_path_digest": "sha256:3d318b2c367c9bbd417824ea425154cbfd92ba65baf55d094813e0b339873f39",
      "capabilities": [
        "Basic Install"
      ],
      "channel_name": "stable",
      "creation_date": "2022-09-21T20:17:55.509000+00:00",
      "csv_description": "### Application Resource Management for Kubernetes\nTurbonomic AI-powered Application Resource Management simultaneously optimizes performance, compliance, and cost in real time.\nSoftware manages the complete application stack, automatically. Applications are continually resourced to perform while satisfying business constraints.\n\nTurbonomic makes workloads smart \u2014 enabling them to self-manage and determines the specific actions that will drive continuous health:\n\n* Continuous placement for Pods (rescheduling)\n* Continuous scaling for applications and  the underlying cluster.\n\nIt assures application performance by giving workloads the resources they need when they need them.\n\n### How does it work?\nTurbonomic uses a container \u2014 KubeTurbo \u2014 that runs in your Kubernetes or Red Hat OpenShift cluster to discover and monitor your environment.\nKubeTurbo runs together with the default scheduler and sends this data back to the Turbonomic analytics engine.\nTurbonomic determines the right actions that drive continuous health, including continuous placement for Pods and continuous scaling for applications and the underlying cluster.",
      "csv_display_name": "Kubeturbo Operator",
      "csv_metadata_description": "Turbonomic Workload Automation for Multicloud simultaneously optimizes performance, compliance, and cost in real-time. Workloads are precisely resourced, automatically, to perform while satisfying business constraints.",
      "csv_name": "kubeturbo-operator.v8.6.4",
      "in_index_img": true,
      "install_modes": [
        {
          "supported": true,
          "type": "OwnNamespace"
        },
        {
          "supported": true,
          "type": "SingleNamespace"
        },
        {
          "supported": false,
          "type": "MultiNamespace"
        },
        {
          "supported": false,
          "type": "AllNamespaces"
        }
      ],
      "is_default_channel": true,
      "last_update_date": "2022-09-21T20:17:55.509000+00:00",
      "latest_in_channel": true,
      "ocp_version": "4.12",
      "organization": "certified-operators",
      "package": "kubeturbo-certified",
      "provided_apis": [
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "version": "v1"
        },
        {
          "group": "charts.helm.k8s.io",
          "kind": "Kubeturbo",
          "version": "v1alpha1"
        }
      ],
      "provider": "Turbonomic, Inc.",
      "related_images": [
        {
          "digest": "sha256:2fa2fd1bf32b6514e53f5bfdda1f401bd9a42aeb8af8237710f9434685e34893",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:2fa2fd1bf32b6514e53f5bfdda1f401bd9a42aeb8af8237710f9434685e34893",
          "name": "kubeturbo-operator-2fa2fd1bf32b6514e53f5bfdda1f401bd9a42aeb8af8237710f9434685e34893-annotation"
        },
        {
          "digest": "sha256:2fa2fd1bf32b6514e53f5bfdda1f401bd9a42aeb8af8237710f9434685e34893",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo-operator@sha256:2fa2fd1bf32b6514e53f5bfdda1f401bd9a42aeb8af8237710f9434685e34893",
          "name": "kubeturbo-operator"
        },
        {
          "digest": "sha256:dcdc45a23a5f4a6b8272513f57b7165f84a4ad817eb89a20fe2e6d0a0fe8f7b8",
          "image": "registry.connect.redhat.com/turbonomic/kubeturbo@sha256:dcdc45a23a5f4a6b8272513f57b7165f84a4ad817eb89a20fe2e6d0a0fe8f7b8",
          "name": "kubeturbo"
        }
      ],
      "replaces": null,
      "skip_range": null,
      "skips": [],
      "source_index_container_path": "registry.redhat.io/redhat/certified-operator-index:v4.12",
      "version": "8.6.4",
      "version_original": "8.6.4"
    }
  ]
}
