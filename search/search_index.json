{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview \u00b6 This repository contains a set of Cloud-Native Network Functions (CNFs) test cases and the framework to build more. The tests and framework are intended to test the interaction of CNFs with OpenShift Container Platform. It also generates a report (claim.json) after running tests. Please consult CATALOG.md for a catalog of the included test cases and test case building blocks. The suite is provided here in part so that CNF Developers can use the suite to test their CNFs readiness for certification. Please see \u201cCNF Developers\u201d below for more information. Architecture \u00b6 In the diagram above: - the CNF is the CNF to be certified. The certification suite identifies the resources (containers/pods/operators etc) belonging to the CNF via labels or static data entries in the config file - the Certification container/exec is the certification test suite running on the platform or in a container. The executable verifies the CNF under test configuration and its interactions with openshift - the Debug pods are part of a daemonset responsible to run various privileged commands on kubernetes nodes. Debug pods are useful to run platform tests and test commands (e.g. ping) in container namespaces without changing the container image content. The debug daemonset is instantiated via the cnf-certification-test-partner repository repo .","title":"Overview"},{"location":"#overview","text":"This repository contains a set of Cloud-Native Network Functions (CNFs) test cases and the framework to build more. The tests and framework are intended to test the interaction of CNFs with OpenShift Container Platform. It also generates a report (claim.json) after running tests. Please consult CATALOG.md for a catalog of the included test cases and test case building blocks. The suite is provided here in part so that CNF Developers can use the suite to test their CNFs readiness for certification. Please see \u201cCNF Developers\u201d below for more information.","title":"Overview"},{"location":"#architecture","text":"In the diagram above: - the CNF is the CNF to be certified. The certification suite identifies the resources (containers/pods/operators etc) belonging to the CNF via labels or static data entries in the config file - the Certification container/exec is the certification test suite running on the platform or in a container. The executable verifies the CNF under test configuration and its interactions with openshift - the Debug pods are part of a daemonset responsible to run various privileged commands on kubernetes nodes. Debug pods are useful to run platform tests and test commands (e.g. ping) in container namespaces without changing the container image content. The debug daemonset is instantiated via the cnf-certification-test-partner repository repo .","title":"Architecture"},{"location":"claim/","text":"Claim file \u00b6 The test suite generates a \u201cclaim\u201d file, which describes the system(s) under test, the tests that were run, and the outcome of all of the tests. This claim file is the proof of the test run that is evaluated by Red Hat when \u201ccertified\u201d status is being considered. For more information about the contents of the claim file please see the schema . You can read more about the purpose of the claim file and CNF Certification in the Guide . Adding Test Results for the CNF Validation Test Suite to a Claim File \u00b6 e.g. Adding a cnf platform test results to your existing claim file. You can use the claim cli tool to append other related test suite results to your existing claim.json file. The output of the tool will be an updated claim file. go run cmd/tools/cmd/main.go claim-add --claimfile=claim.json --reportdir=/home/$USER/reports Args: --claimfile is an existing claim.json file --repordir :path to test results that you want to include. The tests result files from the given report dir will be appended under the result section of the claim file using file name as the key/value pair. The tool will ignore the test result, if the key name is already present under result section of the claim file. \"results\": { \"cnf-certification-tests_junit\": { \"testsuite\": { \"-errors\": \"0\", \"-failures\": \"2\", \"-name\": \"CNF Certification Test Suite\", \"-tests\": \"14\",","title":"Claim file"},{"location":"claim/#claim-file","text":"The test suite generates a \u201cclaim\u201d file, which describes the system(s) under test, the tests that were run, and the outcome of all of the tests. This claim file is the proof of the test run that is evaluated by Red Hat when \u201ccertified\u201d status is being considered. For more information about the contents of the claim file please see the schema . You can read more about the purpose of the claim file and CNF Certification in the Guide .","title":"Claim file"},{"location":"claim/#adding-test-results-for-the-cnf-validation-test-suite-to-a-claim-file","text":"e.g. Adding a cnf platform test results to your existing claim file. You can use the claim cli tool to append other related test suite results to your existing claim.json file. The output of the tool will be an updated claim file. go run cmd/tools/cmd/main.go claim-add --claimfile=claim.json --reportdir=/home/$USER/reports Args: --claimfile is an existing claim.json file --repordir :path to test results that you want to include. The tests result files from the given report dir will be appended under the result section of the claim file using file name as the key/value pair. The tool will ignore the test result, if the key name is already present under result section of the claim file. \"results\": { \"cnf-certification-tests_junit\": { \"testsuite\": { \"-errors\": \"0\", \"-failures\": \"2\", \"-name\": \"CNF Certification Test Suite\", \"-tests\": \"14\",","title":"Adding Test Results for the CNF Validation Test Suite to a Claim File"},{"location":"configuration/","text":"Test configuration Components \u00b6 The Test Network Function support autodiscovery using labels and annotations. The following sections describe how to configure the TNF via labels/annotation and the corresponding settings in the config file. A sample config file can be found here . targetNameSpaces \u00b6 Multiple namespaces can be specified in the configuration file . Namespaces will be used by autodiscovery to find the Pods under test. ``` shell script targetNameSpaces: - name: firstnamespace - name: secondnamespace ## targetPodLabels The goal of this section is to specify the labels to be used to identify the CNF resources under test. It's highly recommended that the labels should be defined in pod definition rather than added after pod is created, as labels added later on will be lost in case the pod gets rescheduled. In case of pods defined as part of a deployment, it's best to use the same label as the one defined in the `spec.selector.matchLabels` section of the deployment yaml. The prefix field can be used to avoid naming collision with other labels. ```shell script targetPodLabels: - prefix: test-network-function.com name: generic value: target The corresponding label used to match pods is: ```shell script test-network-function.com/generic: target Once the pods are found, all of their containers are also added to the target container list. A target deployments list will also be created with all the deployments which the test pods belong to. ## targetCrds In order to autodiscover the CRDs to be tested, an array of search filters can be set under the \"targetCrdFilters\" label. The autodiscovery mechanism will iterate through all the filters to look for all the CRDs that match it. Currently, filters only work by name suffix. ```shell-script targetCrdFilters: - nameSuffix: \"group1.tnf.com\" - nameSuffix: \"anydomain.com\" The autodiscovery mechanism will create a list of all CRD names in the cluster whose names have the suffix \u201cgroup1.tnf.com\u201d or \u201canydomain.com\u201d, e.g. \u201ccrd1.group1.tnf.com\u201d or \u201cmycrd.mygroup.anydomain.com\u201d. testTarget \u00b6 podsUnderTest / containersUnderTest \u00b6 The autodiscovery mechanism will attempt to identify the default network device and all the IP addresses of the pods it needs for network connectivity tests, though that information can be explicitly set using annotations if needed. For Pod IPs: The annotation test-network-function.com/multusips is the highest priority, and must contain a JSON-encoded list of IP addresses to be tested for the pod. This must be explicitly set. If the above is not present, the k8s.v1.cni.cncf.io/networks-status annotation is checked and all IPs from it are used. This annotation is automatically managed in OpenShift but may not be present in K8s. If neither of the above is present, then only known IPs associated with the pod are used (the pod .status.ips field). For Network Interfaces: The annotation test-network-function.com/defaultnetworkinterface is the highest priority, and must contain a JSON-encoded string of the primary network interface for the pod. This must be explicitly set if needed. Examples can be seen in cnf-certification-test-partner If the above is not present, the k8s.v1.cni.cncf.io/networks-status annotation is checked and the \u201cinterface\u201d from the first entry found with \u201cdefault\u201d=true is used. This annotation is automatically managed in OpenShift but may not be present in K8s. The label test-network-function.com/skip_connectivity_tests excludes pods from all connectivity tests. The label value is not important, only its presence. The label test-network-function.com/skip_multus_connectivity_tests excludes pods from multus connectivity tests. Tests on default interface are still done. The label value is not important, only its presence. AffinityRequired \u00b6 For CNF workloads that require pods to use Pod or Node Affinity rules, the label AffinityRequired: true must be included on either the Deployment, StatefulSet, or Pod YAML. This will prevent any tests for anti-affinity to fail as well as test your workloads for affinity rules that support your CNF\u2019s use-case. certifiedcontainerinfo \u00b6 The certifiedcontainerinfo section contains information about CNFs containers that are to be checked for certification status on Red Hat catalogs.","title":"Test Configuration"},{"location":"configuration/#test-configuration-components","text":"The Test Network Function support autodiscovery using labels and annotations. The following sections describe how to configure the TNF via labels/annotation and the corresponding settings in the config file. A sample config file can be found here .","title":"Test configuration Components"},{"location":"configuration/#targetnamespaces","text":"Multiple namespaces can be specified in the configuration file . Namespaces will be used by autodiscovery to find the Pods under test. ``` shell script targetNameSpaces: - name: firstnamespace - name: secondnamespace ## targetPodLabels The goal of this section is to specify the labels to be used to identify the CNF resources under test. It's highly recommended that the labels should be defined in pod definition rather than added after pod is created, as labels added later on will be lost in case the pod gets rescheduled. In case of pods defined as part of a deployment, it's best to use the same label as the one defined in the `spec.selector.matchLabels` section of the deployment yaml. The prefix field can be used to avoid naming collision with other labels. ```shell script targetPodLabels: - prefix: test-network-function.com name: generic value: target The corresponding label used to match pods is: ```shell script test-network-function.com/generic: target Once the pods are found, all of their containers are also added to the target container list. A target deployments list will also be created with all the deployments which the test pods belong to. ## targetCrds In order to autodiscover the CRDs to be tested, an array of search filters can be set under the \"targetCrdFilters\" label. The autodiscovery mechanism will iterate through all the filters to look for all the CRDs that match it. Currently, filters only work by name suffix. ```shell-script targetCrdFilters: - nameSuffix: \"group1.tnf.com\" - nameSuffix: \"anydomain.com\" The autodiscovery mechanism will create a list of all CRD names in the cluster whose names have the suffix \u201cgroup1.tnf.com\u201d or \u201canydomain.com\u201d, e.g. \u201ccrd1.group1.tnf.com\u201d or \u201cmycrd.mygroup.anydomain.com\u201d.","title":"targetNameSpaces"},{"location":"configuration/#testtarget","text":"","title":"testTarget"},{"location":"configuration/#podsundertest-containersundertest","text":"The autodiscovery mechanism will attempt to identify the default network device and all the IP addresses of the pods it needs for network connectivity tests, though that information can be explicitly set using annotations if needed. For Pod IPs: The annotation test-network-function.com/multusips is the highest priority, and must contain a JSON-encoded list of IP addresses to be tested for the pod. This must be explicitly set. If the above is not present, the k8s.v1.cni.cncf.io/networks-status annotation is checked and all IPs from it are used. This annotation is automatically managed in OpenShift but may not be present in K8s. If neither of the above is present, then only known IPs associated with the pod are used (the pod .status.ips field). For Network Interfaces: The annotation test-network-function.com/defaultnetworkinterface is the highest priority, and must contain a JSON-encoded string of the primary network interface for the pod. This must be explicitly set if needed. Examples can be seen in cnf-certification-test-partner If the above is not present, the k8s.v1.cni.cncf.io/networks-status annotation is checked and the \u201cinterface\u201d from the first entry found with \u201cdefault\u201d=true is used. This annotation is automatically managed in OpenShift but may not be present in K8s. The label test-network-function.com/skip_connectivity_tests excludes pods from all connectivity tests. The label value is not important, only its presence. The label test-network-function.com/skip_multus_connectivity_tests excludes pods from multus connectivity tests. Tests on default interface are still done. The label value is not important, only its presence.","title":"podsUnderTest / containersUnderTest"},{"location":"configuration/#affinityrequired","text":"For CNF workloads that require pods to use Pod or Node Affinity rules, the label AffinityRequired: true must be included on either the Deployment, StatefulSet, or Pod YAML. This will prevent any tests for anti-affinity to fail as well as test your workloads for affinity rules that support your CNF\u2019s use-case.","title":"AffinityRequired"},{"location":"configuration/#certifiedcontainerinfo","text":"The certifiedcontainerinfo section contains information about CNFs containers that are to be checked for certification status on Red Hat catalogs.","title":"certifiedcontainerinfo"},{"location":"developers/","text":"Description \u00b6 Set Runtime Environment variables \u00b6 Specify the location of the partner repo \u00b6 For disconnected Environment \u00b6 Execute test suites \u00b6 CNF Developers \u00b6 Developers of CNFs, particularly those targeting CNF Certification with Red Hat on OpenShift , can use this suite to test the interaction of their CNF with OpenShift. If you are interested in CNF Certification please contact Red Hat . Refer to the rest of the documentation in this file to see how to install and run the tests as well as how to interpret the results. You will need an OpenShift 4.10 installation running your CNF, and at least one other machine available to host the test suite. The cnf-certification-test-partner repository has a very simple example of this you can model your setup on.","title":"Developers' Guide"},{"location":"developers/#description","text":"","title":"Description"},{"location":"developers/#set-runtime-environment-variables","text":"","title":"Set Runtime Environment variables"},{"location":"developers/#specify-the-location-of-the-partner-repo","text":"","title":"Specify the location of the partner repo"},{"location":"developers/#for-disconnected-environment","text":"","title":"For disconnected Environment"},{"location":"developers/#execute-test-suites","text":"","title":"Execute test suites"},{"location":"developers/#cnf-developers","text":"Developers of CNFs, particularly those targeting CNF Certification with Red Hat on OpenShift , can use this suite to test the interaction of their CNF with OpenShift. If you are interested in CNF Certification please contact Red Hat . Refer to the rest of the documentation in this file to see how to install and run the tests as well as how to interpret the results. You will need an OpenShift 4.10 installation running your CNF, and at least one other machine available to host the test suite. The cnf-certification-test-partner repository has a very simple example of this you can model your setup on.","title":"CNF Developers"},{"location":"exeception/","text":"Exception Process \u00b6 Please refer to the CATALOG and to the specific test you are attempting to gain an exception for if you are a partner organization.","title":"Exception Process"},{"location":"exeception/#exception-process","text":"Please refer to the CATALOG and to the specific test you are attempting to gain an exception for if you are a partner organization.","title":"Exception Process"},{"location":"reference/","text":"Contribution Guideline \u00b6","title":"Contribution Guideline"},{"location":"reference/#contribution-guideline","text":"","title":"Contribution Guideline"},{"location":"standalone/","text":"Build and Run the standalone test executable \u00b6 Currently, all available tests are part of the \u201cCNF Certification Test Suite\u201d test suite, which serves as the entrypoint to run all test specs. By default, cnf-certification-test emits results to cnf-certification-test/cnf-certification-tests_junit.xml . Dependencies \u00b6 At a minimum, the following dependencies must be installed prior to running make install-tools . Dependency Minimum Version GoLang 1.18 golangci-lint 1.49.0 jq 1.6 OpenShift Client 4.7 Other binary dependencies required to run tests can be installed using the following command: ```shell script make install-tools *Note*: You must also make sure that `$GOBIN` (default `$GOPATH/bin`) is on your `$PATH`. *Note*: Efforts to containerize this offering are considered a work in progress. ### Pulling The Code In order to pull the code, issue the following command: ```shell script mkdir ~/workspace cd ~/workspace git clone git@github.com:test-network-function/cnf-certification-test.git cd cnf-certification-test Building the Tests \u00b6 In order to build the test executable, first make sure you have satisfied the dependencies . ```shell script make build-cnf-tests *Gotcha:* The `make build*` commands run unit tests where appropriate. They do NOT test the CNF. ### Testing a CNF Once the executable is built, a CNF can be tested by specifying which suites to run using the `run-cnf-suites.sh` helper script. Run any combination of the suites keywords listed at in the [General tests](#general-tests) section, e.g. ```shell script ./run-cnf-suites.sh -l \"lifecycle\" ./run-cnf-suites.sh -l \"networking,lifecycle\" ./run-cnf-suites.sh -l \"operator,networking\" ./run-cnf-suites.sh -l \"networking,platform-alteration\" ./run-cnf-suites.sh -l \"networking,lifecycle,affiliated-certification,operator\" As with \u201crun-tnf-container.sh\u201d, if -l is not specified here, the tnf will run in \u2018diagnostic\u2019 mode. See Run the tests section for more info. By default the claim file will be output into the same location as the test executable. The -o argument for run-cnf-suites.sh can be used to provide a new location that the output files will be saved to. For more detailed control over the outputs, see the output of cnf-certification-test.test --help . ```shell script cd cnf-certification-test && ./cnf-certification-test.test \u2013help *Gotcha:* check that OCP cluster has resources to deploy [debug image](#check-cluster-resources) #### Running a single test or a subset All tests have unique labels, which can be used to filter which tests are to be run. This is useful when debugging a single test. You can select the test to be executed when running `run-cnf-suites.sh` with the following command-line: ```shell script ./run-cnf-suites.sh -l operator-install-source Note that the test labels work the same as the suite labels, so you can select more than one test with the filtering mechanism shown before. You can find all the labels attached to the tests by running the following command: ```shell script ./run-cnf-suites.sh \u2013list You can also check the [CATALOG.md](CATALOG.md) to find all test labels. #### Labels to run in offline environments Some tests do require connectivity to Redhat servers to validate certification status. If you're running the tests in an offline environment, you can skip the tests using the `l` option as explained in [Label use](#running-a-single-test-or-a-subset) ```shell script ./run-cnf-suites.sh -l '!online'","title":"Build and Run the standalone test executable"},{"location":"standalone/#build-and-run-the-standalone-test-executable","text":"Currently, all available tests are part of the \u201cCNF Certification Test Suite\u201d test suite, which serves as the entrypoint to run all test specs. By default, cnf-certification-test emits results to cnf-certification-test/cnf-certification-tests_junit.xml .","title":"Build and Run the standalone test executable"},{"location":"standalone/#dependencies","text":"At a minimum, the following dependencies must be installed prior to running make install-tools . Dependency Minimum Version GoLang 1.18 golangci-lint 1.49.0 jq 1.6 OpenShift Client 4.7 Other binary dependencies required to run tests can be installed using the following command: ```shell script make install-tools *Note*: You must also make sure that `$GOBIN` (default `$GOPATH/bin`) is on your `$PATH`. *Note*: Efforts to containerize this offering are considered a work in progress. ### Pulling The Code In order to pull the code, issue the following command: ```shell script mkdir ~/workspace cd ~/workspace git clone git@github.com:test-network-function/cnf-certification-test.git cd cnf-certification-test","title":"Dependencies"},{"location":"standalone/#building-the-tests","text":"In order to build the test executable, first make sure you have satisfied the dependencies . ```shell script make build-cnf-tests *Gotcha:* The `make build*` commands run unit tests where appropriate. They do NOT test the CNF. ### Testing a CNF Once the executable is built, a CNF can be tested by specifying which suites to run using the `run-cnf-suites.sh` helper script. Run any combination of the suites keywords listed at in the [General tests](#general-tests) section, e.g. ```shell script ./run-cnf-suites.sh -l \"lifecycle\" ./run-cnf-suites.sh -l \"networking,lifecycle\" ./run-cnf-suites.sh -l \"operator,networking\" ./run-cnf-suites.sh -l \"networking,platform-alteration\" ./run-cnf-suites.sh -l \"networking,lifecycle,affiliated-certification,operator\" As with \u201crun-tnf-container.sh\u201d, if -l is not specified here, the tnf will run in \u2018diagnostic\u2019 mode. See Run the tests section for more info. By default the claim file will be output into the same location as the test executable. The -o argument for run-cnf-suites.sh can be used to provide a new location that the output files will be saved to. For more detailed control over the outputs, see the output of cnf-certification-test.test --help . ```shell script cd cnf-certification-test && ./cnf-certification-test.test \u2013help *Gotcha:* check that OCP cluster has resources to deploy [debug image](#check-cluster-resources) #### Running a single test or a subset All tests have unique labels, which can be used to filter which tests are to be run. This is useful when debugging a single test. You can select the test to be executed when running `run-cnf-suites.sh` with the following command-line: ```shell script ./run-cnf-suites.sh -l operator-install-source Note that the test labels work the same as the suite labels, so you can select more than one test with the filtering mechanism shown before. You can find all the labels attached to the tests by running the following command: ```shell script ./run-cnf-suites.sh \u2013list You can also check the [CATALOG.md](CATALOG.md) to find all test labels. #### Labels to run in offline environments Some tests do require connectivity to Redhat servers to validate certification status. If you're running the tests in an offline environment, you can skip the tests using the `l` option as explained in [Label use](#running-a-single-test-or-a-subset) ```shell script ./run-cnf-suites.sh -l '!online'","title":"Building the Tests"},{"location":"test-spec/","text":"Test Specifications \u00b6 Available Test Specs \u00b6 There are two categories for CNF tests; \u2018General\u2019 and \u2018CNF-specific\u2019 (TODO). The \u2018General\u2019 tests are designed to test any commodity CNF running on OpenShift, and include specifications such as \u2018Default\u2019 network connectivity. \u2018CNF-specific\u2019 tests are designed to test some unique aspects of the CNF under test are behaving correctly. This could include specifications such as issuing a GET request to a web server, or passing traffic through an IPSEC tunnel. \u2018CNF-specific\u2019 test are yet to be defined. General tests \u00b6 Test in the \u201cgeneral\u201d category belong to multiple suites that can be run in any combination as is appropriate for the CNF(s) under test. Test suites group tests by topic area: Suite Test Spec Description Minimum OpenShift Version access-control The access-control test suite is used to test service account, namespace and cluster/pod role binding for the pods under test. It also tests the pods/containers configuration. 4.6.0 affiliated-certification The affiliated-certification test suite verifies that the containers and operators discovered or listed in the configuration file are certified by Redhat 4.6.0 lifecycle The lifecycle test suite verifies the pods deployment, creation, shutdown and survivability. 4.6.0 networking The networking test suite contains tests that check connectivity and networking config related best practices. 4.6.0 operator The operator test suite is designed to test basic Kubernetes Operator functionality. 4.6.0 platform-alteration verifies that key platform configuration is not modified by the CNF under test 4.6.0 observability the observability test suite contains tests that check CNF logging is following best practices and that CRDs have status fields 4.6.0 Please consult CATALOG.md for a detailed description of tests in each suite. CNF-specific tests \u00b6 TODO Claim File \u00b6 The test suite generates a \u201cclaim\u201d file, which describes the system(s) under test, the tests that were run, and the outcome of all of the tests. This claim file is the proof of the test run that is evaluated by Red Hat when \u201ccertified\u201d status is being considered. For more information about the contents of the claim file please see the schema . You can read more about the purpose of the claim file and CNF Certification in the Guide .","title":"Runtime environment variables"},{"location":"test-spec/#test-specifications","text":"","title":"Test Specifications"},{"location":"test-spec/#available-test-specs","text":"There are two categories for CNF tests; \u2018General\u2019 and \u2018CNF-specific\u2019 (TODO). The \u2018General\u2019 tests are designed to test any commodity CNF running on OpenShift, and include specifications such as \u2018Default\u2019 network connectivity. \u2018CNF-specific\u2019 tests are designed to test some unique aspects of the CNF under test are behaving correctly. This could include specifications such as issuing a GET request to a web server, or passing traffic through an IPSEC tunnel. \u2018CNF-specific\u2019 test are yet to be defined.","title":"Available Test Specs"},{"location":"test-spec/#general-tests","text":"Test in the \u201cgeneral\u201d category belong to multiple suites that can be run in any combination as is appropriate for the CNF(s) under test. Test suites group tests by topic area: Suite Test Spec Description Minimum OpenShift Version access-control The access-control test suite is used to test service account, namespace and cluster/pod role binding for the pods under test. It also tests the pods/containers configuration. 4.6.0 affiliated-certification The affiliated-certification test suite verifies that the containers and operators discovered or listed in the configuration file are certified by Redhat 4.6.0 lifecycle The lifecycle test suite verifies the pods deployment, creation, shutdown and survivability. 4.6.0 networking The networking test suite contains tests that check connectivity and networking config related best practices. 4.6.0 operator The operator test suite is designed to test basic Kubernetes Operator functionality. 4.6.0 platform-alteration verifies that key platform configuration is not modified by the CNF under test 4.6.0 observability the observability test suite contains tests that check CNF logging is following best practices and that CRDs have status fields 4.6.0 Please consult CATALOG.md for a detailed description of tests in each suite.","title":"General tests"},{"location":"test-spec/#cnf-specific-tests","text":"TODO","title":"CNF-specific tests"},{"location":"test-spec/#claim-file","text":"The test suite generates a \u201cclaim\u201d file, which describes the system(s) under test, the tests that were run, and the outcome of all of the tests. This claim file is the proof of the test run that is evaluated by Red Hat when \u201ccertified\u201d status is being considered. For more information about the contents of the claim file please see the schema . You can read more about the purpose of the claim file and CNF Certification in the Guide .","title":"Claim File"}]}